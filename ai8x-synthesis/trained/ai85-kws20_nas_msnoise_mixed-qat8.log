2024-06-05 23:03:22,564 - Log file for this run: /home/merveeyuboglu/Github/ai8x-training-merve/ai8x-training/logs/nas_original/2024.06.05-230322/2024.06.05-230322.log
2024-06-05 23:03:27,122 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2024-06-05 23:03:27,122 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False}
2024-06-05 23:23:16,221 - Reading compression schedule from: policies/schedule_kws20.yaml
2024-06-05 23:23:16,239 - Dataset sizes:
	training=311705
	validation=34633
	test=11005
2024-06-05 23:23:16,240 - 

2024-06-05 23:23:16,240 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:23:23,468 - Epoch: [0][  100/ 1218]    Overall Loss 2.966302    Objective Loss 2.966302                                        LR 0.001000    Time 0.072251    
2024-06-05 23:23:29,265 - Epoch: [0][  200/ 1218]    Overall Loss 2.747532    Objective Loss 2.747532                                        LR 0.001000    Time 0.065094    
2024-06-05 23:23:34,873 - Epoch: [0][  300/ 1218]    Overall Loss 2.539447    Objective Loss 2.539447                                        LR 0.001000    Time 0.062080    
2024-06-05 23:23:40,248 - Epoch: [0][  400/ 1218]    Overall Loss 2.369653    Objective Loss 2.369653                                        LR 0.001000    Time 0.059989    
2024-06-05 23:23:45,527 - Epoch: [0][  500/ 1218]    Overall Loss 2.225530    Objective Loss 2.225530                                        LR 0.001000    Time 0.058543    
2024-06-05 23:23:50,842 - Epoch: [0][  600/ 1218]    Overall Loss 2.106955    Objective Loss 2.106955                                        LR 0.001000    Time 0.057640    
2024-06-05 23:23:56,265 - Epoch: [0][  700/ 1218]    Overall Loss 2.006129    Objective Loss 2.006129                                        LR 0.001000    Time 0.057148    
2024-06-05 23:24:01,410 - Epoch: [0][  800/ 1218]    Overall Loss 1.923327    Objective Loss 1.923327                                        LR 0.001000    Time 0.056433    
2024-06-05 23:24:06,294 - Epoch: [0][  900/ 1218]    Overall Loss 1.852914    Objective Loss 1.852914                                        LR 0.001000    Time 0.055587    
2024-06-05 23:24:11,134 - Epoch: [0][ 1000/ 1218]    Overall Loss 1.790673    Objective Loss 1.790673                                        LR 0.001000    Time 0.054866    
2024-06-05 23:24:15,840 - Epoch: [0][ 1100/ 1218]    Overall Loss 1.734585    Objective Loss 1.734585                                        LR 0.001000    Time 0.054154    
2024-06-05 23:24:20,806 - Epoch: [0][ 1200/ 1218]    Overall Loss 1.685589    Objective Loss 1.685589                                        LR 0.001000    Time 0.053777    
2024-06-05 23:24:21,688 - Epoch: [0][ 1218/ 1218]    Overall Loss 1.677092    Objective Loss 1.677092    Top1 57.212714    Top5 89.731051    LR 0.001000    Time 0.053706    
2024-06-05 23:24:21,867 - --- validate (epoch=0)-----------
2024-06-05 23:24:21,867 - 34633 samples (256 per mini-batch)
2024-06-05 23:24:28,219 - Epoch: [0][  100/  136]    Loss 1.240410    Top1 50.953125    Top5 87.988281    
2024-06-05 23:24:30,145 - Epoch: [0][  136/  136]    Loss 1.238789    Top1 51.176623    Top5 87.887275    
2024-06-05 23:24:30,390 - ==> Top1: 51.177    Top5: 87.887    Loss: 1.239

2024-06-05 23:24:30,392 - ==> Confusion:
[[ 710    1    0    2    9    0    0    3   25  134    0    1    0    4   14    3    3    4    3    5   10]
 [  15  677    9    0   82   37    3   26   35    6    7    3    6   10   76    2   14    3   25   13   14]
 [  73    5  517   42   61   15   30   68    5   19   49    5    2   16   11    8    1    1    9   16   17]
 [  32    3   27  539   16   17    3   18   23   14   87    1    6    8  152    3    4   11   30    6   16]
 [  92   20    5    0  791   13    0    1    5   40    2    1    0   17   35   10    4    2    4    7    5]
 [  11  132    8   16   42  485    7   56   19   24   12   16   13   89   43   12    6    2   16   18   16]
 [  12   11  198   11   19   29  637   40    2    6   23    7    4    6    0   18    2    3    6   36   16]
 [  16   23   26    9   13   60    6  704   18   29   12   13    7    6   14    0    2    4   64   33   18]
 [  27    9    0    1    7    0    1    3  697  139    4    3    8   28   50    1    3    0    2   10    9]
 [ 214    1    1    0   18    1    0    3   71  621    2    0    0   26   27    0    3    1    2    3    7]
 [   5   34   22   23   37   16    3   32   78   10  648    2    3   14   50    1    2    0   62    8   14]
 [   6    7    0    3    3   46    2   20    6    4    0  606   83   74    5   39    4   41   10   36   16]
 [   7    2    3   12    0   19    4   12   28    2    0  144  509   36   27    6    8  116    8   37   15]
 [  15    2    2    2   26   68    3    7   44   90    3   10    3  659   26    5    5    4    1   16   10]
 [  45    8    1    4   35    4    0    3  116   36    2    0    4    7  803    1    3    3    9    5    9]
 [  41    3   15    2   26    7   16    0    1    6    1   78    6    9    3  770    0   46    1   18   17]
 [  53   22    4    4   61   13    2    1   13    4    3   19   15   27   16   38  724    1    0   12   40]
 [  35    2    4    3    5    3    1    2   20    2    0   80   88   12   13   26    3  680    2    7   17]
 [  14   32   13   31    7   13    1   55   65   11   32    3    8    3  105    0    0    2  630   15   18]
 [  11    9   15    1    4   38   30   57    5    5    4   66    9   47    2   11    8    2    8  735   21]
 [1397  395  206  187  705  349   83  354  532  484  179  381  278  640 1236  343  304  262  321  714 4582]]

2024-06-05 23:24:30,403 - ==> Best [Top1: 51.177   Top5: 87.887   Sparsity:0.00   Params: 424448 on epoch: 0]
2024-06-05 23:24:30,403 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:24:30,434 - 

2024-06-05 23:24:30,434 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:24:37,086 - Epoch: [1][  100/ 1218]    Overall Loss 1.127268    Objective Loss 1.127268                                        LR 0.001000    Time 0.066490    
2024-06-05 23:24:42,227 - Epoch: [1][  200/ 1218]    Overall Loss 1.102402    Objective Loss 1.102402                                        LR 0.001000    Time 0.058935    
2024-06-05 23:24:47,604 - Epoch: [1][  300/ 1218]    Overall Loss 1.084029    Objective Loss 1.084029                                        LR 0.001000    Time 0.057205    
2024-06-05 23:24:53,152 - Epoch: [1][  400/ 1218]    Overall Loss 1.073930    Objective Loss 1.073930                                        LR 0.001000    Time 0.056767    
2024-06-05 23:24:57,942 - Epoch: [1][  500/ 1218]    Overall Loss 1.061353    Objective Loss 1.061353                                        LR 0.001000    Time 0.054989    
2024-06-05 23:25:02,723 - Epoch: [1][  600/ 1218]    Overall Loss 1.049286    Objective Loss 1.049286                                        LR 0.001000    Time 0.053789    
2024-06-05 23:25:07,549 - Epoch: [1][  700/ 1218]    Overall Loss 1.040081    Objective Loss 1.040081                                        LR 0.001000    Time 0.052997    
2024-06-05 23:25:12,278 - Epoch: [1][  800/ 1218]    Overall Loss 1.033598    Objective Loss 1.033598                                        LR 0.001000    Time 0.052280    
2024-06-05 23:25:17,694 - Epoch: [1][  900/ 1218]    Overall Loss 1.023279    Objective Loss 1.023279                                        LR 0.001000    Time 0.052485    
2024-06-05 23:25:22,811 - Epoch: [1][ 1000/ 1218]    Overall Loss 1.013916    Objective Loss 1.013916                                        LR 0.001000    Time 0.052351    
2024-06-05 23:25:28,223 - Epoch: [1][ 1100/ 1218]    Overall Loss 1.006681    Objective Loss 1.006681                                        LR 0.001000    Time 0.052510    
2024-06-05 23:25:33,781 - Epoch: [1][ 1200/ 1218]    Overall Loss 1.000463    Objective Loss 1.000463                                        LR 0.001000    Time 0.052763    
2024-06-05 23:25:34,735 - Epoch: [1][ 1218/ 1218]    Overall Loss 0.999353    Objective Loss 0.999353    Top1 64.547677    Top5 94.621027    LR 0.001000    Time 0.052766    
2024-06-05 23:25:34,957 - --- validate (epoch=1)-----------
2024-06-05 23:25:34,957 - 34633 samples (256 per mini-batch)
2024-06-05 23:25:41,142 - Epoch: [1][  100/  136]    Loss 0.916905    Top1 59.468750    Top5 92.195312    
2024-06-05 23:25:43,100 - Epoch: [1][  136/  136]    Loss 0.915623    Top1 59.654087    Top5 92.091358    
2024-06-05 23:25:43,279 - ==> Top1: 59.654    Top5: 92.091    Loss: 0.916

2024-06-05 23:25:43,281 - ==> Confusion:
[[ 724    6    5    0   23    2    0    6   26   81    0    1    1    7   12    8    4    5    2    0   18]
 [   1  882    5    0   53   19    9    8   14    3   12    1    5    3    9    3   19    2    3    1   11]
 [  29    8  618   48   32    9   52   37    6    8   20    5    4   10    3   24   10    3   15    8   21]
 [   6   10   29  715   10   16    8    2    4    2   45    2   13    1   89    3   10   17   22    1   11]
 [  33   27    2    2  850   12    1    1    3   15    4    0    0   13   24   14   32    2    6    0   13]
 [  10  204    5   15   41  569    8   34   10    5   11   13   20   37   16    5   12    6    5    6   11]
 [   3   11   50   10   10    6  855   10    0    0   16    5    6    3    1   49    8    9    5   18   11]
 [   6   70   15   19    8   89   12  682    9    9   15    9    5    5    6    3    4    9   57   34   11]
 [  15   13    1    2    8    5    1    3  803   35   20    1   13   13   31    3    6    6   14    4    5]
 [ 177    5    1    0   22    4    0    5  137  561    8    5    1   26   22    1    6    8    2    2    8]
 [   6   32    6   18    5   17   12   11   35    4  822    4    9    6   20    2    5    2   33    4   11]
 [   3   12    1    0    6   36    1   14    5    0    2  704   61   37    2   29   13   33    6   36   10]
 [   0    9    2    6    2   11    1   13    3    0    3  195  613   10    3   15   18   68    3   12    8]
 [   8    6    0    3   16   39    1    6   50   32   11   16    6  722   17    6   18    9    0   18   17]
 [  24   16    2    7   28    1    1    1   83   17   11    1    9    4  851    3    8   12    5    0   14]
 [   3    2    0    0   19    4    3    1    1    0    1   58   13    7    0  854   44   38    1    4   13]
 [   7   28    5    2   16   11    3    1    5    1    3    8   10    4    1   18  913    4    4    7   21]
 [   3    4    0    2    5    4    0    5    4    2    1   87   61    4   13   26    9  757    3    5   10]
 [   3   53    8   27    9    5    1   40   25    0   16    2    8    0   56    0    9    4  778    3   11]
 [   2   18    5    3    2   20   39   35    7    1    4   39   11   18    0   15   13    4    9  828   15]
 [ 504  742  190  266  512  334  114  256  385  161  264  325  576  397  711  308  978  334  349  667 5559]]

2024-06-05 23:25:43,294 - ==> Best [Top1: 59.654   Top5: 92.091   Sparsity:0.00   Params: 424448 on epoch: 1]
2024-06-05 23:25:43,295 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:25:43,320 - 

2024-06-05 23:25:43,320 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:25:49,645 - Epoch: [2][  100/ 1218]    Overall Loss 0.884715    Objective Loss 0.884715                                        LR 0.001000    Time 0.063219    
2024-06-05 23:25:54,514 - Epoch: [2][  200/ 1218]    Overall Loss 0.878685    Objective Loss 0.878685                                        LR 0.001000    Time 0.055941    
2024-06-05 23:25:59,277 - Epoch: [2][  300/ 1218]    Overall Loss 0.878643    Objective Loss 0.878643                                        LR 0.001000    Time 0.053163    
2024-06-05 23:26:04,462 - Epoch: [2][  400/ 1218]    Overall Loss 0.875626    Objective Loss 0.875626                                        LR 0.001000    Time 0.052829    
2024-06-05 23:26:09,677 - Epoch: [2][  500/ 1218]    Overall Loss 0.875760    Objective Loss 0.875760                                        LR 0.001000    Time 0.052687    
2024-06-05 23:26:14,847 - Epoch: [2][  600/ 1218]    Overall Loss 0.873234    Objective Loss 0.873234                                        LR 0.001000    Time 0.052519    
2024-06-05 23:26:20,223 - Epoch: [2][  700/ 1218]    Overall Loss 0.867184    Objective Loss 0.867184                                        LR 0.001000    Time 0.052692    
2024-06-05 23:26:25,639 - Epoch: [2][  800/ 1218]    Overall Loss 0.860048    Objective Loss 0.860048                                        LR 0.001000    Time 0.052872    
2024-06-05 23:26:30,935 - Epoch: [2][  900/ 1218]    Overall Loss 0.855288    Objective Loss 0.855288                                        LR 0.001000    Time 0.052879    
2024-06-05 23:26:36,202 - Epoch: [2][ 1000/ 1218]    Overall Loss 0.851367    Objective Loss 0.851367                                        LR 0.001000    Time 0.052856    
2024-06-05 23:26:41,158 - Epoch: [2][ 1100/ 1218]    Overall Loss 0.848142    Objective Loss 0.848142                                        LR 0.001000    Time 0.052554    
2024-06-05 23:26:46,138 - Epoch: [2][ 1200/ 1218]    Overall Loss 0.842724    Objective Loss 0.842724                                        LR 0.001000    Time 0.052322    
2024-06-05 23:26:47,143 - Epoch: [2][ 1218/ 1218]    Overall Loss 0.842152    Objective Loss 0.842152    Top1 71.638142    Top5 94.865526    LR 0.001000    Time 0.052374    
2024-06-05 23:26:47,328 - --- validate (epoch=2)-----------
2024-06-05 23:26:47,329 - 34633 samples (256 per mini-batch)
2024-06-05 23:26:52,911 - Epoch: [2][  100/  136]    Loss 0.840213    Top1 62.078125    Top5 91.937500    
2024-06-05 23:26:54,578 - Epoch: [2][  136/  136]    Loss 0.845538    Top1 61.938036    Top5 91.762192    
2024-06-05 23:26:54,831 - ==> Top1: 61.938    Top5: 91.762    Loss: 0.846

2024-06-05 23:26:54,832 - ==> Confusion:
[[ 740    7   20    1   35    0    1    3    7   49    3    9    2    3   17    8    7    4    5    5    5]
 [   0  874    6    1   39   15    5    9    6    1    5   10    2    3   20    3   12    1   33   14    4]
 [  12    7  730   18   10    2   45   18    2    5   19   12    1   14    1   16    5    2   13   22   16]
 [   7    8   48  772    5    7    4    6    0    3   25    2   15    9   27   10   13    4   32    9   10]
 [  37   35   12    2  864    4    1    1    0    8    5    6    0    7   23   12   13    0    7    4   13]
 [   4  165    4    6   68  492    8   61    6    8    5   55    9   64    9   12   10    3   12   27   15]
 [   2   18   61    6    3    4  856   13    0    3    5   14    8    2    0   32    6    3    7   34    9]
 [   4   36   27    3    7   37    8  728    4    3   12   29    9    6    4    2    1    1  115   31   10]
 [  19   15    0    3    6    1    0    6  728   50   31    7    7   15   68    0    6    2   25    2   11]
 [ 191    6    5    0   29    2    1    3   79  594    4    5    2   20   33    1    1    4    5    7    9]
 [   4   11   23   36   10    3    6    4   16    2  826    6    1   20   24    2    2    0   56    9    3]
 [   2    8    0    0    3    5    3    8    6    1    1  826   46   19    3   30    3   20    5   16    6]
 [   2   14    2    2    2    6    5    1    3    0    1  203  650    7    2   21    8   42    7   12    5]
 [   6    5    2    2   24   10    1    5   30   28    9   27    3  784   21    7    8    3    3   17    6]
 [  19   25    3   37   25    2    0    2   34    9    3    3   12    7  861    2    4    5   37    2    6]
 [   4    3    4    1   12    1   10    1    0    0    0   63    7    6    1  912   12    7    0   11   11]
 [   3   23   12    1   17    6    1    2    4    1    4   25   22    9    4   22  874    4    4   17   17]
 [   9    3    0    4    2    2    2    1    8    8    0  104   89    6    3   68    4  665   10    8    9]
 [   5   28    9   21    5    2    3   30   10    0    6   10   13    1   35    0    1    0  863    7    9]
 [   0   13    1    1    1    4   16   19    0    0    2   72   14   15    1   10    2    0    7  899   11]
 [ 423  754  308  197  506  148  133  230  218  139  213  615  477  540  521  530  631  123  579  734 5913]]

2024-06-05 23:26:54,838 - ==> Best [Top1: 61.938   Top5: 91.762   Sparsity:0.00   Params: 424448 on epoch: 2]
2024-06-05 23:26:54,839 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:26:54,873 - 

2024-06-05 23:26:54,874 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:27:01,344 - Epoch: [3][  100/ 1218]    Overall Loss 0.778942    Objective Loss 0.778942                                        LR 0.001000    Time 0.064677    
2024-06-05 23:27:06,500 - Epoch: [3][  200/ 1218]    Overall Loss 0.777176    Objective Loss 0.777176                                        LR 0.001000    Time 0.058106    
2024-06-05 23:27:11,361 - Epoch: [3][  300/ 1218]    Overall Loss 0.771141    Objective Loss 0.771141                                        LR 0.001000    Time 0.054933    
2024-06-05 23:27:16,195 - Epoch: [3][  400/ 1218]    Overall Loss 0.766753    Objective Loss 0.766753                                        LR 0.001000    Time 0.053278    
2024-06-05 23:27:20,976 - Epoch: [3][  500/ 1218]    Overall Loss 0.762727    Objective Loss 0.762727                                        LR 0.001000    Time 0.052181    
2024-06-05 23:27:26,570 - Epoch: [3][  600/ 1218]    Overall Loss 0.761456    Objective Loss 0.761456                                        LR 0.001000    Time 0.052802    
2024-06-05 23:27:31,574 - Epoch: [3][  700/ 1218]    Overall Loss 0.757916    Objective Loss 0.757916                                        LR 0.001000    Time 0.052403    
2024-06-05 23:27:36,226 - Epoch: [3][  800/ 1218]    Overall Loss 0.758123    Objective Loss 0.758123                                        LR 0.001000    Time 0.051666    
2024-06-05 23:27:41,197 - Epoch: [3][  900/ 1218]    Overall Loss 0.754609    Objective Loss 0.754609                                        LR 0.001000    Time 0.051445    
2024-06-05 23:27:46,381 - Epoch: [3][ 1000/ 1218]    Overall Loss 0.754461    Objective Loss 0.754461                                        LR 0.001000    Time 0.051482    
2024-06-05 23:27:51,105 - Epoch: [3][ 1100/ 1218]    Overall Loss 0.751416    Objective Loss 0.751416                                        LR 0.001000    Time 0.051094    
2024-06-05 23:27:55,979 - Epoch: [3][ 1200/ 1218]    Overall Loss 0.748747    Objective Loss 0.748747                                        LR 0.001000    Time 0.050897    
2024-06-05 23:27:56,842 - Epoch: [3][ 1218/ 1218]    Overall Loss 0.748594    Objective Loss 0.748594    Top1 70.171149    Top5 90.464548    LR 0.001000    Time 0.050852    
2024-06-05 23:27:57,049 - --- validate (epoch=3)-----------
2024-06-05 23:27:57,050 - 34633 samples (256 per mini-batch)
2024-06-05 23:28:03,426 - Epoch: [3][  100/  136]    Loss 0.791711    Top1 64.023438    Top5 93.078125    
2024-06-05 23:28:05,197 - Epoch: [3][  136/  136]    Loss 0.794687    Top1 63.999654    Top5 93.012445    
2024-06-05 23:28:05,386 - ==> Top1: 64.000    Top5: 93.012    Loss: 0.795

2024-06-05 23:28:05,387 - ==> Confusion:
[[ 638    0   27    5   83   14    2    5    2   80    5    5    4    3   13   14    4    3    6    4   14]
 [   3  823    6    3   47   36   10   11    3    1   10   11    4    1    3    4   12    2   32   36    5]
 [  10    1  720   29   11    3   92    6    0    1    9    5    3    4    1   11    4    0   20   39    1]
 [   0    2   23  821   10   25   10    0    2    0   24    4   20    1   16    7    4    5   35    5    2]
 [  16   21    7    4  906   26    2    1    0    2    5    7    4    3    5   14    9    1    8    7    6]
 [   5   83    2    8   20  748   14   20    0    1    6   43    4   11    4    5   11    1   12   40    5]
 [   5    2   21    3    1    2  968    7    0    0    5    2    2    1    4    9    1    1    8   37    7]
 [   2   20   42   10    5   79   34  622    2    0   13   23    9    1    4    0    1    1  102  104    3]
 [  21   10    0    2    5    6    1    2  619   69   65    9    9   47   74    1    7    4   39    7    5]
 [  96    0   15    1   70   15    3    3   25  633    8    8    2   56   34    5    5    2    8    4    8]
 [   1   10   23   27    4   12   11    2    8    0  871    4    2   15   11    5    4    0   35   15    4]
 [   3    1    4    0    0   11    3    2    1    0    0  897   19    5    1   10    1    4    4   41    4]
 [   1    1    1    6    2    6    2    1    2    0    2  231  659    1    2   11    4   24   14   17    8]
 [   2    1    5    2   11   70    1    2    2    7   17   67    3  732    9    6    7    3    3   42    9]
 [  11   12    4   54   45    7    1    0   12   12   20    2    8   13  815    0    3    4   62    2   11]
 [   2    1    3    0    5    1   13    0    0    1    0   68   12    1    6  897   16   18    3   12    7]
 [   8   22    6    0   19   13    5    2    1    0    1   25    8    1    1   14  899    2    5   22   18]
 [   1    2    2    4    2    5    5    0    1    0    0  121   47    0    3   39    2  740    8   14    9]
 [   2   13   12   35    6   14    2   11    0    0   11    5    8    0   18    0    1    0  902    8   10]
 [   4    3    2    0    0    6   17    4    0    1    0   51    5    5    3    7    1    2    9  960    8]
 [ 307  385  386  284  540  482  259  164   89   96  436  560  454  410  344  256  500   92  585 1008 6295]]

2024-06-05 23:28:05,401 - ==> Best [Top1: 64.000   Top5: 93.012   Sparsity:0.00   Params: 424448 on epoch: 3]
2024-06-05 23:28:05,401 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:28:05,432 - 

2024-06-05 23:28:05,433 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:28:11,856 - Epoch: [4][  100/ 1218]    Overall Loss 0.699896    Objective Loss 0.699896                                        LR 0.001000    Time 0.064203    
2024-06-05 23:28:16,736 - Epoch: [4][  200/ 1218]    Overall Loss 0.709094    Objective Loss 0.709094                                        LR 0.001000    Time 0.056487    
2024-06-05 23:28:21,790 - Epoch: [4][  300/ 1218]    Overall Loss 0.703443    Objective Loss 0.703443                                        LR 0.001000    Time 0.054498    
2024-06-05 23:28:26,866 - Epoch: [4][  400/ 1218]    Overall Loss 0.705126    Objective Loss 0.705126                                        LR 0.001000    Time 0.053557    
2024-06-05 23:28:31,816 - Epoch: [4][  500/ 1218]    Overall Loss 0.704597    Objective Loss 0.704597                                        LR 0.001000    Time 0.052741    
2024-06-05 23:28:36,715 - Epoch: [4][  600/ 1218]    Overall Loss 0.703121    Objective Loss 0.703121                                        LR 0.001000    Time 0.052110    
2024-06-05 23:28:41,768 - Epoch: [4][  700/ 1218]    Overall Loss 0.701851    Objective Loss 0.701851                                        LR 0.001000    Time 0.051880    
2024-06-05 23:28:46,793 - Epoch: [4][  800/ 1218]    Overall Loss 0.699900    Objective Loss 0.699900                                        LR 0.001000    Time 0.051674    
2024-06-05 23:28:52,123 - Epoch: [4][  900/ 1218]    Overall Loss 0.697316    Objective Loss 0.697316                                        LR 0.001000    Time 0.051852    
2024-06-05 23:28:57,039 - Epoch: [4][ 1000/ 1218]    Overall Loss 0.694046    Objective Loss 0.694046                                        LR 0.001000    Time 0.051580    
2024-06-05 23:29:02,146 - Epoch: [4][ 1100/ 1218]    Overall Loss 0.693808    Objective Loss 0.693808                                        LR 0.001000    Time 0.051532    
2024-06-05 23:29:06,882 - Epoch: [4][ 1200/ 1218]    Overall Loss 0.692261    Objective Loss 0.692261                                        LR 0.001000    Time 0.051182    
2024-06-05 23:29:07,779 - Epoch: [4][ 1218/ 1218]    Overall Loss 0.692307    Objective Loss 0.692307    Top1 69.193154    Top5 95.110024    LR 0.001000    Time 0.051162    
2024-06-05 23:29:08,051 - --- validate (epoch=4)-----------
2024-06-05 23:29:08,051 - 34633 samples (256 per mini-batch)
2024-06-05 23:29:13,744 - Epoch: [4][  100/  136]    Loss 0.712404    Top1 72.800781    Top5 95.925781    
2024-06-05 23:29:15,488 - Epoch: [4][  136/  136]    Loss 0.721681    Top1 72.748535    Top5 95.833454    
2024-06-05 23:29:15,668 - ==> Top1: 72.749    Top5: 95.833    Loss: 0.722

2024-06-05 23:29:15,669 - ==> Confusion:
[[ 697    4    8    1   41    2    0    4   15  105    1    2    0    4    6   11    0    1    4    4   21]
 [   7  887    2    0   24   22    8   20    6    0    7    4    2    1    4    2    4    1   20   15   27]
 [  19    8  686    1   11    2   70   29    1    9   12    1    2    5    3   12    5    2   26   12   54]
 [  12    8   34  741    5    9    9    4    4    5   39    1    5    4   30    9    4    9   44    1   39]
 [  26   37    6    0  881    7    4    2    5    7    5    1    0    2   10   14    4    1    8    4   30]
 [   9   95    1    8   21  655   22   67    3   12    5   34    7   14    3    9    5    7   16   15   35]
 [   6   13   24    2    7    4  945   10    1    0    8    2    1    0    0   10    0    2    7   22   22]
 [  10   36    7    3    3   40    9  823    4    3    8    8    5    1    0    1    0    4   54   26   32]
 [  22   18    1    2    1    1    0    1  813   26   28    3    6    8   22    0    3    3   23    5   16]
 [ 105    4    6    0   19    0    1    4  125  689    3    2    0    8   11    4    0    1    3    0   16]
 [   3   16    8    6    5    2   11    8   23    2  910    1    1    3    7    1    2    0   28    5   22]
 [   8    0    3    0    3   20   10   11    0    3    0  787   31    6    0   44    4   27    5   25   24]
 [   9    4    0    6    0    7    5    4    5    1    6  127  669    4    3   24    1   63   21    9   27]
 [   5    4    2    0   14   26    4    9   61   44   19   29    2  684   14    7    0   10    3   12   52]
 [  21   15    2   13   30    1    0    1   40    7   13    2    6    3  866    1    3    5   43    2   24]
 [   9    4    1    1    3    0   16    0    0    1    0   19    5    2    0  953   15    8    2    6   21]
 [   8   22    1    1   22    8    3    2    5    2    2   12   13    2    2   21  865    1    6   11   63]
 [   5    5    1    3    0    0    3    3    4    3    0   27   42    2    5   46    1  832    3    5   15]
 [   6   21    6   19    3    1    2   34   10    4   11    0    2    0   15    1    0    2  880    5   36]
 [   5    6    4    0    2    6   23   35    3    1    0   25    7    7    1   12    6    2    8  891   44]
 [ 356  497  149   63  297  159  158  219  248  152  188  254  354  196  287  253  225  175  353  308 9041]]

2024-06-05 23:29:15,674 - ==> Best [Top1: 72.749   Top5: 95.833   Sparsity:0.00   Params: 424448 on epoch: 4]
2024-06-05 23:29:15,674 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:29:15,703 - 

2024-06-05 23:29:15,703 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:29:22,204 - Epoch: [5][  100/ 1218]    Overall Loss 0.657276    Objective Loss 0.657276                                        LR 0.001000    Time 0.064975    
2024-06-05 23:29:27,096 - Epoch: [5][  200/ 1218]    Overall Loss 0.657223    Objective Loss 0.657223                                        LR 0.001000    Time 0.056936    
2024-06-05 23:29:32,190 - Epoch: [5][  300/ 1218]    Overall Loss 0.658658    Objective Loss 0.658658                                        LR 0.001000    Time 0.054930    
2024-06-05 23:29:37,507 - Epoch: [5][  400/ 1218]    Overall Loss 0.657839    Objective Loss 0.657839                                        LR 0.001000    Time 0.054484    
2024-06-05 23:29:42,495 - Epoch: [5][  500/ 1218]    Overall Loss 0.654488    Objective Loss 0.654488                                        LR 0.001000    Time 0.053558    
2024-06-05 23:29:47,340 - Epoch: [5][  600/ 1218]    Overall Loss 0.653778    Objective Loss 0.653778                                        LR 0.001000    Time 0.052704    
2024-06-05 23:29:52,104 - Epoch: [5][  700/ 1218]    Overall Loss 0.652905    Objective Loss 0.652905                                        LR 0.001000    Time 0.051977    
2024-06-05 23:29:57,201 - Epoch: [5][  800/ 1218]    Overall Loss 0.653087    Objective Loss 0.653087                                        LR 0.001000    Time 0.051848    
2024-06-05 23:30:02,386 - Epoch: [5][  900/ 1218]    Overall Loss 0.651721    Objective Loss 0.651721                                        LR 0.001000    Time 0.051846    
2024-06-05 23:30:07,439 - Epoch: [5][ 1000/ 1218]    Overall Loss 0.650592    Objective Loss 0.650592                                        LR 0.001000    Time 0.051712    
2024-06-05 23:30:12,542 - Epoch: [5][ 1100/ 1218]    Overall Loss 0.648683    Objective Loss 0.648683                                        LR 0.001000    Time 0.051647    
2024-06-05 23:30:17,480 - Epoch: [5][ 1200/ 1218]    Overall Loss 0.648190    Objective Loss 0.648190                                        LR 0.001000    Time 0.051456    
2024-06-05 23:30:18,308 - Epoch: [5][ 1218/ 1218]    Overall Loss 0.648438    Objective Loss 0.648438    Top1 71.638142    Top5 95.110024    LR 0.001000    Time 0.051376    
2024-06-05 23:30:18,478 - --- validate (epoch=5)-----------
2024-06-05 23:30:18,478 - 34633 samples (256 per mini-batch)
2024-06-05 23:30:24,126 - Epoch: [5][  100/  136]    Loss 0.652225    Top1 70.914063    Top5 94.863281    
2024-06-05 23:30:25,909 - Epoch: [5][  136/  136]    Loss 0.652160    Top1 71.065169    Top5 94.889267    
2024-06-05 23:30:26,075 - ==> Top1: 71.065    Top5: 94.889    Loss: 0.652

2024-06-05 23:30:26,076 - ==> Confusion:
[[ 740    1    9    2   13    4    1    4   30   81    1    3    1    6    6    4    3    4    2    2   14]
 [   5  872    5    3    9   70    6   16    7    2    6    6    4    1    5    2    9    1   15    9   10]
 [  22    4  759   41    5   10   23   30    2    4    7    4    3    7    1    6    6    2   17    3   14]
 [   7    4   14  857    1   19    2    7    7    6   15    2    8    1   27    4    3    9    8    6    9]
 [  40   40    4    3  813   60    1    5    6   24    4    7    1    7   10    6    5    1    4    4    9]
 [   9   31    5    6    3  856    2   46    5    5    0   12    1   23    2    1    7    2    4   14    9]
 [   6    6   61    6    2   21  890   17    1    2    4    7    3    1    0    8    2    3    6   21   19]
 [   6   16    8    8    3   66    1  847    5    4    6   11    3    0    2    1    2    4   52   23    9]
 [  14   17    0    1    1    3    0    3  840   45    5    2   11   11   16    2    5    3   14    2    7]
 [ 103    7    0    0    6    7    0    5   97  735    0    1    3   16    6    1    0    3    2    1    8]
 [   0    6    7   32    6   12    1    9   32    2  880    2    2   17   11    2    4    1   29    3    6]
 [   4    3    1    0    0   62    3    7    2    3    1  799   34   11    1   17    1   18    6   29    9]
 [   8    3    0   11    2   20    1    1    5    0    4   94  750   10    1   10   11   32   11    8   13]
 [   5    0    1    1    5   37    1   10   33   28    7   10    8  813    5    6   12    1    5    4    9]
 [  15   18    0   24   13    9    0    2   72   26    4    4    4    8  846    0    7    6   15    0   25]
 [  11    0    2    4    6    6    6    0    1    2    0   39   10    4    0  922   15   19    0    6   13]
 [  10   11    8    3    6   23    1    0    7    3    0    9    4    3    1   14  939    2    1   14   13]
 [   5    1    1    4    2    8    0    1    9    4    0   52   57    7    2   15    3  815    2    9    8]
 [   2   18    8   38    4   13    2   40   16    2   11    2    1    1   18    0    3    1  864    4   10]
 [   2    6    6    0    0   16   16   23    1    0    1   30    8    6    3    5    7    5    5  936   12]
 [ 321  439  296  230  230  579   93  291  252  168  176  321  452  387  237  221  454  156  332  458 7839]]

2024-06-05 23:30:26,082 - ==> Best [Top1: 72.749   Top5: 95.833   Sparsity:0.00   Params: 424448 on epoch: 4]
2024-06-05 23:30:26,082 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:30:26,108 - 

2024-06-05 23:30:26,108 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:30:32,781 - Epoch: [6][  100/ 1218]    Overall Loss 0.616095    Objective Loss 0.616095                                        LR 0.001000    Time 0.066692    
2024-06-05 23:30:37,619 - Epoch: [6][  200/ 1218]    Overall Loss 0.616748    Objective Loss 0.616748                                        LR 0.001000    Time 0.057525    
2024-06-05 23:30:42,560 - Epoch: [6][  300/ 1218]    Overall Loss 0.618996    Objective Loss 0.618996                                        LR 0.001000    Time 0.054807    
2024-06-05 23:30:47,550 - Epoch: [6][  400/ 1218]    Overall Loss 0.620323    Objective Loss 0.620323                                        LR 0.001000    Time 0.053576    
2024-06-05 23:30:52,298 - Epoch: [6][  500/ 1218]    Overall Loss 0.620967    Objective Loss 0.620967                                        LR 0.001000    Time 0.052352    
2024-06-05 23:30:57,057 - Epoch: [6][  600/ 1218]    Overall Loss 0.621107    Objective Loss 0.621107                                        LR 0.001000    Time 0.051554    
2024-06-05 23:31:02,180 - Epoch: [6][  700/ 1218]    Overall Loss 0.622038    Objective Loss 0.622038                                        LR 0.001000    Time 0.051504    
2024-06-05 23:31:07,059 - Epoch: [6][  800/ 1218]    Overall Loss 0.621633    Objective Loss 0.621633                                        LR 0.001000    Time 0.051162    
2024-06-05 23:31:12,199 - Epoch: [6][  900/ 1218]    Overall Loss 0.622291    Objective Loss 0.622291                                        LR 0.001000    Time 0.051187    
2024-06-05 23:31:17,009 - Epoch: [6][ 1000/ 1218]    Overall Loss 0.620612    Objective Loss 0.620612                                        LR 0.001000    Time 0.050875    
2024-06-05 23:31:21,816 - Epoch: [6][ 1100/ 1218]    Overall Loss 0.619161    Objective Loss 0.619161                                        LR 0.001000    Time 0.050618    
2024-06-05 23:31:26,698 - Epoch: [6][ 1200/ 1218]    Overall Loss 0.619473    Objective Loss 0.619473                                        LR 0.001000    Time 0.050467    
2024-06-05 23:31:27,573 - Epoch: [6][ 1218/ 1218]    Overall Loss 0.618983    Objective Loss 0.618983    Top1 73.838631    Top5 95.354523    LR 0.001000    Time 0.050439    
2024-06-05 23:31:27,761 - --- validate (epoch=6)-----------
2024-06-05 23:31:27,761 - 34633 samples (256 per mini-batch)
2024-06-05 23:31:33,527 - Epoch: [6][  100/  136]    Loss 0.641885    Top1 73.066406    Top5 95.187500    
2024-06-05 23:31:35,294 - Epoch: [6][  136/  136]    Loss 0.634936    Top1 73.138336    Top5 95.279069    
2024-06-05 23:31:35,492 - ==> Top1: 73.138    Top5: 95.279    Loss: 0.635

2024-06-05 23:31:35,493 - ==> Confusion:
[[ 648    1    2    2   15    2    0    5   11  178    4    2    3    9   11    3    1    2    3    3   26]
 [   1  856    3    0   25   46    8   26    8    9   17    5    0    4    8    1    3    5   15   10   13]
 [   5    3  696   21   11    8   58   58    0   10   17    6    4   16    5    8    5    3   10   12   14]
 [   2    4   16  846    4    9    7    6    1    5   31    2    2   13   23    1    3    7   16    4   14]
 [  21   19    2    1  876   17    2    8    5   31    3    1    3   16   10    5    6    1    1    6   20]
 [   6   35    2    6   19  759    6   69    3    3    8   11    6   58    5    0    4    2    6   13   22]
 [   4    9   11    3    2   10  942   16    0    2    9    4    3    7    0   11    0    9    3   34    7]
 [   4   12    5    0    1   32    5  917    1    3    7    8    7    9    1    0    0    1   22   33    9]
 [  10    6    0    0    2    2    0    1  805   43   18    0    4   45   27    0    3    3   16    5   12]
 [  43    1    0    0    4    7    0    5   81  771    3    2    8   45    9    1    0    0    4    2   15]
 [   1    4    5   14    3    5   10   14   14    1  909    1    3   44    5    0    2    0   14    4   11]
 [   1    6    1    1    3   38    1   13    2    2    0  749   36   25    2   19    2   63    1   36   10]
 [   0    0    0   25    0   18    2    6    2    1    2   73  686   15    7    8    3  108    5   26    8]
 [   4    1    0    2    3   17    0    7   15   17    2    4    2  880    3    4    3    9    0   11   17]
 [   7    3    1   23   10    0    0    6   32   17   12    0    4   37  889    1    1    6   22    4   23]
 [   1    3    2    2    4    2    7    1    1    4    0   18    7   13    0  924   11   46    2   11    7]
 [   8   13    5    3   18   17    0    4   10    3    2    9    7   14    4   13  885    6    5   21   25]
 [   1    2    1    6    0    5    1    3    5    3    1   13   15    9    5    2    2  912    2   10    7]
 [   0    4    5   30    2    7    0   68    6    4   11    3    4    2   13    0    1    2  863   11   22]
 [   2    7    0    0    0   10   12   23    1    1    1   12    9   14    1    6    8    1    2  965   13]
 [ 209  224  187  208  260  259  106  359  136  181  263  166  384  672  271  155  263  267  241  569 8552]]

2024-06-05 23:31:35,498 - ==> Best [Top1: 73.138   Top5: 95.279   Sparsity:0.00   Params: 424448 on epoch: 6]
2024-06-05 23:31:35,498 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:31:35,537 - 

2024-06-05 23:31:35,537 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:31:41,745 - Epoch: [7][  100/ 1218]    Overall Loss 0.602074    Objective Loss 0.602074                                        LR 0.001000    Time 0.062047    
2024-06-05 23:31:46,572 - Epoch: [7][  200/ 1218]    Overall Loss 0.598059    Objective Loss 0.598059                                        LR 0.001000    Time 0.055142    
2024-06-05 23:31:51,951 - Epoch: [7][  300/ 1218]    Overall Loss 0.600299    Objective Loss 0.600299                                        LR 0.001000    Time 0.054686    
2024-06-05 23:31:56,910 - Epoch: [7][  400/ 1218]    Overall Loss 0.599044    Objective Loss 0.599044                                        LR 0.001000    Time 0.053405    
2024-06-05 23:32:01,941 - Epoch: [7][  500/ 1218]    Overall Loss 0.599382    Objective Loss 0.599382                                        LR 0.001000    Time 0.052781    
2024-06-05 23:32:07,134 - Epoch: [7][  600/ 1218]    Overall Loss 0.597466    Objective Loss 0.597466                                        LR 0.001000    Time 0.052635    
2024-06-05 23:32:12,056 - Epoch: [7][  700/ 1218]    Overall Loss 0.595774    Objective Loss 0.595774                                        LR 0.001000    Time 0.052143    
2024-06-05 23:32:17,000 - Epoch: [7][  800/ 1218]    Overall Loss 0.594684    Objective Loss 0.594684                                        LR 0.001000    Time 0.051802    
2024-06-05 23:32:22,084 - Epoch: [7][  900/ 1218]    Overall Loss 0.593717    Objective Loss 0.593717                                        LR 0.001000    Time 0.051686    
2024-06-05 23:32:27,076 - Epoch: [7][ 1000/ 1218]    Overall Loss 0.592680    Objective Loss 0.592680                                        LR 0.001000    Time 0.051500    
2024-06-05 23:32:32,156 - Epoch: [7][ 1100/ 1218]    Overall Loss 0.593029    Objective Loss 0.593029                                        LR 0.001000    Time 0.051435    
2024-06-05 23:32:37,145 - Epoch: [7][ 1200/ 1218]    Overall Loss 0.592670    Objective Loss 0.592670                                        LR 0.001000    Time 0.051304    
2024-06-05 23:32:38,171 - Epoch: [7][ 1218/ 1218]    Overall Loss 0.592929    Objective Loss 0.592929    Top1 74.572127    Top5 93.154034    LR 0.001000    Time 0.051388    
2024-06-05 23:32:38,350 - --- validate (epoch=7)-----------
2024-06-05 23:32:38,350 - 34633 samples (256 per mini-batch)
2024-06-05 23:32:43,912 - Epoch: [7][  100/  136]    Loss 0.621056    Top1 73.742188    Top5 95.125000    
2024-06-05 23:32:45,671 - Epoch: [7][  136/  136]    Loss 0.618023    Top1 73.759131    Top5 95.215546    
2024-06-05 23:32:45,873 - ==> Top1: 73.759    Top5: 95.216    Loss: 0.618

2024-06-05 23:32:45,875 - ==> Confusion:
[[ 779    1   16    3   17    1    0    0   10   74    3    0    1    1    6    2    5    0    1    0   11]
 [   7  884   10    2   28   18    3   14    5    3   17    4    1    2    9    2   11    2   16   10   15]
 [  16    5  850   15    2    0   10    9    2    5   14    3    1    4    4    2    8    0    7    5    8]
 [  13    2   34  872    3    3    2    2    0    3   24    1    2    3   26    2    2    4    7    2    9]
 [  36   13    7    3  905    3    1    4    3   13    7    0    0    7   23    6    5    1    3    0   14]
 [  10   81   11   13   29  688    2   62    3    8    9    8    3   39    8    5   12    3    7   17   25]
 [   7    6  110    6    2    6  859   18    1    1   13    2    1    0    0   14    9    4    6   13    8]
 [  14   21   34    7    6   28    5  855    1    4    8    3    4    2    5    1    4    2   55   12    6]
 [  24    5    1    8    0    0    1    2  748   69   43    2    6   29   39    2    4    0   10    1    8]
 [ 107    2    3    2    7    1    0    1   59  768    8    0    0   24    5    1    2    2    1    1    7]
 [   1    7   12   20    3    3    1    7   11    3  946    0    0    5   11    1    2    1   21    1    8]
 [  13    1    7    0    6   13    3   19    4    0    2  797   24   19    4   22   14   21    7   19   16]
 [  10    2    9   40    1    5    0    8    2    0    6  122  657    5    6   14    9   57   16    9   17]
 [  13    2    5    4    4    7    1   11   13   16   22   12    4  837   12    4    3    1    2   15   13]
 [  14    3    5   42   13    0    0    0   19   16    8    0    1    6  927    0    4    2   27    0   11]
 [  14    1   15    4    8    0    4    2    0    2    1   15    6    4    2  922   31   13    2    6   14]
 [  11   11    6    3   14    8    0    3    4    0    5    5    3    4    4   15  942    3    4    8   19]
 [   7    0   10   14    0    1    0    3    5    0    1   32   16    5    6   24    1  863    3    4   10]
 [   9    8   15   47    3    1    1   21    5    1   17    2    1    1   21    0    2    0  892    0   11]
 [  11    6   21    3    2    3   12   32    2    0    2   11    2    9    1    4   10    4    8  934   11]
 [ 434  223  528  324  326   89   67  240  121  139  338  206  281  318  429  135  411  123  295  285 8620]]

2024-06-05 23:32:45,879 - ==> Best [Top1: 73.759   Top5: 95.216   Sparsity:0.00   Params: 424448 on epoch: 7]
2024-06-05 23:32:45,879 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:32:45,911 - 

2024-06-05 23:32:45,912 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:32:52,337 - Epoch: [8][  100/ 1218]    Overall Loss 0.576962    Objective Loss 0.576962                                        LR 0.001000    Time 0.064225    
2024-06-05 23:32:57,323 - Epoch: [8][  200/ 1218]    Overall Loss 0.578521    Objective Loss 0.578521                                        LR 0.001000    Time 0.057029    
2024-06-05 23:33:02,085 - Epoch: [8][  300/ 1218]    Overall Loss 0.580357    Objective Loss 0.580357                                        LR 0.001000    Time 0.053887    
2024-06-05 23:33:07,228 - Epoch: [8][  400/ 1218]    Overall Loss 0.580817    Objective Loss 0.580817                                        LR 0.001000    Time 0.053266    
2024-06-05 23:33:12,108 - Epoch: [8][  500/ 1218]    Overall Loss 0.583101    Objective Loss 0.583101                                        LR 0.001000    Time 0.052369    
2024-06-05 23:33:17,133 - Epoch: [8][  600/ 1218]    Overall Loss 0.582401    Objective Loss 0.582401                                        LR 0.001000    Time 0.052012    
2024-06-05 23:33:21,991 - Epoch: [8][  700/ 1218]    Overall Loss 0.581850    Objective Loss 0.581850                                        LR 0.001000    Time 0.051518    
2024-06-05 23:33:26,989 - Epoch: [8][  800/ 1218]    Overall Loss 0.580264    Objective Loss 0.580264                                        LR 0.001000    Time 0.051323    
2024-06-05 23:33:31,958 - Epoch: [8][  900/ 1218]    Overall Loss 0.581117    Objective Loss 0.581117                                        LR 0.001000    Time 0.051139    
2024-06-05 23:33:37,089 - Epoch: [8][ 1000/ 1218]    Overall Loss 0.579368    Objective Loss 0.579368                                        LR 0.001000    Time 0.051153    
2024-06-05 23:33:42,082 - Epoch: [8][ 1100/ 1218]    Overall Loss 0.578836    Objective Loss 0.578836                                        LR 0.001000    Time 0.051040    
2024-06-05 23:33:47,045 - Epoch: [8][ 1200/ 1218]    Overall Loss 0.577350    Objective Loss 0.577350                                        LR 0.001000    Time 0.050921    
2024-06-05 23:33:47,928 - Epoch: [8][ 1218/ 1218]    Overall Loss 0.577093    Objective Loss 0.577093    Top1 75.305623    Top5 96.088020    LR 0.001000    Time 0.050892    
2024-06-05 23:33:48,148 - --- validate (epoch=8)-----------
2024-06-05 23:33:48,149 - 34633 samples (256 per mini-batch)
2024-06-05 23:33:54,060 - Epoch: [8][  100/  136]    Loss 0.599637    Top1 75.238281    Top5 96.171875    
2024-06-05 23:33:55,785 - Epoch: [8][  136/  136]    Loss 0.595313    Top1 75.251927    Top5 96.205931    
2024-06-05 23:33:55,987 - ==> Top1: 75.252    Top5: 96.206    Loss: 0.595

2024-06-05 23:33:55,988 - ==> Confusion:
[[ 803    2    0    2    2    0    1    0   22   62    0    1    4    5    4    0    0    1    7    5   10]
 [   3  886    5    2   11   27    3    9   11    0    6    5    7    8   18    1   11    0   25    9   16]
 [  26    1  815    5    3    2    4   12    4    9    9    4    9   10    4    4    6    2   13    4   24]
 [   8    5   36  801    1    4    2    0    5    1   16    1   15    7   71    1    3    5   23    1   10]
 [  64   25    3    0  808   12    2    3    8   19    0    3    3    8   40    5   17    0   12    4   18]
 [  15   55    4    9   12  741    4   40    9    3    1   16   16   51    8    3   11    1    8   13   23]
 [   4    1   89    5    2    7  876    7    3    1    4    4    9    2    1   14    0    4    5   37   11]
 [  10   24   22    2    1   30    4  825    4    3    1   14   14   17    4    2    1    4   50   30   15]
 [  13    3    1    0    0    3    0    1  883   28    8    0    9   17   20    1    1    1    5    1    7]
 [ 102    0    1    0    1    1    0    0  121  710    0    1    2   31   10    0    1    7    2    3    8]
 [   3    4   17   26    2    3    2    2   43    2  873    2    7   21   19    0    0    0   23    2   13]
 [   7    0    0    0    0   11    1    4    4    1    2  772  102   37    0    9    1   23    3   21   13]
 [   0    0    1    3    0    1    0    3    6    0    1   59  846   11    3    5    4   24    1    8   19]
 [   4    2    5    1    0    8    1    2   40   19    6   10    9  861    8    1    3    2    1    7   11]
 [  13    3    3    3    3    0    0    0   68    8    5    2    8    8  940    1    1    1   12    2   17]
 [  11    3    8    1    7    0    5    1    1    2    0   19   34    8    1  916   14   15    1    5   14]
 [   9    7    4    1    8    8    0    0    8    0    2    8   13    8    7    8  933    4    2    9   33]
 [   3    0    3    5    0    1    1    2    5    2    0   13  105    6   11   12    4  814    4    6    8]
 [   4    6    6   16    3    6    0   21   16    1    9    3    7    5   44    0    0    0  889    6   16]
 [   1    5    7    0    1    3    6    9    0    1    1   20   24   13    0    9   11    4    4  958   11]
 [ 393  266  251  116  194  210   52  153  275  111  132  168  550  418  436  132  277   89  237  360 9112]]

2024-06-05 23:33:55,993 - ==> Best [Top1: 75.252   Top5: 96.206   Sparsity:0.00   Params: 424448 on epoch: 8]
2024-06-05 23:33:55,993 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:33:56,016 - 

2024-06-05 23:33:56,016 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:34:02,462 - Epoch: [9][  100/ 1218]    Overall Loss 0.538771    Objective Loss 0.538771                                        LR 0.001000    Time 0.064432    
2024-06-05 23:34:07,490 - Epoch: [9][  200/ 1218]    Overall Loss 0.551357    Objective Loss 0.551357                                        LR 0.001000    Time 0.057341    
2024-06-05 23:34:12,585 - Epoch: [9][  300/ 1218]    Overall Loss 0.551656    Objective Loss 0.551656                                        LR 0.001000    Time 0.055203    
2024-06-05 23:34:17,496 - Epoch: [9][  400/ 1218]    Overall Loss 0.552658    Objective Loss 0.552658                                        LR 0.001000    Time 0.053674    
2024-06-05 23:34:22,458 - Epoch: [9][  500/ 1218]    Overall Loss 0.552063    Objective Loss 0.552063                                        LR 0.001000    Time 0.052859    
2024-06-05 23:34:28,515 - Epoch: [9][  600/ 1218]    Overall Loss 0.550316    Objective Loss 0.550316                                        LR 0.001000    Time 0.054138    
2024-06-05 23:34:34,270 - Epoch: [9][  700/ 1218]    Overall Loss 0.553395    Objective Loss 0.553395                                        LR 0.001000    Time 0.054615    
2024-06-05 23:34:39,346 - Epoch: [9][  800/ 1218]    Overall Loss 0.554510    Objective Loss 0.554510                                        LR 0.001000    Time 0.054131    
2024-06-05 23:34:44,721 - Epoch: [9][  900/ 1218]    Overall Loss 0.554545    Objective Loss 0.554545                                        LR 0.001000    Time 0.054085    
2024-06-05 23:34:50,397 - Epoch: [9][ 1000/ 1218]    Overall Loss 0.554703    Objective Loss 0.554703                                        LR 0.001000    Time 0.054349    
2024-06-05 23:34:56,067 - Epoch: [9][ 1100/ 1218]    Overall Loss 0.554028    Objective Loss 0.554028                                        LR 0.001000    Time 0.054561    
2024-06-05 23:35:02,109 - Epoch: [9][ 1200/ 1218]    Overall Loss 0.554355    Objective Loss 0.554355                                        LR 0.001000    Time 0.055047    
2024-06-05 23:35:03,027 - Epoch: [9][ 1218/ 1218]    Overall Loss 0.553866    Objective Loss 0.553866    Top1 75.794621    Top5 97.310513    LR 0.001000    Time 0.054987    
2024-06-05 23:35:03,280 - --- validate (epoch=9)-----------
2024-06-05 23:35:03,280 - 34633 samples (256 per mini-batch)
2024-06-05 23:35:10,344 - Epoch: [9][  100/  136]    Loss 0.572129    Top1 70.324219    Top5 94.308594    
2024-06-05 23:35:12,194 - Epoch: [9][  136/  136]    Loss 0.578284    Top1 70.383738    Top5 94.337770    
2024-06-05 23:35:12,464 - ==> Top1: 70.384    Top5: 94.338    Loss: 0.578

2024-06-05 23:35:12,465 - ==> Confusion:
[[ 812    0    7    3   11    5    0    0    4   64    2    0    0    3    5    4    1    1    1    5    3]
 [   4  879    4    3   35   50    8   17    3    4    4    0    2    2    8    0   13    2   12    9    4]
 [  15    3  829   14    2    3   40   16    0    8    0    6    1    3    5    4    3    3    4    6    5]
 [   9    0   34  873    4   19   10    1    0    3    7    2    3    1   28    1    0    8    9    3    1]
 [  37   11    4    2  917   17    5    4    1   16    1    1    1    3    9    6    6    2    6    1    4]
 [   7   26    5    7   22  862    9   26    1    7    3   13    3   13    5    0   10    2    6   12    4]
 [   5    4   29    3    0   11  991    9    0    5    0    1    2    0    1    2    5    2    3   11    2]
 [  12   18   20    9    3   72   10  847    1    5    7    8    2    0    2    0    0    8   29   19    5]
 [  19    5    2    7    2    2    3    1  729   94   15    4    2   30   53    0    5    5   21    0    3]
 [ 110    0    2    1   11    3    0    4   26  801    1    0    0   18   14    0    1    3    2    1    3]
 [   6    1   21   45    6   10   18    7   16    6  858    2    0   13   19    0    2    1   29    2    2]
 [   2    5    1    1    1   36    6   11    1    3    0  838   30    5    1   28    5   17    7   13    0]
 [   3    4    3   15    3   21    6    4    3    3    1  136  709    3    7   10    7   35   11    4    7]
 [   6    1    3    1    5   54    2    3    5   27    3   24    4  821   13    7    2    3    1    8    8]
 [  16    3    8   25   11    1    0    1   15   19    1    0    4    9  954    1    1    4   19    1    5]
 [   6    4    6    1    6    7   24    0    0    6    1   23    6    3    1  943   10   12    1    4    2]
 [   9    9    5    5   13   18    6    0    2    3    1   12    1    3    5   11  943    3    2   11   10]
 [  11    1    2    8    0    4    7    0    1    2    0   46   37    3    5   30    1  836    2    5    4]
 [   5   12   13   44    5    9    5   19    4    1    2    1    3    0   33    0    1    0  897    2    2]
 [   8    3    7    3    1   28   28   14    0    3    2   40    7    3    0    8    7    6    5  909    6]
 [ 622  274  456  363  368  518  300  288  107  233  154  354  384  331  497  242  387  172  309  445 7128]]

2024-06-05 23:35:12,468 - ==> Best [Top1: 75.252   Top5: 96.206   Sparsity:0.00   Params: 424448 on epoch: 8]
2024-06-05 23:35:12,468 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:35:12,489 - 

2024-06-05 23:35:12,489 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:35:20,582 - Epoch: [10][  100/ 1218]    Overall Loss 0.540984    Objective Loss 0.540984                                        LR 0.001000    Time 0.080894    
2024-06-05 23:35:25,985 - Epoch: [10][  200/ 1218]    Overall Loss 0.543409    Objective Loss 0.543409                                        LR 0.001000    Time 0.067448    
2024-06-05 23:35:31,386 - Epoch: [10][  300/ 1218]    Overall Loss 0.546956    Objective Loss 0.546956                                        LR 0.001000    Time 0.062959    
2024-06-05 23:35:36,997 - Epoch: [10][  400/ 1218]    Overall Loss 0.547605    Objective Loss 0.547605                                        LR 0.001000    Time 0.061240    
2024-06-05 23:35:42,460 - Epoch: [10][  500/ 1218]    Overall Loss 0.548213    Objective Loss 0.548213                                        LR 0.001000    Time 0.059914    
2024-06-05 23:35:48,184 - Epoch: [10][  600/ 1218]    Overall Loss 0.547272    Objective Loss 0.547272                                        LR 0.001000    Time 0.059463    
2024-06-05 23:35:53,564 - Epoch: [10][  700/ 1218]    Overall Loss 0.544956    Objective Loss 0.544956                                        LR 0.001000    Time 0.058651    
2024-06-05 23:35:58,879 - Epoch: [10][  800/ 1218]    Overall Loss 0.542160    Objective Loss 0.542160                                        LR 0.001000    Time 0.057959    
2024-06-05 23:36:04,842 - Epoch: [10][  900/ 1218]    Overall Loss 0.541414    Objective Loss 0.541414                                        LR 0.001000    Time 0.058143    
2024-06-05 23:36:10,335 - Epoch: [10][ 1000/ 1218]    Overall Loss 0.540588    Objective Loss 0.540588                                        LR 0.001000    Time 0.057819    
2024-06-05 23:36:16,125 - Epoch: [10][ 1100/ 1218]    Overall Loss 0.540639    Objective Loss 0.540639                                        LR 0.001000    Time 0.057823    
2024-06-05 23:36:21,773 - Epoch: [10][ 1200/ 1218]    Overall Loss 0.540449    Objective Loss 0.540449                                        LR 0.001000    Time 0.057709    
2024-06-05 23:36:22,963 - Epoch: [10][ 1218/ 1218]    Overall Loss 0.540522    Objective Loss 0.540522    Top1 73.594132    Top5 95.843521    LR 0.001000    Time 0.057832    
2024-06-05 23:36:23,247 - --- validate (epoch=10)-----------
2024-06-05 23:36:23,247 - 34633 samples (256 per mini-batch)
2024-06-05 23:36:29,753 - Epoch: [10][  100/  136]    Loss 0.565260    Top1 73.671875    Top5 95.664062    
2024-06-05 23:36:31,950 - Epoch: [10][  136/  136]    Loss 0.557130    Top1 73.811105    Top5 95.715069    
2024-06-05 23:36:32,215 - ==> Top1: 73.811    Top5: 95.715    Loss: 0.557

2024-06-05 23:36:32,216 - ==> Confusion:
[[ 796    1    8    4   28    4    0    2    9   47    2    1    1    4    6    0    1    0    2    2   13]
 [  10  926    4    2   21   21    6    7    4    0    9    1    0    1    7    1   11    2   15    6    9]
 [   9    5  844    9    8    2   32   23    0    4    7    1    2    3    1    2    7    1    4    3    3]
 [   9    5   20  875    0   10    3    5    2    1   22    1    6    1   25    1    1    3   19    0    7]
 [  25   26    7    2  925   14    1    2    0    4    3    3    1    4    9    3   11    0    2    2   10]
 [   6   68    8    7   28  795    8   33    5    3    8    9    6   26    6    0    9    1    4   10    3]
 [   6    6   41    5    3    6  952   15    0    1    8    4    5    0    0    1    4    1    4   15    9]
 [   7   42   12    3    1   49    3  854    6    1    9   10    5    2    1    0    4    1   45   16    6]
 [  27    2    1    1    4    4    0    3  805   47   33    3    4   11   31    1    6    2    8    2    7]
 [ 152    3    2    1   25    9    0    5   63  679    2    1    3   31   10    0    2    3    0    2    8]
 [   3    5   10    8    3    7    7   11    7    0  952    0    1   17    5    0    0    0   19    3    6]
 [   7    2    5    0    1   36    3   16    2    0    2  759   48   27    0   12   13   21    4   41   12]
 [   8    2    2    6    0   15    4    8    2    2    9   59  789   13    2    1    6   34    8   15   10]
 [   9    0    3    1    6   31    1   10   10   13   13    4    4  862    9    1    3    1    2    9    9]
 [  17    2    4   19   17    4    0    1   26    2    9    4    4    7  942    0    4    4   18    0   14]
 [  13    2   16    2    5    3   23    0    1    4    0   18   19    5    0  905   14   18    1    8    9]
 [   9   14    5    3   20   11    2    2    4    1    3    8    3    7    5    5  939    0    3   10   18]
 [   8    2    3   11    0    8    1    2    7    3    0   14   67    8    5   10    5  833    3    6    9]
 [   5    6   10   13    2    1    1   15   11    0   17    1    3    2   16    0    4    0  940    1   10]
 [   9    9    6    1    2    8   18   30    0    0    2   11    6   10    1    5   12    2    6  945    5]
 [ 473  347  367  197  351  358  109  269  159   92  295  154  457  420  296   76  427  118  280  441 8246]]

2024-06-05 23:36:32,221 - ==> Best [Top1: 75.252   Top5: 96.206   Sparsity:0.00   Params: 424448 on epoch: 8]
2024-06-05 23:36:32,221 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:36:32,258 - 

2024-06-05 23:36:32,259 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:36:39,773 - Epoch: [11][  100/ 1218]    Overall Loss 0.536614    Objective Loss 0.536614                                        LR 0.001000    Time 0.075102    
2024-06-05 23:36:45,563 - Epoch: [11][  200/ 1218]    Overall Loss 0.528699    Objective Loss 0.528699                                        LR 0.001000    Time 0.066483    
2024-06-05 23:36:51,053 - Epoch: [11][  300/ 1218]    Overall Loss 0.532286    Objective Loss 0.532286                                        LR 0.001000    Time 0.062612    
2024-06-05 23:36:56,653 - Epoch: [11][  400/ 1218]    Overall Loss 0.530076    Objective Loss 0.530076                                        LR 0.001000    Time 0.060952    
2024-06-05 23:37:02,247 - Epoch: [11][  500/ 1218]    Overall Loss 0.530096    Objective Loss 0.530096                                        LR 0.001000    Time 0.059945    
2024-06-05 23:37:08,084 - Epoch: [11][  600/ 1218]    Overall Loss 0.527206    Objective Loss 0.527206                                        LR 0.001000    Time 0.059678    
2024-06-05 23:37:13,712 - Epoch: [11][  700/ 1218]    Overall Loss 0.526423    Objective Loss 0.526423                                        LR 0.001000    Time 0.059189    
2024-06-05 23:37:19,297 - Epoch: [11][  800/ 1218]    Overall Loss 0.525247    Objective Loss 0.525247                                        LR 0.001000    Time 0.058768    
2024-06-05 23:37:24,904 - Epoch: [11][  900/ 1218]    Overall Loss 0.525329    Objective Loss 0.525329                                        LR 0.001000    Time 0.058465    
2024-06-05 23:37:30,504 - Epoch: [11][ 1000/ 1218]    Overall Loss 0.526266    Objective Loss 0.526266                                        LR 0.001000    Time 0.058216    
2024-06-05 23:37:36,033 - Epoch: [11][ 1100/ 1218]    Overall Loss 0.526465    Objective Loss 0.526465                                        LR 0.001000    Time 0.057948    
2024-06-05 23:37:41,583 - Epoch: [11][ 1200/ 1218]    Overall Loss 0.526818    Objective Loss 0.526818                                        LR 0.001000    Time 0.057742    
2024-06-05 23:37:42,584 - Epoch: [11][ 1218/ 1218]    Overall Loss 0.526259    Objective Loss 0.526259    Top1 78.973105    Top5 95.354523    LR 0.001000    Time 0.057710    
2024-06-05 23:37:42,868 - --- validate (epoch=11)-----------
2024-06-05 23:37:42,868 - 34633 samples (256 per mini-batch)
2024-06-05 23:37:49,915 - Epoch: [11][  100/  136]    Loss 0.545380    Top1 77.183594    Top5 95.921875    
2024-06-05 23:37:51,756 - Epoch: [11][  136/  136]    Loss 0.543283    Top1 77.172061    Top5 95.998037    
2024-06-05 23:37:51,955 - ==> Top1: 77.172    Top5: 95.998    Loss: 0.543

2024-06-05 23:37:51,957 - ==> Confusion:
[[ 804    1    3    5   15    0    0    0    8   44    2    2    1    5   14    3    2    3    1    1   17]
 [   5  920    1    3   37   21    6    9    2    0    8    4    3    6    7    3    5    0   12    2    9]
 [  10    6  767   41    7    3   32   13    1    4   13    6    3    4    6   12   10    0   11    3   18]
 [   8    2   10  893    1    5    0    3    3    0   22    1   15    4   26    1    3    5    5    1    8]
 [  26   12    6    2  918    8    0    1    2   14    2    2    2    8   17    9   12    2    1    1    9]
 [   9   52    2    6   21  810    6   21    0    5    8   19    8   35    3    3    5    3    7    6   14]
 [   7    5   26    7    4    3  957    3    1    1    7    4    4    2    1   20    2    3    3   13   13]
 [  12   34   12   10    8   67    5  810    3    2    8   14    4    5    3    4    1    2   50    6   17]
 [  17    6    0    2    1    3    0    2  761   56   27    2    7   36   53    2    7    1    9    1    9]
 [ 128    0    4    1   12    1    0    2   44  752    4    2    0   23   17    0    1    1    1    1    7]
 [   2    4    7   16    2    3    9    3   13    1  949    1    1   16   17    0    1    0   14    2    3]
 [   2    1    1    0    4   12    1    8    0    1    2  846   37   15    2   27    6   15    1   11   19]
 [   8    1    2    5    1    5    1    4    2    0    4   96  787    7    5   13    2   34    2    2   14]
 [   6    1    4    0    5   15    1    4    5   19    7   10    7  876   12    6    2    3    0    5   13]
 [   9    3    0   36   13    1    0    1   25    4    8    5    8   13  947    0    1    1   13    0   10]
 [   7    0    1    1    3    0    8    1    0    1    0   33   12    3    0  972    7    8    0    3    6]
 [  10   12    4    2   12    5    2    1    5    1    1   11    7    6    5   13  943    2    2    3   25]
 [   7    0    1    9    0    2    0    1    0    0    0   26   51    3    5   35    1  853    0    3    8]
 [   6   15    6   32    3    7    0   17   10    2   12    4   11    2   29    2    2    1  887    2    8]
 [   6    6    2    1    2    8   12   15    0    0    0   36    9    9    2   10   11    5    8  910   36]
 [ 266  269  193  258  284  195   74  127   96  102  254  205  403  440  360  242  341   82  202  174 9365]]

2024-06-05 23:37:51,968 - ==> Best [Top1: 77.172   Top5: 95.998   Sparsity:0.00   Params: 424448 on epoch: 11]
2024-06-05 23:37:51,968 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:37:52,006 - 

2024-06-05 23:37:52,006 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:37:59,423 - Epoch: [12][  100/ 1218]    Overall Loss 0.506197    Objective Loss 0.506197                                        LR 0.001000    Time 0.074123    
2024-06-05 23:38:05,034 - Epoch: [12][  200/ 1218]    Overall Loss 0.509758    Objective Loss 0.509758                                        LR 0.001000    Time 0.065105    
2024-06-05 23:38:10,855 - Epoch: [12][  300/ 1218]    Overall Loss 0.517715    Objective Loss 0.517715                                        LR 0.001000    Time 0.062797    
2024-06-05 23:38:16,634 - Epoch: [12][  400/ 1218]    Overall Loss 0.516777    Objective Loss 0.516777                                        LR 0.001000    Time 0.061539    
2024-06-05 23:38:22,439 - Epoch: [12][  500/ 1218]    Overall Loss 0.517176    Objective Loss 0.517176                                        LR 0.001000    Time 0.060836    
2024-06-05 23:38:28,268 - Epoch: [12][  600/ 1218]    Overall Loss 0.517907    Objective Loss 0.517907                                        LR 0.001000    Time 0.060406    
2024-06-05 23:38:33,766 - Epoch: [12][  700/ 1218]    Overall Loss 0.516311    Objective Loss 0.516311                                        LR 0.001000    Time 0.059628    
2024-06-05 23:38:39,339 - Epoch: [12][  800/ 1218]    Overall Loss 0.519171    Objective Loss 0.519171                                        LR 0.001000    Time 0.059137    
2024-06-05 23:38:44,918 - Epoch: [12][  900/ 1218]    Overall Loss 0.518518    Objective Loss 0.518518                                        LR 0.001000    Time 0.058761    
2024-06-05 23:38:50,801 - Epoch: [12][ 1000/ 1218]    Overall Loss 0.517438    Objective Loss 0.517438                                        LR 0.001000    Time 0.058766    
2024-06-05 23:38:56,524 - Epoch: [12][ 1100/ 1218]    Overall Loss 0.517371    Objective Loss 0.517371                                        LR 0.001000    Time 0.058624    
2024-06-05 23:39:02,272 - Epoch: [12][ 1200/ 1218]    Overall Loss 0.516938    Objective Loss 0.516938                                        LR 0.001000    Time 0.058526    
2024-06-05 23:39:03,248 - Epoch: [12][ 1218/ 1218]    Overall Loss 0.516390    Objective Loss 0.516390    Top1 80.684597    Top5 97.555012    LR 0.001000    Time 0.058462    
2024-06-05 23:39:03,413 - --- validate (epoch=12)-----------
2024-06-05 23:39:03,413 - 34633 samples (256 per mini-batch)
2024-06-05 23:39:10,029 - Epoch: [12][  100/  136]    Loss 0.557549    Top1 79.000000    Top5 96.656250    
2024-06-05 23:39:12,213 - Epoch: [12][  136/  136]    Loss 0.555755    Top1 79.037334    Top5 96.639044    
2024-06-05 23:39:12,425 - ==> Top1: 79.037    Top5: 96.639    Loss: 0.556

2024-06-05 23:39:12,427 - ==> Confusion:
[[  782     0     2     1    12     2     0     1     6    85     1     2     2     1     7     1     0     3     3     4    16]
 [    3   839     5     0    74    18     2    15     4     5     2     6     2     3    18     3     3     2    18     5    36]
 [    4     4   804    31    12     1    15    12     3     9     5     3     1     6     4     5     3     3    14     4    27]
 [   10     1     8   843     5     2     3     5     5     4    12     0    13     2    55     5     3     4    14     1    21]
 [   27     3     2     4   934     5     0     1     4    27     0     4     0     3    15     1     5     2     0     6    11]
 [    9    23     4     4    52   763     6    41     4    10     1     9     5    26    13     5     7     1     8    12    40]
 [    3     8    42    12     0     6   933     6     0     7     4     3     2     4     0    17     1     5     1    11    21]
 [    2     9    15     5    10    29     3   873     2     9     6     7     3     5     2     2     0     5    35    14    41]
 [   15     3     1     3     2     0     0     2   771   100     4     1     8    24    28     3     1     1     9     0    26]
 [   84     2     0     0     5     1     0     0    26   833     0     0     0    18     5     8     1     3     1     1    13]
 [    1     8     7    27     4     2     3     8    25     4   817     1     1    34    54     1     0     0    30     1    36]
 [    2     0     5     1     2    11     3    11     3     4     0   808    44    34     1    13     0    24     1    23    21]
 [    1     1     1     4     2     4     3     6     3     0     0    58   800    11     7    10     3    38     6     8    29]
 [    6     3     1     2     4     7     2     4     9    32     4     7     9   842    15     5     1     3     1     4    40]
 [   17     0     4    10    17     0     0     0    27    26     1     2     3     4   955     3     0     3     8     1    17]
 [    4     1     2     1    11     0     5     0     0     3     0    21    14     4     0   951     6    19     1     9    14]
 [    4    13     5     2    11     2     1     1     9     2     0     5     9     1     5    18   918     1     3    10    52]
 [    6     1     3     3     1     2     1     1     2     2     0    13    47     7     4    11     3   877     4     3    14]
 [    4     3     4    18     6     1     2    31     9     3     3     1     3     1    33     1     1     1   914     3    16]
 [    4     4     3     3     4    10    10    13     1     1     1     8     8    12     0     4     7     4     2   960    29]
 [  242   147   186   126   420   114    71   124    95   225    79   142   333   245   308   181   126   135   193   284 10156]]

2024-06-05 23:39:12,431 - ==> Best [Top1: 79.037   Top5: 96.639   Sparsity:0.00   Params: 424448 on epoch: 12]
2024-06-05 23:39:12,431 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:39:12,459 - 

2024-06-05 23:39:12,459 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:39:19,590 - Epoch: [13][  100/ 1218]    Overall Loss 0.506036    Objective Loss 0.506036                                        LR 0.001000    Time 0.071276    
2024-06-05 23:39:24,992 - Epoch: [13][  200/ 1218]    Overall Loss 0.509779    Objective Loss 0.509779                                        LR 0.001000    Time 0.062636    
2024-06-05 23:39:30,495 - Epoch: [13][  300/ 1218]    Overall Loss 0.512966    Objective Loss 0.512966                                        LR 0.001000    Time 0.060092    
2024-06-05 23:39:36,095 - Epoch: [13][  400/ 1218]    Overall Loss 0.511133    Objective Loss 0.511133                                        LR 0.001000    Time 0.059061    
2024-06-05 23:39:41,867 - Epoch: [13][  500/ 1218]    Overall Loss 0.510327    Objective Loss 0.510327                                        LR 0.001000    Time 0.058789    
2024-06-05 23:39:47,682 - Epoch: [13][  600/ 1218]    Overall Loss 0.508975    Objective Loss 0.508975                                        LR 0.001000    Time 0.058678    
2024-06-05 23:39:53,168 - Epoch: [13][  700/ 1218]    Overall Loss 0.509080    Objective Loss 0.509080                                        LR 0.001000    Time 0.058129    
2024-06-05 23:39:59,093 - Epoch: [13][  800/ 1218]    Overall Loss 0.508237    Objective Loss 0.508237                                        LR 0.001000    Time 0.058266    
2024-06-05 23:40:04,922 - Epoch: [13][  900/ 1218]    Overall Loss 0.507444    Objective Loss 0.507444                                        LR 0.001000    Time 0.058265    
2024-06-05 23:40:10,647 - Epoch: [13][ 1000/ 1218]    Overall Loss 0.508056    Objective Loss 0.508056                                        LR 0.001000    Time 0.058160    
2024-06-05 23:40:16,048 - Epoch: [13][ 1100/ 1218]    Overall Loss 0.507181    Objective Loss 0.507181                                        LR 0.001000    Time 0.057781    
2024-06-05 23:40:21,191 - Epoch: [13][ 1200/ 1218]    Overall Loss 0.506764    Objective Loss 0.506764                                        LR 0.001000    Time 0.057249    
2024-06-05 23:40:22,138 - Epoch: [13][ 1218/ 1218]    Overall Loss 0.506403    Objective Loss 0.506403    Top1 80.684597    Top5 98.044010    LR 0.001000    Time 0.057181    
2024-06-05 23:40:22,332 - --- validate (epoch=13)-----------
2024-06-05 23:40:22,332 - 34633 samples (256 per mini-batch)
2024-06-05 23:40:29,382 - Epoch: [13][  100/  136]    Loss 0.524153    Top1 77.871094    Top5 96.121094    
2024-06-05 23:40:31,566 - Epoch: [13][  136/  136]    Loss 0.524392    Top1 77.902578    Top5 96.127970    
2024-06-05 23:40:31,822 - ==> Top1: 77.903    Top5: 96.128    Loss: 0.524

2024-06-05 23:40:31,823 - ==> Confusion:
[[ 736    1    8    3   20    1    0    0   19  101    0    3    2    3   11    2    2    3    3    1   12]
 [   2  926    4    0   17    9    2    8   11    3   11    2    2    5   12    3    6    3   23    6    8]
 [   9    3  824   10    8    2    9   13    1    8   14    3    1    5    5    9    3    2   18    5   18]
 [   6    2   14  862    4    5    1    1    2    1   27    1   11    4   31    1    1    7   21    1   13]
 [  17   14    3    1  945    3    4    0    4   11    0    3    2    4   12    6    6    1    8    2    8]
 [   3   81    3    7   31  740    8   31    3    8    5   20   10   27   14    1    7    3    9   17   15]
 [   4   10   50    5    2    5  925    9    1    3   12    3    3    3    2   13    1    3    4   13   15]
 [   4   21    9    5    6   24    3  841    5    5    9   20    2    5    5    1    2    1   76   23   10]
 [  10    2    1    1    2    0    0    2  829   57   12    3    6   18   21    0    6    6   20    1    5]
 [  54    0    0    0    5    1    0    2   50  832    3    0    1   26   10    0    1    4    5    2    5]
 [   2    7    5    2    1    0    3    6   22    3  954    3    1   10    8    0    0    0   24    2   11]
 [   5    0    1    0    3   20    0    4    4    2    1  844   54   19    4   13    4   13    6   10    4]
 [   1    1    2    3    3    3    2    1    7    1    2   65  830    9    4    5    1   34    5    4   12]
 [   5    1    1    2    5    9    0    2   28   24    8   15    6  857   11    3    3    4    2    5   10]
 [  10    5    1    7   15    1    1    0   47   15   11    1    4    5  949    0    0    4   18    0    4]
 [   8    0    6    2    2    1    4    0    0    2    2   19   16    4    2  958    5   15    3    3   14]
 [   5   15    4    6    9    1    1    1   13    4    1    9   10    7    8    8  932    4    1    6   27]
 [   6    1    1    3    0    1    1    5    3    3    0   19   48    7    4   12    0  878    1    1   11]
 [   4   12    4    8    1    2    0   15    7    0    9    2    7    2   20    1    0    0  960    1    3]
 [   2    6    7    2    4    8   13    9    1    0    0   48   15   11    0    5    7    6    6  926   12]
 [ 239  294  179  141  294  120   66  131  189  195  229  263  392  321  406  121  154  136  400  230 9432]]

2024-06-05 23:40:31,829 - ==> Best [Top1: 79.037   Top5: 96.639   Sparsity:0.00   Params: 424448 on epoch: 12]
2024-06-05 23:40:31,830 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:40:31,861 - 

2024-06-05 23:40:31,862 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:40:39,382 - Epoch: [14][  100/ 1218]    Overall Loss 0.487662    Objective Loss 0.487662                                        LR 0.001000    Time 0.075169    
2024-06-05 23:40:45,202 - Epoch: [14][  200/ 1218]    Overall Loss 0.494255    Objective Loss 0.494255                                        LR 0.001000    Time 0.066670    
2024-06-05 23:40:50,706 - Epoch: [14][  300/ 1218]    Overall Loss 0.496860    Objective Loss 0.496860                                        LR 0.001000    Time 0.062785    
2024-06-05 23:40:56,554 - Epoch: [14][  400/ 1218]    Overall Loss 0.495567    Objective Loss 0.495567                                        LR 0.001000    Time 0.061700    
2024-06-05 23:41:02,337 - Epoch: [14][  500/ 1218]    Overall Loss 0.493996    Objective Loss 0.493996                                        LR 0.001000    Time 0.060922    
2024-06-05 23:41:07,950 - Epoch: [14][  600/ 1218]    Overall Loss 0.495269    Objective Loss 0.495269                                        LR 0.001000    Time 0.060118    
2024-06-05 23:41:13,568 - Epoch: [14][  700/ 1218]    Overall Loss 0.496749    Objective Loss 0.496749                                        LR 0.001000    Time 0.059552    
2024-06-05 23:41:19,500 - Epoch: [14][  800/ 1218]    Overall Loss 0.495346    Objective Loss 0.495346                                        LR 0.001000    Time 0.059519    
2024-06-05 23:41:24,962 - Epoch: [14][  900/ 1218]    Overall Loss 0.496629    Objective Loss 0.496629                                        LR 0.001000    Time 0.058972    
2024-06-05 23:41:30,461 - Epoch: [14][ 1000/ 1218]    Overall Loss 0.495562    Objective Loss 0.495562                                        LR 0.001000    Time 0.058571    
2024-06-05 23:41:36,268 - Epoch: [14][ 1100/ 1218]    Overall Loss 0.495359    Objective Loss 0.495359                                        LR 0.001000    Time 0.058523    
2024-06-05 23:41:42,442 - Epoch: [14][ 1200/ 1218]    Overall Loss 0.496222    Objective Loss 0.496222                                        LR 0.001000    Time 0.058789    
2024-06-05 23:41:43,461 - Epoch: [14][ 1218/ 1218]    Overall Loss 0.496360    Objective Loss 0.496360    Top1 76.039120    Top5 93.643032    LR 0.001000    Time 0.058756    
2024-06-05 23:41:43,694 - --- validate (epoch=14)-----------
2024-06-05 23:41:43,694 - 34633 samples (256 per mini-batch)
2024-06-05 23:41:50,501 - Epoch: [14][  100/  136]    Loss 0.497204    Top1 78.562500    Top5 96.277344    
2024-06-05 23:41:52,491 - Epoch: [14][  136/  136]    Loss 0.499986    Top1 78.647533    Top5 96.249242    
2024-06-05 23:41:52,649 - ==> Top1: 78.648    Top5: 96.249    Loss: 0.500

2024-06-05 23:41:52,650 - ==> Confusion:
[[ 775    1    2    5   12    1    1    0   18   87    2    2    2    1    7    2    2    1    0    2    8]
 [   4  882    1    1   18   40    6   15   12    4    5    9    4    1    6    0   12    5   14    8   16]
 [   8    4  788   48    6    4   28   16    1   10    8    4    0    5    8    5    1    0   12    5    9]
 [   8    1    9  894    2    5    1    1    3    1   18    2    7    2   35    2    2    7    7    1    8]
 [  29   14    0    2  927    9    0    2    5   12    0    6    0    6   14   12    7    0    0    0    9]
 [   6   25    1    5   11  847    4   39    5    4    5   14    9   23    4    2    4    1    6    9   19]
 [   3    4   24    6    2    8  984    5    1    1    5    2    1    1    1    6    4    5    3    9   11]
 [   5   13   10    6    3   49    9  884    6    6    5    7    5    4    1    0    0    6   28   18   12]
 [  13    9    0    3    3    1    0    1  838   46   16    2    5   19   23    2    2    6    5    0    8]
 [  66    0    1    1    7    2    0    0   69  806    2    1    1   22    9    2    0    5    0    0    7]
 [   1    9    7   20    4    3    3    7   19    4  941    0    0    9   17    0    2    0   11    1    6]
 [   4    2    4    2    2   16    5    9    0    0    0  835   37    8    0   15    4   37    2   19   10]
 [   6    2    2    7    1    5    4    4    7    0    1   86  744    3    7    7    2   76    3   14   14]
 [   6    1    2    4    4   16    2    5   20   20   23   17    8  823    7    4    4    6    0   13   16]
 [   8    4    1   17    9    0    0    1   47    8    4    4    3    5  966    1    0    3   10    1    6]
 [   8    3    3    3    1    2   16    0    0    2    0   19   16    3    0  932    3   39    1    1   14]
 [   4   10    1    5   10    9    2    1    6    1    2   11    5    3    5   13  945    5    1   10   23]
 [   1    0    1    3    0    1    1    3    1    1    0   23   10    3    7    9    1  929    1    3    7]
 [   4    9    6   33    5    1    4   29   14    1    9    7    2    0   20    1    1    2  902    0    8]
 [   6    3    3    0    3   12   31    8    3    2    2   18    7    4    2   13    4    4    8  943   12]
 [ 262  211  151  254  234  224  150  168  181  131  175  179  302  273  322  198  172  198  183  311 9653]]

2024-06-05 23:41:52,655 - ==> Best [Top1: 79.037   Top5: 96.639   Sparsity:0.00   Params: 424448 on epoch: 12]
2024-06-05 23:41:52,655 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:41:52,689 - 

2024-06-05 23:41:52,689 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:41:59,824 - Epoch: [15][  100/ 1218]    Overall Loss 0.485391    Objective Loss 0.485391                                        LR 0.001000    Time 0.071310    
2024-06-05 23:42:05,298 - Epoch: [15][  200/ 1218]    Overall Loss 0.485103    Objective Loss 0.485103                                        LR 0.001000    Time 0.063013    
2024-06-05 23:42:10,981 - Epoch: [15][  300/ 1218]    Overall Loss 0.484926    Objective Loss 0.484926                                        LR 0.001000    Time 0.060944    
2024-06-05 23:42:16,654 - Epoch: [15][  400/ 1218]    Overall Loss 0.486378    Objective Loss 0.486378                                        LR 0.001000    Time 0.059883    
2024-06-05 23:42:22,534 - Epoch: [15][  500/ 1218]    Overall Loss 0.488027    Objective Loss 0.488027                                        LR 0.001000    Time 0.059661    
2024-06-05 23:42:28,048 - Epoch: [15][  600/ 1218]    Overall Loss 0.486730    Objective Loss 0.486730                                        LR 0.001000    Time 0.058902    
2024-06-05 23:42:33,795 - Epoch: [15][  700/ 1218]    Overall Loss 0.485935    Objective Loss 0.485935                                        LR 0.001000    Time 0.058695    
2024-06-05 23:42:39,533 - Epoch: [15][  800/ 1218]    Overall Loss 0.485869    Objective Loss 0.485869                                        LR 0.001000    Time 0.058527    
2024-06-05 23:42:44,948 - Epoch: [15][  900/ 1218]    Overall Loss 0.486535    Objective Loss 0.486535                                        LR 0.001000    Time 0.058037    
2024-06-05 23:42:50,341 - Epoch: [15][ 1000/ 1218]    Overall Loss 0.485526    Objective Loss 0.485526                                        LR 0.001000    Time 0.057624    
2024-06-05 23:42:56,079 - Epoch: [15][ 1100/ 1218]    Overall Loss 0.486322    Objective Loss 0.486322                                        LR 0.001000    Time 0.057599    
2024-06-05 23:43:01,771 - Epoch: [15][ 1200/ 1218]    Overall Loss 0.486764    Objective Loss 0.486764                                        LR 0.001000    Time 0.057540    
2024-06-05 23:43:02,731 - Epoch: [15][ 1218/ 1218]    Overall Loss 0.486833    Objective Loss 0.486833    Top1 79.217604    Top5 97.066015    LR 0.001000    Time 0.057478    
2024-06-05 23:43:02,969 - --- validate (epoch=15)-----------
2024-06-05 23:43:02,969 - 34633 samples (256 per mini-batch)
2024-06-05 23:43:09,644 - Epoch: [15][  100/  136]    Loss 0.508168    Top1 78.746094    Top5 96.527344    
2024-06-05 23:43:11,644 - Epoch: [15][  136/  136]    Loss 0.502776    Top1 78.869864    Top5 96.598620    
2024-06-05 23:43:11,855 - ==> Top1: 78.870    Top5: 96.599    Loss: 0.503

2024-06-05 23:43:11,857 - ==> Confusion:
[[ 766    1    2    1   19    1    0    2   12   90    1    3    4    3    3    5    5    5    0    6    2]
 [   3  885    3    1   31   27    8   22    4    3   10    6    2    2   11    1    9    2    5   10   18]
 [   8    5  780   14    9    3   46   20    1    3   16    4    1    3    7    6    6    5    8    8   17]
 [   0    2   13  868    2    4    3    4    3    1   27    5    7    1   41    1    2   11    7    3   11]
 [  22   11    0    4  925    9    1    4    5    9    5    9    1    2   15    3   13    2    1    2   11]
 [   7   38    2    3   17  818    9   33    2    3   13   19    7   10    5    3    9    7    3   24   11]
 [   2    3   12    3    3    1 1000    5    1    1    6    6    2    0    1    8    2    5    4   11   10]
 [   6   16   11    5    5   45    6  849    5    3   13   21    9    1    1    0    1    5   25   35   15]
 [  12    6    0    1    1    3    1    0  849   48   17    2    6    8   30    0    5    5    1    0    7]
 [  46    0    1    1    8    2    2    0   49  827    1    2    1   18   22    2    0   11    0    1    7]
 [   3    2    4   10    5    4   10    7   18    1  946    0    0    5   15    2    3    1   11    3   14]
 [   0    1    0    0    0    8    5    5    2    0    0  843   47    6    1   16    1   21    4   34   17]
 [   1    1    3   11    0    3    1    2    0    0    1   79  797    0    2   17    6   41    6   10   14]
 [   6    2    2    0    7   12    2    2   31   25   19   14   13  800   18    2    6    6    1   21   12]
 [  11    6    1   11   12    0    0    0   34    9    9    3    2    3  965    0    2    6    8    2   14]
 [   4    1    2    2    2    1   10    0    0    0    1   15   12    0    0  971   12   15    1    4   13]
 [   1    9    3    2    4    3    1    2    9    0    5    8    7    0    9   12  950    3    1   15   28]
 [   0    0    1    7    2    2    3    1    3    1    0   13   30    1    7   17    1  903    0    8    5]
 [   5    5    4   16    3    0    0   27   10    0   11    2    5    0   35    0    3    3  904    7   18]
 [   3    6    4    0    1    1   13    6    2    0    2   18    8    2    2    8    6    8    4  981   13]
 [ 236  190  139  154  258  145  146  152  167  149  258  175  344  196  339  190  314  143  158  391 9688]]

2024-06-05 23:43:11,869 - ==> Best [Top1: 79.037   Top5: 96.639   Sparsity:0.00   Params: 424448 on epoch: 12]
2024-06-05 23:43:11,870 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:43:11,892 - 

2024-06-05 23:43:11,893 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:43:19,583 - Epoch: [16][  100/ 1218]    Overall Loss 0.481882    Objective Loss 0.481882                                        LR 0.001000    Time 0.076864    
2024-06-05 23:43:25,152 - Epoch: [16][  200/ 1218]    Overall Loss 0.485251    Objective Loss 0.485251                                        LR 0.001000    Time 0.066268    
2024-06-05 23:43:31,101 - Epoch: [16][  300/ 1218]    Overall Loss 0.483842    Objective Loss 0.483842                                        LR 0.001000    Time 0.064000    
2024-06-05 23:43:36,791 - Epoch: [16][  400/ 1218]    Overall Loss 0.484722    Objective Loss 0.484722                                        LR 0.001000    Time 0.062217    
2024-06-05 23:43:42,396 - Epoch: [16][  500/ 1218]    Overall Loss 0.482936    Objective Loss 0.482936                                        LR 0.001000    Time 0.060976    
2024-06-05 23:43:48,365 - Epoch: [16][  600/ 1218]    Overall Loss 0.483551    Objective Loss 0.483551                                        LR 0.001000    Time 0.060756    
2024-06-05 23:43:54,151 - Epoch: [16][  700/ 1218]    Overall Loss 0.482572    Objective Loss 0.482572                                        LR 0.001000    Time 0.060338    
2024-06-05 23:44:00,064 - Epoch: [16][  800/ 1218]    Overall Loss 0.482812    Objective Loss 0.482812                                        LR 0.001000    Time 0.060184    
2024-06-05 23:44:05,829 - Epoch: [16][  900/ 1218]    Overall Loss 0.482604    Objective Loss 0.482604                                        LR 0.001000    Time 0.059900    
2024-06-05 23:44:11,433 - Epoch: [16][ 1000/ 1218]    Overall Loss 0.482272    Objective Loss 0.482272                                        LR 0.001000    Time 0.059510    
2024-06-05 23:44:17,286 - Epoch: [16][ 1100/ 1218]    Overall Loss 0.480477    Objective Loss 0.480477                                        LR 0.001000    Time 0.059419    
2024-06-05 23:44:22,877 - Epoch: [16][ 1200/ 1218]    Overall Loss 0.481538    Objective Loss 0.481538                                        LR 0.001000    Time 0.059124    
2024-06-05 23:44:23,962 - Epoch: [16][ 1218/ 1218]    Overall Loss 0.481730    Objective Loss 0.481730    Top1 75.305623    Top5 95.843521    LR 0.001000    Time 0.059141    
2024-06-05 23:44:24,171 - --- validate (epoch=16)-----------
2024-06-05 23:44:24,171 - 34633 samples (256 per mini-batch)
2024-06-05 23:44:30,602 - Epoch: [16][  100/  136]    Loss 0.505080    Top1 76.722656    Top5 95.871094    
2024-06-05 23:44:32,420 - Epoch: [16][  136/  136]    Loss 0.508154    Top1 76.502180    Top5 95.905639    
2024-06-05 23:44:32,632 - ==> Top1: 76.502    Top5: 95.906    Loss: 0.508

2024-06-05 23:44:32,633 - ==> Confusion:
[[ 784    1    3    3   11    3    2    3    7   77    2    8    1    5    3    5    1    3    1    2    6]
 [   6  893    6    1   24   55    5    8    4    2    5    8    3    1    5    0   10    1    9    7   10]
 [  16    2  802    7    4    4   59   17    2    9    8    7    3    6    1    2    3    0    5   10    3]
 [   9    2   17  863    5   17    8    5    1    2   28    3    5    4   21    3    2    7    5    4    5]
 [  26   13    3    0  926   19    3    0    2   15    0    8    0    3   11    7    9    1    1    4    3]
 [   5   22    4    3   17  885    4   15    4    6    6   21    3   19    2    2    7    2    2   12    2]
 [   2    4   17    3    2    8  984    5    0    4   12    5    0    0    0    8    2    3    0   22    5]
 [   7   23    7    4    3   85   14  826    6    9   11   18    5    6    0    0    1    3   15   24   10]
 [  10    4    0    0    1    7    1    1  828   72   16    7    5   11   20    2    4    1    8    1    3]
 [  62    0    1    0    9    2    0    1   39  846    1    5    0   16    9    0    0    3    3    1    3]
 [   0    3   10    4    1    8    5    3   22    4  968    2    0   15    6    2    0    0    6    2    3]
 [   4    1    1    0    1   17    5    3    3    0    0  884   21   24    0   15    2    9    2   17    2]
 [   6    0    1    6    1   14    5    1    3    2    3  105  775   12    3   10    6   21    3   10    8]
 [   6    0    0    0    5   26    1    1   20   20   12   17    2  875    3    1    1    1    0    6    4]
 [  15    7    5   18   13    8    2    0   31   18   12    4    3   12  920    1    0    9    8    0   12]
 [   2    0    2    1    2    1   15    0    0    6    0   33   10    2    0  962   11    7    0   10    2]
 [   5    8    4    1    8   21    1    1   11    2    3   17    1    7    1   10  933    2    1   18   17]
 [   4    1    0    0    1    2    0    1    2    4    3   48   38    6    2   34    0  848    2    5    4]
 [   3   13    8   14    6    4    4   30    9    6   18    6    7    2   21    2    1    5  882    6   11]
 [   3    5    1    0    0   15   12    4    0    2    0   31    7    6    0    4    6    6    2  974   10]
 [ 293  210  226  135  282  399  166  154  184  207  245  344  358  486  213  186  325  165  116  401 8837]]

2024-06-05 23:44:32,637 - ==> Best [Top1: 79.037   Top5: 96.639   Sparsity:0.00   Params: 424448 on epoch: 12]
2024-06-05 23:44:32,637 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:44:32,665 - 

2024-06-05 23:44:32,665 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:44:40,177 - Epoch: [17][  100/ 1218]    Overall Loss 0.471876    Objective Loss 0.471876                                        LR 0.001000    Time 0.075085    
2024-06-05 23:44:45,757 - Epoch: [17][  200/ 1218]    Overall Loss 0.473762    Objective Loss 0.473762                                        LR 0.001000    Time 0.065427    
2024-06-05 23:44:51,636 - Epoch: [17][  300/ 1218]    Overall Loss 0.470636    Objective Loss 0.470636                                        LR 0.001000    Time 0.063207    
2024-06-05 23:44:57,377 - Epoch: [17][  400/ 1218]    Overall Loss 0.472851    Objective Loss 0.472851                                        LR 0.001000    Time 0.061751    
2024-06-05 23:45:02,904 - Epoch: [17][  500/ 1218]    Overall Loss 0.471477    Objective Loss 0.471477                                        LR 0.001000    Time 0.060449    
2024-06-05 23:45:08,677 - Epoch: [17][  600/ 1218]    Overall Loss 0.473865    Objective Loss 0.473865                                        LR 0.001000    Time 0.059991    
2024-06-05 23:45:14,237 - Epoch: [17][  700/ 1218]    Overall Loss 0.473667    Objective Loss 0.473667                                        LR 0.001000    Time 0.059360    
2024-06-05 23:45:20,013 - Epoch: [17][  800/ 1218]    Overall Loss 0.472996    Objective Loss 0.472996                                        LR 0.001000    Time 0.059156    
2024-06-05 23:45:25,357 - Epoch: [17][  900/ 1218]    Overall Loss 0.472049    Objective Loss 0.472049                                        LR 0.001000    Time 0.058516    
2024-06-05 23:45:31,191 - Epoch: [17][ 1000/ 1218]    Overall Loss 0.471206    Objective Loss 0.471206                                        LR 0.001000    Time 0.058496    
2024-06-05 23:45:37,166 - Epoch: [17][ 1100/ 1218]    Overall Loss 0.471519    Objective Loss 0.471519                                        LR 0.001000    Time 0.058607    
2024-06-05 23:45:42,852 - Epoch: [17][ 1200/ 1218]    Overall Loss 0.472317    Objective Loss 0.472317                                        LR 0.001000    Time 0.058460    
2024-06-05 23:45:43,858 - Epoch: [17][ 1218/ 1218]    Overall Loss 0.472062    Objective Loss 0.472062    Top1 81.418093    Top5 98.777506    LR 0.001000    Time 0.058421    
2024-06-05 23:45:44,122 - --- validate (epoch=17)-----------
2024-06-05 23:45:44,123 - 34633 samples (256 per mini-batch)
2024-06-05 23:45:50,763 - Epoch: [17][  100/  136]    Loss 0.482193    Top1 77.519531    Top5 95.574219    
2024-06-05 23:45:52,796 - Epoch: [17][  136/  136]    Loss 0.484278    Top1 77.446366    Top5 95.590910    
2024-06-05 23:45:53,020 - ==> Top1: 77.446    Top5: 95.591    Loss: 0.484

2024-06-05 23:45:53,021 - ==> Confusion:
[[ 825    0    4    0    6    2    0    3   12   48    1    1    1    6    5    2    2    2    2    2    7]
 [   2  904    6    1   25   23    8   20    8    3    6    1    3    2    8    4    7    2   17    8    5]
 [   9    3  853    5    5    2   19   21    1    6    6    9    1    5    0    4    7    1    3    3    7]
 [   6    1   47  858    2    5    4    2    4    1   15    3    7    6   22    4    0    5   20    1    3]
 [  28   12    4    2  920   16    2    5    4   11    5    2    1    7    9    5    6    1    5    3    6]
 [   4   38    2    6   12  830    5   54    2    1    5   13    4   14    6    2    6    2   11   14   12]
 [   2    1   43    2    3    5  978   12    1    1    7    7    3    2    0    4    2    0    1   10    2]
 [   3   12   15    3    4   33    1  911    2    3    5   18    6    6    0    3    1    2   31   13    5]
 [  13    6    2    1    2    3    0    2  850   55   18    0    4   13   12    2    3    3   11    0    2]
 [  99    1    6    0    4    5    0    6   67  777    3    0    2   19    6    0    0    1    1    1    3]
 [   0    1    8   13    2    4    7   10   23    1  937    0    3   15   12    0    3    0   15    3    7]
 [   2    3    0    1    1   12    3   10    1    0    1  876   21   12    1   12    2   19    6   24    4]
 [   3    1    2    7    2    5    0    5    1    1    1  101  763    5    5    6    7   56    5    9   10]
 [   5    0    5    1    6   26    4   15   18   34   10   18    3  822    5    2    4    7    1    5   10]
 [  19    6    3   14    7    2    0    2   48   14   12    1    2   12  934    1    2    2    9    2    6]
 [   2    0    8    2    8    5   15    0    1    4    0   20    5    7    0  957    6   19    0    3    4]
 [   8    4    5    4   10    5    2    1    5    2    2   10    7    6    4   10  962    0    2    9   14]
 [   5    0    2    9    0    1    3    1    1    2    1   25   24    4    5   11    3  900    2    2    4]
 [  10    2   10    8    2    1    0   26   12    2    7    4    2    4   10    1    0    0  943    3   11]
 [   3    5    6    1    3   11   16   12    2    0    0   23    1    5    2    4    8    3    4  975    4]
 [ 351  237  326  159  255  267  146  252  207  134  194  252  396  294  273  128  298  129  242  345 9047]]

2024-06-05 23:45:53,023 - ==> Best [Top1: 79.037   Top5: 96.639   Sparsity:0.00   Params: 424448 on epoch: 12]
2024-06-05 23:45:53,024 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:45:53,049 - 

2024-06-05 23:45:53,049 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:46:00,655 - Epoch: [18][  100/ 1218]    Overall Loss 0.451704    Objective Loss 0.451704                                        LR 0.001000    Time 0.076022    
2024-06-05 23:46:06,372 - Epoch: [18][  200/ 1218]    Overall Loss 0.458511    Objective Loss 0.458511                                        LR 0.001000    Time 0.066582    
2024-06-05 23:46:11,858 - Epoch: [18][  300/ 1218]    Overall Loss 0.461717    Objective Loss 0.461717                                        LR 0.001000    Time 0.062667    
2024-06-05 23:46:17,331 - Epoch: [18][  400/ 1218]    Overall Loss 0.463788    Objective Loss 0.463788                                        LR 0.001000    Time 0.060677    
2024-06-05 23:46:22,779 - Epoch: [18][  500/ 1218]    Overall Loss 0.466065    Objective Loss 0.466065                                        LR 0.001000    Time 0.059432    
2024-06-05 23:46:28,952 - Epoch: [18][  600/ 1218]    Overall Loss 0.464311    Objective Loss 0.464311                                        LR 0.001000    Time 0.059810    
2024-06-05 23:46:34,629 - Epoch: [18][  700/ 1218]    Overall Loss 0.464334    Objective Loss 0.464334                                        LR 0.001000    Time 0.059371    
2024-06-05 23:46:40,276 - Epoch: [18][  800/ 1218]    Overall Loss 0.466772    Objective Loss 0.466772                                        LR 0.001000    Time 0.059006    
2024-06-05 23:46:45,821 - Epoch: [18][  900/ 1218]    Overall Loss 0.467116    Objective Loss 0.467116                                        LR 0.001000    Time 0.058607    
2024-06-05 23:46:51,517 - Epoch: [18][ 1000/ 1218]    Overall Loss 0.466753    Objective Loss 0.466753                                        LR 0.001000    Time 0.058440    
2024-06-05 23:46:57,408 - Epoch: [18][ 1100/ 1218]    Overall Loss 0.467569    Objective Loss 0.467569                                        LR 0.001000    Time 0.058480    
2024-06-05 23:47:02,716 - Epoch: [18][ 1200/ 1218]    Overall Loss 0.468320    Objective Loss 0.468320                                        LR 0.001000    Time 0.058028    
2024-06-05 23:47:03,840 - Epoch: [18][ 1218/ 1218]    Overall Loss 0.468220    Objective Loss 0.468220    Top1 80.929095    Top5 96.821516    LR 0.001000    Time 0.058093    
2024-06-05 23:47:04,046 - --- validate (epoch=18)-----------
2024-06-05 23:47:04,046 - 34633 samples (256 per mini-batch)
2024-06-05 23:47:10,885 - Epoch: [18][  100/  136]    Loss 0.485707    Top1 78.339844    Top5 96.562500    
2024-06-05 23:47:12,855 - Epoch: [18][  136/  136]    Loss 0.487618    Top1 78.338579    Top5 96.650593    
2024-06-05 23:47:13,111 - ==> Top1: 78.339    Top5: 96.651    Loss: 0.488

2024-06-05 23:47:13,112 - ==> Confusion:
[[ 812    0    5    1    8    4    2    0    7   58    1    2    0    2    5    4    3    2    1    1   13]
 [   8  889    4    1   16   35    1   24    5    1   17    3    1    1    4    5    7    1   16   11   13]
 [  10    4  809   32    6    2   29    9    0    3   17    3    2    3    0    5    7    5    4    9   11]
 [  11    3    5  903    0    7    2    3    5    3   23    0   13    3   14    3    1    4    1    6    6]
 [  47   15    7    4  906   14    1    2    2    6    4    1    0    4    8    6    9    2    4    2   10]
 [  13   27    5    9   14  845   11   31    5    6    4    9    7   13    3    2    6    0    3   19   11]
 [   6    1   12    5    1    4  988    5    0    2    9    2    1    1    0   19    2    2    1   15   10]
 [   5    8   14   10    0   50   13  872    2    1    9    5    9    5    3    1    1    0   15   39   15]
 [  19    3    2    3    2    3    0    1  779   75   43    2    9   24   17    0    2    2    5    3    8]
 [  95    0    4    0    9    4    1    3   38  794   12    0    0   22   10    1    1    1    1    0    5]
 [   2    1    3   18    0    2    9    4   10    1  977    0    3   11    5    0    0    2   10    2    4]
 [   6    0    1    0    1   18    4    5    1    3    0  811   61   12    2   19    2   10    0   46    9]
 [   6    0    1    6    0    6    3    4    0    0    1   45  851    5    1    8    2   23    3   17   13]
 [   7    2    1    1    4   24    1    3    9   17   22    9    4  868    3    1    0    2    2   16    5]
 [  14    5    3   31    7    2    1    1   34    7   17    3    9   10  928    0    4    2   12    0    8]
 [   8    2    0    0    3    0    9    0    0    1    0   14    9    2    0  984    7   16    2    5    4]
 [  13    7    2    2    6    2    3    0    5    1    3    6   15    4    0   12  954    2    2   13   20]
 [   4    1    1    9    0    2    2    2    5    1    0   21   63    4    4   13    1  854    0    4   14]
 [   4    6    8   39    0    4    2   31    7    1   23    2    2    1   19    0    0    0  893    7    9]
 [   4    3    4    0    1    6   18    5    0    2    0   10    5    1    0    3    4    2    4 1013    3]
 [ 359  218  249  211  213  220  133  163  101  143  372  123  408  281  207  208  250   80  142  450 9401]]

2024-06-05 23:47:13,115 - ==> Best [Top1: 79.037   Top5: 96.639   Sparsity:0.00   Params: 424448 on epoch: 12]
2024-06-05 23:47:13,115 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:47:13,141 - 

2024-06-05 23:47:13,141 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:47:20,322 - Epoch: [19][  100/ 1218]    Overall Loss 0.453521    Objective Loss 0.453521                                        LR 0.001000    Time 0.071772    
2024-06-05 23:47:26,388 - Epoch: [19][  200/ 1218]    Overall Loss 0.457209    Objective Loss 0.457209                                        LR 0.001000    Time 0.066201    
2024-06-05 23:47:31,937 - Epoch: [19][  300/ 1218]    Overall Loss 0.460557    Objective Loss 0.460557                                        LR 0.001000    Time 0.062625    
2024-06-05 23:47:37,814 - Epoch: [19][  400/ 1218]    Overall Loss 0.463899    Objective Loss 0.463899                                        LR 0.001000    Time 0.061655    
2024-06-05 23:47:43,301 - Epoch: [19][  500/ 1218]    Overall Loss 0.461736    Objective Loss 0.461736                                        LR 0.001000    Time 0.060292    
2024-06-05 23:47:48,899 - Epoch: [19][  600/ 1218]    Overall Loss 0.460025    Objective Loss 0.460025                                        LR 0.001000    Time 0.059569    
2024-06-05 23:47:54,344 - Epoch: [19][  700/ 1218]    Overall Loss 0.460531    Objective Loss 0.460531                                        LR 0.001000    Time 0.058834    
2024-06-05 23:48:00,100 - Epoch: [19][  800/ 1218]    Overall Loss 0.460305    Objective Loss 0.460305                                        LR 0.001000    Time 0.058671    
2024-06-05 23:48:05,695 - Epoch: [19][  900/ 1218]    Overall Loss 0.460291    Objective Loss 0.460291                                        LR 0.001000    Time 0.058365    
2024-06-05 23:48:11,385 - Epoch: [19][ 1000/ 1218]    Overall Loss 0.461136    Objective Loss 0.461136                                        LR 0.001000    Time 0.058216    
2024-06-05 23:48:17,030 - Epoch: [19][ 1100/ 1218]    Overall Loss 0.461259    Objective Loss 0.461259                                        LR 0.001000    Time 0.058054    
2024-06-05 23:48:22,840 - Epoch: [19][ 1200/ 1218]    Overall Loss 0.460676    Objective Loss 0.460676                                        LR 0.001000    Time 0.058055    
2024-06-05 23:48:23,764 - Epoch: [19][ 1218/ 1218]    Overall Loss 0.460799    Objective Loss 0.460799    Top1 77.995110    Top5 97.066015    LR 0.001000    Time 0.057955    
2024-06-05 23:48:23,990 - --- validate (epoch=19)-----------
2024-06-05 23:48:23,990 - 34633 samples (256 per mini-batch)
2024-06-05 23:48:30,409 - Epoch: [19][  100/  136]    Loss 0.486057    Top1 79.105469    Top5 96.593750    
2024-06-05 23:48:32,264 - Epoch: [19][  136/  136]    Loss 0.479655    Top1 79.103745    Top5 96.589958    
2024-06-05 23:48:32,459 - ==> Top1: 79.104    Top5: 96.590    Loss: 0.480

2024-06-05 23:48:32,460 - ==> Confusion:
[[ 697    0    7    3    8    1    0    1   17  147    1    7    1    4   10    2    2    8    1    1   13]
 [   0  891    2    0   19   40    3   12    5    6    6    5    4    5   11    2   19    3   13    4   13]
 [   3    2  814   29    5    2   21   12    2    9   10    7    4    5    5    4    7    7    5    1   16]
 [   1    0    6  893    2    4    3    1    4    3   29    4    6    6   28    0    5    9    2    3    7]
 [  17    6    6    1  934   13    0    0    5   23    2    6    1    5   16    2    9    3    1    0    4]
 [   4   29    0    5   19  865    5   23    5    5    2   18    9   12    2    0    6    6    2    9   17]
 [   0    0   23    7    1    2  984    6    3    1    5    2    3    2    1    9    5   12    0   12    8]
 [   6   11   15    5    0   45    4  866    4   10   10   16    7    6    2    0    1    3   29   17   20]
 [   5    3    1    1    1    1    0    2  810   81   21    6    6   19   26    0    2    7    3    1    6]
 [  39    0    5    0    1    1    0    2   38  855    1    1    2   27    8    1    1    4    3    1   11]
 [   1    1    6   19    2    2    3    6   18    0  962    2    3   12   11    1    1    0    7    1    6]
 [   2    2    0    0    0   14    3    2    3    2    0  842   57    6    2   19    3   32    0   13    9]
 [   0    1    1   11    1    6    1    1    3    1    2   49  810    6    2   10    6   67    2    5   10]
 [   2    1    0    0    6   18    0    2    8   23    9   15    7  868    7    3    4    6    5    3   14]
 [   8    4    1   28    7    2    0    0   41   15   10    3    3   10  941    0    2    1   12    2    8]
 [   0    1    1    1    3    2    6    0    0    2    1   26   14    3    0  964   11   27    0    1    3]
 [   1    5    3    1    3   10    0    0    9    0    4   13    6    4    3    8  974    5    1    7   15]
 [   3    1    0    2    1    3    2    2    2    3    1    8   29    4    6    7    1  924    2    1    3]
 [   0    2    4   24    4    1    1   24   14    2   18    3    3    1   27    0    3    3  910    1   13]
 [   2    4    1    2    1   14   11    4    0    2    3   25   15    8    1    6   14    7    4  950   14]
 [ 202  165  192  231  189  231   78  152  156  205  257  175  392  293  274  179  308  216  171  224 9642]]

2024-06-05 23:48:32,463 - ==> Best [Top1: 79.104   Top5: 96.590   Sparsity:0.00   Params: 424448 on epoch: 19]
2024-06-05 23:48:32,463 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:48:32,504 - 

2024-06-05 23:48:32,504 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:48:39,838 - Epoch: [20][  100/ 1218]    Overall Loss 0.453325    Objective Loss 0.453325                                        LR 0.001000    Time 0.073302    
2024-06-05 23:48:45,253 - Epoch: [20][  200/ 1218]    Overall Loss 0.456691    Objective Loss 0.456691                                        LR 0.001000    Time 0.063713    
2024-06-05 23:48:50,921 - Epoch: [20][  300/ 1218]    Overall Loss 0.455353    Objective Loss 0.455353                                        LR 0.001000    Time 0.061359    
2024-06-05 23:48:56,606 - Epoch: [20][  400/ 1218]    Overall Loss 0.453135    Objective Loss 0.453135                                        LR 0.001000    Time 0.060226    
2024-06-05 23:49:02,249 - Epoch: [20][  500/ 1218]    Overall Loss 0.455716    Objective Loss 0.455716                                        LR 0.001000    Time 0.059461    
2024-06-05 23:49:07,883 - Epoch: [20][  600/ 1218]    Overall Loss 0.454896    Objective Loss 0.454896                                        LR 0.001000    Time 0.058937    
2024-06-05 23:49:13,691 - Epoch: [20][  700/ 1218]    Overall Loss 0.454293    Objective Loss 0.454293                                        LR 0.001000    Time 0.058810    
2024-06-05 23:49:19,484 - Epoch: [20][  800/ 1218]    Overall Loss 0.454926    Objective Loss 0.454926                                        LR 0.001000    Time 0.058697    
2024-06-05 23:49:24,786 - Epoch: [20][  900/ 1218]    Overall Loss 0.454664    Objective Loss 0.454664                                        LR 0.001000    Time 0.058063    
2024-06-05 23:49:30,154 - Epoch: [20][ 1000/ 1218]    Overall Loss 0.453778    Objective Loss 0.453778                                        LR 0.001000    Time 0.057623    
2024-06-05 23:49:35,916 - Epoch: [20][ 1100/ 1218]    Overall Loss 0.454084    Objective Loss 0.454084                                        LR 0.001000    Time 0.057620    
2024-06-05 23:49:41,894 - Epoch: [20][ 1200/ 1218]    Overall Loss 0.454481    Objective Loss 0.454481                                        LR 0.001000    Time 0.057798    
2024-06-05 23:49:42,997 - Epoch: [20][ 1218/ 1218]    Overall Loss 0.454581    Objective Loss 0.454581    Top1 78.484108    Top5 96.088020    LR 0.001000    Time 0.057849    
2024-06-05 23:49:43,208 - --- validate (epoch=20)-----------
2024-06-05 23:49:43,208 - 34633 samples (256 per mini-batch)
2024-06-05 23:49:49,733 - Epoch: [20][  100/  136]    Loss 0.461225    Top1 80.664062    Top5 96.785156    
2024-06-05 23:49:51,803 - Epoch: [20][  136/  136]    Loss 0.460429    Top1 80.677389    Top5 96.806514    
2024-06-05 23:49:52,057 - ==> Top1: 80.677    Top5: 96.807    Loss: 0.460

2024-06-05 23:49:52,059 - ==> Confusion:
[[  812     0     6     1    15     1     1     2    12    60     0     1     3     7     1     1     0     2     2     1     3]
 [    3   913     4     1    18    43     2    13     4     2     5     3     3     5     2     2     2     3     7     3    25]
 [    4     4   815    34     9     5    24     6     0     8    13     3     4     8     1     3     5     0     3     3    18]
 [    3     0     6   905     2     7     4     1     2     3    27     2     9     7    20     2     1     1     5     0     9]
 [   21    12     2     0   928    16     0     1     6     9     4     2     0    11     5    11     4     1     3     5    13]
 [    7    31     0     2    13   872     4    15     2     4     8    25    13    23     3     1     1     3     1     3    12]
 [    3     3    17     2     2     6   989     5     0     1     8     6     5     3     0    12     1     2     1    12     8]
 [    6    24    12     3     1    68     0   859     5     5    14    16     7     6     0     0     0     3    29     8    11]
 [   15     4     2     0     2     1     0     0   862    37    21     3     6    13    15     1     1     1     6     2    10]
 [   76     0     2     1    11     4     0     3    84   780     1     1     3    22     5     1     2     0     0     0     5]
 [    1     5     3    11     1     3     5     2    16     2   972     0     5    12     4     2     0     1     9     1     9]
 [    3     1     1     0     0    12     4     4     2     0     1   877    54    12     0     7     4    19     1     2     7]
 [    1     0     2     4     0     3     1     2     3     2     0    68   826    12     3     1     3    40     3     5    16]
 [    4     2     2     2     6     8     0     2    28    17     9    17     8   848     4     4     7     7     0     6    20]
 [   17     4     3    27     9     1     0     1    32    15    18     1     3    10   923     0     2     2     7     0    23]
 [    7     1     7     2     1     4     5     0     0     3     0    27    17     5     0   958     5    16     1     1     6]
 [    3     5     5     4     3    10     1     0     3     5     2     7    14     7     4    14   954     2     0     5    24]
 [    3     2     1     4     1     0     2     2     1     1     0    19    25     5     5    12     1   907     1     2    11]
 [    4     7    10    35     0     3     1    24     4     2    13     5     5     2    24     0     1     2   901     1    14]
 [    5     4     4     1     0    16    14    12     2     2     2    40    13    11     1     9    11     4     6   905    26]
 [  297   173   186   166   223   225    90   138   142   135   231   239   402   270   184   104   185   115   150   142 10135]]

2024-06-05 23:49:52,064 - ==> Best [Top1: 80.677   Top5: 96.807   Sparsity:0.00   Params: 424448 on epoch: 20]
2024-06-05 23:49:52,064 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:49:52,105 - 

2024-06-05 23:49:52,106 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:49:59,569 - Epoch: [21][  100/ 1218]    Overall Loss 0.458644    Objective Loss 0.458644                                        LR 0.001000    Time 0.074596    
2024-06-05 23:50:05,218 - Epoch: [21][  200/ 1218]    Overall Loss 0.446600    Objective Loss 0.446600                                        LR 0.001000    Time 0.065527    
2024-06-05 23:50:10,694 - Epoch: [21][  300/ 1218]    Overall Loss 0.446512    Objective Loss 0.446512                                        LR 0.001000    Time 0.061932    
2024-06-05 23:50:16,059 - Epoch: [21][  400/ 1218]    Overall Loss 0.445414    Objective Loss 0.445414                                        LR 0.001000    Time 0.059855    
2024-06-05 23:50:21,481 - Epoch: [21][  500/ 1218]    Overall Loss 0.444876    Objective Loss 0.444876                                        LR 0.001000    Time 0.058721    
2024-06-05 23:50:26,826 - Epoch: [21][  600/ 1218]    Overall Loss 0.445310    Objective Loss 0.445310                                        LR 0.001000    Time 0.057839    
2024-06-05 23:50:32,160 - Epoch: [21][  700/ 1218]    Overall Loss 0.445580    Objective Loss 0.445580                                        LR 0.001000    Time 0.057193    
2024-06-05 23:50:37,719 - Epoch: [21][  800/ 1218]    Overall Loss 0.446086    Objective Loss 0.446086                                        LR 0.001000    Time 0.056989    
2024-06-05 23:50:43,463 - Epoch: [21][  900/ 1218]    Overall Loss 0.447009    Objective Loss 0.447009                                        LR 0.001000    Time 0.057036    
2024-06-05 23:50:49,117 - Epoch: [21][ 1000/ 1218]    Overall Loss 0.447840    Objective Loss 0.447840                                        LR 0.001000    Time 0.056984    
2024-06-05 23:50:54,563 - Epoch: [21][ 1100/ 1218]    Overall Loss 0.447737    Objective Loss 0.447737                                        LR 0.001000    Time 0.056752    
2024-06-05 23:50:59,959 - Epoch: [21][ 1200/ 1218]    Overall Loss 0.447928    Objective Loss 0.447928                                        LR 0.001000    Time 0.056518    
2024-06-05 23:51:01,104 - Epoch: [21][ 1218/ 1218]    Overall Loss 0.447590    Objective Loss 0.447590    Top1 78.973105    Top5 96.332518    LR 0.001000    Time 0.056622    
2024-06-05 23:51:01,356 - --- validate (epoch=21)-----------
2024-06-05 23:51:01,356 - 34633 samples (256 per mini-batch)
2024-06-05 23:51:08,193 - Epoch: [21][  100/  136]    Loss 0.447078    Top1 80.167969    Top5 96.921875    
2024-06-05 23:51:10,174 - Epoch: [21][  136/  136]    Loss 0.447996    Top1 80.154766    Top5 96.893137    
2024-06-05 23:51:10,418 - ==> Top1: 80.155    Top5: 96.893    Loss: 0.448

2024-06-05 23:51:10,420 - ==> Confusion:
[[ 830    1    4    1    8    0    1    2    8   54    1    5    4    1    3    0    1    2    1    0    4]
 [   1  864    4    0   26   74    5   11    4    0    7   10    4    2    7    2    7    2   15    9    9]
 [  10    2  874    5    3    1   12    8    0    8   11    5    1    3    3    4    7    1    6    2    4]
 [   6    2   28  861    6    9    3    3    0    1   22    3   11    2   21    4    3    6   16    2    7]
 [  30    8    3    0  935   24    1    0    1   10    4    3    3    3    8    3    6    0    3    1    8]
 [   8    8    5    3   12  858    6   33    2    2    4   25   12   27    1    2    8    0    8   11    8]
 [   1    1   27    1    4    5  989    1    1    1    5    5    5    3    2    6    1    5    5   13    5]
 [   3    9   15    3    1   46    9  874    1    2    3   29    7    6    0    0    0    2   31   20   16]
 [  15    5    0    0    4    1    0    1  826   59   12    3    8   22   28    0    0    5    8    0    5]
 [ 100    1    3    0   10    1    1    1   36  808    5    1    2   13   10    1    0    3    1    2    2]
 [   2    1    8    4    5    0    1    3   18    2  968    1    3   12    7    0    1    1    9    1   17]
 [   1    2    0    0    1   13    3    2    2    1    0  828   67   11    1   18    1   40    0   13    7]
 [   0    2    2    2    1    2    0    1    3    1    0   48  857    4    3    6    2   40    5    5   11]
 [   8    0    1    0    4   14    0    3   14   20    4   17    9  877    6    3    2    6    0    3   10]
 [  15    3    4   15   14    2    0    0   26   10    6    2    5    5  963    0    0    2   18    0    8]
 [   4    0    8    0    4    3   15    0    0    3    0   26    8    0    1  967    9   11    0    0    7]
 [  10   11    5    3   14   12    1    1    5    2    1    8    5    2    3   10  946    3    2    8   20]
 [   4    0    1    4    2    0    2    1    0    2    0   19   30    2    1    8    0  922    2    2    3]
 [   7    4    5    7    6    2    2   22    3    0    8    3    5    3    9    1    2    1  961    1    6]
 [   5    3    2    0    2    7   15    9    0    1    3   39   14    9    0    3    5    6    5  942   18]
 [ 348  120  267   91  337  232   98  148  120  148  210  224  381  252  216  150  201  153  217  209 9810]]

2024-06-05 23:51:10,423 - ==> Best [Top1: 80.677   Top5: 96.807   Sparsity:0.00   Params: 424448 on epoch: 20]
2024-06-05 23:51:10,423 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:51:10,455 - 

2024-06-05 23:51:10,456 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:51:17,553 - Epoch: [22][  100/ 1218]    Overall Loss 0.428371    Objective Loss 0.428371                                        LR 0.001000    Time 0.070930    
2024-06-05 23:51:23,551 - Epoch: [22][  200/ 1218]    Overall Loss 0.440281    Objective Loss 0.440281                                        LR 0.001000    Time 0.065410    
2024-06-05 23:51:28,943 - Epoch: [22][  300/ 1218]    Overall Loss 0.441806    Objective Loss 0.441806                                        LR 0.001000    Time 0.061570    
2024-06-05 23:51:34,271 - Epoch: [22][  400/ 1218]    Overall Loss 0.444259    Objective Loss 0.444259                                        LR 0.001000    Time 0.059491    
2024-06-05 23:51:39,746 - Epoch: [22][  500/ 1218]    Overall Loss 0.441863    Objective Loss 0.441863                                        LR 0.001000    Time 0.058538    
2024-06-05 23:51:45,333 - Epoch: [22][  600/ 1218]    Overall Loss 0.443209    Objective Loss 0.443209                                        LR 0.001000    Time 0.058090    
2024-06-05 23:51:50,714 - Epoch: [22][  700/ 1218]    Overall Loss 0.443862    Objective Loss 0.443862                                        LR 0.001000    Time 0.057475    
2024-06-05 23:51:56,296 - Epoch: [22][  800/ 1218]    Overall Loss 0.443835    Objective Loss 0.443835                                        LR 0.001000    Time 0.057264    
2024-06-05 23:52:01,482 - Epoch: [22][  900/ 1218]    Overall Loss 0.441791    Objective Loss 0.441791                                        LR 0.001000    Time 0.056661    
2024-06-05 23:52:06,851 - Epoch: [22][ 1000/ 1218]    Overall Loss 0.442487    Objective Loss 0.442487                                        LR 0.001000    Time 0.056360    
2024-06-05 23:52:12,342 - Epoch: [22][ 1100/ 1218]    Overall Loss 0.441837    Objective Loss 0.441837                                        LR 0.001000    Time 0.056227    
2024-06-05 23:52:17,909 - Epoch: [22][ 1200/ 1218]    Overall Loss 0.441369    Objective Loss 0.441369                                        LR 0.001000    Time 0.056178    
2024-06-05 23:52:18,801 - Epoch: [22][ 1218/ 1218]    Overall Loss 0.442146    Objective Loss 0.442146    Top1 76.772616    Top5 96.088020    LR 0.001000    Time 0.056079    
2024-06-05 23:52:19,052 - --- validate (epoch=22)-----------
2024-06-05 23:52:19,052 - 34633 samples (256 per mini-batch)
2024-06-05 23:52:25,345 - Epoch: [22][  100/  136]    Loss 0.451261    Top1 80.699219    Top5 96.910156    
2024-06-05 23:52:27,458 - Epoch: [22][  136/  136]    Loss 0.446287    Top1 80.642740    Top5 96.945110    
2024-06-05 23:52:27,649 - ==> Top1: 80.643    Top5: 96.945    Loss: 0.446

2024-06-05 23:52:27,651 - ==> Confusion:
[[  797     0     2     0     5     1     0     2    17    71     0     2     2     6     7     2     2     0     2     1    12]
 [    0   902     4     2    20    21     1    29     8     3     9     4     3     3     7     0     7     1    23     4    12]
 [   11     1   828    10     6     2    22    23     2     7    12     2     2     6     2     4     2     1     9     2    16]
 [    4     0    16   879     3     7     3     4     1     4    21     0     3     6    22     1     1     6    21     3    11]
 [   37    13     5     0   893     7     0     3     5    21     1     3     2     8    23     7    10     1     4     1    10]
 [    2    32     4     5    13   804     4    78     3    11     6    20     2    17     1     0     5     2     8     8    18]
 [    2     5    21     3     3     3   976     9     0     4     9     1     0     4     1    10     2     4     4    13    12]
 [    2    12     7     5     2    14     2   946     2     5     4     7     3     3     0     0     1     0    45     9     8]
 [    8     3     0     1     2     1     0     1   872    46     9     0     7    14    15     2     2     1     5     1    12]
 [   62     1     0     0     5     1     0     1    71   824     0     0     0    18    10     0     1     1     1     0     5]
 [    0     3     4    11     1     6     1     7    24     4   947     1     1    17     6     0     3     0    22     2     4]
 [    3     2     2     0     0     7     2     9     0     6     2   847    36    21     2    14     5    17     4    23     9]
 [    0     0     3     5     2     1     0     4     6     3     3    73   802    16     2     5     2    50     2     5    11]
 [    2     2     1     1     5    11     0     8    15    24     8     8     3   879     4     3     2     5     3     6    11]
 [    7     2     3    17     8     2     0     3    44     9     8     2     4    13   939     0     1     2    21     0    13]
 [    3     2     6     3     3     0     4     0     1     5     1    15    13     9     0   960     9    17     0     1    14]
 [    2     3     1     1     6     4     3     3     8     4     3     3     4     3     0    10   972     2     7     9    24]
 [    3     1     7     4     1     2     1     4     2     4     1    12    29     6     3    10     0   904     4     1     6]
 [    3     1     7    15     1     1     2    31     8     3     7     0     2     2    20     1     0     0   944     4     6]
 [    1     6     3     1     1    12     8    15     1     3     1     9     9     3     1     5     8     3     5   981    12]
 [  189   146   193   107   157   147    79   203   172   176   194   153   353   335   211   111   272   108   298   295 10033]]

2024-06-05 23:52:27,664 - ==> Best [Top1: 80.677   Top5: 96.807   Sparsity:0.00   Params: 424448 on epoch: 20]
2024-06-05 23:52:27,664 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:52:27,689 - 

2024-06-05 23:52:27,690 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:52:34,753 - Epoch: [23][  100/ 1218]    Overall Loss 0.427918    Objective Loss 0.427918                                        LR 0.001000    Time 0.070595    
2024-06-05 23:52:40,361 - Epoch: [23][  200/ 1218]    Overall Loss 0.434961    Objective Loss 0.434961                                        LR 0.001000    Time 0.063325    
2024-06-05 23:52:46,309 - Epoch: [23][  300/ 1218]    Overall Loss 0.436689    Objective Loss 0.436689                                        LR 0.001000    Time 0.062035    
2024-06-05 23:52:51,471 - Epoch: [23][  400/ 1218]    Overall Loss 0.438110    Objective Loss 0.438110                                        LR 0.001000    Time 0.059425    
2024-06-05 23:52:56,707 - Epoch: [23][  500/ 1218]    Overall Loss 0.439592    Objective Loss 0.439592                                        LR 0.001000    Time 0.058007    
2024-06-05 23:53:01,926 - Epoch: [23][  600/ 1218]    Overall Loss 0.439015    Objective Loss 0.439015                                        LR 0.001000    Time 0.057032    
2024-06-05 23:53:07,266 - Epoch: [23][  700/ 1218]    Overall Loss 0.440141    Objective Loss 0.440141                                        LR 0.001000    Time 0.056510    
2024-06-05 23:53:12,703 - Epoch: [23][  800/ 1218]    Overall Loss 0.438967    Objective Loss 0.438967                                        LR 0.001000    Time 0.056236    
2024-06-05 23:53:17,838 - Epoch: [23][  900/ 1218]    Overall Loss 0.439716    Objective Loss 0.439716                                        LR 0.001000    Time 0.055691    
2024-06-05 23:53:23,382 - Epoch: [23][ 1000/ 1218]    Overall Loss 0.438997    Objective Loss 0.438997                                        LR 0.001000    Time 0.055663    
2024-06-05 23:53:28,639 - Epoch: [23][ 1100/ 1218]    Overall Loss 0.438689    Objective Loss 0.438689                                        LR 0.001000    Time 0.055379    
2024-06-05 23:53:33,903 - Epoch: [23][ 1200/ 1218]    Overall Loss 0.439171    Objective Loss 0.439171                                        LR 0.001000    Time 0.055148    
2024-06-05 23:53:34,855 - Epoch: [23][ 1218/ 1218]    Overall Loss 0.439325    Objective Loss 0.439325    Top1 80.195599    Top5 95.354523    LR 0.001000    Time 0.055115    
2024-06-05 23:53:35,118 - --- validate (epoch=23)-----------
2024-06-05 23:53:35,118 - 34633 samples (256 per mini-batch)
2024-06-05 23:53:41,312 - Epoch: [23][  100/  136]    Loss 0.453453    Top1 79.847656    Top5 96.578125    
2024-06-05 23:53:43,093 - Epoch: [23][  136/  136]    Loss 0.456498    Top1 79.750527    Top5 96.598620    
2024-06-05 23:53:43,302 - ==> Top1: 79.751    Top5: 96.599    Loss: 0.456

2024-06-05 23:53:43,304 - ==> Confusion:
[[ 741    3    4    0   10    2    0    2   16  114    0    3    6    5    6    2    2    1    0    3   11]
 [   5  950    2    1    5   24    7   17    1    1    3    3    1    2    5    1    6    5    8    4   12]
 [   6    4  817   22    6    1   14   28    2    3   11    3    4    5    3    4    4    1    6   15   11]
 [   3    2   10  892    0    7    4    4    1    1   18    3    8    2   21    1    2   14   12    1   10]
 [  22   36    6    1  887   16    0    4    1   11    2    4    1    6   19    5   19    0    4    1    9]
 [   3   27    3    2    7  835    3   59    3    3    6   15    5   31   11    0    4    4    0   15    7]
 [   3    9   26    0    2    5  976   10    0    2    2    6    0    4    0   10    2    5    1   16    7]
 [   3   15   10    1    0   13    2  936    0    2    5   13    2   11    1    1    1    3   23   25   10]
 [   7    8    1    1    2    1    0    2  839   50   11    4    5   32   19    0    0    4    4    3    9]
 [  45    4    1    1    6    1    0    3   57  827    3    3    1   34    6    0    0    1    0    1    7]
 [   0    5    6   12    0    3    1    8   17    2  957    0    0   18    5    0    0    3    9    4   14]
 [   5    3    1    0    1   12    2    8    3    1    0  864   16   25    2   15    1   27    0   24    1]
 [   3    1    1    6    1    5    0    4    2    0    1   99  749   15    5    6    2   68    6    7   14]
 [   2    0    1    0    4    9    0    5    8   14    6    7    7  911    2    2    5    4    0    6    8]
 [   7   11    4   21    7    4    1    2   31    9   15    3    2   16  938    0    0    4   10    1   12]
 [   7    2    6    1    2    1   14    0    0    2    0   15    7    5    0  963   10   25    1    2    3]
 [   2   15    7    2    5    3    2    3    8    1    4    9    0    4    0   11  958    2    1   12   23]
 [   1    6    0    3    0    1    1    2    1    4    0   17    9    9    3   14    2  920    1    2    9]
 [   2   11    4   14    1    1    2   40    1    2   11    2    1    0   13    0    1    1  938    2   11]
 [   2    6    0    1    0    7    7   11    0    0    1   26   10   12    0    5    5    7    0  981    7]
 [ 140  355  184  140  145  185   95  292  120  127  195  227  269  366  209  115  253  195  180  399 9741]]

2024-06-05 23:53:43,308 - ==> Best [Top1: 80.677   Top5: 96.807   Sparsity:0.00   Params: 424448 on epoch: 20]
2024-06-05 23:53:43,309 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:53:43,337 - 

2024-06-05 23:53:43,338 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:53:50,155 - Epoch: [24][  100/ 1218]    Overall Loss 0.418297    Objective Loss 0.418297                                        LR 0.001000    Time 0.068140    
2024-06-05 23:53:55,401 - Epoch: [24][  200/ 1218]    Overall Loss 0.426983    Objective Loss 0.426983                                        LR 0.001000    Time 0.060283    
2024-06-05 23:54:00,526 - Epoch: [24][  300/ 1218]    Overall Loss 0.430579    Objective Loss 0.430579                                        LR 0.001000    Time 0.057266    
2024-06-05 23:54:05,546 - Epoch: [24][  400/ 1218]    Overall Loss 0.428662    Objective Loss 0.428662                                        LR 0.001000    Time 0.055491    
2024-06-05 23:54:10,734 - Epoch: [24][  500/ 1218]    Overall Loss 0.428872    Objective Loss 0.428872                                        LR 0.001000    Time 0.054765    
2024-06-05 23:54:15,855 - Epoch: [24][  600/ 1218]    Overall Loss 0.429800    Objective Loss 0.429800                                        LR 0.001000    Time 0.054168    
2024-06-05 23:54:21,163 - Epoch: [24][  700/ 1218]    Overall Loss 0.429794    Objective Loss 0.429794                                        LR 0.001000    Time 0.054009    
2024-06-05 23:54:26,471 - Epoch: [24][  800/ 1218]    Overall Loss 0.430023    Objective Loss 0.430023                                        LR 0.001000    Time 0.053889    
2024-06-05 23:54:31,455 - Epoch: [24][  900/ 1218]    Overall Loss 0.430518    Objective Loss 0.430518                                        LR 0.001000    Time 0.053436    
2024-06-05 23:54:36,419 - Epoch: [24][ 1000/ 1218]    Overall Loss 0.432505    Objective Loss 0.432505                                        LR 0.001000    Time 0.053054    
2024-06-05 23:54:41,609 - Epoch: [24][ 1100/ 1218]    Overall Loss 0.432314    Objective Loss 0.432314                                        LR 0.001000    Time 0.052946    
2024-06-05 23:54:46,931 - Epoch: [24][ 1200/ 1218]    Overall Loss 0.433091    Objective Loss 0.433091                                        LR 0.001000    Time 0.052967    
2024-06-05 23:54:47,959 - Epoch: [24][ 1218/ 1218]    Overall Loss 0.432662    Objective Loss 0.432662    Top1 81.907090    Top5 96.577017    LR 0.001000    Time 0.053027    
2024-06-05 23:54:48,185 - --- validate (epoch=24)-----------
2024-06-05 23:54:48,185 - 34633 samples (256 per mini-batch)
2024-06-05 23:54:54,359 - Epoch: [24][  100/  136]    Loss 0.450152    Top1 80.328125    Top5 97.019531    
2024-06-05 23:54:56,172 - Epoch: [24][  136/  136]    Loss 0.449631    Top1 80.475269    Top5 97.025958    
2024-06-05 23:54:56,377 - ==> Top1: 80.475    Top5: 97.026    Loss: 0.450

2024-06-05 23:54:56,378 - ==> Confusion:
[[ 737    3    4    0   10    0    2    1   18  122    0    4    1    1    4    0    1    1    2    5   15]
 [   1  942    4    1   16   18    5   17    5    3    5    7    2    1    4    2    3    2   14    6    5]
 [  11    3  856    6    5    1   37    8    2    8    2    1    4    4    1    2    7    1    2    2    7]
 [   4    3   23  877    4    5    3    1    3    3   30    3    2    2   15    2    3    3   16    2   12]
 [  19   15    4    0  947    9    1    2    1   19    0    6    2    3    2    2    9    2    1    2    8]
 [   9   39    2    9   18  813    4   62    3    5    8   12    3   23    2    1    3    1    5   12    9]
 [   5    2   24    1    0    4  983    9    0    1    9    3    3    2    0    6    1    6    0   21    6]
 [   5   10   12    6    2   26    7  921    3    4   16    8    4    3    0    1    0    0   28   13    8]
 [  10    6    0    1    0    4    0    3  838   52   27    4    3   23   14    1    1    0    8    2    5]
 [  40    1    0    0    3    1    0    1   50  865    2    3    0   19    4    0    1    2    3    1    5]
 [   2    3   13    5    1    3    6    4    8    2  980    0    1    9    4    0    0    0   11    4    8]
 [   6    2    3    0    1   18    2   10    1    1    3  824   44   20    0    9    2   26    1   28   10]
 [   2    0    5   11    1    3    2    2    3    1    6   67  806    4    2    5    3   43    6    7   16]
 [   4    0    4    2    7   16    4    2   15   24   21    8    2  853    4    2    0    4    2   10   17]
 [   8    9    8   18   19    1    0    0   56   18   19    1    1    7  897    1    0    2   15    1   17]
 [   4    0    4    1    5    0    9    0    0    1    2   22    8    3    0  963   12   17    1    6    8]
 [   5   13    2    0    5    5    2    2    4    0    4   11    4    3    1    7  972    2    1   11   18]
 [   3    1    1    4    2    2    2    4    0    3    0   13   13    7    6    6    2  926    0    5    5]
 [   5    6   15   17    1    2    2   21   15    2   12    4    3    1    8    0    1    3  926    5    9]
 [   3    2    4    0    1    7   11    9    2    1    0   15    3    8    0    2   10    5    3  998    4]
 [ 165  281  217   88  218  139  149  233  149  166  273  177  329  254  139  114  230  131  170  363 9947]]

2024-06-05 23:54:56,388 - ==> Best [Top1: 80.677   Top5: 96.807   Sparsity:0.00   Params: 424448 on epoch: 20]
2024-06-05 23:54:56,388 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:54:56,412 - 

2024-06-05 23:54:56,412 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:55:03,247 - Epoch: [25][  100/ 1218]    Overall Loss 0.427765    Objective Loss 0.427765                                        LR 0.001000    Time 0.068312    
2024-06-05 23:55:08,627 - Epoch: [25][  200/ 1218]    Overall Loss 0.427126    Objective Loss 0.427126                                        LR 0.001000    Time 0.061040    
2024-06-05 23:55:13,853 - Epoch: [25][  300/ 1218]    Overall Loss 0.427850    Objective Loss 0.427850                                        LR 0.001000    Time 0.058106    
2024-06-05 23:55:19,059 - Epoch: [25][  400/ 1218]    Overall Loss 0.427736    Objective Loss 0.427736                                        LR 0.001000    Time 0.056588    
2024-06-05 23:55:24,348 - Epoch: [25][  500/ 1218]    Overall Loss 0.429387    Objective Loss 0.429387                                        LR 0.001000    Time 0.055844    
2024-06-05 23:55:29,324 - Epoch: [25][  600/ 1218]    Overall Loss 0.429146    Objective Loss 0.429146                                        LR 0.001000    Time 0.054825    
2024-06-05 23:55:34,305 - Epoch: [25][  700/ 1218]    Overall Loss 0.430732    Objective Loss 0.430732                                        LR 0.001000    Time 0.054105    
2024-06-05 23:55:39,612 - Epoch: [25][  800/ 1218]    Overall Loss 0.430998    Objective Loss 0.430998                                        LR 0.001000    Time 0.053972    
2024-06-05 23:55:44,741 - Epoch: [25][  900/ 1218]    Overall Loss 0.429758    Objective Loss 0.429758                                        LR 0.001000    Time 0.053671    
2024-06-05 23:55:49,898 - Epoch: [25][ 1000/ 1218]    Overall Loss 0.430077    Objective Loss 0.430077                                        LR 0.001000    Time 0.053459    
2024-06-05 23:55:55,094 - Epoch: [25][ 1100/ 1218]    Overall Loss 0.430117    Objective Loss 0.430117                                        LR 0.001000    Time 0.053320    
2024-06-05 23:56:00,145 - Epoch: [25][ 1200/ 1218]    Overall Loss 0.429579    Objective Loss 0.429579                                        LR 0.001000    Time 0.053084    
2024-06-05 23:56:01,135 - Epoch: [25][ 1218/ 1218]    Overall Loss 0.429170    Objective Loss 0.429170    Top1 81.907090    Top5 95.599022    LR 0.001000    Time 0.053111    
2024-06-05 23:56:01,372 - --- validate (epoch=25)-----------
2024-06-05 23:56:01,372 - 34633 samples (256 per mini-batch)
2024-06-05 23:56:07,837 - Epoch: [25][  100/  136]    Loss 0.442385    Top1 80.648438    Top5 96.882812    
2024-06-05 23:56:09,761 - Epoch: [25][  136/  136]    Loss 0.441610    Top1 80.394422    Top5 96.835388    
2024-06-05 23:56:10,019 - ==> Top1: 80.394    Top5: 96.835    Loss: 0.442

2024-06-05 23:56:10,021 - ==> Confusion:
[[ 844    3    1    0    8    0    0    3    7   44    0    1    5    3    3    1    1    1    2    1    3]
 [   4  945    2    2   21   15    3    8    5    4    5    3    5    3   10    1    2    2    8    2   13]
 [  11    6  830   10    8    2   21   14    1   11    8    6    7    4    6    1    5    3    5    1   10]
 [   2    1   14  875    5    6    2    4    2    1   14    1    6    6   47    3    0    8   10    1    8]
 [  30   10    1    0  935    8    0    1    4   13    2    3    4   12   13    3    6    1    1    0    7]
 [   7   31    2    7   23  825    7   48    3    9    3   12    4   31    3    0    4    1    5   11    7]
 [   3    3   23    2    3    6  978   13    2    1   11    1    8    3    1    7    1    3    4    7    6]
 [   5   19    6    2    5   20    3  914    6    2    2    9    8    6    1    2    1    0   38   20    8]
 [  16    5    0    0    0    0    0    0  854   33    5    3    8   19   35    2    3    2    4    0   13]
 [  94    0    1    0    4    3    1    1   65  782    1    2    4   18   14    0    0    2    0    0    9]
 [   0    9    5   16    2    2    0    8   16    3  918    0    1   16   31    0    0    0   15    4   18]
 [   1    0    0    0    2   29    3   12    1    1    1  826   47   23    1    9    1   25    5   18    6]
 [   1    2    3    4    0    9    2    5    5    0    3   52  832    8    2    8    3   28    5    8   15]
 [   4    0    2    1    2   12    0    3   15   24    8    2   10  877   10    4    1    5    1    2   18]
 [  11    5    1   13    7    2    0    3   25   10    0    1    4    6  992    0    1    2    4    1   10]
 [   2    1    2    1    1    0    9    1    2    4    0   26    8    3    0  970    7   18    1    2    8]
 [   2    8    3    4    8   10    1    3   13    2    0    6    9    3    3    7  946    4    0    6   34]
 [   3    1    2    3    0    2    1    1    1    2    0   13   42    8    5   11    0  902    2    3    3]
 [   2    8    3    5    2    1    3   25    7    2    3    1    3    0   26    0    2    0  960    1    4]
 [   0    8    5    4    2   15   11   21    1    1    1    8   10   14    1    9    4    3    3  953   14]
 [ 254  189  218  131  281  191   83  211  152  119  108  145  393  310  371  140  154  126  232  239 9885]]

2024-06-05 23:56:10,025 - ==> Best [Top1: 80.677   Top5: 96.807   Sparsity:0.00   Params: 424448 on epoch: 20]
2024-06-05 23:56:10,025 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:56:10,058 - 

2024-06-05 23:56:10,058 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:56:16,860 - Epoch: [26][  100/ 1218]    Overall Loss 0.415719    Objective Loss 0.415719                                        LR 0.001000    Time 0.067988    
2024-06-05 23:56:22,117 - Epoch: [26][  200/ 1218]    Overall Loss 0.416485    Objective Loss 0.416485                                        LR 0.001000    Time 0.060263    
2024-06-05 23:56:27,313 - Epoch: [26][  300/ 1218]    Overall Loss 0.424102    Objective Loss 0.424102                                        LR 0.001000    Time 0.057486    
2024-06-05 23:56:32,623 - Epoch: [26][  400/ 1218]    Overall Loss 0.422768    Objective Loss 0.422768                                        LR 0.001000    Time 0.056384    
2024-06-05 23:56:37,897 - Epoch: [26][  500/ 1218]    Overall Loss 0.423229    Objective Loss 0.423229                                        LR 0.001000    Time 0.055651    
2024-06-05 23:56:43,248 - Epoch: [26][  600/ 1218]    Overall Loss 0.424960    Objective Loss 0.424960                                        LR 0.001000    Time 0.055285    
2024-06-05 23:56:48,271 - Epoch: [26][  700/ 1218]    Overall Loss 0.424100    Objective Loss 0.424100                                        LR 0.001000    Time 0.054559    
2024-06-05 23:56:53,517 - Epoch: [26][  800/ 1218]    Overall Loss 0.424119    Objective Loss 0.424119                                        LR 0.001000    Time 0.054294    
2024-06-05 23:56:59,079 - Epoch: [26][  900/ 1218]    Overall Loss 0.424424    Objective Loss 0.424424                                        LR 0.001000    Time 0.054438    
2024-06-05 23:57:04,325 - Epoch: [26][ 1000/ 1218]    Overall Loss 0.424997    Objective Loss 0.424997                                        LR 0.001000    Time 0.054238    
2024-06-05 23:57:09,513 - Epoch: [26][ 1100/ 1218]    Overall Loss 0.424803    Objective Loss 0.424803                                        LR 0.001000    Time 0.054021    
2024-06-05 23:57:14,559 - Epoch: [26][ 1200/ 1218]    Overall Loss 0.424677    Objective Loss 0.424677                                        LR 0.001000    Time 0.053720    
2024-06-05 23:57:15,549 - Epoch: [26][ 1218/ 1218]    Overall Loss 0.424672    Objective Loss 0.424672    Top1 80.929095    Top5 97.066015    LR 0.001000    Time 0.053738    
2024-06-05 23:57:15,811 - --- validate (epoch=26)-----------
2024-06-05 23:57:15,811 - 34633 samples (256 per mini-batch)
2024-06-05 23:57:22,096 - Epoch: [26][  100/  136]    Loss 0.458068    Top1 81.328125    Top5 96.988281    
2024-06-05 23:57:23,992 - Epoch: [26][  136/  136]    Loss 0.456340    Top1 81.341495    Top5 97.031733    
2024-06-05 23:57:24,240 - ==> Top1: 81.341    Top5: 97.032    Loss: 0.456

2024-06-05 23:57:24,241 - ==> Confusion:
[[  763     0     5     0    13     1     1     0     4   111     0     8     2     5     6     1     0     0     1     2     8]
 [    1   917     2     1    23    23    11    16     3     1     2     6     1     0     7     0     5     2    16     7    19]
 [    4     1   852     7     5     1    24    14     1    11     9     3     2     6     4     0     4     0     6     7     9]
 [    4     1    21   879     4     7     4     0     5     3    22     6     3     4    21     2     3     4     8     1    14]
 [   21     7     2     0   939    11     3     4     3    17     1     6     2     6     6     3     8     3     1     0    11]
 [    7    30     1     4    11   811     9    56     1     6     5    11    10    32     7     2     8     0     5    11    16]
 [    1     1    18     2     1     2  1004     7     0     3     3     8     3     2     0     0     1     1     1    18    10]
 [    3     5    13     4     2    23     3   903     4     5     7    10     2     8     1     0     0     1    48    19    16]
 [    6     3     1     2     5     2     1     2   826    73    15     5     6    11    18     0     3     3     6     0    14]
 [   43     0     1     1     6     1     0     2    37   866     2     6     2    21     5     0     0     0     3     2     3]
 [    1     0     5    17     2     1     3     6    12     1   947     0     2    20    10     1     2     0    13     3    18]
 [    3     2     6     1     3    13     4     5     1     5     1   770    35    24     0    20    10    29     3    57    19]
 [    0     2     5     5     0     1     2     4     3     1     3    41   801     6     3     8     5    47     7    26    25]
 [    2     0     3     1     2     5     2     3    18    17    10     6     5   886     3     1     3     2     0     7    25]
 [    7     4     2    14    12     1     0     0    26    16    12     4     1     7   959     0     3     3    16     0    11]
 [    2     0     7     0     3     3    16     2     1     7     0    17     8     4     0   951     6    11     1    12    15]
 [    3     6     6     2     5     7     1     3    12     3     3     8     0     6     2    10   943     2     3    18    29]
 [    5     0     3     8     2     0     1     1     7    10     0    11    16     7     4    19     2   886     2     4    17]
 [    0     5     7    11     2     1     0    11     4     3     7     5     3     1    17     1     1     0   958     8    13]
 [    2     2     2     1     0     5    10     5     1     0     1    10     5     7     1     3     8     3     5  1006    11]
 [  221   145   253   104   213   149   129   180   122   174   188   127   244   273   171    94   204    87   231   319 10304]]

2024-06-05 23:57:24,246 - ==> Best [Top1: 81.341   Top5: 97.032   Sparsity:0.00   Params: 424448 on epoch: 26]
2024-06-05 23:57:24,246 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:57:24,277 - 

2024-06-05 23:57:24,278 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:57:31,437 - Epoch: [27][  100/ 1218]    Overall Loss 0.414853    Objective Loss 0.414853                                        LR 0.001000    Time 0.071556    
2024-06-05 23:57:36,506 - Epoch: [27][  200/ 1218]    Overall Loss 0.417494    Objective Loss 0.417494                                        LR 0.001000    Time 0.061109    
2024-06-05 23:57:41,970 - Epoch: [27][  300/ 1218]    Overall Loss 0.414585    Objective Loss 0.414585                                        LR 0.001000    Time 0.058944    
2024-06-05 23:57:47,586 - Epoch: [27][  400/ 1218]    Overall Loss 0.414318    Objective Loss 0.414318                                        LR 0.001000    Time 0.058241    
2024-06-05 23:57:53,048 - Epoch: [27][  500/ 1218]    Overall Loss 0.417883    Objective Loss 0.417883                                        LR 0.001000    Time 0.057512    
2024-06-05 23:57:58,232 - Epoch: [27][  600/ 1218]    Overall Loss 0.416595    Objective Loss 0.416595                                        LR 0.001000    Time 0.056562    
2024-06-05 23:58:03,425 - Epoch: [27][  700/ 1218]    Overall Loss 0.418532    Objective Loss 0.418532                                        LR 0.001000    Time 0.055890    
2024-06-05 23:58:08,666 - Epoch: [27][  800/ 1218]    Overall Loss 0.417763    Objective Loss 0.417763                                        LR 0.001000    Time 0.055451    
2024-06-05 23:58:13,729 - Epoch: [27][  900/ 1218]    Overall Loss 0.418328    Objective Loss 0.418328                                        LR 0.001000    Time 0.054913    
2024-06-05 23:58:18,931 - Epoch: [27][ 1000/ 1218]    Overall Loss 0.419398    Objective Loss 0.419398                                        LR 0.001000    Time 0.054621    
2024-06-05 23:58:23,986 - Epoch: [27][ 1100/ 1218]    Overall Loss 0.419958    Objective Loss 0.419958                                        LR 0.001000    Time 0.054248    
2024-06-05 23:58:29,437 - Epoch: [27][ 1200/ 1218]    Overall Loss 0.419785    Objective Loss 0.419785                                        LR 0.001000    Time 0.054268    
2024-06-05 23:58:30,439 - Epoch: [27][ 1218/ 1218]    Overall Loss 0.420536    Objective Loss 0.420536    Top1 78.239609    Top5 96.088020    LR 0.001000    Time 0.054288    
2024-06-05 23:58:30,727 - --- validate (epoch=27)-----------
2024-06-05 23:58:30,727 - 34633 samples (256 per mini-batch)
2024-06-05 23:58:36,819 - Epoch: [27][  100/  136]    Loss 0.452088    Top1 80.558594    Top5 96.835938    
2024-06-05 23:58:38,650 - Epoch: [27][  136/  136]    Loss 0.449846    Top1 80.738024    Top5 96.867150    
2024-06-05 23:58:38,908 - ==> Top1: 80.738    Top5: 96.867    Loss: 0.450

2024-06-05 23:58:38,910 - ==> Confusion:
[[  737     0     7     1     8     0     2     0    21   122     2     2     4     4     5     0     2     3     4     0     7]
 [    0   911     9     3    19    19     2     9     9     2    11     1     2     3     7     2     2     4    33     2    13]
 [    5     4   843     7     2     1    36    14     3    11     8     4     2     8     3     3     0     0     3     3    10]
 [    3     5    17   898     0     4     6     2     1     2    18     1    14     5    14     0     3     7     5     2     9]
 [   23    12     6     5   910     8     1     1     4    21     3     1     3     5    12     9     5     4     8     0    13]
 [    2    54     4     7    15   795    11    43     5     7     7    11     8    26     3     2     3     4    12    13    11]
 [    0     1    22     2     0     0  1010     5     2     3     5     2     2     4     0     6     1     4     5     4     8]
 [    3    10    17     5     1    18     3   921     6     1     6     5    10     2     0     0     0     1    55     6     7]
 [    9     3     1     0     0     0     0     3   887    33     8     1     3    22    18     0     1     3     5     0     5]
 [   33     3     2     0     5     0     1     2    83   821     2     3     4    23     8     0     0     3     1     1     6]
 [    0     3     2    12     1     1     5     4    25     4   947     1     5    26     7     0     2     1    13     2     3]
 [    2     2     1     1     0     7     7    14     3     2     1   825    66    15     0    10     2    29     5    10     9]
 [    2     2     2     4     0     2     1     5     3     2     2    37   867     3     2     1     2    37     7     5     9]
 [    0     1     1     1     3     7     1     4    19    23     3     6     7   903     3     1     3     4     1     3     7]
 [    4     1     4    31     7     1     0     1    37    19     7     2     6    19   931     1     0     2    17     1     7]
 [    1     0     6     3     1     1    16     0     1     5     0    20    20     2     0   952     5    22     1     1     9]
 [    6     7     5     2     2     2     4     2     7     5     2     5     8     5     3     7   959     1     2    15    23]
 [    1     1     2     5     0     1     1     3     4     3     0    14    54     6     4     6     1   886     9     2     2]
 [    2     5     9    14     1     4     1    10     8     1    16     1     1     1    17     1     1     0   957     1     7]
 [    1     8     4     1     0     6    34    15     2     1     1    21    18     4     1     2     3     2     6   948    10]
 [  168   176   223   136   126    91   138   161   217   163   195   147   450   418   190    89   148    98   274   270 10054]]

2024-06-05 23:58:38,912 - ==> Best [Top1: 81.341   Top5: 97.032   Sparsity:0.00   Params: 424448 on epoch: 26]
2024-06-05 23:58:38,912 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:58:38,945 - 

2024-06-05 23:58:38,945 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-05 23:58:45,887 - Epoch: [28][  100/ 1218]    Overall Loss 0.416644    Objective Loss 0.416644                                        LR 0.001000    Time 0.069386    
2024-06-05 23:58:51,042 - Epoch: [28][  200/ 1218]    Overall Loss 0.416963    Objective Loss 0.416963                                        LR 0.001000    Time 0.060455    
2024-06-05 23:58:56,251 - Epoch: [28][  300/ 1218]    Overall Loss 0.420402    Objective Loss 0.420402                                        LR 0.001000    Time 0.057657    
2024-06-05 23:59:01,339 - Epoch: [28][  400/ 1218]    Overall Loss 0.418782    Objective Loss 0.418782                                        LR 0.001000    Time 0.055958    
2024-06-05 23:59:06,460 - Epoch: [28][  500/ 1218]    Overall Loss 0.418378    Objective Loss 0.418378                                        LR 0.001000    Time 0.055002    
2024-06-05 23:59:11,782 - Epoch: [28][  600/ 1218]    Overall Loss 0.419219    Objective Loss 0.419219                                        LR 0.001000    Time 0.054701    
2024-06-05 23:59:17,067 - Epoch: [28][  700/ 1218]    Overall Loss 0.419263    Objective Loss 0.419263                                        LR 0.001000    Time 0.054432    
2024-06-05 23:59:22,323 - Epoch: [28][  800/ 1218]    Overall Loss 0.420122    Objective Loss 0.420122                                        LR 0.001000    Time 0.054195    
2024-06-05 23:59:27,656 - Epoch: [28][  900/ 1218]    Overall Loss 0.420324    Objective Loss 0.420324                                        LR 0.001000    Time 0.054096    
2024-06-05 23:59:32,942 - Epoch: [28][ 1000/ 1218]    Overall Loss 0.419411    Objective Loss 0.419411                                        LR 0.001000    Time 0.053970    
2024-06-05 23:59:38,090 - Epoch: [28][ 1100/ 1218]    Overall Loss 0.419312    Objective Loss 0.419312                                        LR 0.001000    Time 0.053741    
2024-06-05 23:59:43,366 - Epoch: [28][ 1200/ 1218]    Overall Loss 0.417647    Objective Loss 0.417647                                        LR 0.001000    Time 0.053657    
2024-06-05 23:59:44,257 - Epoch: [28][ 1218/ 1218]    Overall Loss 0.417758    Objective Loss 0.417758    Top1 79.951100    Top5 95.599022    LR 0.001000    Time 0.053595    
2024-06-05 23:59:44,476 - --- validate (epoch=28)-----------
2024-06-05 23:59:44,477 - 34633 samples (256 per mini-batch)
2024-06-05 23:59:50,712 - Epoch: [28][  100/  136]    Loss 0.428697    Top1 81.917969    Top5 97.308594    
2024-06-05 23:59:52,509 - Epoch: [28][  136/  136]    Loss 0.435465    Top1 81.809257    Top5 97.230965    
2024-06-05 23:59:52,718 - ==> Top1: 81.809    Top5: 97.231    Loss: 0.435

2024-06-05 23:59:52,720 - ==> Confusion:
[[  783     2     5     0    10     4     0     4    12    75     1     1     3     2     7     0     1     5     1     3    12]
 [    0   941     1     6    11    17     6    19     5     3     4     1     4     2     5     2     4     3    15     6     8]
 [    5     2   854    19     4     1    32    14     0     2     3     1     5     1     0     4     2     2     3     3    13]
 [    3     2     9   915     1     3     5     4     1     0    15     1     6     0    20     5     1     9    12     0     4]
 [   19    18     5     2   899    24     2     5     2    15     3     4     2     4    15     6     4     3     6     2    14]
 [    1    33     6     8     8   863     5    48     1     2     4    14     7     5     3     1     1     5     1    14    13]
 [    3     2    18     2     0     0  1014    15     0     2     4     3     2     0     0     2     0     3     1     9     6]
 [    2    15    13     1     3    27     7   943     0     0     6     5     6     1     2     1     1     4    15    12    13]
 [   11     7     2     1     1     4     0     7   829    55    28     3     7     6    20     2     2     3     6     0     8]
 [   62     3     0     0     4     8     2     5    37   840     1     2     0     9     5     4     0     5     0     2    12]
 [    0     2     5    16     0     3     3    11    14     2   969     1     2     7     8     1     3     0     9     2     6]
 [    0     1     2     2     2    16     3     5     1     1     2   835    44     3     0    15     1    31     4    34     9]
 [    1     1     4    14     0     4     1     5     1     0     1    55   805     2     2     8     3    55     4     9    20]
 [    3     1    10     2     4    23     7     6    18    22    12    22    11   808     6     3     4     7     1    16    15]
 [    7     8     1    23     3     3     0     3    36     9     6     0     1     3   953     0     2    11    13     2    14]
 [    5     3     3     1     1     0    20     0     0     0     0    11     7     1     1   966     8    24     0     6     9]
 [    7    12     3     5     6    12     1     1     7     2     4    11     8     1     5     9   935     2     2    20    19]
 [    1     1     0     4     1     2     5     3     1     1     0     9    30     0     4    11     0   922     0     4     6]
 [    2     9     7    16     2     1     1    30     6     0     6     0     4     0    13     0     0     3   946     4     8]
 [    1     2     1     0     0     4    24    16     0     1     1    15     6     8     0     8     2     5     1   978    15]
 [  156   199   167   168   147   228   124   239   117   127   204   147   301   180   220   126   108   177   183   279 10335]]

2024-06-05 23:59:52,722 - ==> Best [Top1: 81.809   Top5: 97.231   Sparsity:0.00   Params: 424448 on epoch: 28]
2024-06-05 23:59:52,722 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-05 23:59:52,750 - 

2024-06-05 23:59:52,751 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:00:00,006 - Epoch: [29][  100/ 1218]    Overall Loss 0.412211    Objective Loss 0.412211                                        LR 0.001000    Time 0.072519    
2024-06-06 00:00:04,988 - Epoch: [29][  200/ 1218]    Overall Loss 0.409681    Objective Loss 0.409681                                        LR 0.001000    Time 0.061157    
2024-06-06 00:00:10,116 - Epoch: [29][  300/ 1218]    Overall Loss 0.413112    Objective Loss 0.413112                                        LR 0.001000    Time 0.057856    
2024-06-06 00:00:15,295 - Epoch: [29][  400/ 1218]    Overall Loss 0.414266    Objective Loss 0.414266                                        LR 0.001000    Time 0.056334    
2024-06-06 00:00:20,538 - Epoch: [29][  500/ 1218]    Overall Loss 0.412713    Objective Loss 0.412713                                        LR 0.001000    Time 0.055547    
2024-06-06 00:00:25,986 - Epoch: [29][  600/ 1218]    Overall Loss 0.411049    Objective Loss 0.411049                                        LR 0.001000    Time 0.055365    
2024-06-06 00:00:31,296 - Epoch: [29][  700/ 1218]    Overall Loss 0.411440    Objective Loss 0.411440                                        LR 0.001000    Time 0.055038    
2024-06-06 00:00:36,808 - Epoch: [29][  800/ 1218]    Overall Loss 0.411495    Objective Loss 0.411495                                        LR 0.001000    Time 0.055044    
2024-06-06 00:00:41,994 - Epoch: [29][  900/ 1218]    Overall Loss 0.412581    Objective Loss 0.412581                                        LR 0.001000    Time 0.054688    
2024-06-06 00:00:47,172 - Epoch: [29][ 1000/ 1218]    Overall Loss 0.412850    Objective Loss 0.412850                                        LR 0.001000    Time 0.054394    
2024-06-06 00:00:52,125 - Epoch: [29][ 1100/ 1218]    Overall Loss 0.412600    Objective Loss 0.412600                                        LR 0.001000    Time 0.053950    
2024-06-06 00:00:57,416 - Epoch: [29][ 1200/ 1218]    Overall Loss 0.413598    Objective Loss 0.413598                                        LR 0.001000    Time 0.053861    
2024-06-06 00:00:58,272 - Epoch: [29][ 1218/ 1218]    Overall Loss 0.413457    Objective Loss 0.413457    Top1 81.907090    Top5 96.088020    LR 0.001000    Time 0.053768    
2024-06-06 00:00:58,506 - --- validate (epoch=29)-----------
2024-06-06 00:00:58,507 - 34633 samples (256 per mini-batch)
2024-06-06 00:01:04,879 - Epoch: [29][  100/  136]    Loss 0.442208    Top1 79.578125    Top5 96.542969    
2024-06-06 00:01:06,733 - Epoch: [29][  136/  136]    Loss 0.441322    Top1 79.499321    Top5 96.569746    
2024-06-06 00:01:06,953 - ==> Top1: 79.499    Top5: 96.570    Loss: 0.441

2024-06-06 00:01:06,954 - ==> Confusion:
[[ 791    1    4    3    7    1    0    2   14   64    2    2    1    5   19    4    2    1    0    1    7]
 [   3  945    1    2   14   23    0    3    4    0   10    4    2    3   15    0    7    5   12    3    7]
 [   5    6  856   12    4    1   16    5    1    4   12    1    2    4    6    6    7    3    4    9    6]
 [   3    3   16  927    3    4    0    0    1    1   14    1    8    2   18    2    1    5    3    3    1]
 [  18   10    2    2  929   10    0    1    1   12    4    1    1    8   28    5    6    1    5    3    7]
 [   9   36    4    5   12  866    4   11    1    2    6   11   11   16    8    2    8    5    4   11   11]
 [   3    6   29    6    0    2  970    6    2    2    6    4    3    1    1   10    4    6    4   19    2]
 [   6   23   23    9    2   52    4  850    1    6   15   10    9    5    9    0    3    3   26   14    7]
 [  12    4    0    2    2    2    0    1  838   30   31    1   12   15   37    0    2    4    3    1    5]
 [  80    1    3    2    3    2    0    0   72  782    4    0    0   21   17    0    1    5    3    0    5]
 [   0    2    5   12    1    2    1    2    9    1  986    1    2    9   15    1    1    2    9    0    3]
 [   1    1    2    1    0    9    6    5    2    1    2  817   89   17    0   17    2   20    1   14    4]
 [   0    1    3    6    0    4    2    3    2    0    4   34  868    4    3   10    4   25    6    9    7]
 [   5    0    2    1    6   13    0    3   20   12   23   10    9  845   15    1    6    6    1   10   13]
 [   7    1    2   29    5    2    0    0   20    3    5    1    9    2  988    0    2    2   14    0    6]
 [   2    5    5    1    5    1    7    0    0    4    0    8   18    4    0  972    8   15    2    2    7]
 [   2   10    3    2    8    5    0    0    5    1    4    9    8    5    5    9  973    5    1    6   11]
 [   2    2    1    5    2    2    1    0    1    1    0   13   60    7    3    8    0  888    1    4    4]
 [   2    7    4   17    1    1    2    5    5    4    6    0    5    0   13    2    3    2  966    2   11]
 [   3    7    4    0    1    4    8   11    0    2    0   11    7    8    4    5   11    3    5  986    8]
 [ 202  232  191  175  249  190   78  111  139  127  255  132  472  256  451  146  353  158  211  314 9490]]

2024-06-06 00:01:06,958 - ==> Best [Top1: 81.809   Top5: 97.231   Sparsity:0.00   Params: 424448 on epoch: 28]
2024-06-06 00:01:06,958 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:01:06,983 - 

2024-06-06 00:01:06,984 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:01:13,580 - Epoch: [30][  100/ 1218]    Overall Loss 0.417654    Objective Loss 0.417654                                        LR 0.001000    Time 0.065924    
2024-06-06 00:01:18,595 - Epoch: [30][  200/ 1218]    Overall Loss 0.417680    Objective Loss 0.417680                                        LR 0.001000    Time 0.058025    
2024-06-06 00:01:23,795 - Epoch: [30][  300/ 1218]    Overall Loss 0.412700    Objective Loss 0.412700                                        LR 0.001000    Time 0.056009    
2024-06-06 00:01:28,899 - Epoch: [30][  400/ 1218]    Overall Loss 0.412435    Objective Loss 0.412435                                        LR 0.001000    Time 0.054762    
2024-06-06 00:01:33,955 - Epoch: [30][  500/ 1218]    Overall Loss 0.410786    Objective Loss 0.410786                                        LR 0.001000    Time 0.053916    
2024-06-06 00:01:39,007 - Epoch: [30][  600/ 1218]    Overall Loss 0.408656    Objective Loss 0.408656                                        LR 0.001000    Time 0.053346    
2024-06-06 00:01:43,904 - Epoch: [30][  700/ 1218]    Overall Loss 0.408832    Objective Loss 0.408832                                        LR 0.001000    Time 0.052716    
2024-06-06 00:01:49,025 - Epoch: [30][  800/ 1218]    Overall Loss 0.408814    Objective Loss 0.408814                                        LR 0.001000    Time 0.052526    
2024-06-06 00:01:53,966 - Epoch: [30][  900/ 1218]    Overall Loss 0.407318    Objective Loss 0.407318                                        LR 0.001000    Time 0.052176    
2024-06-06 00:01:59,032 - Epoch: [30][ 1000/ 1218]    Overall Loss 0.409289    Objective Loss 0.409289                                        LR 0.001000    Time 0.052023    
2024-06-06 00:02:04,152 - Epoch: [30][ 1100/ 1218]    Overall Loss 0.409485    Objective Loss 0.409485                                        LR 0.001000    Time 0.051945    
2024-06-06 00:02:09,285 - Epoch: [30][ 1200/ 1218]    Overall Loss 0.409130    Objective Loss 0.409130                                        LR 0.001000    Time 0.051892    
2024-06-06 00:02:10,170 - Epoch: [30][ 1218/ 1218]    Overall Loss 0.409596    Objective Loss 0.409596    Top1 81.662592    Top5 97.310513    LR 0.001000    Time 0.051851    
2024-06-06 00:02:10,352 - --- validate (epoch=30)-----------
2024-06-06 00:02:10,352 - 34633 samples (256 per mini-batch)
2024-06-06 00:02:16,766 - Epoch: [30][  100/  136]    Loss 0.433782    Top1 80.800781    Top5 96.738281    
2024-06-06 00:02:18,576 - Epoch: [30][  136/  136]    Loss 0.433736    Top1 80.833309    Top5 96.740103    
2024-06-06 00:02:18,783 - ==> Top1: 80.833    Top5: 96.740    Loss: 0.434

2024-06-06 00:02:18,785 - ==> Confusion:
[[ 763    1    1    1    5    2    0    4   12  106    2    1    4    2    9    1    1    2    4    3    7]
 [   2  928    2    5   21   21    3   17    9    0   11    3    3    0    8    1    6    3   11    4    5]
 [   9    4  826   12    5    4   27   14    0    9   13    5    6    3    4    5    2    1    3    5   13]
 [   2    2   13  896    2    1    2    5    3    6   20    2   10    4   22    1    1    6   11    1    6]
 [  22   11    1    4  919    8    1    3    4   27    0    3    4    5   12    5    5    1    5    2   12]
 [   4   30    1    2   13  846    6   37    1    6    2   23   21   15    4    2    1    1    6    8   14]
 [   0    1   20    2    1    0  996    4    0    5    8   14    6    0    0    2    0    5    1   13    8]
 [   3   12   11    3    2   22    9  917    1    4    8   14   14    5    2    0    1    2   25   17    5]
 [   5    1    0    2    0    3    2    1  878   43   12    1    5    6   18    0    0    4   12    1    8]
 [  40    2    1    0    2    3    0    1   62  850    0    0    4   15    7    1    1    2    2    0    8]
 [   0    1    3    5    1    4    3    8   29    2  954    1    7   10    7    1    1    0   17    2    8]
 [   2    1    1    0    0    6    1    3    4    1    2  890   39    5    1   10    4   23    2   12    4]
 [   0    1    1    2    1    1    1    2    3    1    1   66  843    1    2    7    1   43    3    6    9]
 [   1    0    0    0    1    7    1    2   23   23    9   21   14  872    6    3    2    5    1    3    7]
 [  10    1    0   14    4    4    1    0   45   16    6    0    3    8  948    0    0    4   22    2   10]
 [   1    0    3    2    4    0    6    0    0    6    0   31   17    1    2  967    7   14    1    0    4]
 [   1   13    2    5    8    5    5    2   10    0    1    5   13    5    3    6  954    4    2    7   21]
 [   0    1    0    2    1    0    1    2    0    2    0   21   31    1    5   10    1  907    6    5    9]
 [   1    4    6   10    4    1    1   20    6    3    7    1    7    1   13    0    0    2  960    6    5]
 [   2    4    4    0    1    7   15    5    0    2    1   42   19    5    0    5    4    2    5  956    9]
 [ 178  173  180  117  190  126  134  152  184  173  219  224  460  234  294  137  192  127  242  271 9925]]

2024-06-06 00:02:18,788 - ==> Best [Top1: 81.809   Top5: 97.231   Sparsity:0.00   Params: 424448 on epoch: 28]
2024-06-06 00:02:18,788 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:02:18,821 - 

2024-06-06 00:02:18,821 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:02:25,437 - Epoch: [31][  100/ 1218]    Overall Loss 0.414794    Objective Loss 0.414794                                        LR 0.001000    Time 0.066116    
2024-06-06 00:02:30,405 - Epoch: [31][  200/ 1218]    Overall Loss 0.406162    Objective Loss 0.406162                                        LR 0.001000    Time 0.057886    
2024-06-06 00:02:35,491 - Epoch: [31][  300/ 1218]    Overall Loss 0.407279    Objective Loss 0.407279                                        LR 0.001000    Time 0.055536    
2024-06-06 00:02:40,608 - Epoch: [31][  400/ 1218]    Overall Loss 0.406349    Objective Loss 0.406349                                        LR 0.001000    Time 0.054437    
2024-06-06 00:02:45,737 - Epoch: [31][  500/ 1218]    Overall Loss 0.407948    Objective Loss 0.407948                                        LR 0.001000    Time 0.053804    
2024-06-06 00:02:50,761 - Epoch: [31][  600/ 1218]    Overall Loss 0.407144    Objective Loss 0.407144                                        LR 0.001000    Time 0.053205    
2024-06-06 00:02:55,925 - Epoch: [31][  700/ 1218]    Overall Loss 0.407545    Objective Loss 0.407545                                        LR 0.001000    Time 0.052978    
2024-06-06 00:03:01,109 - Epoch: [31][  800/ 1218]    Overall Loss 0.407069    Objective Loss 0.407069                                        LR 0.001000    Time 0.052833    
2024-06-06 00:03:06,314 - Epoch: [31][  900/ 1218]    Overall Loss 0.404990    Objective Loss 0.404990                                        LR 0.001000    Time 0.052742    
2024-06-06 00:03:11,542 - Epoch: [31][ 1000/ 1218]    Overall Loss 0.405563    Objective Loss 0.405563                                        LR 0.001000    Time 0.052694    
2024-06-06 00:03:16,343 - Epoch: [31][ 1100/ 1218]    Overall Loss 0.405023    Objective Loss 0.405023                                        LR 0.001000    Time 0.052266    
2024-06-06 00:03:21,588 - Epoch: [31][ 1200/ 1218]    Overall Loss 0.404948    Objective Loss 0.404948                                        LR 0.001000    Time 0.052279    
2024-06-06 00:03:22,427 - Epoch: [31][ 1218/ 1218]    Overall Loss 0.405272    Objective Loss 0.405272    Top1 81.907090    Top5 97.555012    LR 0.001000    Time 0.052195    
2024-06-06 00:03:22,630 - --- validate (epoch=31)-----------
2024-06-06 00:03:22,630 - 34633 samples (256 per mini-batch)
2024-06-06 00:03:29,080 - Epoch: [31][  100/  136]    Loss 0.427374    Top1 79.601562    Top5 96.488281    
2024-06-06 00:03:30,960 - Epoch: [31][  136/  136]    Loss 0.430488    Top1 79.464672    Top5 96.442699    
2024-06-06 00:03:31,213 - ==> Top1: 79.465    Top5: 96.443    Loss: 0.430

2024-06-06 00:03:31,215 - ==> Confusion:
[[ 845    1    7    2    8    1    1    0    4   35    1    1    1    1    5    2    0    3    1    4    8]
 [   2  931    3    2   17   21    5   16    1    3   14    2    3    1   13    3    1    4    8    8    5]
 [   7    1  854   13    2    3   23   10    1    6    8    6    5    1    1    4    1    8    4    8    4]
 [   5    1   17  885    4    4    2    2    0    2   19    3   11    0   35    1    2   13    4    4    2]
 [  32   12    6    4  942    9    1    0    3    8    2    3    3    3   10    6    1    4    0    2    3]
 [   7   29    5    6   13  840    5   32    5    2    4   22   15   18    3    4    6    7    3    8    9]
 [   2    2   22    3    2    2 1003    1    0    1    4    5    5    1    0   18    0    3    3    6    3]
 [   8   12   20    6    2   36   11  891    1    4   11   15    5    5    1    0    2    2   20   17    8]
 [  17    5    0    2    1    0    0    0  838   56   20    4    5    8   27    2    0    8    4    3    2]
 [ 111    0    2    0    6    0    1    1   36  794    2    2    1   10   13    1    0   12    2    3    4]
 [   3    4    6    9    0    4    2    3   19    4  974    1    2    8   10    0    1    1   11    2    0]
 [   4    1    3    1    0    7    4    3    1    1    0  871   44    4    0   20    3   34    1    5    4]
 [   2    0    2    6    0    2    1    1    6    0    6   55  827    2    4    5    5   50    3   11    7]
 [   6    1    1    1    2   14    1    4   28   18   10   15    5  863    9    4    1    6    1    4    7]
 [  16    0    3    7    5    1    0    0   24    4    6    1    2    8 1004    0    1    0   10    1    5]
 [   1    0    5    1    1    2    3    0    1    2    0   17   17    1    0  965    9   31    1    6    3]
 [   4   10   11    2    6    6    1    2    6    0    7    9    5    4    3    8  954   13    1    6   14]
 [   2    0    1    1    1    1    0    0    0    1    2   13   30    1    4    4    0  937    1    3    3]
 [   1   11   15   14    1    0    1   25    7    0    9    4    3    0   21    0    2    2  933    4    5]
 [   2    4    4    1    1   11   19   10    0    0    2   30   21    9    0    9    8    4    3  937   13]
 [ 284  190  370  175  200  195  103  182  143   99  224  196  421  231  349  188  229  267  182  271 9433]]

2024-06-06 00:03:31,219 - ==> Best [Top1: 81.809   Top5: 97.231   Sparsity:0.00   Params: 424448 on epoch: 28]
2024-06-06 00:03:31,219 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:03:31,252 - 

2024-06-06 00:03:31,252 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:03:38,049 - Epoch: [32][  100/ 1218]    Overall Loss 0.423331    Objective Loss 0.423331                                        LR 0.001000    Time 0.067933    
2024-06-06 00:03:43,052 - Epoch: [32][  200/ 1218]    Overall Loss 0.413843    Objective Loss 0.413843                                        LR 0.001000    Time 0.058970    
2024-06-06 00:03:48,326 - Epoch: [32][  300/ 1218]    Overall Loss 0.409825    Objective Loss 0.409825                                        LR 0.001000    Time 0.056883    
2024-06-06 00:03:53,376 - Epoch: [32][  400/ 1218]    Overall Loss 0.408950    Objective Loss 0.408950                                        LR 0.001000    Time 0.055281    
2024-06-06 00:03:58,477 - Epoch: [32][  500/ 1218]    Overall Loss 0.409503    Objective Loss 0.409503                                        LR 0.001000    Time 0.054422    
2024-06-06 00:04:03,624 - Epoch: [32][  600/ 1218]    Overall Loss 0.411590    Objective Loss 0.411590                                        LR 0.001000    Time 0.053926    
2024-06-06 00:04:08,740 - Epoch: [32][  700/ 1218]    Overall Loss 0.410281    Objective Loss 0.410281                                        LR 0.001000    Time 0.053527    
2024-06-06 00:04:14,262 - Epoch: [32][  800/ 1218]    Overall Loss 0.406549    Objective Loss 0.406549                                        LR 0.001000    Time 0.053735    
2024-06-06 00:04:19,435 - Epoch: [32][  900/ 1218]    Overall Loss 0.405980    Objective Loss 0.405980                                        LR 0.001000    Time 0.053510    
2024-06-06 00:04:24,512 - Epoch: [32][ 1000/ 1218]    Overall Loss 0.406229    Objective Loss 0.406229                                        LR 0.001000    Time 0.053234    
2024-06-06 00:04:29,572 - Epoch: [32][ 1100/ 1218]    Overall Loss 0.405605    Objective Loss 0.405605                                        LR 0.001000    Time 0.052992    
2024-06-06 00:04:34,920 - Epoch: [32][ 1200/ 1218]    Overall Loss 0.405844    Objective Loss 0.405844                                        LR 0.001000    Time 0.053031    
2024-06-06 00:04:35,783 - Epoch: [32][ 1218/ 1218]    Overall Loss 0.405756    Objective Loss 0.405756    Top1 78.973105    Top5 96.088020    LR 0.001000    Time 0.052955    
2024-06-06 00:04:35,991 - --- validate (epoch=32)-----------
2024-06-06 00:04:35,991 - 34633 samples (256 per mini-batch)
2024-06-06 00:04:41,986 - Epoch: [32][  100/  136]    Loss 0.418242    Top1 79.843750    Top5 96.730469    
2024-06-06 00:04:43,762 - Epoch: [32][  136/  136]    Loss 0.424135    Top1 79.845812    Top5 96.688130    
2024-06-06 00:04:43,985 - ==> Top1: 79.846    Top5: 96.688    Loss: 0.424

2024-06-06 00:04:43,986 - ==> Confusion:
[[ 824    1    7    1   14    3    0    3    2   42    1    6    6    4    7    0    2    1    2    0    5]
 [   0  933    3    5   19   25    2   19    2    2    6    4    4    2   10    0   10    1   12    2    2]
 [   7    4  861   10    8    1    6   16    0    4   10    5    3    6    3    3    5    1    7    3    7]
 [   3    1   16  893    3    5    1    3    3    1   15    5   10    4   24    2    2    6   11    5    3]
 [  13   10    1    1  948   20    0    6    1   17    1    8    3    3    9    2    5    0    2    0    4]
 [   1   26    6    2   13  881    0   33    0    2    5   16    9   18    7    0    4    0    5    9    6]
 [   0    4   24    1    6    8  985    7    0    3   12    5    3    2    1    7    2    1    4    8    3]
 [   3   10   10    1    2   32    3  925    1    1    5   13    4    2    1    0    1    1   33   19   10]
 [  15    7    2    0    3    3    0    3  797   79   21    5    6   24   26    0    2    3    2    1    3]
 [  88    0    4    0    8    2    0    3   30  811    2    9    2   21   11    0    0    3    1    2    4]
 [   2    3   11    9    1    3    1    5   11    4  968    1    2   12   14    0    3    0    9    3    2]
 [   1    2    2    0    2   17    5   14    0    1    2  863   44   11    1    6    1   13    4   20    2]
 [   0    2    3    5    2    4    0    7    1    0    2   84  818    4    7    4    9   24    3    9    7]
 [   4    1    4    0    4   21    1    6    9   20    8    6    7  875    7    0    9    4    0    7    8]
 [  14    3    3   11   17    0    0    2   25    7    4    3    6   12  965    0    4    3   11    1    7]
 [   4    3   12    0    8    8   10    1    0    1    0   33   16    6    0  933   11   15    0    0    5]
 [   7   13    3    0    8   12    0    1    3    1    6    8    6    5    0    4  972    0    2   10   11]
 [   4    1    4    4    0    5    2    2    0    2    0   42   44    7    3    5    1  873    2    3    1]
 [   2    4    9   14    0    3    0   17    2    1    9    3    5    0   16    0    4    0  961    1    7]
 [   0    7    3    1    2    5   13   11    0    0    0   18   12    2    1    3    7    5    2  988    8]
 [ 264  254  269  152  286  270   86  263  102  122  151  243  330  273  276  109  256  110  180  357 9579]]

2024-06-06 00:04:43,992 - ==> Best [Top1: 81.809   Top5: 97.231   Sparsity:0.00   Params: 424448 on epoch: 28]
2024-06-06 00:04:43,992 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:04:44,017 - 

2024-06-06 00:04:44,017 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:04:50,790 - Epoch: [33][  100/ 1218]    Overall Loss 0.397548    Objective Loss 0.397548                                        LR 0.001000    Time 0.067694    
2024-06-06 00:04:56,067 - Epoch: [33][  200/ 1218]    Overall Loss 0.391148    Objective Loss 0.391148                                        LR 0.001000    Time 0.060220    
2024-06-06 00:05:01,370 - Epoch: [33][  300/ 1218]    Overall Loss 0.394346    Objective Loss 0.394346                                        LR 0.001000    Time 0.057816    
2024-06-06 00:05:06,374 - Epoch: [33][  400/ 1218]    Overall Loss 0.399800    Objective Loss 0.399800                                        LR 0.001000    Time 0.055865    
2024-06-06 00:05:11,473 - Epoch: [33][  500/ 1218]    Overall Loss 0.401322    Objective Loss 0.401322                                        LR 0.001000    Time 0.054885    
2024-06-06 00:05:16,447 - Epoch: [33][  600/ 1218]    Overall Loss 0.399415    Objective Loss 0.399415                                        LR 0.001000    Time 0.054023    
2024-06-06 00:05:21,261 - Epoch: [33][  700/ 1218]    Overall Loss 0.400155    Objective Loss 0.400155                                        LR 0.001000    Time 0.053180    
2024-06-06 00:05:26,554 - Epoch: [33][  800/ 1218]    Overall Loss 0.400113    Objective Loss 0.400113                                        LR 0.001000    Time 0.053145    
2024-06-06 00:05:31,680 - Epoch: [33][  900/ 1218]    Overall Loss 0.400221    Objective Loss 0.400221                                        LR 0.001000    Time 0.052933    
2024-06-06 00:05:36,906 - Epoch: [33][ 1000/ 1218]    Overall Loss 0.399961    Objective Loss 0.399961                                        LR 0.001000    Time 0.052863    
2024-06-06 00:05:42,092 - Epoch: [33][ 1100/ 1218]    Overall Loss 0.400705    Objective Loss 0.400705                                        LR 0.001000    Time 0.052770    
2024-06-06 00:05:47,008 - Epoch: [33][ 1200/ 1218]    Overall Loss 0.401215    Objective Loss 0.401215                                        LR 0.001000    Time 0.052467    
2024-06-06 00:05:48,003 - Epoch: [33][ 1218/ 1218]    Overall Loss 0.401219    Objective Loss 0.401219    Top1 84.841076    Top5 97.066015    LR 0.001000    Time 0.052507    
2024-06-06 00:05:48,226 - --- validate (epoch=33)-----------
2024-06-06 00:05:48,227 - 34633 samples (256 per mini-batch)
2024-06-06 00:05:54,747 - Epoch: [33][  100/  136]    Loss 0.418696    Top1 83.429688    Top5 97.527344    
2024-06-06 00:05:56,772 - Epoch: [33][  136/  136]    Loss 0.421285    Top1 83.330927    Top5 97.418647    
2024-06-06 00:05:56,965 - ==> Top1: 83.331    Top5: 97.419    Loss: 0.421

2024-06-06 00:05:56,967 - ==> Confusion:
[[  776     0     2     0     2     1     0     1    12    98     1     1     3     2     4     3     1     1     0     3    20]
 [    1   944     4     3    15    11     4    19     4     7     1     0     0     0     5     0     6     3    21     6     9]
 [    3     1   856     8     1     3    25    10     1    11     7     2     4     4     1     1     2     2     5     5    18]
 [    4     1    15   881     4    10     5     3     2     4     7     2    16     2    23     1     1     9    16     0    10]
 [   21    13     5     1   911     9     2     5     4    21     1     4     2     4    15     4     2     1     5     2    22]
 [    4    37     4     1    15   828     7    62     5     5     1    10     4    19     4     2     6     1     5     8    15]
 [    0     2     9     0     3     2  1020     6     0     4     2     0     1     2     0     3     2     3     4    14     9]
 [    2    10    14     1     0     8     9   970     0     4     1     3     5     1     1     0     0     0    27    11    10]
 [    5     1     1     1     1     3     1     6   819    62    29     1     5    10    32     0     2     1    11     0    11]
 [   47     2     1     1     2     3     2     2    36   850     4     0     3    11    11     1     2     1     6     0    16]
 [    1     4     5    14     1     7     8     5     9     2   952     0     2     7     8     1     1     0    22     3    12]
 [    1     0     0     0     2    13     3     7     2     3     0   899    25     5     0    14     0    12     3    13     9]
 [    1     1     1     3     1     3     1     3     3     6     2   112   783     3     0     7     1    27     6     4    27]
 [    7     1     0     0     4    14     0     9    13    22    12    12     8   863     3     2     2     3     1     8    17]
 [    5     2     1    16     5     2     1     2    18    14    13     2     4     6   965     0     1     1    22     0    18]
 [    4     0     0     0     4     1    13     1     1     9     0    34    13     1     1   959     2     7     0     4    12]
 [    3    13     4     2     4     8     2     0     4     4     3     7     4     2     2     7   956     3     7     9    28]
 [    4     0     1     1     0     2     1     0     0     3     1    40    37     3     5     7     2   878     4     4    12]
 [    0     4     4     8     2     3     2    31     8     0     8     6     4     1     8     0     0     0   950     7    12]
 [    0     6     1     2     0     9    11    10     2     2     1    32     7     1     0     4     5     3     0   974    18]
 [  136   166   137    81   136   125    92   215    97   137   152   209   255   236   218    75   104    74   221   240 10826]]

2024-06-06 00:05:56,972 - ==> Best [Top1: 83.331   Top5: 97.419   Sparsity:0.00   Params: 424448 on epoch: 33]
2024-06-06 00:05:56,972 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:05:57,003 - 

2024-06-06 00:05:57,004 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:06:03,965 - Epoch: [34][  100/ 1218]    Overall Loss 0.395021    Objective Loss 0.395021                                        LR 0.001000    Time 0.069579    
2024-06-06 00:06:09,052 - Epoch: [34][  200/ 1218]    Overall Loss 0.393391    Objective Loss 0.393391                                        LR 0.001000    Time 0.060208    
2024-06-06 00:06:14,032 - Epoch: [34][  300/ 1218]    Overall Loss 0.397417    Objective Loss 0.397417                                        LR 0.001000    Time 0.056732    
2024-06-06 00:06:18,948 - Epoch: [34][  400/ 1218]    Overall Loss 0.397786    Objective Loss 0.397786                                        LR 0.001000    Time 0.054832    
2024-06-06 00:06:24,139 - Epoch: [34][  500/ 1218]    Overall Loss 0.397463    Objective Loss 0.397463                                        LR 0.001000    Time 0.054244    
2024-06-06 00:06:29,248 - Epoch: [34][  600/ 1218]    Overall Loss 0.397706    Objective Loss 0.397706                                        LR 0.001000    Time 0.053714    
2024-06-06 00:06:34,599 - Epoch: [34][  700/ 1218]    Overall Loss 0.398705    Objective Loss 0.398705                                        LR 0.001000    Time 0.053681    
2024-06-06 00:06:39,671 - Epoch: [34][  800/ 1218]    Overall Loss 0.399537    Objective Loss 0.399537                                        LR 0.001000    Time 0.053308    
2024-06-06 00:06:44,661 - Epoch: [34][  900/ 1218]    Overall Loss 0.398641    Objective Loss 0.398641                                        LR 0.001000    Time 0.052927    
2024-06-06 00:06:49,858 - Epoch: [34][ 1000/ 1218]    Overall Loss 0.397705    Objective Loss 0.397705                                        LR 0.001000    Time 0.052829    
2024-06-06 00:06:54,839 - Epoch: [34][ 1100/ 1218]    Overall Loss 0.397299    Objective Loss 0.397299                                        LR 0.001000    Time 0.052552    
2024-06-06 00:07:00,036 - Epoch: [34][ 1200/ 1218]    Overall Loss 0.397904    Objective Loss 0.397904                                        LR 0.001000    Time 0.052501    
2024-06-06 00:07:00,902 - Epoch: [34][ 1218/ 1218]    Overall Loss 0.398151    Objective Loss 0.398151    Top1 83.129584    Top5 98.288509    LR 0.001000    Time 0.052436    
2024-06-06 00:07:01,127 - --- validate (epoch=34)-----------
2024-06-06 00:07:01,127 - 34633 samples (256 per mini-batch)
2024-06-06 00:07:07,178 - Epoch: [34][  100/  136]    Loss 0.420767    Top1 81.675781    Top5 96.894531    
2024-06-06 00:07:09,133 - Epoch: [34][  136/  136]    Loss 0.422488    Top1 81.442555    Top5 96.942223    
2024-06-06 00:07:09,334 - ==> Top1: 81.443    Top5: 96.942    Loss: 0.422

2024-06-06 00:07:09,336 - ==> Confusion:
[[  846     0     1     0    12     2     1     3     8    29     1     1     2     2     9     2     0     0     0     0    12]
 [    2   928     1     2    21    29     5    22     4     3     5     0     2     1     2     0     8     0    17     0    11]
 [    9     1   862     9    10     3    13     6     0     8     6     3     1     2     3     7     3     1     8     4    11]
 [    4     2    13   900     5     6     1     2     2     3    16     0     7     2    26     2     3     7     9     0     6]
 [   28     8     1     1   950     7     1     5     3     7     1     0     3     2     9     8    11     1     2     0     6]
 [    9    16     5     2    10   845     6    55     3     6     2     8     4    33     5     5     7     1     5     9     7]
 [    3     6    21     2     3     8   984     9     0     2     3     3     5     2     0    11     6     2     1     7     8]
 [    2     9    19     3     3    19     1   937     1     1     7     7     5     6     0     2     0     1    34    15     5]
 [   13     4     0     0     1     4     0     2   869    36    15     0     4     9    18     1     6     4     7     1     8]
 [  127     3     0     0    12     2     1     1    54   764     3     0     1    12     8     3     2     3     0     0     5]
 [    0     4    10    14     1     0     2     6    19     4   960     0     1    14     9     2     3     0     9     0     6]
 [    5     4     3     2     3    25     3     6     1     2     1   830    36    25     2    25     9     8     1    17     3]
 [    3     2     3    13     0     7     1     3     4     3     2    65   793    10     4    12     8    27     6    10    19]
 [    3     4     4     2     5     9     1     5    14    14     4     3     7   900     5     0     4     2     1     4    10]
 [    9     3     2     8    13     0     0     0    28    13     3     1     4     5   974     3     3     1    19     0     9]
 [    7     1     6     5     2     2     9     1     1     2     0    15     3     4     0   975    15     6     2     1     9]
 [    3     6     3     3     9    15     1     1     4     2     1     1     3     4     1    11   977     1     2     6    18]
 [    4     2     2     8     0     2     1     1     2     3     0    11    42     6     6    22     1   879     2     3     8]
 [    3     5     9    17     1     5     1    22     7     0     5     0     0     1    20     1     2     0   951     2     6]
 [    2     4     7     2     2    11    14    14     0     2     0     9     3    10     0     9    10     3     4   974     8]
 [  236   169   199   131   248   188   109   211   144   127   165   116   250   273   282   155   252    86   247   236 10108]]

2024-06-06 00:07:09,344 - ==> Best [Top1: 83.331   Top5: 97.419   Sparsity:0.00   Params: 424448 on epoch: 33]
2024-06-06 00:07:09,344 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:07:09,377 - 

2024-06-06 00:07:09,377 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:07:16,083 - Epoch: [35][  100/ 1218]    Overall Loss 0.396995    Objective Loss 0.396995                                        LR 0.001000    Time 0.067019    
2024-06-06 00:07:21,130 - Epoch: [35][  200/ 1218]    Overall Loss 0.401163    Objective Loss 0.401163                                        LR 0.001000    Time 0.058735    
2024-06-06 00:07:26,374 - Epoch: [35][  300/ 1218]    Overall Loss 0.396144    Objective Loss 0.396144                                        LR 0.001000    Time 0.056627    
2024-06-06 00:07:31,634 - Epoch: [35][  400/ 1218]    Overall Loss 0.395472    Objective Loss 0.395472                                        LR 0.001000    Time 0.055614    
2024-06-06 00:07:36,777 - Epoch: [35][  500/ 1218]    Overall Loss 0.394810    Objective Loss 0.394810                                        LR 0.001000    Time 0.054773    
2024-06-06 00:07:41,773 - Epoch: [35][  600/ 1218]    Overall Loss 0.395517    Objective Loss 0.395517                                        LR 0.001000    Time 0.053966    
2024-06-06 00:07:46,730 - Epoch: [35][  700/ 1218]    Overall Loss 0.395774    Objective Loss 0.395774                                        LR 0.001000    Time 0.053333    
2024-06-06 00:07:52,044 - Epoch: [35][  800/ 1218]    Overall Loss 0.394365    Objective Loss 0.394365                                        LR 0.001000    Time 0.053306    
2024-06-06 00:07:57,200 - Epoch: [35][  900/ 1218]    Overall Loss 0.393773    Objective Loss 0.393773                                        LR 0.001000    Time 0.053109    
2024-06-06 00:08:02,293 - Epoch: [35][ 1000/ 1218]    Overall Loss 0.394864    Objective Loss 0.394864                                        LR 0.001000    Time 0.052890    
2024-06-06 00:08:07,612 - Epoch: [35][ 1100/ 1218]    Overall Loss 0.395866    Objective Loss 0.395866                                        LR 0.001000    Time 0.052915    
2024-06-06 00:08:12,986 - Epoch: [35][ 1200/ 1218]    Overall Loss 0.394851    Objective Loss 0.394851                                        LR 0.001000    Time 0.052981    
2024-06-06 00:08:13,856 - Epoch: [35][ 1218/ 1218]    Overall Loss 0.394747    Objective Loss 0.394747    Top1 80.195599    Top5 98.044010    LR 0.001000    Time 0.052912    
2024-06-06 00:08:14,084 - --- validate (epoch=35)-----------
2024-06-06 00:08:14,084 - 34633 samples (256 per mini-batch)
2024-06-06 00:08:20,392 - Epoch: [35][  100/  136]    Loss 0.418801    Top1 81.261719    Top5 96.843750    
2024-06-06 00:08:22,404 - Epoch: [35][  136/  136]    Loss 0.421450    Top1 81.139376    Top5 96.806514    
2024-06-06 00:08:22,618 - ==> Top1: 81.139    Top5: 96.807    Loss: 0.421

2024-06-06 00:08:22,620 - ==> Confusion:
[[ 791    1    1    0   10    1    0    3    7   90    0    5    3    2    1    4    4    3    0    0    5]
 [   4  922    2    0   24   33    2   15    6    2    6    2    5    2    2    5    4    1    9    4   13]
 [  10    6  815   14    7    1   35   24    1    7    3    4    3    4    3   10    3    1    4    4   11]
 [   3    2   12  891    5    7    4    2    0    4    9    4    9    5   30    2    4    4   13    1    5]
 [  22    7    4    1  949    9    4    1    3   15    0    6    2    0    7    5    7    1    2    0    9]
 [   4   37    2    4   13  869    8   23    4    2    2   21    9   14    5    3    2    1    1    9   10]
 [   3    2   12    0    3    5 1011    5    0    4    1    4    3    1    0   10    3    1    1    9    8]
 [   2   15   11    0    4   37    3  922    4    4    0   16   10    3    2    0    1    2   21   12    8]
 [  14    5    0    0    2    1    1    2  853   61    7    2    8   18   14    0    1    1    7    1    4]
 [  58    1    2    0    3    1    3    0   35  854    1    1    5   27    4    1    0    2    1    1    1]
 [   1    7   10   10    1    5    3    8   21    2  935    2    4   15   11    2    0    1   13    7    6]
 [   1    3    2    0    1    6    1    2    1    2    0  897   39    7    0   18    1   11    2   10    7]
 [   3    2    3    4    1    3    3    3    3    0    0   63  842    3    2   15    2   25    4    5    9]
 [   3    0    1    1    6   19    2    3    7   18    8   16   10  879    7    2    2    4    0    8    5]
 [  16    3    3   15   11    1    0    0   32   20    4    3    3   10  954    0    2    5   10    0    6]
 [   3    0    1    0    1    4   10    0    1    0    1   25    9    1    0  978   16    7    0    1    8]
 [   4   11    1    1   12    8    1    0    5    1    1    7    4    2    3   13  980    1    2    1   14]
 [   5    1    0    0    1    1    3    0    1    1    0   25   39    0    4   24    0  891    3    1    5]
 [   2    9    7    5    4    5    0   25    7    1    4    5    7    1   17    1    1    1  947    0    9]
 [   3    2    1    0    3    8   14    8    0    2    1   38   16    6    2    8   11    0    2  945   18]
 [ 233  214  128  102  260  234  124  190  148  169  135  259  328  299  238  170  201  103  214  207 9976]]

2024-06-06 00:08:22,624 - ==> Best [Top1: 83.331   Top5: 97.419   Sparsity:0.00   Params: 424448 on epoch: 33]
2024-06-06 00:08:22,624 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:08:22,655 - 

2024-06-06 00:08:22,656 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:08:29,684 - Epoch: [36][  100/ 1218]    Overall Loss 0.388214    Objective Loss 0.388214                                        LR 0.001000    Time 0.070242    
2024-06-06 00:08:34,685 - Epoch: [36][  200/ 1218]    Overall Loss 0.390317    Objective Loss 0.390317                                        LR 0.001000    Time 0.060114    
2024-06-06 00:08:39,847 - Epoch: [36][  300/ 1218]    Overall Loss 0.395502    Objective Loss 0.395502                                        LR 0.001000    Time 0.057276    
2024-06-06 00:08:45,010 - Epoch: [36][  400/ 1218]    Overall Loss 0.395155    Objective Loss 0.395155                                        LR 0.001000    Time 0.055857    
2024-06-06 00:08:50,166 - Epoch: [36][  500/ 1218]    Overall Loss 0.394254    Objective Loss 0.394254                                        LR 0.001000    Time 0.054994    
2024-06-06 00:08:55,332 - Epoch: [36][  600/ 1218]    Overall Loss 0.394197    Objective Loss 0.394197                                        LR 0.001000    Time 0.054433    
2024-06-06 00:09:00,508 - Epoch: [36][  700/ 1218]    Overall Loss 0.393873    Objective Loss 0.393873                                        LR 0.001000    Time 0.054047    
2024-06-06 00:09:05,803 - Epoch: [36][  800/ 1218]    Overall Loss 0.393354    Objective Loss 0.393354                                        LR 0.001000    Time 0.053904    
2024-06-06 00:09:10,828 - Epoch: [36][  900/ 1218]    Overall Loss 0.392582    Objective Loss 0.392582                                        LR 0.001000    Time 0.053495    
2024-06-06 00:09:16,025 - Epoch: [36][ 1000/ 1218]    Overall Loss 0.392933    Objective Loss 0.392933                                        LR 0.001000    Time 0.053340    
2024-06-06 00:09:21,125 - Epoch: [36][ 1100/ 1218]    Overall Loss 0.393232    Objective Loss 0.393232                                        LR 0.001000    Time 0.053125    
2024-06-06 00:09:26,171 - Epoch: [36][ 1200/ 1218]    Overall Loss 0.394282    Objective Loss 0.394282                                        LR 0.001000    Time 0.052901    
2024-06-06 00:09:27,147 - Epoch: [36][ 1218/ 1218]    Overall Loss 0.394381    Objective Loss 0.394381    Top1 82.885086    Top5 96.332518    LR 0.001000    Time 0.052919    
2024-06-06 00:09:27,328 - --- validate (epoch=36)-----------
2024-06-06 00:09:27,328 - 34633 samples (256 per mini-batch)
2024-06-06 00:09:33,707 - Epoch: [36][  100/  136]    Loss 0.408810    Top1 83.144531    Top5 97.445312    
2024-06-06 00:09:35,390 - Epoch: [36][  136/  136]    Loss 0.410585    Top1 83.149020    Top5 97.464846    
2024-06-06 00:09:35,605 - ==> Top1: 83.149    Top5: 97.465    Loss: 0.411

2024-06-06 00:09:35,607 - ==> Confusion:
[[  829     1     2     0    11     2     0     4     6    44     0     1     3     5     1     2     6     0     0     0    14]
 [    6   922     3     0    10    47     3    13     5     0     1     3     2     1     2     1    15     3    12     3    11]
 [    5     3   873     9     6     1     7    12     0     4     6     4     4     1     4     2    10     2     7     3     7]
 [    2     1    13   901     3     9     3     5     0     3     9     3    11     3    17     3     2     6    14     0     8]
 [   30    18     3     4   888    30     2     5     1     7     3     4     1     5    11     1    11     2     7     4    17]
 [    3    12     2     1     4   909     4    39     3     2     3     9     9    14     2     1     9     2     2     2    11]
 [    4     1    36     2     1     5  1004     7     0     0     1     2     4     1     0     6     2     0     2     5     3]
 [    5    11    13     2     4    35     9   936     0     0     1    11     2     5     1     0     0     3    21     4    14]
 [   16     2     1     0     1     1     1     2   859    38    11     4     6    19    14     0     5     4     7     0    11]
 [  103     0     0     1     4     1     0     2    47   774     2     1     3    42     7     0     2     1     0     0    11]
 [    0     1     5    15     1     9     3     6    24     1   922     1     5    14     8     1     4     0    17     0    27]
 [    4     1     2     0     0    20     3     9     0     1     0   868    40     7     1    10     2    17     2    13    11]
 [    4     2     3     3     3     5     1     6     1     0     0    80   820     2     3     6     6    27     3     4    16]
 [    4     1     5     0     3    16     1     6     6     8     2     9     6   891     4     3     9     3     1     7    16]
 [   15     4     3    17     9     1     0     0    30     8     3     2     4    10   933     0     2     6    30     1    20]
 [    7     2     4     1     6     0     3     0     0     1     0    29    15     4     0   955    15    13     2     2     7]
 [    3     5     3     1     6     6     2     1     6     1     0     9     5     0     1     8   991     1     3     2    18]
 [    4     1     0     6     2     2     1     2     0     1     0    13    45     4     4     5     2   903     1     3     6]
 [    6     3     6     6     1     3     0    19     3     1     4     1     3     0     4     0     2     0   978     2    16]
 [    4     6     5     1     0    17    16    12     0     1     0    27     9     4     0     5     7     2     4   949    19]
 [  197   152   183    71   112   302    71   210    86    86    92   169   326   218   113    84   281   113   183   191 10692]]

2024-06-06 00:09:35,612 - ==> Best [Top1: 83.331   Top5: 97.419   Sparsity:0.00   Params: 424448 on epoch: 33]
2024-06-06 00:09:35,612 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:09:35,647 - 

2024-06-06 00:09:35,648 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:09:42,451 - Epoch: [37][  100/ 1218]    Overall Loss 0.386219    Objective Loss 0.386219                                        LR 0.001000    Time 0.068000    
2024-06-06 00:09:47,649 - Epoch: [37][  200/ 1218]    Overall Loss 0.383454    Objective Loss 0.383454                                        LR 0.001000    Time 0.059974    
2024-06-06 00:09:52,845 - Epoch: [37][  300/ 1218]    Overall Loss 0.382003    Objective Loss 0.382003                                        LR 0.001000    Time 0.057295    
2024-06-06 00:09:58,124 - Epoch: [37][  400/ 1218]    Overall Loss 0.382873    Objective Loss 0.382873                                        LR 0.001000    Time 0.056163    
2024-06-06 00:10:03,335 - Epoch: [37][  500/ 1218]    Overall Loss 0.382506    Objective Loss 0.382506                                        LR 0.001000    Time 0.055348    
2024-06-06 00:10:08,681 - Epoch: [37][  600/ 1218]    Overall Loss 0.384694    Objective Loss 0.384694                                        LR 0.001000    Time 0.055028    
2024-06-06 00:10:13,832 - Epoch: [37][  700/ 1218]    Overall Loss 0.384988    Objective Loss 0.384988                                        LR 0.001000    Time 0.054523    
2024-06-06 00:10:19,133 - Epoch: [37][  800/ 1218]    Overall Loss 0.386243    Objective Loss 0.386243                                        LR 0.001000    Time 0.054331    
2024-06-06 00:10:24,010 - Epoch: [37][  900/ 1218]    Overall Loss 0.387503    Objective Loss 0.387503                                        LR 0.001000    Time 0.053711    
2024-06-06 00:10:29,317 - Epoch: [37][ 1000/ 1218]    Overall Loss 0.387146    Objective Loss 0.387146                                        LR 0.001000    Time 0.053644    
2024-06-06 00:10:34,612 - Epoch: [37][ 1100/ 1218]    Overall Loss 0.386946    Objective Loss 0.386946                                        LR 0.001000    Time 0.053578    
2024-06-06 00:10:39,655 - Epoch: [37][ 1200/ 1218]    Overall Loss 0.387295    Objective Loss 0.387295                                        LR 0.001000    Time 0.053314    
2024-06-06 00:10:40,499 - Epoch: [37][ 1218/ 1218]    Overall Loss 0.387286    Objective Loss 0.387286    Top1 83.618582    Top5 96.577017    LR 0.001000    Time 0.053218    
2024-06-06 00:10:40,657 - --- validate (epoch=37)-----------
2024-06-06 00:10:40,657 - 34633 samples (256 per mini-batch)
2024-06-06 00:10:47,005 - Epoch: [37][  100/  136]    Loss 0.406427    Top1 81.578125    Top5 97.140625    
2024-06-06 00:10:48,965 - Epoch: [37][  136/  136]    Loss 0.409408    Top1 81.584038    Top5 97.150117    
2024-06-06 00:10:49,167 - ==> Top1: 81.584    Top5: 97.150    Loss: 0.409

2024-06-06 00:10:49,169 - ==> Confusion:
[[  791     3     5     0    10     4     0     2    13    73     0     2     2     4     8     1     0     5     3     1     4]
 [    0   975     1     0     8    13     1    13     3     0     6     3     3     2     1     2     3     2    15     3     9]
 [    5     5   818    24     6     3    38    20     0     5     5     7     2     4     3     4     4     2     6     3     6]
 [    3     6    11   911     1     6     5     0     1     1    13     3     8     2    10     2     2    10    12     1     8]
 [   12    33     0     1   928     9     1     1     3    12     4     4     1     3     8     4     8     2     4     1    15]
 [    4    34     3     4    13   868     1    32     3     5     4    11    10    16     4     1     5     7     2     8     8]
 [    0    13    12     0     1     7  1007     8     0     2     5     0     0     5     0     2     2     1     2    12     7]
 [    1    13    10     3     2    35     4   933     2     2     6     5     4     7     0     0     4     3    30    11     2]
 [   10     6     1     6     0     0     1     0   835    47    25     2     5    12    22     0     2     5    12     1    10]
 [   45     2     2     0     7     1     1     1    57   845     4     3     0    13     9     2     0     3     0     0     6]
 [    1    10     4    19     1     2     4     7     6     3   960     0     2     9     5     0     3     0    20     0     8]
 [    1     1     3     0     2    13     4    13     1     1     0   833    51    11     1     6     4    34     4    22     6]
 [    1     0     2     6     1     2     0     6     1     0     1    45   839     9     5     9     2    47     2    11     6]
 [    2     2     1     5     4    11     1     4    17    20    22     7     6   859     6     2     0     5     1     7    19]
 [    6     5     2    45     4     2     1     0    20     4    14     2     1     7   944     1     1     2    26     2     9]
 [    0     2     2     0     2     1    11     0     0     1     0    16     9     7     0   965     9    32     0     5     4]
 [    2    17     2     2     7     7     1     1     5     0     5     4     0     8     2     9   967     3     5     7    18]
 [    3     1     0     3     0     0     1     1     0     1     0     4     9     1     1     7     1   961     3     3     5]
 [    1     9     3     8     3     1     1    25     7     0     6     1     4     1     7     2     1     0   965     5     8]
 [    3     5     1     3     2    13    13     7     0     0     0    13     6     8     2     5     5     8     5   980     9]
 [  174   321   176   164   154   194   101   237    87   104   160   155   354   213   178   127   216   180   244   322 10071]]

2024-06-06 00:10:49,173 - ==> Best [Top1: 83.331   Top5: 97.419   Sparsity:0.00   Params: 424448 on epoch: 33]
2024-06-06 00:10:49,173 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:10:49,207 - 

2024-06-06 00:10:49,207 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:10:56,114 - Epoch: [38][  100/ 1218]    Overall Loss 0.389815    Objective Loss 0.389815                                        LR 0.001000    Time 0.069036    
2024-06-06 00:11:01,096 - Epoch: [38][  200/ 1218]    Overall Loss 0.387768    Objective Loss 0.387768                                        LR 0.001000    Time 0.059410    
2024-06-06 00:11:06,333 - Epoch: [38][  300/ 1218]    Overall Loss 0.388749    Objective Loss 0.388749                                        LR 0.001000    Time 0.057055    
2024-06-06 00:11:11,514 - Epoch: [38][  400/ 1218]    Overall Loss 0.385790    Objective Loss 0.385790                                        LR 0.001000    Time 0.055739    
2024-06-06 00:11:16,694 - Epoch: [38][  500/ 1218]    Overall Loss 0.386061    Objective Loss 0.386061                                        LR 0.001000    Time 0.054945    
2024-06-06 00:11:22,041 - Epoch: [38][  600/ 1218]    Overall Loss 0.386946    Objective Loss 0.386946                                        LR 0.001000    Time 0.054696    
2024-06-06 00:11:27,192 - Epoch: [38][  700/ 1218]    Overall Loss 0.386572    Objective Loss 0.386572                                        LR 0.001000    Time 0.054236    
2024-06-06 00:11:32,375 - Epoch: [38][  800/ 1218]    Overall Loss 0.386484    Objective Loss 0.386484                                        LR 0.001000    Time 0.053933    
2024-06-06 00:11:37,386 - Epoch: [38][  900/ 1218]    Overall Loss 0.387463    Objective Loss 0.387463                                        LR 0.001000    Time 0.053506    
2024-06-06 00:11:42,268 - Epoch: [38][ 1000/ 1218]    Overall Loss 0.387403    Objective Loss 0.387403                                        LR 0.001000    Time 0.053035    
2024-06-06 00:11:47,695 - Epoch: [38][ 1100/ 1218]    Overall Loss 0.388179    Objective Loss 0.388179                                        LR 0.001000    Time 0.053144    
2024-06-06 00:11:52,706 - Epoch: [38][ 1200/ 1218]    Overall Loss 0.388672    Objective Loss 0.388672                                        LR 0.001000    Time 0.052889    
2024-06-06 00:11:53,630 - Epoch: [38][ 1218/ 1218]    Overall Loss 0.388419    Objective Loss 0.388419    Top1 80.195599    Top5 97.066015    LR 0.001000    Time 0.052866    
2024-06-06 00:11:53,842 - --- validate (epoch=38)-----------
2024-06-06 00:11:53,842 - 34633 samples (256 per mini-batch)
2024-06-06 00:12:00,060 - Epoch: [38][  100/  136]    Loss 0.405557    Top1 81.230469    Top5 97.046875    
2024-06-06 00:12:01,963 - Epoch: [38][  136/  136]    Loss 0.417914    Top1 80.986343    Top5 96.971097    
2024-06-06 00:12:02,208 - ==> Top1: 80.986    Top5: 96.971    Loss: 0.418

2024-06-06 00:12:02,210 - ==> Confusion:
[[ 815    0    4    0    9    1    0    1    8   62    1    1    2    5    6    2    3    2    2    0    7]
 [   4  900    3    2   18   15    3   27   14    4    5    1    5    0    8    2    9    2   28    4    9]
 [   7    0  881    6    2    0    6   12    0   10    9    4    4    5    7    2    4    1    4    2    4]
 [   4    0   19  906    2    2    1    2    5    2   14    1    3    1   29    2    0    3   15    1    4]
 [  23   11    5    2  937    7    1    5    2   16    3    2    2    1   12    6    5    2    3    0    9]
 [  12   36    8   10   16  785    8   72    9    4    9   17   10   13    7    0    7    0    7    7    6]
 [   3    2   38    2    0    0  997   10    0    2    5    3    3    2    1    6    3    3    1    3    2]
 [   2    9   28    4    1    8    1  910    8    5    9   10    6    0    1    0    1    1   58    7    8]
 [  12    1    2    2    3    1    0    1  868   46   16    0    5    3   19    1    3    2   10    2    5]
 [  72    1    2    3    3    0    0    1   65  824    3    1    4    6   11    0    1    0    1    1    2]
 [   1    3    8   12    1    2    4    5   19    2  975    0    1    2    8    0    0    1   16    1    3]
 [   3    0    5    0    1   11    2    5    5    3    1  877   50    1    0    7    4   17    3    7    9]
 [   3    2    1    4    3    1    0    5    6    1    5   58  855    2    5    3    5   22    2    3    9]
 [   5    2    4    1    4    9    0    7   55   19   22   10   10  814   13    1    3    1    3    4   14]
 [  11    0    3   20    3    1    0    0   23    9    7    1    4    4  988    0    1    2   16    1    4]
 [   6    2    2    0    4    0    7    0    0    4    0   22   14    5    0  971    6   10    1    3    9]
 [   6    7    7    3    8    6    1    5    7    3    7    7    3    2    2    9  968    2    2    4   13]
 [   5    1    2    5    2    2    3    2    4    3    1   13   37    5    5    9    2  896    4    0    4]
 [   4    3    4   15    1    3    1   16    6    5    6    1    5    1   14    0    2    1  966    1    3]
 [   3    5   10    0    1    4   18   11    1    0    0   24   13    3    1    3    7    2    8  968    6]
 [ 240  151  279  160  191  123   86  169  233  162  236  155  381  204  272  116  227   92  286  222 9947]]

2024-06-06 00:12:02,221 - ==> Best [Top1: 83.331   Top5: 97.419   Sparsity:0.00   Params: 424448 on epoch: 33]
2024-06-06 00:12:02,221 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:12:02,245 - 

2024-06-06 00:12:02,245 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:12:09,218 - Epoch: [39][  100/ 1218]    Overall Loss 0.385911    Objective Loss 0.385911                                        LR 0.001000    Time 0.069699    
2024-06-06 00:12:14,323 - Epoch: [39][  200/ 1218]    Overall Loss 0.386537    Objective Loss 0.386537                                        LR 0.001000    Time 0.060362    
2024-06-06 00:12:19,471 - Epoch: [39][  300/ 1218]    Overall Loss 0.386208    Objective Loss 0.386208                                        LR 0.001000    Time 0.057393    
2024-06-06 00:12:24,453 - Epoch: [39][  400/ 1218]    Overall Loss 0.387481    Objective Loss 0.387481                                        LR 0.001000    Time 0.055493    
2024-06-06 00:12:29,652 - Epoch: [39][  500/ 1218]    Overall Loss 0.386343    Objective Loss 0.386343                                        LR 0.001000    Time 0.054788    
2024-06-06 00:12:34,650 - Epoch: [39][  600/ 1218]    Overall Loss 0.388128    Objective Loss 0.388128                                        LR 0.001000    Time 0.053983    
2024-06-06 00:12:39,793 - Epoch: [39][  700/ 1218]    Overall Loss 0.386474    Objective Loss 0.386474                                        LR 0.001000    Time 0.053614    
2024-06-06 00:12:44,918 - Epoch: [39][  800/ 1218]    Overall Loss 0.385766    Objective Loss 0.385766                                        LR 0.001000    Time 0.053315    
2024-06-06 00:12:50,068 - Epoch: [39][  900/ 1218]    Overall Loss 0.384815    Objective Loss 0.384815                                        LR 0.001000    Time 0.053111    
2024-06-06 00:12:55,064 - Epoch: [39][ 1000/ 1218]    Overall Loss 0.385535    Objective Loss 0.385535                                        LR 0.001000    Time 0.052793    
2024-06-06 00:13:00,309 - Epoch: [39][ 1100/ 1218]    Overall Loss 0.385884    Objective Loss 0.385884                                        LR 0.001000    Time 0.052760    
2024-06-06 00:13:05,072 - Epoch: [39][ 1200/ 1218]    Overall Loss 0.385763    Objective Loss 0.385763                                        LR 0.001000    Time 0.052330    
2024-06-06 00:13:05,980 - Epoch: [39][ 1218/ 1218]    Overall Loss 0.386016    Objective Loss 0.386016    Top1 81.907090    Top5 97.310513    LR 0.001000    Time 0.052302    
2024-06-06 00:13:06,230 - --- validate (epoch=39)-----------
2024-06-06 00:13:06,230 - 34633 samples (256 per mini-batch)
2024-06-06 00:13:12,643 - Epoch: [39][  100/  136]    Loss 0.396867    Top1 81.195312    Top5 96.937500    
2024-06-06 00:13:14,496 - Epoch: [39][  136/  136]    Loss 0.403164    Top1 81.150925    Top5 96.820951    
2024-06-06 00:13:14,751 - ==> Top1: 81.151    Top5: 96.821    Loss: 0.403

2024-06-06 00:13:14,753 - ==> Confusion:
[[ 808    1    2    0   11    1    0    1    3   82    2    0    1    4    4    3    2    2    0    1    3]
 [   2  933    0    4   27   38    6   11    3    0    4    1    1    4    8    1    3    3    8    4    2]
 [   9    3  851   12    9    5   10   19    0    5    9    3    0    7    5    3    4    0    5    7    4]
 [   7    1   11  897    2    6    2    7    1    5   21    0    6    2   26    3    1    5    6    0    7]
 [  26    5    0    1  960    6    0    4    2   17    2    3    0    4    7    3    3    1    1    2    7]
 [   6   16    2    1   16  881    1   38    4    9    2   12    5   20    2    2    3    3    6    6    8]
 [   5    3   35    1    3   11  981    6    0    1    6    1    0    4    1    6    2    3    3   10    4]
 [   4    8   15    2    4   36    3  951    2    3    4    1    3    2    0    1    2    4   22    7    3]
 [  15    4    1    0    1    2    0    2  858   67    7    1    4    6   18    1    1    2    6    1    5]
 [  65    0    3    2    3    1    0    3   25  864    1    1    0   14    9    1    0    1    1    1    6]
 [   0    4    3    7    1    3    1    8   18    4  975    4    1   12    8    0    0    0    7    3    5]
 [   6    1    2    0    4   16    3    8    1    2    0  858   48   11    0   13    3   17    2   11    5]
 [   1    1    4    6    0    1    0    4    5    1    2   51  852    5    2    2    3   33    8   11    3]
 [   4    1    1    1    6   10    1    6   23   21    7    9    5  881    8    2    3    0    2    2    8]
 [   7    4    2    7   10    7    0    1   24   16    6    0    0    6  977    0    2    2   15    1   11]
 [  10    2    3    1    8    3    8    0    2    3    0   21   17    6    2  922   22   24    3    2    7]
 [   8    6    3    2    4   12    0    2    6    3    2    9    3    6    2    3  972    0    4    9   16]
 [   5    2    1    2    1    5    2    4    1    2    3   11   24    5    1    7    0  921    2    0    6]
 [   4   11    8   20    5    4    0   19    5    2    6    0    0    0   11    0    1    1  954    2    5]
 [   3    7    4    2    2   17    7   12    0    1    1   17    6   14    1    8    9    2    3  966    6]
 [ 254  209  270  135  242  268   81  227  123  154  172  138  382  304  200  100  287  114  178  251 9843]]

2024-06-06 00:13:14,758 - ==> Best [Top1: 83.331   Top5: 97.419   Sparsity:0.00   Params: 424448 on epoch: 33]
2024-06-06 00:13:14,758 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:13:14,791 - 

2024-06-06 00:13:14,792 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:13:21,964 - Epoch: [40][  100/ 1218]    Overall Loss 0.387182    Objective Loss 0.387182                                        LR 0.001000    Time 0.071684    
2024-06-06 00:13:27,313 - Epoch: [40][  200/ 1218]    Overall Loss 0.379982    Objective Loss 0.379982                                        LR 0.001000    Time 0.062572    
2024-06-06 00:13:32,356 - Epoch: [40][  300/ 1218]    Overall Loss 0.380991    Objective Loss 0.380991                                        LR 0.001000    Time 0.058518    
2024-06-06 00:13:37,262 - Epoch: [40][  400/ 1218]    Overall Loss 0.382078    Objective Loss 0.382078                                        LR 0.001000    Time 0.056148    
2024-06-06 00:13:42,530 - Epoch: [40][  500/ 1218]    Overall Loss 0.381602    Objective Loss 0.381602                                        LR 0.001000    Time 0.055448    
2024-06-06 00:13:47,544 - Epoch: [40][  600/ 1218]    Overall Loss 0.382566    Objective Loss 0.382566                                        LR 0.001000    Time 0.054559    
2024-06-06 00:13:52,655 - Epoch: [40][  700/ 1218]    Overall Loss 0.381051    Objective Loss 0.381051                                        LR 0.001000    Time 0.054064    
2024-06-06 00:13:58,008 - Epoch: [40][  800/ 1218]    Overall Loss 0.381513    Objective Loss 0.381513                                        LR 0.001000    Time 0.053993    
2024-06-06 00:14:03,135 - Epoch: [40][  900/ 1218]    Overall Loss 0.381851    Objective Loss 0.381851                                        LR 0.001000    Time 0.053688    
2024-06-06 00:14:08,329 - Epoch: [40][ 1000/ 1218]    Overall Loss 0.382534    Objective Loss 0.382534                                        LR 0.001000    Time 0.053511    
2024-06-06 00:14:13,303 - Epoch: [40][ 1100/ 1218]    Overall Loss 0.382738    Objective Loss 0.382738                                        LR 0.001000    Time 0.053165    
2024-06-06 00:14:18,369 - Epoch: [40][ 1200/ 1218]    Overall Loss 0.383617    Objective Loss 0.383617                                        LR 0.001000    Time 0.052954    
2024-06-06 00:14:19,269 - Epoch: [40][ 1218/ 1218]    Overall Loss 0.383654    Objective Loss 0.383654    Top1 80.684597    Top5 98.044010    LR 0.001000    Time 0.052911    
2024-06-06 00:14:19,452 - --- validate (epoch=40)-----------
2024-06-06 00:14:19,452 - 34633 samples (256 per mini-batch)
2024-06-06 00:14:25,945 - Epoch: [40][  100/  136]    Loss 0.410651    Top1 81.996094    Top5 97.351562    
2024-06-06 00:14:27,876 - Epoch: [40][  136/  136]    Loss 0.405862    Top1 81.855456    Top5 97.343574    
2024-06-06 00:14:28,104 - ==> Top1: 81.855    Top5: 97.344    Loss: 0.406

2024-06-06 00:14:28,105 - ==> Confusion:
[[  793     0     3     0    14     5     0     2    10    78     0     0     5     4     5     1     2     0     2     1     6]
 [    4   964     2     0    16    10     6     8     4     2     5     2     1     0     3     0     7     0    14     8     7]
 [    9     1   831    14     8     3    31    17     0     5     6     4     0     7     2     3     5     0     7     7    10]
 [    7     3     7   913     3     1     3     3     2     0    16     0     6     4    25     1     1     2     8     5     6]
 [   14    17     4     2   946    11     1     2     2     9     2     3     2     4     9     3    12     1     3     1     6]
 [    4    44     3     3     7   851     8    27     6     3     6    10     6    18     8     1     6     1     2    14    15]
 [    2     4    12     0     1     3  1010     3     3     3     4     1     6     0     2     3     3     1     3    14     8]
 [    4    29     9     1     1    29     4   911     1     2     4     5     1     4     1     0     1     0    33    25    12]
 [   11    10     0     4     2     3     0     1   847    33    18     6     2    12    31     1     2     2     9     0     8]
 [   51     1     0     1    14     2     0     1    74   777     4     0     1    43    13     0     2     1     2     2    12]
 [    0     6     6    11     1     1     2     4    18     1   969     1     1    10     7     0     0     0    12     4    10]
 [    2     3     0     1     0    12     7    10     2     1     2   837    29     3     1    25     4     9     2    50    11]
 [    4     1     2     5     0     6     3     4     4     2     2    59   844     4     2     6     5    17     3    12    10]
 [    2     3     1     1     2    10     2     1    17    13    10     9     5   888     6     2     6     1     0    15     7]
 [    8     2     1    10     6     1     0     2    29     9     7     0     0     6   986     0     3     1    11     3    13]
 [    3     3     4     0     3     4    14     0     1     6     0    13     8     2     0   979     9     8     3     2     4]
 [    1     7     0     0     7     6     3     2     3     5     1     4     2     3     4    14   975     0     1    13    21]
 [    3     3     3     4     0     3     3     2     4     2     0    19    38     5     7    19     3   870     3     6     8]
 [    5     6     6     8     3     1     3    15     2     3     5     0     1     2    19     0     2     2   959     2    14]
 [    2     3     2     0     1     3    14     5     2     1     0     9     1     3     0     7     4     4     5  1014     8]
 [  179   257   138   123   172   144   150   165   113    88   175   132   345   252   224   114   227    69   167   513 10185]]

2024-06-06 00:14:28,114 - ==> Best [Top1: 83.331   Top5: 97.419   Sparsity:0.00   Params: 424448 on epoch: 33]
2024-06-06 00:14:28,114 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:14:28,139 - 

2024-06-06 00:14:28,139 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:14:35,012 - Epoch: [41][  100/ 1218]    Overall Loss 0.387235    Objective Loss 0.387235                                        LR 0.001000    Time 0.068698    
2024-06-06 00:14:40,193 - Epoch: [41][  200/ 1218]    Overall Loss 0.380050    Objective Loss 0.380050                                        LR 0.001000    Time 0.060240    
2024-06-06 00:14:45,181 - Epoch: [41][  300/ 1218]    Overall Loss 0.374171    Objective Loss 0.374171                                        LR 0.001000    Time 0.056777    
2024-06-06 00:14:50,383 - Epoch: [41][  400/ 1218]    Overall Loss 0.375336    Objective Loss 0.375336                                        LR 0.001000    Time 0.055581    
2024-06-06 00:14:55,420 - Epoch: [41][  500/ 1218]    Overall Loss 0.377233    Objective Loss 0.377233                                        LR 0.001000    Time 0.054534    
2024-06-06 00:15:00,537 - Epoch: [41][  600/ 1218]    Overall Loss 0.377863    Objective Loss 0.377863                                        LR 0.001000    Time 0.053969    
2024-06-06 00:15:05,781 - Epoch: [41][  700/ 1218]    Overall Loss 0.378894    Objective Loss 0.378894                                        LR 0.001000    Time 0.053747    
2024-06-06 00:15:11,021 - Epoch: [41][  800/ 1218]    Overall Loss 0.379569    Objective Loss 0.379569                                        LR 0.001000    Time 0.053575    
2024-06-06 00:15:16,236 - Epoch: [41][  900/ 1218]    Overall Loss 0.381568    Objective Loss 0.381568                                        LR 0.001000    Time 0.053415    
2024-06-06 00:15:21,756 - Epoch: [41][ 1000/ 1218]    Overall Loss 0.381254    Objective Loss 0.381254                                        LR 0.001000    Time 0.053590    
2024-06-06 00:15:26,802 - Epoch: [41][ 1100/ 1218]    Overall Loss 0.380292    Objective Loss 0.380292                                        LR 0.001000    Time 0.053304    
2024-06-06 00:15:31,774 - Epoch: [41][ 1200/ 1218]    Overall Loss 0.380638    Objective Loss 0.380638                                        LR 0.001000    Time 0.053003    
2024-06-06 00:15:32,678 - Epoch: [41][ 1218/ 1218]    Overall Loss 0.380829    Objective Loss 0.380829    Top1 80.440098    Top5 94.865526    LR 0.001000    Time 0.052961    
2024-06-06 00:15:32,917 - --- validate (epoch=41)-----------
2024-06-06 00:15:32,918 - 34633 samples (256 per mini-batch)
2024-06-06 00:15:39,026 - Epoch: [41][  100/  136]    Loss 0.410579    Top1 80.589844    Top5 96.574219    
2024-06-06 00:15:40,851 - Epoch: [41][  136/  136]    Loss 0.409487    Top1 80.608091    Top5 96.613057    
2024-06-06 00:15:41,087 - ==> Top1: 80.608    Top5: 96.613    Loss: 0.409

2024-06-06 00:15:41,088 - ==> Confusion:
[[ 779    1    1    0   24    3    1    1   12   86    0    2    3    4    4    0    0    1    2    1    6]
 [   2  945    1    1   28   18    3   10    3    1    6    4    5    1    6    4    7    3    8    3    4]
 [   7    5  793    6    9    1   37   22    2   11   21    4    2    4    3   17    6    1    5    5    9]
 [   3    7    5  880    4   11    4    5    2    4   22    2    7    2   37    4    1    3    7    0    6]
 [  14    5    0    2  971    4    4    1    5   13    2    4    2    4    4    7    4    0    2    3    3]
 [   1   49    3    1   17  845    1   28   11    2    3   20    5   22    2    3    5    5    2   13    5]
 [   1    4    7    1    2    2 1013    9    2    3    6    4    1    3    0   12    1    0    1    9    5]
 [   1   15    9    3    3   19    7  933    6    6   11   11    7    1    0    3    0    2   21   15    4]
 [   7    8    0    0    6    1    2    0  867   49    9    1    7    8   26    0    1    2    5    1    2]
 [  32    2    0    0   14    1    0    0   67  855    0    0    3   15    6    0    0    2    0    0    4]
 [   2    5    2    4    3    1    2    8   33    2  974    1    1    4   10    1    1    0    4    3    3]
 [   2    1    0    0    2   10    3    7    4    1    1  876   25   17    1   29    0   11    4   11    6]
 [   1    3    2    2    1    3    2    2    8    0    3   68  816    2    2   18    2   37    2   10   11]
 [   3    2    0    0    3   16    1    1   41   15    9   14    6  863    7    4    1    2    0    5    8]
 [  11    4    1    7   15    2    1    0   41    7    3    2    4    3  982    0    0    1    6    1    7]
 [   3    0    1    0    3    1    6    0    1    6    0   11    5    4    0 1003    4    6    1    4    7]
 [   2   10    2    2   11    5    1    1   10    0    1   10    8    5    3   15  961    0    1   13   11]
 [   1    0    0    1    0    2    5    2    3    3    1   20   24    6    5   25    3  898    0    2    4]
 [   2   16    6    9    6    1    1   20    9    0    8    1    5    1   21    0    0    2  943    1    6]
 [   2    8    1    0    1    8   17    9    4    1    1   12    6    0    3   15    5    4    2  983    6]
 [ 152  274  117   68  361  182  127  208  201  146  193  237  306  228  230  345  236  104  187  293 9737]]

2024-06-06 00:15:41,096 - ==> Best [Top1: 83.331   Top5: 97.419   Sparsity:0.00   Params: 424448 on epoch: 33]
2024-06-06 00:15:41,096 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:15:41,117 - 

2024-06-06 00:15:41,117 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:15:47,970 - Epoch: [42][  100/ 1218]    Overall Loss 0.369847    Objective Loss 0.369847                                        LR 0.001000    Time 0.068491    
2024-06-06 00:15:53,271 - Epoch: [42][  200/ 1218]    Overall Loss 0.371476    Objective Loss 0.371476                                        LR 0.001000    Time 0.060737    
2024-06-06 00:15:58,501 - Epoch: [42][  300/ 1218]    Overall Loss 0.370906    Objective Loss 0.370906                                        LR 0.001000    Time 0.057916    
2024-06-06 00:16:03,494 - Epoch: [42][  400/ 1218]    Overall Loss 0.372461    Objective Loss 0.372461                                        LR 0.001000    Time 0.055913    
2024-06-06 00:16:08,561 - Epoch: [42][  500/ 1218]    Overall Loss 0.375056    Objective Loss 0.375056                                        LR 0.001000    Time 0.054860    
2024-06-06 00:16:13,765 - Epoch: [42][  600/ 1218]    Overall Loss 0.376400    Objective Loss 0.376400                                        LR 0.001000    Time 0.054386    
2024-06-06 00:16:19,039 - Epoch: [42][  700/ 1218]    Overall Loss 0.376781    Objective Loss 0.376781                                        LR 0.001000    Time 0.054146    
2024-06-06 00:16:23,951 - Epoch: [42][  800/ 1218]    Overall Loss 0.377706    Objective Loss 0.377706                                        LR 0.001000    Time 0.053515    
2024-06-06 00:16:29,202 - Epoch: [42][  900/ 1218]    Overall Loss 0.380013    Objective Loss 0.380013                                        LR 0.001000    Time 0.053401    
2024-06-06 00:16:34,343 - Epoch: [42][ 1000/ 1218]    Overall Loss 0.380747    Objective Loss 0.380747                                        LR 0.001000    Time 0.053199    
2024-06-06 00:16:39,318 - Epoch: [42][ 1100/ 1218]    Overall Loss 0.380443    Objective Loss 0.380443                                        LR 0.001000    Time 0.052883    
2024-06-06 00:16:44,517 - Epoch: [42][ 1200/ 1218]    Overall Loss 0.379958    Objective Loss 0.379958                                        LR 0.001000    Time 0.052806    
2024-06-06 00:16:45,440 - Epoch: [42][ 1218/ 1218]    Overall Loss 0.380112    Objective Loss 0.380112    Top1 77.995110    Top5 96.332518    LR 0.001000    Time 0.052783    
2024-06-06 00:16:45,681 - --- validate (epoch=42)-----------
2024-06-06 00:16:45,681 - 34633 samples (256 per mini-batch)
2024-06-06 00:16:52,163 - Epoch: [42][  100/  136]    Loss 0.402356    Top1 82.351562    Top5 97.183594    
2024-06-06 00:16:54,017 - Epoch: [42][  136/  136]    Loss 0.405631    Top1 82.158635    Top5 97.233852    
2024-06-06 00:16:54,212 - ==> Top1: 82.159    Top5: 97.234    Loss: 0.406

2024-06-06 00:16:54,213 - ==> Confusion:
[[  857     4     4     0     5     1     1     1     6    37     0     1     1     1     3     2     1     1     0     0     5]
 [    5   951     5     1    18    20     4    13     1     3     3     2     3     2     5     2     3     0     9     4     9]
 [   15     2   878    11     3     3     9     3     1     6     5     1     3     5     2     7     4     2     3     4     3]
 [    7     2    16   914     0     4     1     2     3     1     9     2     5     5    22     5     3     4     0     1    10]
 [   39    11     5     3   921     9     1     1     0    13     1     4     3     5    12     4     8     0     2     1    11]
 [    9    35     5     6    13   854     8    28     4     5     4    10     3    16     3     3     7     2     1    10    17]
 [    3     4    28     6     0     3   995     3     0     4     2     1     3     3     0    11     3     1     2     8     6]
 [    7    11    28     5     2    25     3   907     2     3    11     5     5     6     4     3     0     2    18    15    15]
 [   25     1     0     4     2     1     0     1   851    56     9     1     5    10    23     4     3     0     1     1     4]
 [  111     1     2     0     1     1     0     0    37   818     1     1     2    14     5     0     1     2     0     0     4]
 [    2     4    13    12     0     1     4     3    25     5   945     0     0    14     9     1     5     1     8     1    11]
 [    6     5     2     1     0     9     4     9     1     2     0   825    46    21     1    29     4    19     0    19     8]
 [    6     1     7     5     1     1     2     2     1     0     1    44   855     8     1    14     5    27     4     2     8]
 [    4     1     1     2     4     3     0     0    14    39     4     8     2   890     9     2     5     0     0     8     5]
 [   16     2     2    18     6     1     1     0    21     9     4     1     2     4   982     1     2     2    10     0    14]
 [    6     0     5     0     2     1     5     0     0     0     0     6     7     9     3   995    10     6     1     4     6]
 [    4    11     2     3     7     3     1     1     2     1     2     1     5     7     3    16   976     1     2     4    20]
 [    6     2     2     3     4     3     0     2     0     6     0     8    29     8     0    13     4   903     1     5     6]
 [    4    12    15    29     1     0     2    17    10     0    11     1     5     1    16     0     4     1   921     1     7]
 [    2     3     5     1     2     6    13     7     1     0     2     6     7     6     2     6    12     6     5   982    14]
 [  275   207   298   172   203   131    87   126   104   145   162    99   358   285   180   169   227    93   123   254 10234]]

2024-06-06 00:16:54,215 - ==> Best [Top1: 83.331   Top5: 97.419   Sparsity:0.00   Params: 424448 on epoch: 33]
2024-06-06 00:16:54,215 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:16:54,243 - 

2024-06-06 00:16:54,243 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:17:01,256 - Epoch: [43][  100/ 1218]    Overall Loss 0.367185    Objective Loss 0.367185                                        LR 0.001000    Time 0.070083    
2024-06-06 00:17:06,461 - Epoch: [43][  200/ 1218]    Overall Loss 0.371742    Objective Loss 0.371742                                        LR 0.001000    Time 0.061054    
2024-06-06 00:17:11,432 - Epoch: [43][  300/ 1218]    Overall Loss 0.375860    Objective Loss 0.375860                                        LR 0.001000    Time 0.057265    
2024-06-06 00:17:16,318 - Epoch: [43][  400/ 1218]    Overall Loss 0.375480    Objective Loss 0.375480                                        LR 0.001000    Time 0.055157    
2024-06-06 00:17:21,316 - Epoch: [43][  500/ 1218]    Overall Loss 0.375251    Objective Loss 0.375251                                        LR 0.001000    Time 0.054117    
2024-06-06 00:17:26,371 - Epoch: [43][  600/ 1218]    Overall Loss 0.376549    Objective Loss 0.376549                                        LR 0.001000    Time 0.053519    
2024-06-06 00:17:31,387 - Epoch: [43][  700/ 1218]    Overall Loss 0.375594    Objective Loss 0.375594                                        LR 0.001000    Time 0.053035    
2024-06-06 00:17:36,306 - Epoch: [43][  800/ 1218]    Overall Loss 0.374826    Objective Loss 0.374826                                        LR 0.001000    Time 0.052551    
2024-06-06 00:17:41,400 - Epoch: [43][  900/ 1218]    Overall Loss 0.374785    Objective Loss 0.374785                                        LR 0.001000    Time 0.052370    
2024-06-06 00:17:46,500 - Epoch: [43][ 1000/ 1218]    Overall Loss 0.375968    Objective Loss 0.375968                                        LR 0.001000    Time 0.052229    
2024-06-06 00:17:51,863 - Epoch: [43][ 1100/ 1218]    Overall Loss 0.375428    Objective Loss 0.375428                                        LR 0.001000    Time 0.052355    
2024-06-06 00:17:56,868 - Epoch: [43][ 1200/ 1218]    Overall Loss 0.375387    Objective Loss 0.375387                                        LR 0.001000    Time 0.052160    
2024-06-06 00:17:57,749 - Epoch: [43][ 1218/ 1218]    Overall Loss 0.375681    Objective Loss 0.375681    Top1 79.706601    Top5 96.577017    LR 0.001000    Time 0.052113    
2024-06-06 00:17:57,913 - --- validate (epoch=43)-----------
2024-06-06 00:17:57,914 - 34633 samples (256 per mini-batch)
2024-06-06 00:18:04,122 - Epoch: [43][  100/  136]    Loss 0.401765    Top1 83.207031    Top5 97.582031    
2024-06-06 00:18:05,923 - Epoch: [43][  136/  136]    Loss 0.397654    Top1 83.068172    Top5 97.568793    
2024-06-06 00:18:06,174 - ==> Top1: 83.068    Top5: 97.569    Loss: 0.398

2024-06-06 00:18:06,175 - ==> Confusion:
[[  783     0     4     0    15     5     1     1     6    86     0     1     0     4     4     2     4     3     0     3     9]
 [    4   969     4     0    12    15     5     2     2     1     4     3     2     0     5     1    11     2    15     4     2]
 [    6     1   876     7     2     3    20     9     1     4     5     5     0     4     0     6     0     2     1     5    13]
 [    6     2    20   876     1     4     4     2     0     1    18     5     6     2    24     4     1     6    18     2    14]
 [   17    17     2     2   928    14     3     2     0     9     0     3     0     1    11     4     8     0     4     3    26]
 [   10    47     1     2     8   852     7    29     2     4     2    22     1    13     2     1    10     2     1    15    12]
 [    3     2    17     2     1     1  1007     7     0     0     5     6     0     1     0     7     2     1     3    10    11]
 [    2    31    15     1     2    37     5   879     2     2     2    17     4     0     2     0     1     0    32    30    13]
 [    8     9     0     0     2     1     1     2   871    31    16     3     5    13    22     1     8     2     3     1     3]
 [   37     2     3     0     9     6     2     2    67   816     2     7     1    21     8     0     4     1     2     2     9]
 [    1     4     7    11     2     0     4     3    13     2   962     2     3     5     9     0     3     1    11     5    16]
 [    4     1     0     0     2     9     5     4     0     0     0   908    20     1     0    18     4     9     1    16     9]
 [    4     0     3     4     0     2     2     2     3     1     2   110   774     3     2    15    11    30     2    10    15]
 [    4     4     0     0     6    16     0     2    13    12    10    16     3   875     2     6     5     0     1    14    12]
 [    9     4     4     6    11     3     0     0    17     6     5     7     2     8   986     0     2     2    15     1    10]
 [    4     2     2     1     3     1    12     0     1     2     0    18     5     1     0   991     7     5     1     3     7]
 [    4    10     3     1     9     0     4     0     3     1     2     9     1     0     2    11   989     0     1     7    15]
 [    3     1     2     3     1     0     1     1     0     2     0    47    28     3     9    21     3   861     3     2    14]
 [    4     6     9     8     2     2     5     6     2     0     7     2     5     1     7     1     2     1   978     1     9]
 [    1     2     3     1     0     3    14     3     0     1     1    19     2     1     0     7     3     2     6  1004    15]
 [  194   234   185    66   147   167   103    92    92    90   146   189   229   224   193   172   306    80   174   265 10584]]

2024-06-06 00:18:06,180 - ==> Best [Top1: 83.331   Top5: 97.419   Sparsity:0.00   Params: 424448 on epoch: 33]
2024-06-06 00:18:06,180 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:18:06,213 - 

2024-06-06 00:18:06,213 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:18:12,885 - Epoch: [44][  100/ 1218]    Overall Loss 0.376236    Objective Loss 0.376236                                        LR 0.001000    Time 0.066682    
2024-06-06 00:18:18,040 - Epoch: [44][  200/ 1218]    Overall Loss 0.376919    Objective Loss 0.376919                                        LR 0.001000    Time 0.059102    
2024-06-06 00:18:23,084 - Epoch: [44][  300/ 1218]    Overall Loss 0.375292    Objective Loss 0.375292                                        LR 0.001000    Time 0.056207    
2024-06-06 00:18:28,151 - Epoch: [44][  400/ 1218]    Overall Loss 0.376091    Objective Loss 0.376091                                        LR 0.001000    Time 0.054817    
2024-06-06 00:18:33,330 - Epoch: [44][  500/ 1218]    Overall Loss 0.375858    Objective Loss 0.375858                                        LR 0.001000    Time 0.054206    
2024-06-06 00:18:38,400 - Epoch: [44][  600/ 1218]    Overall Loss 0.378328    Objective Loss 0.378328                                        LR 0.001000    Time 0.053618    
2024-06-06 00:18:43,553 - Epoch: [44][  700/ 1218]    Overall Loss 0.378033    Objective Loss 0.378033                                        LR 0.001000    Time 0.053317    
2024-06-06 00:18:48,651 - Epoch: [44][  800/ 1218]    Overall Loss 0.376783    Objective Loss 0.376783                                        LR 0.001000    Time 0.053021    
2024-06-06 00:18:53,984 - Epoch: [44][  900/ 1218]    Overall Loss 0.377637    Objective Loss 0.377637                                        LR 0.001000    Time 0.053053    
2024-06-06 00:18:59,016 - Epoch: [44][ 1000/ 1218]    Overall Loss 0.376276    Objective Loss 0.376276                                        LR 0.001000    Time 0.052776    
2024-06-06 00:19:04,082 - Epoch: [44][ 1100/ 1218]    Overall Loss 0.376469    Objective Loss 0.376469                                        LR 0.001000    Time 0.052582    
2024-06-06 00:19:09,263 - Epoch: [44][ 1200/ 1218]    Overall Loss 0.376385    Objective Loss 0.376385                                        LR 0.001000    Time 0.052515    
2024-06-06 00:19:10,174 - Epoch: [44][ 1218/ 1218]    Overall Loss 0.376515    Objective Loss 0.376515    Top1 83.129584    Top5 97.066015    LR 0.001000    Time 0.052487    
2024-06-06 00:19:10,405 - --- validate (epoch=44)-----------
2024-06-06 00:19:10,405 - 34633 samples (256 per mini-batch)
2024-06-06 00:19:16,617 - Epoch: [44][  100/  136]    Loss 0.405237    Top1 83.402344    Top5 97.425781    
2024-06-06 00:19:18,604 - Epoch: [44][  136/  136]    Loss 0.401202    Top1 83.336702    Top5 97.412872    
2024-06-06 00:19:18,822 - ==> Top1: 83.337    Top5: 97.413    Loss: 0.401

2024-06-06 00:19:18,824 - ==> Confusion:
[[  809     2     2     2    15     2     0     2     6    56     0     4     2     4     7     1     1     0     1     2    13]
 [    3   942     2     2    18    23     3    12     3     0     6     2     3     1     4     1    12     1    14     4     7]
 [    9     2   853    13     3     1    17    14     1     6    18     5     0     3     1     3     6     1     3     3     8]
 [    4     0     9   895     1     4     4     5     2     2    23     4     7     2    25     2     3     4     7     0    13]
 [   18    11     4     1   951     8     1     2     3     8     3     6     2     6     9     3     7     0     1     2     8]
 [    6    34     4     3    17   859     7    24     2     5     2     5     6    25     2     2     8     4     5     7    16]
 [    0     1    25     1     1    11  1003     5     2     0    10     5     2     1     0     3     1     0     1     6     8]
 [    3    11    12     4     2    35     4   928     2     1     6     6     5     5     2     2     0     1    29     9    10]
 [    8     1     0     3     2     3     1     4   820    43    28     4     9    27    23     0     2     2    12     1     9]
 [   58     1     2     1     7     1     0     1    51   822     3     6     0    28    11     3     0     1     0     0     5]
 [    1     2     3     6     2     2     1     9     8     2   976     2     0    14     8     0     1     0    10     3    14]
 [    0     1     3     1     2    19     6     3     0     3     1   826    29    25     2    19     7    26     2    27     9]
 [    1     1     8     6     0     6     2     0     4     1     3    60   810     4     4    11     8    44     5     5    12]
 [    1     0     3     0     3    10     2     2     8    18    14     5     0   907     5     2     2     4     0     4    11]
 [    6     3     4    18     7     1     0     1    30     6     9     3     2     8   964     0     2     2    10     1    21]
 [    1     1     5     0     4     3     8     0     0     2     0    17     6     5     0   973    15    14     0     3     9]
 [    3    11     1     3     6     7     2     0     5     1     5     3     4     3     2     9   983     1     1     9    13]
 [    1     2     2     9     1     2     4     3     2     3     1     7    19     5     0    12     2   924     2     1     3]
 [    3     4     5    16     5     3     2    19     6     0     6     4     2     1    19     1     1     0   948     2    11]
 [    3     3     4     2     0    10    10     7     0     2     1    15     7     5     0    10     3     4     2   989    11]
 [  131   142   162   129   214   149    96   155    79   106   168   150   256   281   193   129   240   117   168   187 10680]]

2024-06-06 00:19:18,835 - ==> Best [Top1: 83.337   Top5: 97.413   Sparsity:0.00   Params: 424448 on epoch: 44]
2024-06-06 00:19:18,835 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:19:18,878 - 

2024-06-06 00:19:18,878 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:19:25,709 - Epoch: [45][  100/ 1218]    Overall Loss 0.378171    Objective Loss 0.378171                                        LR 0.001000    Time 0.068274    
2024-06-06 00:19:30,658 - Epoch: [45][  200/ 1218]    Overall Loss 0.376814    Objective Loss 0.376814                                        LR 0.001000    Time 0.058871    
2024-06-06 00:19:35,574 - Epoch: [45][  300/ 1218]    Overall Loss 0.376891    Objective Loss 0.376891                                        LR 0.001000    Time 0.055625    
2024-06-06 00:19:40,693 - Epoch: [45][  400/ 1218]    Overall Loss 0.376352    Objective Loss 0.376352                                        LR 0.001000    Time 0.054511    
2024-06-06 00:19:45,838 - Epoch: [45][  500/ 1218]    Overall Loss 0.376220    Objective Loss 0.376220                                        LR 0.001000    Time 0.053892    
2024-06-06 00:19:51,079 - Epoch: [45][  600/ 1218]    Overall Loss 0.375408    Objective Loss 0.375408                                        LR 0.001000    Time 0.053642    
2024-06-06 00:19:56,258 - Epoch: [45][  700/ 1218]    Overall Loss 0.374750    Objective Loss 0.374750                                        LR 0.001000    Time 0.053374    
2024-06-06 00:20:01,374 - Epoch: [45][  800/ 1218]    Overall Loss 0.374240    Objective Loss 0.374240                                        LR 0.001000    Time 0.053094    
2024-06-06 00:20:06,612 - Epoch: [45][  900/ 1218]    Overall Loss 0.373785    Objective Loss 0.373785                                        LR 0.001000    Time 0.053011    
2024-06-06 00:20:11,856 - Epoch: [45][ 1000/ 1218]    Overall Loss 0.373489    Objective Loss 0.373489                                        LR 0.001000    Time 0.052952    
2024-06-06 00:20:16,985 - Epoch: [45][ 1100/ 1218]    Overall Loss 0.374542    Objective Loss 0.374542                                        LR 0.001000    Time 0.052798    
2024-06-06 00:20:22,136 - Epoch: [45][ 1200/ 1218]    Overall Loss 0.374412    Objective Loss 0.374412                                        LR 0.001000    Time 0.052689    
2024-06-06 00:20:23,073 - Epoch: [45][ 1218/ 1218]    Overall Loss 0.374737    Objective Loss 0.374737    Top1 83.129584    Top5 97.310513    LR 0.001000    Time 0.052679    
2024-06-06 00:20:23,306 - --- validate (epoch=45)-----------
2024-06-06 00:20:23,307 - 34633 samples (256 per mini-batch)
2024-06-06 00:20:29,496 - Epoch: [45][  100/  136]    Loss 0.402674    Top1 82.390625    Top5 97.191406    
2024-06-06 00:20:31,398 - Epoch: [45][  136/  136]    Loss 0.402157    Top1 82.277019    Top5 97.167441    
2024-06-06 00:20:31,592 - ==> Top1: 82.277    Top5: 97.167    Loss: 0.402

2024-06-06 00:20:31,594 - ==> Confusion:
[[  790     0     4     1    11     2     0     3     8    85     2     2     0     6     4     2     1     1     1     1     7]
 [    7   904     5     6    21    24     4    22     6     3     4     2     3     2     8     1     7     1    13     7    13]
 [    8     0   860    14     3     0    18    18     1     6     7     5     1     4     1     6     5     0     6     3     4]
 [    9     0     9   923     0     4     4     1     2     3    12     2     8     3    14     3     2     4     8     0     5]
 [   23     3     4     0   943     5     2     3     2    11     2     2     2     4    22     6     7     0     1     2    10]
 [    9    10     2     5     9   854     5    41     2     3     1    19     4    32     3     3     4     2     4    23     8]
 [    6     1    16     2     1     3   997     9     0     1     3     7     1     1     0    10     2     3     3    14     6]
 [    5     5    15     3     2    24     7   940     2     2     2     9     5     2     0     1     1     1    23    20     8]
 [   13     1     0     2     1     0     0     3   845    56    24     1     3    23    14     3     2     1     6     2     2]
 [   60     0     0     1     6     0     1     0    34   864     2     0     1    15     6     1     0     1     2     1     6]
 [    2     1     4    23     1     3     4     7     6     0   976     1     0    18     7     0     0     0     9     0     2]
 [    2     2     2     0     0     6     4     6     3     1     1   899    23    12     1    15     4     8     3    12     7]
 [    6     0     2     7     2     7     1     5     2     2     1    85   790    15     3     9     2    18     6     9    23]
 [    2     1     4     1     1     7     0     6     7    16     3    15     5   906     6     5     3     2     1     4     6]
 [   10     3     3    22     2     3     0     2    20    11    10     1     3    10   969     0     3     1    12     0    13]
 [    2     1     3     0     3     0     7     0     0     2     0    24    11     0     0   992     5     4     2     4     6]
 [    5     2     6     6     4     2     1     1     7     1     2     8     3     3     2    10   974     1     2    12    20]
 [    5     1     1     3     1     1     2     4     1     1     0    35    36     4     5    26     4   867     2     5     1]
 [    5     0    10    13     0     2     0    27     5     0     9     2     1     0    18     0     1     0   954     4     7]
 [    3     1     4     0     0     4     8    14     0     0     2    22     4     9     1    10     1     2     3   988    12]
 [  231   100   246   150   172   136   106   181    90   114   199   208   280   324   211   207   213    65   198   241 10260]]

2024-06-06 00:20:31,596 - ==> Best [Top1: 83.337   Top5: 97.413   Sparsity:0.00   Params: 424448 on epoch: 44]
2024-06-06 00:20:31,596 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:20:31,616 - 

2024-06-06 00:20:31,617 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:20:38,394 - Epoch: [46][  100/ 1218]    Overall Loss 0.382998    Objective Loss 0.382998                                        LR 0.001000    Time 0.067736    
2024-06-06 00:20:43,444 - Epoch: [46][  200/ 1218]    Overall Loss 0.373393    Objective Loss 0.373393                                        LR 0.001000    Time 0.059105    
2024-06-06 00:20:48,559 - Epoch: [46][  300/ 1218]    Overall Loss 0.368225    Objective Loss 0.368225                                        LR 0.001000    Time 0.056447    
2024-06-06 00:20:53,857 - Epoch: [46][  400/ 1218]    Overall Loss 0.368410    Objective Loss 0.368410                                        LR 0.001000    Time 0.055575    
2024-06-06 00:20:58,886 - Epoch: [46][  500/ 1218]    Overall Loss 0.369095    Objective Loss 0.369095                                        LR 0.001000    Time 0.054513    
2024-06-06 00:21:03,860 - Epoch: [46][  600/ 1218]    Overall Loss 0.368669    Objective Loss 0.368669                                        LR 0.001000    Time 0.053713    
2024-06-06 00:21:09,350 - Epoch: [46][  700/ 1218]    Overall Loss 0.368646    Objective Loss 0.368646                                        LR 0.001000    Time 0.053879    
2024-06-06 00:21:14,282 - Epoch: [46][  800/ 1218]    Overall Loss 0.368124    Objective Loss 0.368124                                        LR 0.001000    Time 0.053306    
2024-06-06 00:21:19,473 - Epoch: [46][  900/ 1218]    Overall Loss 0.367323    Objective Loss 0.367323                                        LR 0.001000    Time 0.053148    
2024-06-06 00:21:24,509 - Epoch: [46][ 1000/ 1218]    Overall Loss 0.366653    Objective Loss 0.366653                                        LR 0.001000    Time 0.052866    
2024-06-06 00:21:29,585 - Epoch: [46][ 1100/ 1218]    Overall Loss 0.368375    Objective Loss 0.368375                                        LR 0.001000    Time 0.052673    
2024-06-06 00:21:34,560 - Epoch: [46][ 1200/ 1218]    Overall Loss 0.368590    Objective Loss 0.368590                                        LR 0.001000    Time 0.052427    
2024-06-06 00:21:35,451 - Epoch: [46][ 1218/ 1218]    Overall Loss 0.368506    Objective Loss 0.368506    Top1 80.929095    Top5 97.066015    LR 0.001000    Time 0.052383    
2024-06-06 00:21:35,667 - --- validate (epoch=46)-----------
2024-06-06 00:21:35,667 - 34633 samples (256 per mini-batch)
2024-06-06 00:21:42,076 - Epoch: [46][  100/  136]    Loss 0.404994    Top1 81.945312    Top5 97.074219    
2024-06-06 00:21:43,907 - Epoch: [46][  136/  136]    Loss 0.399349    Top1 82.069125    Top5 97.118355    
2024-06-06 00:21:44,095 - ==> Top1: 82.069    Top5: 97.118    Loss: 0.399

2024-06-06 00:21:44,097 - ==> Confusion:
[[  835     1     7     0     9     0     0     0    10    53     0     0     4     2     1     1     0     0     1     2     5]
 [    4   952     3     1    22    17     2     8     8     0     1     0     3     2     6     0     5     1    17     2     9]
 [    7     3   897     6     3     2     7     7     1     4     1     0     6     4     5     6     2     1     5     2     1]
 [    4     4    22   898     1     7     3     2     2     2    11     1     8     7    12     2     1     5    15     1     8]
 [   33     9     5     3   948     4     0     2     1    13     1     0     2     7     5     3     8     0     3     4     3]
 [    6    30    12     5    13   863     2    34     2     5     3     2    10    17     3     1     8     2     1     8    16]
 [    1     8    38     2     4     6   970    11     0     2     2     1     3     3     1     8     2     3     5    13     3]
 [    2    10    19     3     2    18     0   929     5     3     4     4     7     5     3     1     2     3    39    10     8]
 [   11     4     3     2     3     0     0     3   881    55     5     1     6     5    10     0     2     1     5     2     3]
 [   84     1     2     2     2     1     0     0    42   827     3     0     4    13     9     1     0     1     3     0     6]
 [    1     2    24    20     3     0     0     4    22     4   932     0     1    11    12     1     2     1    18     0     6]
 [    3     4     4     0     1    39     3     7     3     2     0   819    57    10     1     6     3    15     3    23     8]
 [    1     1     2     5     5    16     0     2     5     0     1    36   869     8     2     6     3    22     5     3     3]
 [    2     1     9     0     5    12     1     5    28    36     5     6     6   853     5     4     6     2     1     5     9]
 [   11     2     4    15     9     2     0     0    33    14     5     0     3     8   962     0     2     4    16     1     7]
 [    2     1     3     2     5     1     7     0     0     2     0    11     8    10     0   989     8    10     1     1     5]
 [    5    11     5     0    10     8     1     0     4     1     2     4     7     3     1    13   981     1     2     5     8]
 [    3     2     1     3     2     3     1     3     3     3     0    13    40     3     1    15     1   894     5     4     5]
 [    0     0    12     4     2     2     0    18     8     1     2     2     4     2    13     0     0     0   983     0     5]
 [    2     3     7     0     4    15     5     9     1     0     2     7     7     7     1     4     8     6     3   988     9]
 [  185   188   325   120   216   197    69   137   142   137   127    99   360   255   225   140   243    99   230   285 10153]]

2024-06-06 00:21:44,101 - ==> Best [Top1: 83.337   Top5: 97.413   Sparsity:0.00   Params: 424448 on epoch: 44]
2024-06-06 00:21:44,101 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:21:44,134 - 

2024-06-06 00:21:44,134 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:21:50,922 - Epoch: [47][  100/ 1218]    Overall Loss 0.379878    Objective Loss 0.379878                                        LR 0.001000    Time 0.067835    
2024-06-06 00:21:56,205 - Epoch: [47][  200/ 1218]    Overall Loss 0.375907    Objective Loss 0.375907                                        LR 0.001000    Time 0.060319    
2024-06-06 00:22:01,425 - Epoch: [47][  300/ 1218]    Overall Loss 0.373111    Objective Loss 0.373111                                        LR 0.001000    Time 0.057607    
2024-06-06 00:22:06,513 - Epoch: [47][  400/ 1218]    Overall Loss 0.369268    Objective Loss 0.369268                                        LR 0.001000    Time 0.055918    
2024-06-06 00:22:11,342 - Epoch: [47][  500/ 1218]    Overall Loss 0.369045    Objective Loss 0.369045                                        LR 0.001000    Time 0.054387    
2024-06-06 00:22:16,676 - Epoch: [47][  600/ 1218]    Overall Loss 0.369169    Objective Loss 0.369169                                        LR 0.001000    Time 0.054208    
2024-06-06 00:22:22,034 - Epoch: [47][  700/ 1218]    Overall Loss 0.370626    Objective Loss 0.370626                                        LR 0.001000    Time 0.054115    
2024-06-06 00:22:26,937 - Epoch: [47][  800/ 1218]    Overall Loss 0.371351    Objective Loss 0.371351                                        LR 0.001000    Time 0.053476    
2024-06-06 00:22:31,941 - Epoch: [47][  900/ 1218]    Overall Loss 0.371516    Objective Loss 0.371516                                        LR 0.001000    Time 0.053092    
2024-06-06 00:22:36,993 - Epoch: [47][ 1000/ 1218]    Overall Loss 0.370696    Objective Loss 0.370696                                        LR 0.001000    Time 0.052832    
2024-06-06 00:22:42,102 - Epoch: [47][ 1100/ 1218]    Overall Loss 0.370875    Objective Loss 0.370875                                        LR 0.001000    Time 0.052671    
2024-06-06 00:22:47,187 - Epoch: [47][ 1200/ 1218]    Overall Loss 0.370619    Objective Loss 0.370619                                        LR 0.001000    Time 0.052517    
2024-06-06 00:22:48,094 - Epoch: [47][ 1218/ 1218]    Overall Loss 0.370406    Objective Loss 0.370406    Top1 86.797066    Top5 98.777506    LR 0.001000    Time 0.052485    
2024-06-06 00:22:48,284 - --- validate (epoch=47)-----------
2024-06-06 00:22:48,284 - 34633 samples (256 per mini-batch)
2024-06-06 00:22:54,728 - Epoch: [47][  100/  136]    Loss 0.399654    Top1 82.519531    Top5 97.167969    
2024-06-06 00:22:56,530 - Epoch: [47][  136/  136]    Loss 0.400262    Top1 82.479138    Top5 97.193428    
2024-06-06 00:22:56,748 - ==> Top1: 82.479    Top5: 97.193    Loss: 0.400

2024-06-06 00:22:56,749 - ==> Confusion:
[[  856     0     3     2    15     1     1     1     2    37     0     1     1     1     4     1     1     0     0     0     4]
 [    4   941     2     1    20    19     3    20     4     1     3     1     2     1    11     0     9     1     9     3     8]
 [   10     1   873    14     7     1     8    11     1     6     3     5     1     2     5     1     5     0     5     4     7]
 [    3     0     1   914     4     6     2     4     0     2    17     1     5     3    28     2     1     5     8     1     9]
 [   19     5     1     1   979     1     1     0     0    13     1     3     0     1    14     0     4     1     2     0     8]
 [    5    35     2     2    23   839     1    45     1     9     0    15     7    17     5     2     8     3     4     5    15]
 [    4     5    41     5     6     9   956    11     1     3     5     7     1     1     0     7     2     2     5     7     8]
 [    3    14    14     0     3    16     1   936     2     3     4     7     2     3     6     2     2     2    32    11    14]
 [   15     3     0     2     3     3     0     2   875    49    10     1     6     4    16     0     6     3     1     1     2]
 [   92     2     0     0     7     2     1     1    26   843     2     0     3     4     6     0     1     1     0     0    10]
 [    2     4     9    19     4     1     1     3    21     5   958     0     2     6    14     0     2     0     5     2     6]
 [    5     1     3     1     0     8     2     6     3     5     0   901    18     7     0     7     5    19     2    12     6]
 [    3     1     2     9     1     5     0     2     5     2     6   109   795     3     2     6     5    20     3     1    15]
 [    4     1     0     2     7    11     0     3    21    21    10    17     5   861     8     2     2     5     3     4    14]
 [   12     0     1    19     6     0     0     1    36    14     4     2     4     2   979     0     0     3     9     0     6]
 [    4     2     4     0    10     2     4     0     0     4     0    30     8     0     0   968    17     7     0     1     5]
 [    7     7     1     4    14     6     1     2     3     3     2     7     0     6     1     7   980     2     1     3    15]
 [    4     0     2     4     3     1     0     1     2     4     1    29    27     0     1    17     5   896     1     1     6]
 [    5     4     4    10     4     5     1    17     6     1     6     1     4     0    15     0     1     0   958     2    14]
 [    1     3     2     3     5    10     9    12     1     1     0    25    10     8     0     6    15     3     5   958    11]
 [  302   138   182   130   266   148    63   159   132   167   153   239   259   218   228    97   294   122   153   183 10299]]

2024-06-06 00:22:56,753 - ==> Best [Top1: 83.337   Top5: 97.413   Sparsity:0.00   Params: 424448 on epoch: 44]
2024-06-06 00:22:56,753 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:22:56,779 - 

2024-06-06 00:22:56,780 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:23:03,637 - Epoch: [48][  100/ 1218]    Overall Loss 0.366535    Objective Loss 0.366535                                        LR 0.001000    Time 0.068540    
2024-06-06 00:23:08,919 - Epoch: [48][  200/ 1218]    Overall Loss 0.362596    Objective Loss 0.362596                                        LR 0.001000    Time 0.060665    
2024-06-06 00:23:13,807 - Epoch: [48][  300/ 1218]    Overall Loss 0.358154    Objective Loss 0.358154                                        LR 0.001000    Time 0.056727    
2024-06-06 00:23:18,794 - Epoch: [48][  400/ 1218]    Overall Loss 0.362042    Objective Loss 0.362042                                        LR 0.001000    Time 0.055006    
2024-06-06 00:23:23,880 - Epoch: [48][  500/ 1218]    Overall Loss 0.362830    Objective Loss 0.362830                                        LR 0.001000    Time 0.054172    
2024-06-06 00:23:28,766 - Epoch: [48][  600/ 1218]    Overall Loss 0.364084    Objective Loss 0.364084                                        LR 0.001000    Time 0.053284    
2024-06-06 00:23:33,889 - Epoch: [48][  700/ 1218]    Overall Loss 0.364507    Objective Loss 0.364507                                        LR 0.001000    Time 0.052987    
2024-06-06 00:23:38,912 - Epoch: [48][  800/ 1218]    Overall Loss 0.365117    Objective Loss 0.365117                                        LR 0.001000    Time 0.052640    
2024-06-06 00:23:44,037 - Epoch: [48][  900/ 1218]    Overall Loss 0.365685    Objective Loss 0.365685                                        LR 0.001000    Time 0.052482    
2024-06-06 00:23:49,330 - Epoch: [48][ 1000/ 1218]    Overall Loss 0.365279    Objective Loss 0.365279                                        LR 0.001000    Time 0.052524    
2024-06-06 00:23:54,256 - Epoch: [48][ 1100/ 1218]    Overall Loss 0.365987    Objective Loss 0.365987                                        LR 0.001000    Time 0.052225    
2024-06-06 00:23:59,371 - Epoch: [48][ 1200/ 1218]    Overall Loss 0.365253    Objective Loss 0.365253                                        LR 0.001000    Time 0.052134    
2024-06-06 00:24:00,275 - Epoch: [48][ 1218/ 1218]    Overall Loss 0.365199    Objective Loss 0.365199    Top1 82.640587    Top5 97.066015    LR 0.001000    Time 0.052105    
2024-06-06 00:24:00,518 - --- validate (epoch=48)-----------
2024-06-06 00:24:00,518 - 34633 samples (256 per mini-batch)
2024-06-06 00:24:06,604 - Epoch: [48][  100/  136]    Loss 0.394849    Top1 81.214844    Top5 96.921875    
2024-06-06 00:24:08,411 - Epoch: [48][  136/  136]    Loss 0.393948    Top1 81.156700    Top5 96.962435    
2024-06-06 00:24:08,597 - ==> Top1: 81.157    Top5: 96.962    Loss: 0.394

2024-06-06 00:24:08,598 - ==> Confusion:
[[ 768    1    5    1   20    2    0    1    9   95    0    6    0    2    8    3    1    1    0    3    5]
 [   0  959    4    1   24   23    2    7    2    1    0    5    1    0    5    3   10    3    5    3    5]
 [   5    3  864    5    3    5   26   10    1    9    4    8    0    5    2    2    7    1    2    2    6]
 [   4    2   10  908    2   11    4    3    2    0    7    4    9    2   30    3    3    2    5    0    5]
 [  19    8    0    2  969    6    1    1    1    5    0    8    1    5   11    5    8    0    0    0    4]
 [   3   26    3    2   18  901    2   15    0    5    2   17    3   12    3    3    6    2    3    8    9]
 [   1    3   20    3    2    9 1002    5    1    0    1    8    0    0    1    4    3    4    0   15    4]
 [   2   29   16    1    5   48    3  911    1    2    3   13    4    1    3    2    1    1   14   13    4]
 [   9    7    2    1    4    3    0    1  842   54   16    6    3    9   33    1    3    3    1    1    3]
 [  40    0    0    0   12    1    1    2   30  880    0    8    0   14    6    1    3    1    0    0    2]
 [   0    4   11   21    1    2    8    2   15    3  940    2    5   10   25    0    2    1    7    2    3]
 [   2    0    3    0    2   19    0    4    2    3    0  873   39    8    3   14    7   13    0   17    2]
 [   0    2    3    4    1    6    1    3    0    0    1   69  849    1    1    4    6   27    3    9    5]
 [   2    3    2    1    5   15    1    0   16   28   12   10    4  864    8    3    6    2    3    7    9]
 [   3    8    2   15   10    3    0    1   23    5    1    5    2    2 1004    1    3    0    6    1    3]
 [   6    2    2    0    4    1   12    0    0    0    0   32    6    1    0  967   19   10    0    2    2]
 [   3    8    5    0    8    9    1    0    5    3    1    7    2    1    3    9  991    1    1    9    5]
 [   4    0    1    3    3    3    2    0    0    1    0   21   22    7    4    7    0  920    2    2    3]
 [   6   12   11   21    6    7    2   25    8    0    7    5    3    1   22    0    0    0  913    1    8]
 [   1    2    2    1    3    9    9    9    0    0    0   24   11    4    1    6    5    6    0  991    4]
 [ 178  224  209  137  266  289  114  148  128  130  146  223  373  225  328  139  321  122  129  312 9791]]

2024-06-06 00:24:08,602 - ==> Best [Top1: 83.337   Top5: 97.413   Sparsity:0.00   Params: 424448 on epoch: 44]
2024-06-06 00:24:08,602 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:24:08,633 - 

2024-06-06 00:24:08,633 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:24:15,590 - Epoch: [49][  100/ 1218]    Overall Loss 0.350783    Objective Loss 0.350783                                        LR 0.001000    Time 0.069535    
2024-06-06 00:24:20,802 - Epoch: [49][  200/ 1218]    Overall Loss 0.360081    Objective Loss 0.360081                                        LR 0.001000    Time 0.060814    
2024-06-06 00:24:25,791 - Epoch: [49][  300/ 1218]    Overall Loss 0.364673    Objective Loss 0.364673                                        LR 0.001000    Time 0.057165    
2024-06-06 00:24:30,948 - Epoch: [49][  400/ 1218]    Overall Loss 0.367378    Objective Loss 0.367378                                        LR 0.001000    Time 0.055760    
2024-06-06 00:24:36,090 - Epoch: [49][  500/ 1218]    Overall Loss 0.368727    Objective Loss 0.368727                                        LR 0.001000    Time 0.054886    
2024-06-06 00:24:41,150 - Epoch: [49][  600/ 1218]    Overall Loss 0.368068    Objective Loss 0.368068                                        LR 0.001000    Time 0.054169    
2024-06-06 00:24:46,518 - Epoch: [49][  700/ 1218]    Overall Loss 0.368874    Objective Loss 0.368874                                        LR 0.001000    Time 0.054096    
2024-06-06 00:24:51,642 - Epoch: [49][  800/ 1218]    Overall Loss 0.369300    Objective Loss 0.369300                                        LR 0.001000    Time 0.053735    
2024-06-06 00:24:56,766 - Epoch: [49][  900/ 1218]    Overall Loss 0.369058    Objective Loss 0.369058                                        LR 0.001000    Time 0.053455    
2024-06-06 00:25:01,897 - Epoch: [49][ 1000/ 1218]    Overall Loss 0.368336    Objective Loss 0.368336                                        LR 0.001000    Time 0.053239    
2024-06-06 00:25:07,086 - Epoch: [49][ 1100/ 1218]    Overall Loss 0.368511    Objective Loss 0.368511                                        LR 0.001000    Time 0.053113    
2024-06-06 00:25:12,205 - Epoch: [49][ 1200/ 1218]    Overall Loss 0.368971    Objective Loss 0.368971                                        LR 0.001000    Time 0.052951    
2024-06-06 00:25:13,177 - Epoch: [49][ 1218/ 1218]    Overall Loss 0.368550    Objective Loss 0.368550    Top1 84.107579    Top5 96.821516    LR 0.001000    Time 0.052966    
2024-06-06 00:25:13,395 - --- validate (epoch=49)-----------
2024-06-06 00:25:13,395 - 34633 samples (256 per mini-batch)
2024-06-06 00:25:19,955 - Epoch: [49][  100/  136]    Loss 0.401434    Top1 80.320312    Top5 96.574219    
2024-06-06 00:25:21,667 - Epoch: [49][  136/  136]    Loss 0.401421    Top1 80.151878    Top5 96.563971    
2024-06-06 00:25:21,885 - ==> Top1: 80.152    Top5: 96.564    Loss: 0.401

2024-06-06 00:25:21,887 - ==> Confusion:
[[ 840    2    5    1   10    0    1    2    7   40    1    0    2    4    5    2    2    2    3    0    2]
 [   1  947    3    2   24   19   11   11    0    2    3    0    2    0    5    3    4    1   15    6    4]
 [   5    2  876   13    1    0   33    7    0    3    2    4    3    1    4    2    4    1    6    2    1]
 [   3    3    6  926    0    2    9    3    2    3    8    0    9    0   19    2    1    9    6    1    4]
 [  26    5    5    2  957    9    0    1    3   10    2    2    2    4    9    6    4    1    3    0    3]
 [   3   33    4    7   14  847    8   37    5    6    2   10   15   15    4    4    5    3    9    6    6]
 [   2    2   23    4    0    0 1011    4    2    5    1    3    3    1    0    6    3    0    4   10    2]
 [   3   16   15    4    3   19    9  902    4    5    8    5   10    3    4    0    1    2   45   17    2]
 [  15    2    2    5    0    0    1    6  865   36   16    1    6    4   27    0    3    3    7    1    2]
 [ 103    1    4    0    4    2    0    1   54  780    2    0    2   18   11    1    4    6    2    5    1]
 [   3    1   13   20    1    1    9    8    7    0  961    2    4    3    5    1    0    1   19    4    1]
 [   2    1    2    1    2    6    3   10    2    2    1  817   65    3    0   18    4   39    4   25    4]
 [   2    1    2    2    1    2    0    5    1    3    0   37  870    3    1    6    3   47    6    2    1]
 [   0    2    4    1    4   10    1    7   17   20   13   11   11  857    7    2    6    9    3   13    3]
 [  11    3    3   30   10    4    1    0   22    6    6    1    2    3  974    0    1    9    5    2    5]
 [   4    0    2    1    4    1    8    1    0    3    0   14   10    3    1  993    2   11    2    4    2]
 [   7    6    6    4    5    6    1    2    6    1    0    2    3    4    4   18  967    2    0   16   12]
 [   4    0    1    3    1    3    0    6    1    1    0    8   27    2    2   14    0  919    1    5    7]
 [   6    6    7   19    2    2    2   10    5    2    3    1    5    0   17    0    1    0  964    3    3]
 [   3    1    2    0    0    1   12    7    1    1    0   10    8    7    0    7    1    4    6 1010    7]
 [ 327  207  293  195  266  167  147  180  141  119  164  142  459  256  264  167  208  157  254  343 9476]]

2024-06-06 00:25:21,891 - ==> Best [Top1: 83.337   Top5: 97.413   Sparsity:0.00   Params: 424448 on epoch: 44]
2024-06-06 00:25:21,891 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:25:21,921 - 

2024-06-06 00:25:21,921 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:25:28,530 - Epoch: [50][  100/ 1218]    Overall Loss 0.351433    Objective Loss 0.351433                                        LR 0.001000    Time 0.066049    
2024-06-06 00:25:33,701 - Epoch: [50][  200/ 1218]    Overall Loss 0.352885    Objective Loss 0.352885                                        LR 0.001000    Time 0.058873    
2024-06-06 00:25:38,836 - Epoch: [50][  300/ 1218]    Overall Loss 0.355115    Objective Loss 0.355115                                        LR 0.001000    Time 0.056356    
2024-06-06 00:25:43,881 - Epoch: [50][  400/ 1218]    Overall Loss 0.360095    Objective Loss 0.360095                                        LR 0.001000    Time 0.054873    
2024-06-06 00:25:49,040 - Epoch: [50][  500/ 1218]    Overall Loss 0.361010    Objective Loss 0.361010                                        LR 0.001000    Time 0.054211    
2024-06-06 00:25:54,256 - Epoch: [50][  600/ 1218]    Overall Loss 0.360831    Objective Loss 0.360831                                        LR 0.001000    Time 0.053866    
2024-06-06 00:25:59,412 - Epoch: [50][  700/ 1218]    Overall Loss 0.360781    Objective Loss 0.360781                                        LR 0.001000    Time 0.053532    
2024-06-06 00:26:04,637 - Epoch: [50][  800/ 1218]    Overall Loss 0.361995    Objective Loss 0.361995                                        LR 0.001000    Time 0.053364    
2024-06-06 00:26:09,709 - Epoch: [50][  900/ 1218]    Overall Loss 0.362850    Objective Loss 0.362850                                        LR 0.001000    Time 0.053068    
2024-06-06 00:26:14,856 - Epoch: [50][ 1000/ 1218]    Overall Loss 0.362493    Objective Loss 0.362493                                        LR 0.001000    Time 0.052905    
2024-06-06 00:26:20,134 - Epoch: [50][ 1100/ 1218]    Overall Loss 0.363319    Objective Loss 0.363319                                        LR 0.001000    Time 0.052892    
2024-06-06 00:26:25,324 - Epoch: [50][ 1200/ 1218]    Overall Loss 0.364593    Objective Loss 0.364593                                        LR 0.001000    Time 0.052807    
2024-06-06 00:26:26,228 - Epoch: [50][ 1218/ 1218]    Overall Loss 0.364376    Objective Loss 0.364376    Top1 83.618582    Top5 98.288509    LR 0.001000    Time 0.052769    
2024-06-06 00:26:26,435 - --- validate (epoch=50)-----------
2024-06-06 00:26:26,435 - 34633 samples (256 per mini-batch)
2024-06-06 00:26:32,524 - Epoch: [50][  100/  136]    Loss 0.394426    Top1 82.308594    Top5 97.207031    
2024-06-06 00:26:34,398 - Epoch: [50][  136/  136]    Loss 0.393136    Top1 82.447377    Top5 97.254064    
2024-06-06 00:26:34,597 - ==> Top1: 82.447    Top5: 97.254    Loss: 0.393

2024-06-06 00:26:34,598 - ==> Confusion:
[[  833     0     2     0    15     1     1     4     2    53     0     2     4     1     2     0     3     1     1     1     5]
 [    3   913     8     3    29    36     2    23     5     2     3     3     4     2     3     0     5     1     7     4     7]
 [    7     3   897     9     2     2    12    11     0     2     0     1     2     3     2     0     3     2     2     3     7]
 [    2     0    21   922     5     5     1     5     1     4     7     1     3     2    13     1     1     8     5     1     8]
 [   17     3     5     0   984    10     1     1     2    14     0     0     3     0     3     1     1     2     1     1     5]
 [   12    15     3    10    10   875     3    36     3     8     0    15     5    15     3     0     3     3     3    17     4]
 [    2     3    53     2     4     4   967     7     0     3     2     5     1     1     0     6     3     2     2    13     6]
 [    4     5    15     1     4    26     2   963     2     5     2     7     7     1     0     0     0     1    16    10     6]
 [   17     2     1     2     3     6     0     2   853    67     7     1     5     7    13     0     2     3     6     0     5]
 [  102     0     2     0     6     3     0     4    28   826     2     0     2    17     2     0     1     1     0     0     5]
 [    1     3    16    28     5     5     5    15    18     3   926     1     1    12     9     0     2     0     5     1     8]
 [    1     0     1     0     4     8     3    12     2     5     0   867    23     8     0    18     2    27     0    22     8]
 [    3     1     4    10     2     6     1     5     1     1     1    77   804     4     1     6     5    46     2     6     9]
 [    5     1     2     2     7    20     0     5    18    44     8    11     7   846     3     3     4     1     0    10     4]
 [   10     0     2    27    16     2     0     4    36    17     1     1     2     1   960     0     0     4     8     1     6]
 [    3     1     6     2     5     0     5     1     0     3     0    13     8     3     0   992     7     8     0     2     7]
 [    8    10     8     2    13     8     3     5     6     0     0     8     3     3     1     8   961     2     1     4    18]
 [    6     0     1     2     1     0     1     7     2     3     0    14    10     1     2    10     2   933     0     1     9]
 [    2     6     9    18     6     3     1    42     4     4     7     2     4     1    14     0     2     1   927     1     4]
 [    1     3     3     1     4     5     8    13     1     1     2    17     6     4     0     6     3     4     1   995    10]
 [  241   128   299   140   287   216    90   218   107   148    94   150   267   242   167   113   212   140   142   221 10310]]

2024-06-06 00:26:34,610 - ==> Best [Top1: 83.337   Top5: 97.413   Sparsity:0.00   Params: 424448 on epoch: 44]
2024-06-06 00:26:34,610 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:26:34,644 - 

2024-06-06 00:26:34,644 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:26:41,252 - Epoch: [51][  100/ 1218]    Overall Loss 0.362533    Objective Loss 0.362533                                        LR 0.001000    Time 0.066039    
2024-06-06 00:26:46,002 - Epoch: [51][  200/ 1218]    Overall Loss 0.364427    Objective Loss 0.364427                                        LR 0.001000    Time 0.056758    
2024-06-06 00:26:51,350 - Epoch: [51][  300/ 1218]    Overall Loss 0.366631    Objective Loss 0.366631                                        LR 0.001000    Time 0.055657    
2024-06-06 00:26:56,457 - Epoch: [51][  400/ 1218]    Overall Loss 0.366028    Objective Loss 0.366028                                        LR 0.001000    Time 0.054502    
2024-06-06 00:27:01,355 - Epoch: [51][  500/ 1218]    Overall Loss 0.363607    Objective Loss 0.363607                                        LR 0.001000    Time 0.053394    
2024-06-06 00:27:06,528 - Epoch: [51][  600/ 1218]    Overall Loss 0.362777    Objective Loss 0.362777                                        LR 0.001000    Time 0.053112    
2024-06-06 00:27:11,670 - Epoch: [51][  700/ 1218]    Overall Loss 0.363412    Objective Loss 0.363412                                        LR 0.001000    Time 0.052864    
2024-06-06 00:27:16,748 - Epoch: [51][  800/ 1218]    Overall Loss 0.363282    Objective Loss 0.363282                                        LR 0.001000    Time 0.052601    
2024-06-06 00:27:21,867 - Epoch: [51][  900/ 1218]    Overall Loss 0.362776    Objective Loss 0.362776                                        LR 0.001000    Time 0.052441    
2024-06-06 00:27:26,628 - Epoch: [51][ 1000/ 1218]    Overall Loss 0.363050    Objective Loss 0.363050                                        LR 0.001000    Time 0.051955    
2024-06-06 00:27:31,798 - Epoch: [51][ 1100/ 1218]    Overall Loss 0.362480    Objective Loss 0.362480                                        LR 0.001000    Time 0.051930    
2024-06-06 00:27:36,750 - Epoch: [51][ 1200/ 1218]    Overall Loss 0.362412    Objective Loss 0.362412                                        LR 0.001000    Time 0.051727    
2024-06-06 00:27:37,636 - Epoch: [51][ 1218/ 1218]    Overall Loss 0.362358    Objective Loss 0.362358    Top1 84.841076    Top5 98.533007    LR 0.001000    Time 0.051690    
2024-06-06 00:27:37,863 - --- validate (epoch=51)-----------
2024-06-06 00:27:37,863 - 34633 samples (256 per mini-batch)
2024-06-06 00:27:44,303 - Epoch: [51][  100/  136]    Loss 0.389873    Top1 83.437500    Top5 97.289062    
2024-06-06 00:27:46,269 - Epoch: [51][  136/  136]    Loss 0.390619    Top1 83.391563    Top5 97.386885    
2024-06-06 00:27:46,510 - ==> Top1: 83.392    Top5: 97.387    Loss: 0.391

2024-06-06 00:27:46,511 - ==> Confusion:
[[  856     2     1     0     8     1     0     0     7    30     2     4     3     1     7     2     0     2     1     0     4]
 [    5   958     1     1    21    16     2     8     5     1     4     8     2     1     5     1     4     0     9     2     9]
 [   10     4   860     9     4     1    22     7     1     4     5     3     7     3     5     7     2     1     5     1     9]
 [    3     1     3   898     2     2     4     0     3     4    17     2    16     5    29     1     1     6     6     3    10]
 [   20     6     2     1   952    14     1     2     2    12     2     3     1     4     5     2     8     3     2     1    11]
 [    8    25     2     4    14   862     0    21     6     5     7    18    16    11     9     2     5     1     3     7    17]
 [    1     2    14     2     2     8   981     7     0     1     4     8     6     0     1    15     1     6     1    14    12]
 [    1    17    13     6     2    39     3   886     1     2     3    10    13     4     0     0     2     4    37    21    13]
 [   14     2     0     0     3     0     0     1   865    51    10     4     4    14    18     0     2     4     5     2     3]
 [  104     0     3     0     8     2     0     1    49   793     1     2     3    16     6     0     1     3     0     1     8]
 [    1     4     8     9     1     5     3     5    19     2   954     3     5     6    13     0     1     0    11     6     8]
 [    5     1     0     0     1     9     2     2     0     1     0   876    60     7     1    10     1    20     1     8     6]
 [    1     1     1     4     1     2     0     2     0     0     2    57   859     1     1     5     2    36     6     1    13]
 [    6     1     1     0     4    13     0     0    14    20     8    16    19   852    12     2     7     4     0     6    16]
 [   12     4     2    12    10     0     0     0    27    14     4     2     1     5   990     1     2     3     4     1     4]
 [    0     0     2     1     2     0     2     0     0     2     0    27    23     6     0   973     6    13     2     0     7]
 [    3    10     1     1     7     2     0     0     3     2     3     7    11     2     1    12   983     1     0     4    19]
 [    1     0     1     3     0     0     0     0     1     0     1    14    38     2     3     8     1   924     2     1     5]
 [    3    13     8     8     4     1     1    13    10     1     6     2     4     1    18     0     1     0   951     3    10]
 [    1     6     3     0     1     7     3     9     0     0     1    29     9     6     0     6     9     3     3   982    10]
 [  244   206   130    92   154   141    55    91   124   111   156   183   412   193   215   109   195   100   181   214 10626]]

2024-06-06 00:27:46,517 - ==> Best [Top1: 83.392   Top5: 97.387   Sparsity:0.00   Params: 424448 on epoch: 51]
2024-06-06 00:27:46,517 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:27:46,552 - 

2024-06-06 00:27:46,553 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:27:53,419 - Epoch: [52][  100/ 1218]    Overall Loss 0.369182    Objective Loss 0.369182                                        LR 0.001000    Time 0.068631    
2024-06-06 00:27:58,424 - Epoch: [52][  200/ 1218]    Overall Loss 0.365863    Objective Loss 0.365863                                        LR 0.001000    Time 0.059330    
2024-06-06 00:28:03,762 - Epoch: [52][  300/ 1218]    Overall Loss 0.365731    Objective Loss 0.365731                                        LR 0.001000    Time 0.057314    
2024-06-06 00:28:08,876 - Epoch: [52][  400/ 1218]    Overall Loss 0.365245    Objective Loss 0.365245                                        LR 0.001000    Time 0.055766    
2024-06-06 00:28:14,101 - Epoch: [52][  500/ 1218]    Overall Loss 0.362846    Objective Loss 0.362846                                        LR 0.001000    Time 0.055058    
2024-06-06 00:28:19,107 - Epoch: [52][  600/ 1218]    Overall Loss 0.360902    Objective Loss 0.360902                                        LR 0.001000    Time 0.054220    
2024-06-06 00:28:24,311 - Epoch: [52][  700/ 1218]    Overall Loss 0.361774    Objective Loss 0.361774                                        LR 0.001000    Time 0.053904    
2024-06-06 00:28:29,368 - Epoch: [52][  800/ 1218]    Overall Loss 0.360665    Objective Loss 0.360665                                        LR 0.001000    Time 0.053486    
2024-06-06 00:28:34,426 - Epoch: [52][  900/ 1218]    Overall Loss 0.360395    Objective Loss 0.360395                                        LR 0.001000    Time 0.053160    
2024-06-06 00:28:39,476 - Epoch: [52][ 1000/ 1218]    Overall Loss 0.360887    Objective Loss 0.360887                                        LR 0.001000    Time 0.052892    
2024-06-06 00:28:44,573 - Epoch: [52][ 1100/ 1218]    Overall Loss 0.360673    Objective Loss 0.360673                                        LR 0.001000    Time 0.052714    
2024-06-06 00:28:49,773 - Epoch: [52][ 1200/ 1218]    Overall Loss 0.360801    Objective Loss 0.360801                                        LR 0.001000    Time 0.052653    
2024-06-06 00:28:50,651 - Epoch: [52][ 1218/ 1218]    Overall Loss 0.360839    Objective Loss 0.360839    Top1 80.684597    Top5 97.310513    LR 0.001000    Time 0.052595    
2024-06-06 00:28:50,860 - --- validate (epoch=52)-----------
2024-06-06 00:28:50,860 - 34633 samples (256 per mini-batch)
2024-06-06 00:28:57,251 - Epoch: [52][  100/  136]    Loss 0.388310    Top1 82.898438    Top5 97.269531    
2024-06-06 00:28:59,164 - Epoch: [52][  136/  136]    Loss 0.387874    Top1 82.926688    Top5 97.280051    
2024-06-06 00:28:59,409 - ==> Top1: 82.927    Top5: 97.280    Loss: 0.388

2024-06-06 00:28:59,411 - ==> Confusion:
[[  818     0     4     0    12     3     0     1     4    63     1     1     2     1     3     2     1     1     2     1    11]
 [    1   916     2     5    22    33     8    18     1     2     6     2     4     1     4     1     9     1    14     8     5]
 [    3     2   874     9     6     2    25     7     1     5     4     3     4     1     0     3     2     0     1     6    12]
 [    4     0    16   926     3     3     2     4     1     2     7     1     3     4    13     4     0     3     9     3     8]
 [   26    11     2     1   967    14     0     0     0     9     0     2     1     2     2     3     1     0     4     3     6]
 [    2     8     1     0    12   911     8    24     0     3     4    10    10     9     3     3     5     2     7    10    11]
 [    1     0    19     3     2     5  1023     6     0     2     3     2     2     0     0     1     2     0     2     6     7]
 [    0     4    18     3     2    42     3   938     1     4     2     8     3     1     0     2     0     1    21    12    12]
 [    8     3     3     1     5     4     0     1   831    49    25     7     2     9    25     0     4     2    10     2    11]
 [   60     0     2     1     4     5     1     3    31   846     2     1     2    13     7     2     1     6     3     2     9]
 [    0     1     9    25     3     2     3     5     4     4   972     1     0     7     8     0     1     1    10     1     7]
 [    2     0     4     0     3    18     6     3     0     2     1   864    32     4     0    19     2    13     0    19    19]
 [    3     0     2     4     1     5     3     3     1     0     4    83   824     3     1     9     5    16     6    10    12]
 [    4     0     3     0     4    23     4     4     7    13    13    16     7   859     3     5     7     3     1    12    13]
 [    8     0     4    44    16     3     0     1    15    11     7     3     2     4   935     0     6     1    24     1    13]
 [    2     1     7     3     5     1    21     2     0     1     0    10     5     0     0   980     5     8     4     2     9]
 [    4     2     2     3     9    13     4     1     2     1     4     6     1     1     2     8   978     1     4     5    21]
 [    1     0     1     5     2     2     5     1     0     0     0    20    42     1     0    17     1   894     3     4     6]
 [    2     5    11    14     2     0     1    32     5     0    10     3     6     0    13     1     4     1   935     2    11]
 [    0     4     8     0     3     6    19     9     0     2     1     8     5     4     0     5     7     0     9   990     8]
 [  191   143   258   126   236   246   148   156    62   106   163   127   312   227   163    89   163    69   175   333 10439]]

2024-06-06 00:28:59,415 - ==> Best [Top1: 83.392   Top5: 97.387   Sparsity:0.00   Params: 424448 on epoch: 51]
2024-06-06 00:28:59,415 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:28:59,441 - 

2024-06-06 00:28:59,441 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:29:06,306 - Epoch: [53][  100/ 1218]    Overall Loss 0.362477    Objective Loss 0.362477                                        LR 0.001000    Time 0.068612    
2024-06-06 00:29:11,462 - Epoch: [53][  200/ 1218]    Overall Loss 0.364015    Objective Loss 0.364015                                        LR 0.001000    Time 0.060073    
2024-06-06 00:29:16,506 - Epoch: [53][  300/ 1218]    Overall Loss 0.357638    Objective Loss 0.357638                                        LR 0.001000    Time 0.056856    
2024-06-06 00:29:21,787 - Epoch: [53][  400/ 1218]    Overall Loss 0.355782    Objective Loss 0.355782                                        LR 0.001000    Time 0.055837    
2024-06-06 00:29:26,742 - Epoch: [53][  500/ 1218]    Overall Loss 0.359377    Objective Loss 0.359377                                        LR 0.001000    Time 0.054574    
2024-06-06 00:29:31,741 - Epoch: [53][  600/ 1218]    Overall Loss 0.359039    Objective Loss 0.359039                                        LR 0.001000    Time 0.053808    
2024-06-06 00:29:36,884 - Epoch: [53][  700/ 1218]    Overall Loss 0.358900    Objective Loss 0.358900                                        LR 0.001000    Time 0.053464    
2024-06-06 00:29:41,978 - Epoch: [53][  800/ 1218]    Overall Loss 0.359565    Objective Loss 0.359565                                        LR 0.001000    Time 0.053145    
2024-06-06 00:29:46,934 - Epoch: [53][  900/ 1218]    Overall Loss 0.359376    Objective Loss 0.359376                                        LR 0.001000    Time 0.052744    
2024-06-06 00:29:52,031 - Epoch: [53][ 1000/ 1218]    Overall Loss 0.359175    Objective Loss 0.359175                                        LR 0.001000    Time 0.052564    
2024-06-06 00:29:57,194 - Epoch: [53][ 1100/ 1218]    Overall Loss 0.359479    Objective Loss 0.359479                                        LR 0.001000    Time 0.052476    
2024-06-06 00:30:02,349 - Epoch: [53][ 1200/ 1218]    Overall Loss 0.358973    Objective Loss 0.358973                                        LR 0.001000    Time 0.052398    
2024-06-06 00:30:03,289 - Epoch: [53][ 1218/ 1218]    Overall Loss 0.359122    Objective Loss 0.359122    Top1 83.129584    Top5 97.799511    LR 0.001000    Time 0.052394    
2024-06-06 00:30:03,507 - --- validate (epoch=53)-----------
2024-06-06 00:30:03,508 - 34633 samples (256 per mini-batch)
2024-06-06 00:30:10,044 - Epoch: [53][  100/  136]    Loss 0.373686    Top1 83.722656    Top5 97.300781    
2024-06-06 00:30:11,930 - Epoch: [53][  136/  136]    Loss 0.379847    Top1 83.651431    Top5 97.320475    
2024-06-06 00:30:12,137 - ==> Top1: 83.651    Top5: 97.320    Loss: 0.380

2024-06-06 00:30:12,138 - ==> Confusion:
[[  800     1     5     0     5     1     0     3     7    72     0     2     3     6     5     3     1     3     1     3    10]
 [    0   955     2     1    20    24     3    14     1     3     4     1     4     4     2     2     7     2     6     4     4]
 [    2     4   877    10     4     1    13    10     1     4     8     2     5     3     2     6     5     0     2     4     7]
 [    2     1    16   890     5     6     6     5     4     5    21     2    10     1    19     3     3     2     9     1     5]
 [   14    16     4     0   956     2     0     2     3     8     3     3     2     8     6     7     5     1     3     0    11]
 [    2    25     6     1    14   872     3    30     4     2     3    20     6    21     2     2     8     0     3     8    11]
 [    1     5    25     0     2     5   995     7     1     2     4     0     5     5     2     5     5     2     1    11     3]
 [    3    12    16     1     1    20     4   955     1     2     1    10     4     8     0     0     1     2    13    12    11]
 [   13     6     1     2     1     2     0     2   832    50    15     4     3    30    24     1     3     0     4     0     9]
 [   46     0     2     1     9     4     1     2    40   843     1     0     2    22     9     3     0     1     1     0    14]
 [    1     7     9     2     1     3     3    10    21     0   965     0     1    18     3     0     2     0    12     1     5]
 [    3     2     3     0     0     8     3     5     2     1     1   888    16    15     0    22     7    12     2    13     8]
 [    1     3     6     1     1     5     2     1     7     0     1    85   795    10     3    15     6    28     2     9    14]
 [    3     4     1     0     5     5     2     2     9    16     6     8     2   898     6     5     2     5     2     7    13]
 [    7     5     0    24    11     2     0     0    25     7    11     2     1    11   964     1     2     3    10     0    12]
 [    1     3     2     0     1     0    15     2     0     3     0    10     3     6     0   995     5    11     3     2     4]
 [    4    13     2     1     7     5     0     0     3     0     1     3     1     7     1    14   983     2     2     8    15]
 [    3     2     3     3     1     2     2     4     0     3     0    17    18     4     2    16     2   911     2     3     7]
 [    4     5     9    10     2     1     1    27     7     0     3     0     3     3    13     1     1     0   955     4     9]
 [    1     5     4     0     0     5    11    10     1     3     2    12     5     3     0     9     4     1     3   996    13]
 [  195   201   166    75   192   145   109   169    97    82   190   139   255   320   148   157   218    65   126   237 10646]]

2024-06-06 00:30:12,142 - ==> Best [Top1: 83.651   Top5: 97.320   Sparsity:0.00   Params: 424448 on epoch: 53]
2024-06-06 00:30:12,143 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:30:12,173 - 

2024-06-06 00:30:12,174 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:30:18,992 - Epoch: [54][  100/ 1218]    Overall Loss 0.345340    Objective Loss 0.345340                                        LR 0.001000    Time 0.068157    
2024-06-06 00:30:23,935 - Epoch: [54][  200/ 1218]    Overall Loss 0.352395    Objective Loss 0.352395                                        LR 0.001000    Time 0.058780    
2024-06-06 00:30:28,932 - Epoch: [54][  300/ 1218]    Overall Loss 0.354312    Objective Loss 0.354312                                        LR 0.001000    Time 0.055836    
2024-06-06 00:30:33,910 - Epoch: [54][  400/ 1218]    Overall Loss 0.355069    Objective Loss 0.355069                                        LR 0.001000    Time 0.054316    
2024-06-06 00:30:38,918 - Epoch: [54][  500/ 1218]    Overall Loss 0.356047    Objective Loss 0.356047                                        LR 0.001000    Time 0.053463    
2024-06-06 00:30:43,952 - Epoch: [54][  600/ 1218]    Overall Loss 0.355702    Objective Loss 0.355702                                        LR 0.001000    Time 0.052939    
2024-06-06 00:30:49,222 - Epoch: [54][  700/ 1218]    Overall Loss 0.355538    Objective Loss 0.355538                                        LR 0.001000    Time 0.052901    
2024-06-06 00:30:54,460 - Epoch: [54][  800/ 1218]    Overall Loss 0.355916    Objective Loss 0.355916                                        LR 0.001000    Time 0.052833    
2024-06-06 00:30:59,449 - Epoch: [54][  900/ 1218]    Overall Loss 0.357890    Objective Loss 0.357890                                        LR 0.001000    Time 0.052502    
2024-06-06 00:31:04,484 - Epoch: [54][ 1000/ 1218]    Overall Loss 0.357704    Objective Loss 0.357704                                        LR 0.001000    Time 0.052284    
2024-06-06 00:31:09,659 - Epoch: [54][ 1100/ 1218]    Overall Loss 0.358565    Objective Loss 0.358565                                        LR 0.001000    Time 0.052234    
2024-06-06 00:31:14,771 - Epoch: [54][ 1200/ 1218]    Overall Loss 0.358386    Objective Loss 0.358386                                        LR 0.001000    Time 0.052139    
2024-06-06 00:31:15,644 - Epoch: [54][ 1218/ 1218]    Overall Loss 0.358349    Objective Loss 0.358349    Top1 88.753056    Top5 99.022005    LR 0.001000    Time 0.052085    
2024-06-06 00:31:15,871 - --- validate (epoch=54)-----------
2024-06-06 00:31:15,871 - 34633 samples (256 per mini-batch)
2024-06-06 00:31:22,027 - Epoch: [54][  100/  136]    Loss 0.386444    Top1 83.574219    Top5 97.500000    
2024-06-06 00:31:23,920 - Epoch: [54][  136/  136]    Loss 0.383508    Top1 83.553258    Top5 97.444634    
2024-06-06 00:31:24,113 - ==> Top1: 83.553    Top5: 97.445    Loss: 0.384

2024-06-06 00:31:24,115 - ==> Confusion:
[[  801     0     3     1     7     1     2     1     7    82     1     5     1     2     3     2     1     1     3     1     6]
 [    1   934     4     1    17    23     3    23     1     5     5     4     3     0     7     1     6     3    11     1    10]
 [    3     2   846    15     4     0    35    16     0     8     9     2     4     3     1     2     5     0     2     7     6]
 [    4     1    10   912     2     6     2     4     3     4    15     1     7     2    12     2     5     4     7     2    11]
 [   16    11     2     3   942     9     0     5     2    19     4     1     0     7     6     2     9     0     1     2    13]
 [    4    29     3     3     5   853     3    59     3     7     1    13     7    16     2     1    10     2     5     7    10]
 [    0     1    13     1     1     6  1023     8     0     4     1     4     2     0     0     3     5     1     0     4     9]
 [    2     7    11     3     2    15     3   959     1     4     7    16     1     2     0     0     2     1    22    15     4]
 [   13     3     2     0     2     5     1     4   872    33    11     1     4    12    20     1     5     2     6     1     4]
 [   58     2     2     1     2     2     1     3    56   824     2     0     0    26     7     0     0     3     3     0     9]
 [    1     6     3    18     1     8     3     4     9     1   971     3     1     8     7     0     4     0    10     1     5]
 [    3     0     1     0     1    11     3     6     3     2     0   905    28     3     1     9     5    10     1     9    10]
 [    1     3     4     1     1     0     2     3     2     4     2    64   842     2     2     6     6    19     2     7    22]
 [    1     0     3     2     2    10     0     3    18    12    11    12     3   885     6     1     5     4     1     6    16]
 [    8     3     0    22    11     5     0     1    21     7     7     2     3     4   976     0     2     2    15     0     9]
 [    3     0     4     0     3     3    12     2     1     8     0    24     7     4     2   955    15     8     0     3    12]
 [    7     5     3     1     6     4     2     2     3     5     5     4     3     1     3     4   985     1     2     2    24]
 [    2     2     0     0     0     2     1     2     2     2     0    24    33     2     3    15     4   896     1     3    11]
 [    2    13     1    16     3     3     3    35     5     4     8     2     0     0    12     0     2     1   939     3     6]
 [    0     8     2     1     1     4     9    10     1     3     0    23     5     6     0     6     5     2     4   988    10]
 [  162   173   184   119   161   166    92   251   114   128   179   194   250   237   145    67   202    59   162   258 10629]]

2024-06-06 00:31:24,117 - ==> Best [Top1: 83.651   Top5: 97.320   Sparsity:0.00   Params: 424448 on epoch: 53]
2024-06-06 00:31:24,117 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:31:24,145 - 

2024-06-06 00:31:24,145 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:31:31,086 - Epoch: [55][  100/ 1218]    Overall Loss 0.357351    Objective Loss 0.357351                                        LR 0.001000    Time 0.069376    
2024-06-06 00:31:36,355 - Epoch: [55][  200/ 1218]    Overall Loss 0.348844    Objective Loss 0.348844                                        LR 0.001000    Time 0.061019    
2024-06-06 00:31:41,734 - Epoch: [55][  300/ 1218]    Overall Loss 0.354140    Objective Loss 0.354140                                        LR 0.001000    Time 0.058601    
2024-06-06 00:31:46,941 - Epoch: [55][  400/ 1218]    Overall Loss 0.353755    Objective Loss 0.353755                                        LR 0.001000    Time 0.056962    
2024-06-06 00:31:51,931 - Epoch: [55][  500/ 1218]    Overall Loss 0.353771    Objective Loss 0.353771                                        LR 0.001000    Time 0.055544    
2024-06-06 00:31:57,194 - Epoch: [55][  600/ 1218]    Overall Loss 0.353771    Objective Loss 0.353771                                        LR 0.001000    Time 0.055054    
2024-06-06 00:32:02,520 - Epoch: [55][  700/ 1218]    Overall Loss 0.355404    Objective Loss 0.355404                                        LR 0.001000    Time 0.054794    
2024-06-06 00:32:07,705 - Epoch: [55][  800/ 1218]    Overall Loss 0.355240    Objective Loss 0.355240                                        LR 0.001000    Time 0.054423    
2024-06-06 00:32:12,846 - Epoch: [55][  900/ 1218]    Overall Loss 0.354997    Objective Loss 0.354997                                        LR 0.001000    Time 0.054085    
2024-06-06 00:32:18,034 - Epoch: [55][ 1000/ 1218]    Overall Loss 0.355216    Objective Loss 0.355216                                        LR 0.001000    Time 0.053862    
2024-06-06 00:32:23,116 - Epoch: [55][ 1100/ 1218]    Overall Loss 0.356899    Objective Loss 0.356899                                        LR 0.001000    Time 0.053582    
2024-06-06 00:32:28,295 - Epoch: [55][ 1200/ 1218]    Overall Loss 0.356684    Objective Loss 0.356684                                        LR 0.001000    Time 0.053430    
2024-06-06 00:32:29,177 - Epoch: [55][ 1218/ 1218]    Overall Loss 0.356398    Objective Loss 0.356398    Top1 85.085575    Top5 97.066015    LR 0.001000    Time 0.053364    
2024-06-06 00:32:29,430 - --- validate (epoch=55)-----------
2024-06-06 00:32:29,431 - 34633 samples (256 per mini-batch)
2024-06-06 00:32:35,488 - Epoch: [55][  100/  136]    Loss 0.376164    Top1 82.445312    Top5 97.324219    
2024-06-06 00:32:37,344 - Epoch: [55][  136/  136]    Loss 0.372414    Top1 82.574423    Top5 97.343574    
2024-06-06 00:32:37,594 - ==> Top1: 82.574    Top5: 97.344    Loss: 0.372

2024-06-06 00:32:37,596 - ==> Confusion:
[[  818     0     2     0     4     2     0     2     7    79     0     1     5     2     2     1     1     1     0     2     2]
 [    3   909     2     1    14    42     2    14     8     9     3     2     2     1     9     1     4     6    12     5    14]
 [   12     0   853    16     4     2    25    17     1    10     5     1     2     4     0     5     4     1     4     2     2]
 [    7     1    10   907     0     7     8     0     4     6    11     1     6     2    21     3     3     5     3     3     8]
 [   33     8     2     1   934    18     0     2     3    27     0     2     1     3     5     5     3     1     0     0     6]
 [    4    14     1     1    10   903     5    26     1     5     7    12     7    11     3     4     5     4     4     8     8]
 [    3     1     9     1     2     6  1016     4     1     5     5     3     1     0     0     5     2     1     2    13     6]
 [    7     7    10     0     0    45     6   938     2     4     3     7     2     0     1     0     1     0    20    18     6]
 [   11     2     1     0     0     2     0     1   885    58     8     0     2     8    12     0     2     4     0     0     6]
 [   48     0     2     0     6     4     0     0    39   877     0     1     2    11     3     0     0     2     1     2     3]
 [    0     1     5    21     1    11     4     7    20     3   955     1     3     9    10     1     0     0     9     0     3]
 [    5     1     1     0     1    15     3     6     3     4     0   896    27     6     1    10     2    14     1    12     3]
 [    2     0     1     5     1     6     0     3     2     3     0    65   835     1     2     8     2    29     5    15    10]
 [    3     0     0     0     3    37     1     4    17    32     8     9     6   849     6     4     1     4     1    13     3]
 [   13     0     2    19     6     2     0     1    35    24     3     3     6     6   959     0     0     2    10     0     7]
 [    3     0     0     1     1     1     6     0     1     4     0    19    15     2     0   980    10    16     1     3     3]
 [    3    10     3     1    10     4     1     2     6     1     4     3     5     4     2     8   977     2     1    11    14]
 [    2     0     0     1     2     2     2     2     1     3     0    22    22     1     0    12     1   926     1     2     3]
 [    4     2     4    16     3     2     0    23     9     3     1     2     4     2    16     0     1     1   953     5     7]
 [    3     6     3     1     1     7    13     5     0     1     0    15     8     1     0     4     5     1     4  1007     3]
 [  270   117   172   150   162   257    94   184   138   182   164   171   290   222   206   109   179   111   181   352 10221]]

2024-06-06 00:32:37,601 - ==> Best [Top1: 83.651   Top5: 97.320   Sparsity:0.00   Params: 424448 on epoch: 53]
2024-06-06 00:32:37,601 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:32:37,631 - 

2024-06-06 00:32:37,631 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:32:44,572 - Epoch: [56][  100/ 1218]    Overall Loss 0.340468    Objective Loss 0.340468                                        LR 0.001000    Time 0.069373    
2024-06-06 00:32:49,693 - Epoch: [56][  200/ 1218]    Overall Loss 0.353603    Objective Loss 0.353603                                        LR 0.001000    Time 0.060279    
2024-06-06 00:32:54,824 - Epoch: [56][  300/ 1218]    Overall Loss 0.351341    Objective Loss 0.351341                                        LR 0.001000    Time 0.057281    
2024-06-06 00:33:00,215 - Epoch: [56][  400/ 1218]    Overall Loss 0.354366    Objective Loss 0.354366                                        LR 0.001000    Time 0.056433    
2024-06-06 00:33:05,376 - Epoch: [56][  500/ 1218]    Overall Loss 0.354208    Objective Loss 0.354208                                        LR 0.001000    Time 0.055462    
2024-06-06 00:33:10,468 - Epoch: [56][  600/ 1218]    Overall Loss 0.354498    Objective Loss 0.354498                                        LR 0.001000    Time 0.054702    
2024-06-06 00:33:15,689 - Epoch: [56][  700/ 1218]    Overall Loss 0.354519    Objective Loss 0.354519                                        LR 0.001000    Time 0.054342    
2024-06-06 00:33:20,850 - Epoch: [56][  800/ 1218]    Overall Loss 0.353922    Objective Loss 0.353922                                        LR 0.001000    Time 0.053998    
2024-06-06 00:33:25,888 - Epoch: [56][  900/ 1218]    Overall Loss 0.353871    Objective Loss 0.353871                                        LR 0.001000    Time 0.053594    
2024-06-06 00:33:30,897 - Epoch: [56][ 1000/ 1218]    Overall Loss 0.353183    Objective Loss 0.353183                                        LR 0.001000    Time 0.053241    
2024-06-06 00:33:35,778 - Epoch: [56][ 1100/ 1218]    Overall Loss 0.352766    Objective Loss 0.352766                                        LR 0.001000    Time 0.052835    
2024-06-06 00:33:40,786 - Epoch: [56][ 1200/ 1218]    Overall Loss 0.353196    Objective Loss 0.353196                                        LR 0.001000    Time 0.052604    
2024-06-06 00:33:41,681 - Epoch: [56][ 1218/ 1218]    Overall Loss 0.353662    Objective Loss 0.353662    Top1 81.418093    Top5 95.843521    LR 0.001000    Time 0.052561    
2024-06-06 00:33:41,890 - --- validate (epoch=56)-----------
2024-06-06 00:33:41,891 - 34633 samples (256 per mini-batch)
2024-06-06 00:33:48,456 - Epoch: [56][  100/  136]    Loss 0.381929    Top1 82.691406    Top5 97.527344    
2024-06-06 00:33:50,286 - Epoch: [56][  136/  136]    Loss 0.384541    Top1 82.808304    Top5 97.441746    
2024-06-06 00:33:50,491 - ==> Top1: 82.808    Top5: 97.442    Loss: 0.385

2024-06-06 00:33:50,493 - ==> Confusion:
[[  797     4     5     3    12     1     0     3     8    64     0     1     1     4     7     3     3     2     2     3     8]
 [    1   970     1     2    18    15     4     8     1     4     3     1     3     1     5     0     1     1    14     4     6]
 [    6     0   872     8     6     1    12    16     0     8     5     7     4     2     1     4     4     0     0     7     7]
 [    1     0    12   916     3     4     6     3     2     3     9     1     8     4    12     2     3     5    11     3     8]
 [   15    13     9     2   952    15     1     0     1     9     0     2     3     4     7     6     4     1     0     1     9]
 [    3    44     5     2    12   860     5    31     0     3     1     9    11    21     4     3     4     2     4    10     9]
 [    0     2    27     3     1     4  1000     4     0     3     1     1     2     0     0     8     1     1     2    20     6]
 [    1    11    16     2     6    39     2   919     2     5     5     4     4     3     2     0     0     3    24    20     9]
 [   12     2     1     0     1     3     1     1   817    53    27     2     8    26    26     0     2     3    10     4     3]
 [   48     0     3     1     4     2     1     0    33   844     2     1     1    34    11     2     2     0     1     4     7]
 [    3     3    12    16     0     3     6     4     8     1   965     1     1     8    14     2     2     0     6     3     6]
 [    1     0     3     0     0    11     2     3     0     4     3   878    32     6     0    13     4    19     2    27     3]
 [    0     1     1     6     0     4     0     3     0     0     1    68   835     4     1     7     2    35     3    13    11]
 [    1     0     1     2     3    15     2     4     7    10    10    13     9   889     7     3     3     4     0    10     8]
 [    5     1     2    12    13     0     0     2    14     7     6     1     2     7   992     0     3     6    17     1     7]
 [    1     0     5     0     2     1     8     0     0     2     0    21    15     3     0   974    11    11     0     8     4]
 [    3    21     4     3     3     8     4     2     3     2     1    10     2     5     1    11   956     1     1    13    18]
 [    2     1     1     1     1     3     3     1     0     2     0    12    36     4     2     7     2   911     2     8     6]
 [    3    10     8    14     2     1     0    13     7     0     6     1     3     1    14     0     0     2   961     7     5]
 [    1     2     2     0     1     8    11     4     1     0     0    17     9     0     1     8     4     2     0  1010     7]
 [  140   213   214   126   209   151    95   126    90   117   146   157   306   277   233   156   190    89   170   366 10361]]

2024-06-06 00:33:50,498 - ==> Best [Top1: 83.651   Top5: 97.320   Sparsity:0.00   Params: 424448 on epoch: 53]
2024-06-06 00:33:50,498 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:33:50,533 - 

2024-06-06 00:33:50,533 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:33:57,230 - Epoch: [57][  100/ 1218]    Overall Loss 0.348488    Objective Loss 0.348488                                        LR 0.001000    Time 0.066939    
2024-06-06 00:34:02,439 - Epoch: [57][  200/ 1218]    Overall Loss 0.349431    Objective Loss 0.349431                                        LR 0.001000    Time 0.059498    
2024-06-06 00:34:07,606 - Epoch: [57][  300/ 1218]    Overall Loss 0.352708    Objective Loss 0.352708                                        LR 0.001000    Time 0.056880    
2024-06-06 00:34:12,745 - Epoch: [57][  400/ 1218]    Overall Loss 0.354085    Objective Loss 0.354085                                        LR 0.001000    Time 0.055500    
2024-06-06 00:34:17,871 - Epoch: [57][  500/ 1218]    Overall Loss 0.353839    Objective Loss 0.353839                                        LR 0.001000    Time 0.054648    
2024-06-06 00:34:23,238 - Epoch: [57][  600/ 1218]    Overall Loss 0.352396    Objective Loss 0.352396                                        LR 0.001000    Time 0.054481    
2024-06-06 00:34:28,400 - Epoch: [57][  700/ 1218]    Overall Loss 0.352822    Objective Loss 0.352822                                        LR 0.001000    Time 0.054068    
2024-06-06 00:34:33,332 - Epoch: [57][  800/ 1218]    Overall Loss 0.353543    Objective Loss 0.353543                                        LR 0.001000    Time 0.053472    
2024-06-06 00:34:38,724 - Epoch: [57][  900/ 1218]    Overall Loss 0.353355    Objective Loss 0.353355                                        LR 0.001000    Time 0.053519    
2024-06-06 00:34:43,710 - Epoch: [57][ 1000/ 1218]    Overall Loss 0.353991    Objective Loss 0.353991                                        LR 0.001000    Time 0.053150    
2024-06-06 00:34:48,836 - Epoch: [57][ 1100/ 1218]    Overall Loss 0.353453    Objective Loss 0.353453                                        LR 0.001000    Time 0.052977    
2024-06-06 00:34:53,810 - Epoch: [57][ 1200/ 1218]    Overall Loss 0.354472    Objective Loss 0.354472                                        LR 0.001000    Time 0.052704    
2024-06-06 00:34:54,768 - Epoch: [57][ 1218/ 1218]    Overall Loss 0.354978    Objective Loss 0.354978    Top1 80.684597    Top5 97.310513    LR 0.001000    Time 0.052712    
2024-06-06 00:34:54,984 - --- validate (epoch=57)-----------
2024-06-06 00:34:54,984 - 34633 samples (256 per mini-batch)
2024-06-06 00:35:01,336 - Epoch: [57][  100/  136]    Loss 0.381370    Top1 83.367188    Top5 97.355469    
2024-06-06 00:35:03,384 - Epoch: [57][  136/  136]    Loss 0.381753    Top1 83.342477    Top5 97.340687    
2024-06-06 00:35:03,603 - ==> Top1: 83.342    Top5: 97.341    Loss: 0.382

2024-06-06 00:35:03,605 - ==> Confusion:
[[  839     1     4     0    14     0     1     1     7    33     0     0     2     2     3     1     3     6     2     4     8]
 [    1   965     1     2    18     9     4    17     2     1     1     0     2     1     2     0     5     5    12     6     9]
 [    4     5   879    14     1     1    13     9     1     2     1     2     1     2     0     2     4     1     8     6    14]
 [    4     2     7   917     0     6     1     5     0     0     8     1     5     4    12     3     5    13    13     4     6]
 [   21    14     9     1   951     8     0     3     2     4     2     1     1     1     7     7     2     3     4     2    11]
 [    3    37     1     1    10   850     4    55     1     1     2    14     9    14     2     4     6     5     5    14     5]
 [    2     6    22     0     2     0  1004     9     0     1     1     1     0     1     0     6     4     7     3    12     5]
 [    1    10    12     2     3    14     2   960     1     0     4     6     4     3     1     1     0    10    25    12     6]
 [   18     8     0     0     0     1     0     4   847    32    20     3     5    18    17     1     7     6     7     1     7]
 [  125     3     3     1     7     4     0     8    55   747     1     1     1    22     8     1     2     6     0     3     3]
 [    2     5    11    14     2     2     4     3    14     0   962     0     1     4    10     0     0     0    17     3    10]
 [    1     3     1     0     0    12     1     6     0     2     1   871    31    10     0    14     1    24     0    21    12]
 [    0     1     2     2     0     4     0     7     0     0     1    70   826     3     1     7     4    38     6     8    15]
 [    2     0     1     1     6    14     1     5    17     2    13     9     4   882     7     3     4     7     1    11    11]
 [    8     7     3    21     9     4     1     2    24     4     6     2     1     0   960     0     1    10    19     4    12]
 [    3     3     4     1     0     0     5     2     0     1     0    17     7     0     1   975    10    22     4     5     6]
 [    0    14     7     2     1     6     0     0     3     0     2    10     2     1     0     9   990     4     0     9    12]
 [    5     2     0     0     0     1     1     0     0     2     0    24    24     0     2     3     0   929     3     5     4]
 [    0    11     6     7     1     1     1    24     6     2     0     2     0     0     8     0     0     4   974     3     8]
 [    3     3     1     0     1     5    12    12     0     0     0    21     2     3     2     6     3     4     5   998     7]
 [  208   292   189   115   175   148    73   190   110    62   121   179   241   163   173   114   215   159   214   253 10538]]

2024-06-06 00:35:03,617 - ==> Best [Top1: 83.651   Top5: 97.320   Sparsity:0.00   Params: 424448 on epoch: 53]
2024-06-06 00:35:03,618 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:35:03,654 - 

2024-06-06 00:35:03,654 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:35:10,637 - Epoch: [58][  100/ 1218]    Overall Loss 0.349073    Objective Loss 0.349073                                        LR 0.001000    Time 0.069793    
2024-06-06 00:35:15,694 - Epoch: [58][  200/ 1218]    Overall Loss 0.352675    Objective Loss 0.352675                                        LR 0.001000    Time 0.060168    
2024-06-06 00:35:20,814 - Epoch: [58][  300/ 1218]    Overall Loss 0.351913    Objective Loss 0.351913                                        LR 0.001000    Time 0.057171    
2024-06-06 00:35:25,885 - Epoch: [58][  400/ 1218]    Overall Loss 0.352062    Objective Loss 0.352062                                        LR 0.001000    Time 0.055549    
2024-06-06 00:35:30,755 - Epoch: [58][  500/ 1218]    Overall Loss 0.352124    Objective Loss 0.352124                                        LR 0.001000    Time 0.054176    
2024-06-06 00:35:35,802 - Epoch: [58][  600/ 1218]    Overall Loss 0.354007    Objective Loss 0.354007                                        LR 0.001000    Time 0.053554    
2024-06-06 00:35:41,110 - Epoch: [58][  700/ 1218]    Overall Loss 0.354544    Objective Loss 0.354544                                        LR 0.001000    Time 0.053482    
2024-06-06 00:35:46,235 - Epoch: [58][  800/ 1218]    Overall Loss 0.353572    Objective Loss 0.353572                                        LR 0.001000    Time 0.053199    
2024-06-06 00:35:51,361 - Epoch: [58][  900/ 1218]    Overall Loss 0.354999    Objective Loss 0.354999                                        LR 0.001000    Time 0.052974    
2024-06-06 00:35:56,586 - Epoch: [58][ 1000/ 1218]    Overall Loss 0.354175    Objective Loss 0.354175                                        LR 0.001000    Time 0.052893    
2024-06-06 00:36:01,863 - Epoch: [58][ 1100/ 1218]    Overall Loss 0.354239    Objective Loss 0.354239                                        LR 0.001000    Time 0.052873    
2024-06-06 00:36:06,956 - Epoch: [58][ 1200/ 1218]    Overall Loss 0.354503    Objective Loss 0.354503                                        LR 0.001000    Time 0.052709    
2024-06-06 00:36:07,779 - Epoch: [58][ 1218/ 1218]    Overall Loss 0.354731    Objective Loss 0.354731    Top1 83.374083    Top5 98.533007    LR 0.001000    Time 0.052601    
2024-06-06 00:36:07,974 - --- validate (epoch=58)-----------
2024-06-06 00:36:07,974 - 34633 samples (256 per mini-batch)
2024-06-06 00:36:14,392 - Epoch: [58][  100/  136]    Loss 0.365001    Top1 82.242188    Top5 97.164062    
2024-06-06 00:36:16,362 - Epoch: [58][  136/  136]    Loss 0.365776    Top1 82.363642    Top5 97.242514    
2024-06-06 00:36:16,584 - ==> Top1: 82.364    Top5: 97.243    Loss: 0.366

2024-06-06 00:36:16,585 - ==> Confusion:
[[  847     2     3     1     9     2     0     3     5    37     0     2     2     2     5     0     3     2     0     0     6]
 [    2   971     2     2     8    23     4    21     1     0     5     2     2     0     4     0     4     3     6     2     1]
 [    3     7   830    13     5     3    43     9     1     6     6     7     1     2     3     3     1     1     6     9    11]
 [    4     6     6   905     2     7     5     1     0     3    14     1     6     2    17     3     1    12    10     2     9]
 [   21    18     1     0   956     5     1     6     0     8     0     3     2     2     4     3     9     0     0     3    12]
 [    2    30     1     1    11   898     6    28     2     7     4     9     3    11     1     0     8     4     2     8     7]
 [    3    11    11     2     3     1  1014     4     1     1     4     4     4     0     0     6     1     2     1     9     4]
 [    1    11     8     1     2    14     6   979     3     1     7     4     2     3     1     0     1     3    14    12     4]
 [   16     7     0     0     0     4     0     1   877    42    10     1     4     9    12     1     3     5     6     1     3]
 [   78     1     4     0     6     2     0     4    38   834     1     2     2    15     5     1     2     2     0     0     4]
 [    0     3     7     8     1     2     4    11    18     2   979     1     0     6     8     0     2     0     5     1     6]
 [    0     4     2     0     1    15     4    14     0     1     1   884    20    11     1     5     1    19     0    23     5]
 [    2     3     2     0     2     9     1     7     1     0     4    64   828     2     2     6     4    32     8    11     7]
 [    4     1     2     0     5    18     1     9    16    21     7    11     4   865     6     2     6     5     2    11     5]
 [   12     6     4    11     8     0     2     1    34     9     8     1     2     3   969     0     2     3    14     0     9]
 [    3     3     2     1     0     1    14     0     1     0     0    23     2     0     0   971     8    29     0     4     4]
 [    2    11     1     2     5     6     4     1     5     1     3     6     0     2     2     7   982     3     3     9    17]
 [    2     5     2     1     0     1     2     2     5     2     0    17    20     1     2    11     0   922     2     1     7]
 [    7     4     7     7     2     2     1    34     6     1     3     2     2     0     5     1     1     1   964     4     4]
 [    0     7     2     3     1     9    13    16     0     1     0    10     3     2     0     8     3     2     4   994    10]
 [  198   291   148    89   190   206   149   270   125   118   162   187   268   248   189   107   207   154   185   385 10056]]

2024-06-06 00:36:16,589 - ==> Best [Top1: 83.651   Top5: 97.320   Sparsity:0.00   Params: 424448 on epoch: 53]
2024-06-06 00:36:16,589 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:36:16,618 - 

2024-06-06 00:36:16,619 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:36:23,548 - Epoch: [59][  100/ 1218]    Overall Loss 0.354847    Objective Loss 0.354847                                        LR 0.001000    Time 0.069261    
2024-06-06 00:36:28,507 - Epoch: [59][  200/ 1218]    Overall Loss 0.350102    Objective Loss 0.350102                                        LR 0.001000    Time 0.059412    
2024-06-06 00:36:33,771 - Epoch: [59][  300/ 1218]    Overall Loss 0.349696    Objective Loss 0.349696                                        LR 0.001000    Time 0.057146    
2024-06-06 00:36:38,913 - Epoch: [59][  400/ 1218]    Overall Loss 0.354389    Objective Loss 0.354389                                        LR 0.001000    Time 0.055708    
2024-06-06 00:36:44,306 - Epoch: [59][  500/ 1218]    Overall Loss 0.353485    Objective Loss 0.353485                                        LR 0.001000    Time 0.055348    
2024-06-06 00:36:49,285 - Epoch: [59][  600/ 1218]    Overall Loss 0.351807    Objective Loss 0.351807                                        LR 0.001000    Time 0.054418    
2024-06-06 00:36:54,701 - Epoch: [59][  700/ 1218]    Overall Loss 0.352846    Objective Loss 0.352846                                        LR 0.001000    Time 0.054377    
2024-06-06 00:36:59,977 - Epoch: [59][  800/ 1218]    Overall Loss 0.352549    Objective Loss 0.352549                                        LR 0.001000    Time 0.054172    
2024-06-06 00:37:05,119 - Epoch: [59][  900/ 1218]    Overall Loss 0.353376    Objective Loss 0.353376                                        LR 0.001000    Time 0.053863    
2024-06-06 00:37:10,240 - Epoch: [59][ 1000/ 1218]    Overall Loss 0.352002    Objective Loss 0.352002                                        LR 0.001000    Time 0.053596    
2024-06-06 00:37:15,657 - Epoch: [59][ 1100/ 1218]    Overall Loss 0.352705    Objective Loss 0.352705                                        LR 0.001000    Time 0.053645    
2024-06-06 00:37:20,585 - Epoch: [59][ 1200/ 1218]    Overall Loss 0.352196    Objective Loss 0.352196                                        LR 0.001000    Time 0.053279    
2024-06-06 00:37:21,498 - Epoch: [59][ 1218/ 1218]    Overall Loss 0.351989    Objective Loss 0.351989    Top1 85.330073    Top5 98.777506    LR 0.001000    Time 0.053242    
2024-06-06 00:37:21,714 - --- validate (epoch=59)-----------
2024-06-06 00:37:21,715 - 34633 samples (256 per mini-batch)
2024-06-06 00:37:28,094 - Epoch: [59][  100/  136]    Loss 0.393135    Top1 82.085938    Top5 97.269531    
2024-06-06 00:37:29,907 - Epoch: [59][  136/  136]    Loss 0.395281    Top1 81.913204    Top5 97.271389    
2024-06-06 00:37:30,093 - ==> Top1: 81.913    Top5: 97.271    Loss: 0.395

2024-06-06 00:37:30,095 - ==> Confusion:
[[  831     2     9     0    15     4     0     3     9    34     0     4     0     3     5     3     2     0     1     0     6]
 [    9   955     5     0    21    11     5     9     0     1     1     2     1     1     3     2    18     3    13     2     1]
 [    6     0   897     2     2     1    11     3     0     2     8     2     3     5     1     1     7     0     4     8     7]
 [    8     2    16   897     0     6     4     1     4     1    13     3     5     0    19     7     2     4    12     0    12]
 [   15    14     7     0   930     7     4     1     1    11     2     4     0     3    11    12    12     1     5     4    10]
 [    6    42     7     1    14   831     4    31     1     6     4    13     6    18     4     9    13     1     6    17     9]
 [    4     2    31     0     0     1   993     7     0     0     1     4     3     0     0     8     6     1     3    18     4]
 [    3    13    30     0     2    18     1   897     1     2     3    12     3     4     1     2     3     3    48    23     8]
 [   13     3     0     0     1     2     0     1   856    43    11     2     4    13    22     4     6     1    11     0     9]
 [  104     2     3     0     2     0     0     1    62   776     0     5     0    20    10     2     5     4     0     0     5]
 [    1     5    10     5     0     1     3     6    10     2   964     2     1    14     3     3     4     0    19     5     6]
 [    4     0     4     1     0     5     2     4     0     2     1   870    44     8     1    19    17     3     1    25     0]
 [    1     3     2     3     2     0     0     3     0     1     0    60   852     2     2    12     7    17     5    10    13]
 [    5     2     5     0     1     9     0     1    13     7     9    12     6   877     6     6    12     3     1    18     8]
 [   10     3     7    13     9     0     1     1    31     6     5     6     6     5   959     0     5     2    14     2    13]
 [    2     1     3     0     2     0     6     0     0     3     0    19     7     1     0   996    10     6     1     3     6]
 [    1     9     2     2     4     2     0     0     2     3     0     8     6     2     1    13  1000     0     2     4    11]
 [    5     1     1     1     0     0     1     0     0     3     2    23    35     2     3    26     6   890     1     1     4]
 [    5     4     5     5     1     1     0    11     5     0     5     2     2     1    12     2     1     2   989     1     4]
 [    6     5     2     0     1     5     5    10     1     0     0    15     5     1     0     9    12     1     5   995    10]
 [  206   235   216    69   176   129    84   152   106    83   156   157   366   200   155   191   463    64   216   394 10114]]

2024-06-06 00:37:30,099 - ==> Best [Top1: 83.651   Top5: 97.320   Sparsity:0.00   Params: 424448 on epoch: 53]
2024-06-06 00:37:30,099 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:37:30,134 - 

2024-06-06 00:37:30,134 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:37:36,877 - Epoch: [60][  100/ 1218]    Overall Loss 0.349495    Objective Loss 0.349495                                        LR 0.001000    Time 0.067385    
2024-06-06 00:37:42,053 - Epoch: [60][  200/ 1218]    Overall Loss 0.352335    Objective Loss 0.352335                                        LR 0.001000    Time 0.059563    
2024-06-06 00:37:47,512 - Epoch: [60][  300/ 1218]    Overall Loss 0.351702    Objective Loss 0.351702                                        LR 0.001000    Time 0.057897    
2024-06-06 00:37:52,594 - Epoch: [60][  400/ 1218]    Overall Loss 0.351492    Objective Loss 0.351492                                        LR 0.001000    Time 0.056121    
2024-06-06 00:37:57,470 - Epoch: [60][  500/ 1218]    Overall Loss 0.349687    Objective Loss 0.349687                                        LR 0.001000    Time 0.054643    
2024-06-06 00:38:02,709 - Epoch: [60][  600/ 1218]    Overall Loss 0.348581    Objective Loss 0.348581                                        LR 0.001000    Time 0.054263    
2024-06-06 00:38:07,849 - Epoch: [60][  700/ 1218]    Overall Loss 0.349014    Objective Loss 0.349014                                        LR 0.001000    Time 0.053850    
2024-06-06 00:38:13,099 - Epoch: [60][  800/ 1218]    Overall Loss 0.350061    Objective Loss 0.350061                                        LR 0.001000    Time 0.053676    
2024-06-06 00:38:18,160 - Epoch: [60][  900/ 1218]    Overall Loss 0.350725    Objective Loss 0.350725                                        LR 0.001000    Time 0.053333    
2024-06-06 00:38:23,399 - Epoch: [60][ 1000/ 1218]    Overall Loss 0.350860    Objective Loss 0.350860                                        LR 0.001000    Time 0.053236    
2024-06-06 00:38:28,572 - Epoch: [60][ 1100/ 1218]    Overall Loss 0.350891    Objective Loss 0.350891                                        LR 0.001000    Time 0.053097    
2024-06-06 00:38:33,478 - Epoch: [60][ 1200/ 1218]    Overall Loss 0.351402    Objective Loss 0.351402                                        LR 0.001000    Time 0.052759    
2024-06-06 00:38:34,370 - Epoch: [60][ 1218/ 1218]    Overall Loss 0.351155    Objective Loss 0.351155    Top1 82.396088    Top5 97.310513    LR 0.001000    Time 0.052711    
2024-06-06 00:38:34,595 - --- validate (epoch=60)-----------
2024-06-06 00:38:34,595 - 34633 samples (256 per mini-batch)
2024-06-06 00:38:40,835 - Epoch: [60][  100/  136]    Loss 0.376098    Top1 82.335938    Top5 97.125000    
2024-06-06 00:38:42,573 - Epoch: [60][  136/  136]    Loss 0.371690    Top1 82.349205    Top5 97.178991    
2024-06-06 00:38:42,818 - ==> Top1: 82.349    Top5: 97.179    Loss: 0.372

2024-06-06 00:38:42,820 - ==> Confusion:
[[  749     0     4     1    17     5     0     1     7   126     1     1     0     3     4     1     3     0     1     0     7]
 [    2   955     0     2    10    20     5    11     5     3     8     1     2     2     6     0     6     0    14     2     9]
 [    3     1   874     9     3     1    22     8     3    10     6     2     5     3     4     0     3     0     4     1     8]
 [    3     3     7   920     0     7     2     2     1     4     8     1     8     3    20     0     1     6    12     3     5]
 [   13    13     1     0   952    12     0     4     0    20     2     2     2     7    13     0     4     0     2     1     6]
 [    4    28     5     4     9   896     3    22     4     6     2     6     5    20     2     0     1     4     4    10     8]
 [    2     2    24     3     1     6  1015     6     0     3     6     2     1     1     1     3     1     2     2     2     3]
 [    1    10    10     2     2    29     3   947     2     6     2     4     4     1     0     0     0     0    36    11     7]
 [   10     0     0     0     3     1     0     2   890    55     7     3     4    11    10     0     0     0     6     0     0]
 [   28     0     0     0     5     0     0     0    26   913     1     0     2    11     6     1     0     0     2     2     4]
 [    0     2     6     9     0     4     2     5    18     4   980     2     2     6     9     0     0     0    10     0     5]
 [    4     2     1     1     0    16     6    10     5     7     0   869    34    14     2     6     4    13     1    13     3]
 [    1     3     2     5     5     9     2     6     5     3     0    69   843     2     2     4     1    21     4     3     5]
 [    3     3     1     2     6    16     1     3    15    25     7     8     3   885     4     0     2     1     4     5     7]
 [    8     2     1    16     6     1     0     2    25     6     3     0     8     7   990     0     3     3    11     0     6]
 [    1     0     8     2    11     1    18     1     0     6     1    21    15     5     1   942    18     9     1     1     4]
 [    3     8     3     3     9     4     4     3     6     3     0     7     4     3     3     4   987     1     0     5    12]
 [    2     0     1     2     1     3     2     4     2     6     1    14    33     4     6    13     1   896     5     4     5]
 [    0     5     5    10     4     3     1    13     4     2     2     1     4     4    17     1     1     0   972     4     5]
 [    0     4     4     0     4    12    14    15     0     1     0    11     7     6     1     3    10     3     3   985     5]
 [  145   205   197   142   203   205   141   179   121   187   183   151   315   307   227    76   321   107   211   249 10060]]

2024-06-06 00:38:42,824 - ==> Best [Top1: 83.651   Top5: 97.320   Sparsity:0.00   Params: 424448 on epoch: 53]
2024-06-06 00:38:42,825 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:38:42,853 - 

2024-06-06 00:38:42,854 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:38:49,579 - Epoch: [61][  100/ 1218]    Overall Loss 0.346364    Objective Loss 0.346364                                        LR 0.001000    Time 0.067220    
2024-06-06 00:38:54,718 - Epoch: [61][  200/ 1218]    Overall Loss 0.349628    Objective Loss 0.349628                                        LR 0.001000    Time 0.059292    
2024-06-06 00:38:59,814 - Epoch: [61][  300/ 1218]    Overall Loss 0.344139    Objective Loss 0.344139                                        LR 0.001000    Time 0.056505    
2024-06-06 00:39:04,930 - Epoch: [61][  400/ 1218]    Overall Loss 0.345158    Objective Loss 0.345158                                        LR 0.001000    Time 0.055163    
2024-06-06 00:39:10,156 - Epoch: [61][  500/ 1218]    Overall Loss 0.344975    Objective Loss 0.344975                                        LR 0.001000    Time 0.054578    
2024-06-06 00:39:15,468 - Epoch: [61][  600/ 1218]    Overall Loss 0.344694    Objective Loss 0.344694                                        LR 0.001000    Time 0.054331    
2024-06-06 00:39:20,733 - Epoch: [61][  700/ 1218]    Overall Loss 0.345561    Objective Loss 0.345561                                        LR 0.001000    Time 0.054086    
2024-06-06 00:39:25,591 - Epoch: [61][  800/ 1218]    Overall Loss 0.345463    Objective Loss 0.345463                                        LR 0.001000    Time 0.053396    
2024-06-06 00:39:30,650 - Epoch: [61][  900/ 1218]    Overall Loss 0.346414    Objective Loss 0.346414                                        LR 0.001000    Time 0.053081    
2024-06-06 00:39:36,036 - Epoch: [61][ 1000/ 1218]    Overall Loss 0.345946    Objective Loss 0.345946                                        LR 0.001000    Time 0.053156    
2024-06-06 00:39:40,894 - Epoch: [61][ 1100/ 1218]    Overall Loss 0.346828    Objective Loss 0.346828                                        LR 0.001000    Time 0.052738    
2024-06-06 00:39:46,222 - Epoch: [61][ 1200/ 1218]    Overall Loss 0.347851    Objective Loss 0.347851                                        LR 0.001000    Time 0.052781    
2024-06-06 00:39:47,141 - Epoch: [61][ 1218/ 1218]    Overall Loss 0.347936    Objective Loss 0.347936    Top1 82.640587    Top5 96.332518    LR 0.001000    Time 0.052755    
2024-06-06 00:39:47,408 - --- validate (epoch=61)-----------
2024-06-06 00:39:47,409 - 34633 samples (256 per mini-batch)
2024-06-06 00:39:53,586 - Epoch: [61][  100/  136]    Loss 0.361552    Top1 82.398438    Top5 97.265625    
2024-06-06 00:39:55,416 - Epoch: [61][  136/  136]    Loss 0.366229    Top1 82.305893    Top5 97.288713    
2024-06-06 00:39:55,669 - ==> Top1: 82.306    Top5: 97.289    Loss: 0.366

2024-06-06 00:39:55,670 - ==> Confusion:
[[  756     3     4     0    25     0     0     3     5   110     0     1     3     3     2     0     1     2     0     4     9]
 [    2   967     3     1    21    22     5    13     0     1     4     3     6     0     2     0     1     1     8     1     2]
 [    2     7   870    12     2     5    20    12     0     5     3     2     5     4     1     3     4     1     1     6     5]
 [    6     2    11   913     2    11     1     2     0     2    19     1     7     0    16     1     0     8     3     5     6]
 [    8     8     4     2   979     9     0     1     3    14     3     1     0     3     8     0     2     0     2     2     5]
 [    4    27     4     7    14   881     1    28     1     6     2    14     7    11     3     1     7     2     5    13     5]
 [    1     6    14     2     3     6  1002     6     1     5     5     5     5     1     0     4     2     3     1    11     3]
 [    3     9    14     0     4    30     4   940     0     3     5    11     6     3     1     1     1     2    20    16     4]
 [    8     6     2     0     2     1     0     1   818    68    20     3     5    21    22     0     3     4    11     2     5]
 [   39     0     2     1     9     1     0     1    16   907     2     1     0    16     3     0     0     0     0     0     3]
 [    0     7     4     7     3     3     0     4     6     0   982     1     3    16    11     0     0     0    12     2     3]
 [    2     1     1     0     1    14     1     4     2     2     0   907    23     6     0    12     6    18     1     7     3]
 [    2     1     1     8     0     6     0     3     4     2     4    73   841     5     1     2     3    23     2     8     6]
 [    1     1     2     0     8    19     0     5    10    19     8    10     7   891     4     0     5     4     2     4     1]
 [    8     6     3    17     7     0     0     0    24    17     7     3     0     7   973     0     4     1    15     2     4]
 [    0     1     3     0     4     1     8     0     0     7     1    21    11     0     1   979     8    12     0     4     5]
 [    2    11     3     0     5     6     1     0     4     5     1     8     5     2     0     8   988     3     2     5    13]
 [    5     2     1     3     1     0     2     1     1     3     0    15    24     4     1    10     0   923     4     3     2]
 [    2     5     9    10     6     3     0    21     3     2     5     0     4     1    11     0     2     0   966     4     4]
 [    2     2     2     1     0    14    10     5     1     2     0    19     8     4     1     3     6     3     1   997     7]
 [  144   253   186   114   254   206   113   183    97   142   207   171   345   289   183   109   288   104   190   329 10025]]

2024-06-06 00:39:55,676 - ==> Best [Top1: 83.651   Top5: 97.320   Sparsity:0.00   Params: 424448 on epoch: 53]
2024-06-06 00:39:55,677 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:39:55,703 - 

2024-06-06 00:39:55,704 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:40:02,434 - Epoch: [62][  100/ 1218]    Overall Loss 0.348977    Objective Loss 0.348977                                        LR 0.001000    Time 0.067266    
2024-06-06 00:40:07,897 - Epoch: [62][  200/ 1218]    Overall Loss 0.339055    Objective Loss 0.339055                                        LR 0.001000    Time 0.060936    
2024-06-06 00:40:13,090 - Epoch: [62][  300/ 1218]    Overall Loss 0.338324    Objective Loss 0.338324                                        LR 0.001000    Time 0.057925    
2024-06-06 00:40:18,174 - Epoch: [62][  400/ 1218]    Overall Loss 0.342455    Objective Loss 0.342455                                        LR 0.001000    Time 0.056150    
2024-06-06 00:40:23,176 - Epoch: [62][  500/ 1218]    Overall Loss 0.343834    Objective Loss 0.343834                                        LR 0.001000    Time 0.054919    
2024-06-06 00:40:28,326 - Epoch: [62][  600/ 1218]    Overall Loss 0.342624    Objective Loss 0.342624                                        LR 0.001000    Time 0.054344    
2024-06-06 00:40:33,424 - Epoch: [62][  700/ 1218]    Overall Loss 0.343323    Objective Loss 0.343323                                        LR 0.001000    Time 0.053860    
2024-06-06 00:40:38,627 - Epoch: [62][  800/ 1218]    Overall Loss 0.344657    Objective Loss 0.344657                                        LR 0.001000    Time 0.053629    
2024-06-06 00:40:43,846 - Epoch: [62][  900/ 1218]    Overall Loss 0.344655    Objective Loss 0.344655                                        LR 0.001000    Time 0.053466    
2024-06-06 00:40:48,630 - Epoch: [62][ 1000/ 1218]    Overall Loss 0.344575    Objective Loss 0.344575                                        LR 0.001000    Time 0.052900    
2024-06-06 00:40:53,701 - Epoch: [62][ 1100/ 1218]    Overall Loss 0.345888    Objective Loss 0.345888                                        LR 0.001000    Time 0.052699    
2024-06-06 00:40:58,777 - Epoch: [62][ 1200/ 1218]    Overall Loss 0.346467    Objective Loss 0.346467                                        LR 0.001000    Time 0.052536    
2024-06-06 00:40:59,722 - Epoch: [62][ 1218/ 1218]    Overall Loss 0.346374    Objective Loss 0.346374    Top1 87.041565    Top5 97.066015    LR 0.001000    Time 0.052535    
2024-06-06 00:40:59,901 - --- validate (epoch=62)-----------
2024-06-06 00:40:59,901 - 34633 samples (256 per mini-batch)
2024-06-06 00:41:06,240 - Epoch: [62][  100/  136]    Loss 0.381054    Top1 81.785156    Top5 97.085938    
2024-06-06 00:41:08,090 - Epoch: [62][  136/  136]    Loss 0.377158    Top1 82.022926    Top5 97.089481    
2024-06-06 00:41:08,311 - ==> Top1: 82.023    Top5: 97.089    Loss: 0.377

2024-06-06 00:41:08,312 - ==> Confusion:
[[ 857    1    1    0    6    0    1    0    6   38    0    2    2    1    4    2    2    2    2    1    3]
 [   2  977    2    1   10   13    1   13    5    0    5    3    4    0    6    1    6    0   13    1    0]
 [   9    3  857    9    0    3   22   11    2   10    3    1    4    3    1    4   11    3    3    3    8]
 [   8    1   15  917    0    3    4    1    1    3   20    2    6    2   13    2    5    3    5    2    3]
 [  19   18    5    0  925   11    3    4    2   11    3    1    1    1    6   12   20    1    2    1    8]
 [   5   31    7    9    8  867    6   28    2    4    4   10   18    8    2    5    9    4    4    5    7]
 [   0    2   19    2    2    6 1008    5    0    1    2    4    4    1    0   10    2    6    2    7    3]
 [   7   17    8    5    0   24    5  940    1    4    3    9    6    2    1    3    3    1   23   13    2]
 [  19    8    0    0    2    1    0    4  850   52   10    0    5    5   19    1    7    7    5    0    7]
 [  98    0    0    1    6    3    0    3   38  823    0    3    3    6    4    3    2    3    2    0    3]
 [   1    4    6    4    1    1    3    5   17    3  987    0    0    5   11    0    1    0   11    1    3]
 [   3    3    0    0    1   12    2    6    3    1    0  843   52    3    1   23    6   32    0   13    7]
 [   1    2    3    8    0    2    1    0    3    0    1   37  869    0    1    7    5   45    4    1    5]
 [   3    2    3    0    2   17    4    4   25   26    7   12    6  853    7    2    7    8    2    5    6]
 [  11    7    1   19    4    4    0    1   30   11    8    0    6    5  958    1    4    4   12    2   10]
 [   2    1    0    0    2    0    4    1    1    2    0   11   12    1    0  997    7   17    1    3    4]
 [   4    6    2    1    2    0    1    1    2    3    2    6    4    1    1   19 1005    2    1    6    3]
 [   0    1    0    4    1    0    0    4    1    2    1   10   17    2    0   11    2  943    2    1    3]
 [   7    3    8   14    2    3    1   19    3    0    8    2    4    0   15    1    1    3  956    1    7]
 [   5    5    2    2    0   10    4   12    2    1    0    8   11    2    0    3    8    3    7  997    6]
 [ 259  274  195  126  151  136  105  164  148  145  207  127  377  166  182  195  337  176  177  307 9978]]

2024-06-06 00:41:08,316 - ==> Best [Top1: 83.651   Top5: 97.320   Sparsity:0.00   Params: 424448 on epoch: 53]
2024-06-06 00:41:08,317 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:41:08,347 - 

2024-06-06 00:41:08,347 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:41:15,123 - Epoch: [63][  100/ 1218]    Overall Loss 0.331830    Objective Loss 0.331830                                        LR 0.001000    Time 0.067725    
2024-06-06 00:41:20,209 - Epoch: [63][  200/ 1218]    Overall Loss 0.334185    Objective Loss 0.334185                                        LR 0.001000    Time 0.059280    
2024-06-06 00:41:25,412 - Epoch: [63][  300/ 1218]    Overall Loss 0.338931    Objective Loss 0.338931                                        LR 0.001000    Time 0.056857    
2024-06-06 00:41:30,467 - Epoch: [63][  400/ 1218]    Overall Loss 0.340735    Objective Loss 0.340735                                        LR 0.001000    Time 0.055272    
2024-06-06 00:41:35,714 - Epoch: [63][  500/ 1218]    Overall Loss 0.341576    Objective Loss 0.341576                                        LR 0.001000    Time 0.054706    
2024-06-06 00:41:40,875 - Epoch: [63][  600/ 1218]    Overall Loss 0.340359    Objective Loss 0.340359                                        LR 0.001000    Time 0.054187    
2024-06-06 00:41:46,161 - Epoch: [63][  700/ 1218]    Overall Loss 0.338267    Objective Loss 0.338267                                        LR 0.001000    Time 0.053994    
2024-06-06 00:41:51,280 - Epoch: [63][  800/ 1218]    Overall Loss 0.338911    Objective Loss 0.338911                                        LR 0.001000    Time 0.053639    
2024-06-06 00:41:56,258 - Epoch: [63][  900/ 1218]    Overall Loss 0.339932    Objective Loss 0.339932                                        LR 0.001000    Time 0.053208    
2024-06-06 00:42:01,393 - Epoch: [63][ 1000/ 1218]    Overall Loss 0.341791    Objective Loss 0.341791                                        LR 0.001000    Time 0.053018    
2024-06-06 00:42:06,597 - Epoch: [63][ 1100/ 1218]    Overall Loss 0.342509    Objective Loss 0.342509                                        LR 0.001000    Time 0.052926    
2024-06-06 00:42:11,869 - Epoch: [63][ 1200/ 1218]    Overall Loss 0.343116    Objective Loss 0.343116                                        LR 0.001000    Time 0.052907    
2024-06-06 00:42:12,795 - Epoch: [63][ 1218/ 1218]    Overall Loss 0.343162    Objective Loss 0.343162    Top1 84.352078    Top5 98.777506    LR 0.001000    Time 0.052885    
2024-06-06 00:42:13,074 - --- validate (epoch=63)-----------
2024-06-06 00:42:13,074 - 34633 samples (256 per mini-batch)
2024-06-06 00:42:19,078 - Epoch: [63][  100/  136]    Loss 0.375345    Top1 82.707031    Top5 97.285156    
2024-06-06 00:42:20,898 - Epoch: [63][  136/  136]    Loss 0.373706    Top1 82.730344    Top5 97.366673    
2024-06-06 00:42:21,142 - ==> Top1: 82.730    Top5: 97.367    Loss: 0.374

2024-06-06 00:42:21,143 - ==> Confusion:
[[  836     2     1     1    18     1     0     1     5    52     0     1     7     3     0     1     1     0     0     0     1]
 [    1   976     3     1    21    16     1     6     0     1     2     0     6     0     4     0     9     2     4     3     7]
 [    5     5   881     1     5     1    12     9     0     5     8     4     3     5     3     3     1     1     2     2    14]
 [    6     4    33   888     6     3     3     2     0     3    14     1    10     2    25     1     1     5     3     2     4]
 [   17    14     2     0   974     2     0     3     0    12     0     0     7     2     8     7     2     1     0     0     3]
 [    4    32     4     0    23   880     3    32     2     1     4    19     5    12     4     2     1     4     0     4     7]
 [    3     9    36     0     4    12   971     6     0     3     2     1     5     2     0    14     1     2     0     9     6]
 [    0    14    22     1     4    29     0   934     2     1     2    12    10     1     4     3     1     2    21     6     8]
 [   14    10     1     1     3     3     1     1   829    62     8     6     6    20    21     2     0     2     8     0     4]
 [   72     3     0     0     8     1     0     0    32   849     2     1     5    13     6     3     4     1     0     0     1]
 [    1     6    12     4     7     2     4     7    12     3   967     2     1     7    11     0     0     0     7     1    10]
 [    4     1     6     1     1     7     2     3     0     1     0   920    32     3     0     9     2     6     0     6     7]
 [    3     3     6     4     5     1     1     0     2     2     1    61   841     2     1    14     3    25     0     4    16]
 [    5     2     3     0     8    13     2     2     8    18     5    19     7   887     3     2     2     2     0     5     8]
 [   11     4     4     9    16     2     0     1    25    11     3     5     6     7   978     0     0     2     9     1     4]
 [    2     1     4     0     4     0     5     0     0     1     0    14    11     2     0   992    11     8     0     3     8]
 [    2     9     7     0     9     7     0     1     0     2     0     7     7     2     1     6   986     0     0     4    22]
 [    5     1     2     2     0     0     0     1     1     2     0    29    27     4     2    17     1   903     1     1     6]
 [    2    18    14     7     5     1     0    25     7     2     5     2     4     2    25     1     1     0   922     3    12]
 [    0     7     5     0     2     6     6     4     0     0     0    31    14     2     0     7     6     2     4   977    15]
 [  244   260   260    61   332   197    71   147    91   135   135   205   299   256   246   164   189   101   128   150 10261]]

2024-06-06 00:42:21,147 - ==> Best [Top1: 83.651   Top5: 97.320   Sparsity:0.00   Params: 424448 on epoch: 53]
2024-06-06 00:42:21,148 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:42:21,184 - 

2024-06-06 00:42:21,184 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:42:27,808 - Epoch: [64][  100/ 1218]    Overall Loss 0.334201    Objective Loss 0.334201                                        LR 0.001000    Time 0.066199    
2024-06-06 00:42:33,014 - Epoch: [64][  200/ 1218]    Overall Loss 0.339967    Objective Loss 0.339967                                        LR 0.001000    Time 0.059118    
2024-06-06 00:42:38,180 - Epoch: [64][  300/ 1218]    Overall Loss 0.339321    Objective Loss 0.339321                                        LR 0.001000    Time 0.056622    
2024-06-06 00:42:43,307 - Epoch: [64][  400/ 1218]    Overall Loss 0.340678    Objective Loss 0.340678                                        LR 0.001000    Time 0.055278    
2024-06-06 00:42:48,175 - Epoch: [64][  500/ 1218]    Overall Loss 0.342028    Objective Loss 0.342028                                        LR 0.001000    Time 0.053954    
2024-06-06 00:42:53,464 - Epoch: [64][  600/ 1218]    Overall Loss 0.342082    Objective Loss 0.342082                                        LR 0.001000    Time 0.053773    
2024-06-06 00:42:58,645 - Epoch: [64][  700/ 1218]    Overall Loss 0.341557    Objective Loss 0.341557                                        LR 0.001000    Time 0.053489    
2024-06-06 00:43:03,899 - Epoch: [64][  800/ 1218]    Overall Loss 0.341456    Objective Loss 0.341456                                        LR 0.001000    Time 0.053367    
2024-06-06 00:43:09,114 - Epoch: [64][  900/ 1218]    Overall Loss 0.342847    Objective Loss 0.342847                                        LR 0.001000    Time 0.053229    
2024-06-06 00:43:14,313 - Epoch: [64][ 1000/ 1218]    Overall Loss 0.343731    Objective Loss 0.343731                                        LR 0.001000    Time 0.053103    
2024-06-06 00:43:19,229 - Epoch: [64][ 1100/ 1218]    Overall Loss 0.343756    Objective Loss 0.343756                                        LR 0.001000    Time 0.052741    
2024-06-06 00:43:24,216 - Epoch: [64][ 1200/ 1218]    Overall Loss 0.343693    Objective Loss 0.343693                                        LR 0.001000    Time 0.052500    
2024-06-06 00:43:25,015 - Epoch: [64][ 1218/ 1218]    Overall Loss 0.343346    Objective Loss 0.343346    Top1 84.107579    Top5 97.555012    LR 0.001000    Time 0.052380    
2024-06-06 00:43:25,217 - --- validate (epoch=64)-----------
2024-06-06 00:43:25,217 - 34633 samples (256 per mini-batch)
2024-06-06 00:43:31,792 - Epoch: [64][  100/  136]    Loss 0.373906    Top1 83.722656    Top5 97.519531    
2024-06-06 00:43:33,595 - Epoch: [64][  136/  136]    Loss 0.372106    Top1 83.746716    Top5 97.568793    
2024-06-06 00:43:33,840 - ==> Top1: 83.747    Top5: 97.569    Loss: 0.372

2024-06-06 00:43:33,842 - ==> Confusion:
[[  826     0     2     1     3     1     0     0     2    72     0     8     1     1     2     0     0     1     0     0    11]
 [    1   929     2     3     9    37     5    22     4     0     6     6     1     1     6     0     3     2    14     2    10]
 [    6     1   862    10     6     6    25    11     0     6     5     7     3     3     3     2     0     2     2     4     6]
 [    9     0     5   903     2     6     4     3     1     4    19     4     8     2    26     2     0     6     6     0     6]
 [   14     6     2     0   956     8     0     2     2    13     1    10     2     4    16     4     2     0     5     1     6]
 [    6    11     2     2    13   891     3    23     1     3     5    24     4    11     5     2     7     5     3     9    13]
 [    4     2    11     1     3     6  1009     2     0     0     4     5     4     1     0     4     1     5     1    16     7]
 [    3     6     9     1     0    28     5   946     1     3     5    12     5     1     2     0     1     1    26    15     7]
 [   15     1     0     3     1     1     0     2   814    84    21     7     4     8    20     0     1     2     9     0     9]
 [   69     0     1     0     0     1     0     0    16   885     1     4     0    10     7     0     0     0     0     0     7]
 [    0     0     6    10     0     5     2     1    12     1   978     2     3    12    10     0     0     0     9     1    12]
 [    2     0     0     0     1    13     2     4     2     2     0   884    30     6     0     7     1    22     3    24     8]
 [    1     0     3    11     0     2     0     1     2     1     4    71   802     4     2     7     2    53     1    11    17]
 [    3     1     0     0     2    16     1     3     8    25    10    16     3   881     7     4     1     3     0     8     9]
 [    9     3     1    13     2     0     0     1    17    12     5     7     1     2  1000     0     1     2    11     1    10]
 [    5     2     1     2     3     0     3     0     0     3     0    28     3     1     0   974     4    18     1     9     9]
 [    4     8     2     3     7     6     1     2     7     2     3     6     6     2     3    12   964     4     0    14    16]
 [    5     0     1     0     0     0     1     0     2     2     0    14    16     3     3     7     0   942     3     3     3]
 [    2     3     8    18     2     3     1    15     6     0     9     3     1     1    21     0     0     0   949     6    10]
 [    2     0     3     0     0    14    19     7     2     1     0    11     8     4     0     4     3     6     2   999     3]
 [  220   119   193   112   179   183    87   123    80   147   159   196   242   217   176   149   132   157   133   318 10610]]

2024-06-06 00:43:33,847 - ==> Best [Top1: 83.747   Top5: 97.569   Sparsity:0.00   Params: 424448 on epoch: 64]
2024-06-06 00:43:33,847 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:43:33,887 - 

2024-06-06 00:43:33,888 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:43:40,931 - Epoch: [65][  100/ 1218]    Overall Loss 0.336134    Objective Loss 0.336134                                        LR 0.001000    Time 0.070397    
2024-06-06 00:43:46,235 - Epoch: [65][  200/ 1218]    Overall Loss 0.339454    Objective Loss 0.339454                                        LR 0.001000    Time 0.061703    
2024-06-06 00:43:51,158 - Epoch: [65][  300/ 1218]    Overall Loss 0.338666    Objective Loss 0.338666                                        LR 0.001000    Time 0.057538    
2024-06-06 00:43:56,368 - Epoch: [65][  400/ 1218]    Overall Loss 0.338797    Objective Loss 0.338797                                        LR 0.001000    Time 0.056172    
2024-06-06 00:44:01,470 - Epoch: [65][  500/ 1218]    Overall Loss 0.341005    Objective Loss 0.341005                                        LR 0.001000    Time 0.055138    
2024-06-06 00:44:06,748 - Epoch: [65][  600/ 1218]    Overall Loss 0.340610    Objective Loss 0.340610                                        LR 0.001000    Time 0.054740    
2024-06-06 00:44:11,641 - Epoch: [65][  700/ 1218]    Overall Loss 0.341370    Objective Loss 0.341370                                        LR 0.001000    Time 0.053907    
2024-06-06 00:44:16,729 - Epoch: [65][  800/ 1218]    Overall Loss 0.341534    Objective Loss 0.341534                                        LR 0.001000    Time 0.053526    
2024-06-06 00:44:21,789 - Epoch: [65][  900/ 1218]    Overall Loss 0.341710    Objective Loss 0.341710                                        LR 0.001000    Time 0.053198    
2024-06-06 00:44:26,684 - Epoch: [65][ 1000/ 1218]    Overall Loss 0.341304    Objective Loss 0.341304                                        LR 0.001000    Time 0.052770    
2024-06-06 00:44:31,794 - Epoch: [65][ 1100/ 1218]    Overall Loss 0.341433    Objective Loss 0.341433                                        LR 0.001000    Time 0.052616    
2024-06-06 00:44:37,128 - Epoch: [65][ 1200/ 1218]    Overall Loss 0.342333    Objective Loss 0.342333                                        LR 0.001000    Time 0.052675    
2024-06-06 00:44:38,095 - Epoch: [65][ 1218/ 1218]    Overall Loss 0.342605    Objective Loss 0.342605    Top1 84.107579    Top5 98.044010    LR 0.001000    Time 0.052690    
2024-06-06 00:44:38,358 - --- validate (epoch=65)-----------
2024-06-06 00:44:38,359 - 34633 samples (256 per mini-batch)
2024-06-06 00:44:44,796 - Epoch: [65][  100/  136]    Loss 0.369464    Top1 83.921875    Top5 97.632812    
2024-06-06 00:44:46,747 - Epoch: [65][  136/  136]    Loss 0.369522    Top1 83.827563    Top5 97.643866    
2024-06-06 00:44:46,935 - ==> Top1: 83.828    Top5: 97.644    Loss: 0.370

2024-06-06 00:44:46,937 - ==> Confusion:
[[  807     1     0     3    23     0     1     1    13    49     1     4     4     4     8     4     0     0     0     0     8]
 [    1   957     1     4    17    23     4     6     3     0     9     4     2     2     6     1     9     1     7     1     5]
 [    9     0   845    15     7     2    26     9     0     4     8     4     4     9     1     8     5     0     2     3     9]
 [    0     2     6   928     1     3     3     2     3     3    13     1     8     2    18     2     3     7     5     0     6]
 [    4     6     0     1   964     6     0     0     4    10     4     3     3     5    12     5     7     0     1     1    18]
 [    0    28     1     9    15   893     5    23     1     4     7     5    11    10     3     1     7     3     3     5     9]
 [    1     1    17     2     0     2  1024     3     0     4     4     1     2     0     0     6     2     4     2     6     5]
 [    2    14    19     6     4    43     5   899     2     3     8     8     6     2     4     1     0     2    25     9    15]
 [   11     2     0     0     1     2     1     1   875    40    12     2     4    10    24     1     3     6     4     0     3]
 [   55     0     0     0     9     3     1     1    55   807     4     1     4    23    26     1     1     2     3     1     4]
 [    0     5     7     9     2     2     6     2    12     1   976     2     1    10    11     0     5     1     7     1     4]
 [    2     0     1     0     1    13     4     3     1     4     1   878    44    10     0    11     3    18     0    11     6]
 [    1     2     0     2     2     5     0     1     2     1     3    68   853     1     2     3     4    23     6     2    14]
 [    2     0     0     3     6    12     4     0    16    12    11    12     3   890     4     4     6     3     1     4     8]
 [    8     3     1     9    12     2     0     0    25     6     4     3     4     2   995     0     2     3    10     0     9]
 [    1     2     3     0     2     1    12     0     1     2     0     8    16     1     1   992    13     6     2     1     2]
 [    4     5     3     1     4     4     2     0     3     1     3     7     0     2     3     6  1005     0     1     5    13]
 [    2     1     0     3     1     2     2     0     1     2     0    11    28     2     3     9     1   922     4     3     8]
 [    2     5     9    13     3     4     7    10     7     2     8     1     5     2    18     0     2     1   949     1     9]
 [    1     6     4     1     1     8    16    12     2     1     0    22    12     1     1     8     6     3     2   968    13]
 [  180   178   144   113   198   156   114   105   118    99   196   160   326   236   219   128   241   107   153   156 10605]]

2024-06-06 00:44:46,940 - ==> Best [Top1: 83.828   Top5: 97.644   Sparsity:0.00   Params: 424448 on epoch: 65]
2024-06-06 00:44:46,940 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:44:46,970 - 

2024-06-06 00:44:46,971 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:44:53,816 - Epoch: [66][  100/ 1218]    Overall Loss 0.334802    Objective Loss 0.334802                                        LR 0.001000    Time 0.068421    
2024-06-06 00:44:58,922 - Epoch: [66][  200/ 1218]    Overall Loss 0.333594    Objective Loss 0.333594                                        LR 0.001000    Time 0.059727    
2024-06-06 00:45:04,113 - Epoch: [66][  300/ 1218]    Overall Loss 0.336724    Objective Loss 0.336724                                        LR 0.001000    Time 0.057113    
2024-06-06 00:45:09,283 - Epoch: [66][  400/ 1218]    Overall Loss 0.338249    Objective Loss 0.338249                                        LR 0.001000    Time 0.055753    
2024-06-06 00:45:14,492 - Epoch: [66][  500/ 1218]    Overall Loss 0.338255    Objective Loss 0.338255                                        LR 0.001000    Time 0.055015    
2024-06-06 00:45:19,677 - Epoch: [66][  600/ 1218]    Overall Loss 0.340962    Objective Loss 0.340962                                        LR 0.001000    Time 0.054484    
2024-06-06 00:45:24,708 - Epoch: [66][  700/ 1218]    Overall Loss 0.342085    Objective Loss 0.342085                                        LR 0.001000    Time 0.053884    
2024-06-06 00:45:29,848 - Epoch: [66][  800/ 1218]    Overall Loss 0.343482    Objective Loss 0.343482                                        LR 0.001000    Time 0.053571    
2024-06-06 00:45:35,143 - Epoch: [66][  900/ 1218]    Overall Loss 0.344675    Objective Loss 0.344675                                        LR 0.001000    Time 0.053499    
2024-06-06 00:45:40,186 - Epoch: [66][ 1000/ 1218]    Overall Loss 0.344518    Objective Loss 0.344518                                        LR 0.001000    Time 0.053189    
2024-06-06 00:45:45,098 - Epoch: [66][ 1100/ 1218]    Overall Loss 0.344852    Objective Loss 0.344852                                        LR 0.001000    Time 0.052818    
2024-06-06 00:45:49,991 - Epoch: [66][ 1200/ 1218]    Overall Loss 0.344714    Objective Loss 0.344714                                        LR 0.001000    Time 0.052491    
2024-06-06 00:45:50,835 - Epoch: [66][ 1218/ 1218]    Overall Loss 0.344689    Objective Loss 0.344689    Top1 81.662592    Top5 95.843521    LR 0.001000    Time 0.052408    
2024-06-06 00:45:51,046 - --- validate (epoch=66)-----------
2024-06-06 00:45:51,046 - 34633 samples (256 per mini-batch)
2024-06-06 00:45:57,282 - Epoch: [66][  100/  136]    Loss 0.381900    Top1 83.570312    Top5 97.636719    
2024-06-06 00:45:59,252 - Epoch: [66][  136/  136]    Loss 0.379712    Top1 83.602345    Top5 97.684290    
2024-06-06 00:45:59,504 - ==> Top1: 83.602    Top5: 97.684    Loss: 0.380

2024-06-06 00:45:59,505 - ==> Confusion:
[[  817     0     2     1    10     2     0     1    11    60     0     1     3     3     2     5     0     3     0     0    10]
 [    5   970     0     0    10    19     3    11     6     1     1     3     3     1     2     1     3     2    12     1     9]
 [    7     1   873    11     0     1     9     8     0     7     2     4     3     4     2     6     6     4     5     4    13]
 [   13     4    17   897     2     2     1     3     1     4     7     0     4     0    19     1     5    13    16     0     7]
 [   28     7     5     0   927    16     0     2     4    19     0     1     2     6     7     4    11     1     3     0    11]
 [    4    38     3     2     7   865     4    39     7     3     1     7     8    28     2     2     1     7     4     7     4]
 [    1     9    36     4     1     3   970     5     1     3     2     2     6     2     0    18     1     2     1    10     9]
 [    2    11    18     2     2    22     0   931     2     3     5     8    11     3     1     1     0     5    32     4    14]
 [   10     1     0     4     0     1     0     1   872    46    14     1     3    14    16     1     1     4     9     0     4]
 [   74     1     4     1     1     2     1     1    47   833     1     2     3    15     7     1     0     4     0     0     3]
 [    1     4    11    10     2     2     1     8    16     4   959     0     2     8     6     2     1     0    19     1     7]
 [    5     3     0     0     1    10     1     2     0     4     0   868    43     4     0    25     5    24     0     8     8]
 [    1     3     3     4     1     2     0     3     2     1     0    52   818     6     1    17     4    53     4     3    17]
 [    2     4     2     2     1     7     0     4    12    16     6     8     6   901     4     4     3     2     2     6     9]
 [   11     4     4    10     5     4     0     3    26     9     4     1     3     4   974     2     2     6    15     0    11]
 [    1     2     3     0     2     0     3     0     1     3     0     5     6     2     0  1009    10    16     1     1     1]
 [    6     8     4     1     2     5     0     3     4     1     2     4     5     2     1    15   985     6     1     2    15]
 [    1     3     1     0     1     2     0     0     2     3     1     8    15     4     2    24     4   928     0     1     5]
 [    1     5     5     8     1     1     0    15     7     1     5     1     1     1    12     1     5     0   982     0     6]
 [    3     7     2     1     0     6    11     6     0     2     0    20    14     7     1    16     9     6     5   961    11]
 [  182   202   165    66   116   163    57   172   112   139   111   140   278   280   198   166   177   168   223   203 10614]]

2024-06-06 00:45:59,509 - ==> Best [Top1: 83.828   Top5: 97.644   Sparsity:0.00   Params: 424448 on epoch: 65]
2024-06-06 00:45:59,509 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:45:59,534 - 

2024-06-06 00:45:59,534 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:46:06,278 - Epoch: [67][  100/ 1218]    Overall Loss 0.344474    Objective Loss 0.344474                                        LR 0.001000    Time 0.067406    
2024-06-06 00:46:11,334 - Epoch: [67][  200/ 1218]    Overall Loss 0.348290    Objective Loss 0.348290                                        LR 0.001000    Time 0.058955    
2024-06-06 00:46:16,321 - Epoch: [67][  300/ 1218]    Overall Loss 0.345458    Objective Loss 0.345458                                        LR 0.001000    Time 0.055919    
2024-06-06 00:46:21,391 - Epoch: [67][  400/ 1218]    Overall Loss 0.342312    Objective Loss 0.342312                                        LR 0.001000    Time 0.054609    
2024-06-06 00:46:26,559 - Epoch: [67][  500/ 1218]    Overall Loss 0.340118    Objective Loss 0.340118                                        LR 0.001000    Time 0.054017    
2024-06-06 00:46:31,883 - Epoch: [67][  600/ 1218]    Overall Loss 0.339764    Objective Loss 0.339764                                        LR 0.001000    Time 0.053884    
2024-06-06 00:46:37,067 - Epoch: [67][  700/ 1218]    Overall Loss 0.338814    Objective Loss 0.338814                                        LR 0.001000    Time 0.053589    
2024-06-06 00:46:42,185 - Epoch: [67][  800/ 1218]    Overall Loss 0.339238    Objective Loss 0.339238                                        LR 0.001000    Time 0.053284    
2024-06-06 00:46:47,239 - Epoch: [67][  900/ 1218]    Overall Loss 0.339988    Objective Loss 0.339988                                        LR 0.001000    Time 0.052977    
2024-06-06 00:46:52,018 - Epoch: [67][ 1000/ 1218]    Overall Loss 0.338737    Objective Loss 0.338737                                        LR 0.001000    Time 0.052455    
2024-06-06 00:46:57,201 - Epoch: [67][ 1100/ 1218]    Overall Loss 0.340664    Objective Loss 0.340664                                        LR 0.001000    Time 0.052396    
2024-06-06 00:47:02,378 - Epoch: [67][ 1200/ 1218]    Overall Loss 0.340643    Objective Loss 0.340643                                        LR 0.001000    Time 0.052342    
2024-06-06 00:47:03,273 - Epoch: [67][ 1218/ 1218]    Overall Loss 0.340769    Objective Loss 0.340769    Top1 84.352078    Top5 96.821516    LR 0.001000    Time 0.052303    
2024-06-06 00:47:03,498 - --- validate (epoch=67)-----------
2024-06-06 00:47:03,498 - 34633 samples (256 per mini-batch)
2024-06-06 00:47:09,964 - Epoch: [67][  100/  136]    Loss 0.364031    Top1 83.226562    Top5 97.476562    
2024-06-06 00:47:11,759 - Epoch: [67][  136/  136]    Loss 0.368832    Top1 82.978662    Top5 97.412872    
2024-06-06 00:47:11,972 - ==> Top1: 82.979    Top5: 97.413    Loss: 0.369

2024-06-06 00:47:11,974 - ==> Confusion:
[[  834     3     5     0     8     4     0     1     7    46     0     2     1     0     8     3     0     2     0     3     4]
 [    0   973     5     2    20    12     1     7     2     1     5     2     5     1     6     0     5     2     9     3     2]
 [    8     1   891     7     3     1    11     7     0     3     1     2     3     4     3     3     4     0     4     6     8]
 [    2     3    13   887     3     3     1     0     2     3    16     3    16     2    28     0     3     7    12     1    11]
 [   18    11     2     0   956     6     0     2     2     9     0     5     2     4    16     5     2     1     0     2    11]
 [    2    42     7     2    21   865     1    27     5     3     3    11     8    15     3     2     5     2     4    11     4]
 [    0     4    43     2     1     3   980     6     0     5     2     5     3     0     0     5     2     5     1    13     6]
 [    0    26    15     0     2    27     1   926     4     4     6     5     3     5     0     0     2     2    30    14     5]
 [   14     6     2     3     3     1     0     0   855    37    12     4     4    19    18     0     6     4     9     3     2]
 [   91     2     1     0     6     1     0     0    37   814     1     1     4    22    10     1     1     4     0     2     3]
 [    1     2    12    12     1     2     4     2    15     1   976     0     1    12     7     1     0     0     7     1     7]
 [    1     4     2     0     0     9     0     4     1     2     0   900    33     9     0     9     1    14     3    16     3]
 [    0     2    12     1     1     4     1     1     0     1     5    56   844     2     0    10     5    26     7     7    10]
 [    6     1     6     0     3     9     0     2    13    24     6    17     6   884     2     2     2     4     0     6     8]
 [    4     2     7     8     9     1     0     0    20     8     7     1     5     4   998     1     2     1    12     1     7]
 [    2     0     5     2     5     0     3     1     0     4     0    23     9     1     1   980     8    15     0     3     4]
 [    2     9     9     1     3     5     0     0     3     3     5     7    10     7     2     7   980     0     3     3    13]
 [    2     2     0     2     0     1     0     1     1     2     0    20    28     4     3     8     0   917     3     4     7]
 [    2    11    10     8     2     2     0    12     4     2     8     1     2     0    18     0     1     0   961     7     7]
 [    0     3     5     0     1     9     7     3     0     1     1    22    12     4     0     5     6     4     6   990     9]
 [  188   296   229    81   202   144    69   118   117   112   175   183   319   251   201   124   240   102   179   275 10327]]

2024-06-06 00:47:11,987 - ==> Best [Top1: 83.828   Top5: 97.644   Sparsity:0.00   Params: 424448 on epoch: 65]
2024-06-06 00:47:11,987 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:47:12,013 - 

2024-06-06 00:47:12,013 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:47:18,788 - Epoch: [68][  100/ 1218]    Overall Loss 0.340248    Objective Loss 0.340248                                        LR 0.001000    Time 0.067711    
2024-06-06 00:47:23,961 - Epoch: [68][  200/ 1218]    Overall Loss 0.340513    Objective Loss 0.340513                                        LR 0.001000    Time 0.059709    
2024-06-06 00:47:29,129 - Epoch: [68][  300/ 1218]    Overall Loss 0.338425    Objective Loss 0.338425                                        LR 0.001000    Time 0.057024    
2024-06-06 00:47:34,266 - Epoch: [68][  400/ 1218]    Overall Loss 0.337664    Objective Loss 0.337664                                        LR 0.001000    Time 0.055604    
2024-06-06 00:47:39,161 - Epoch: [68][  500/ 1218]    Overall Loss 0.338552    Objective Loss 0.338552                                        LR 0.001000    Time 0.054267    
2024-06-06 00:47:44,313 - Epoch: [68][  600/ 1218]    Overall Loss 0.339099    Objective Loss 0.339099                                        LR 0.001000    Time 0.053806    
2024-06-06 00:47:49,565 - Epoch: [68][  700/ 1218]    Overall Loss 0.340224    Objective Loss 0.340224                                        LR 0.001000    Time 0.053619    
2024-06-06 00:47:54,651 - Epoch: [68][  800/ 1218]    Overall Loss 0.340390    Objective Loss 0.340390                                        LR 0.001000    Time 0.053271    
2024-06-06 00:47:59,856 - Epoch: [68][  900/ 1218]    Overall Loss 0.340190    Objective Loss 0.340190                                        LR 0.001000    Time 0.053132    
2024-06-06 00:48:04,809 - Epoch: [68][ 1000/ 1218]    Overall Loss 0.340009    Objective Loss 0.340009                                        LR 0.001000    Time 0.052769    
2024-06-06 00:48:09,855 - Epoch: [68][ 1100/ 1218]    Overall Loss 0.339950    Objective Loss 0.339950                                        LR 0.001000    Time 0.052557    
2024-06-06 00:48:14,868 - Epoch: [68][ 1200/ 1218]    Overall Loss 0.339932    Objective Loss 0.339932                                        LR 0.001000    Time 0.052352    
2024-06-06 00:48:15,744 - Epoch: [68][ 1218/ 1218]    Overall Loss 0.339990    Objective Loss 0.339990    Top1 86.797066    Top5 98.044010    LR 0.001000    Time 0.052298    
2024-06-06 00:48:15,938 - --- validate (epoch=68)-----------
2024-06-06 00:48:15,939 - 34633 samples (256 per mini-batch)
2024-06-06 00:48:21,831 - Epoch: [68][  100/  136]    Loss 0.373315    Top1 83.382812    Top5 97.375000    
2024-06-06 00:48:23,736 - Epoch: [68][  136/  136]    Loss 0.371082    Top1 83.475298    Top5 97.340687    
2024-06-06 00:48:23,923 - ==> Top1: 83.475    Top5: 97.341    Loss: 0.371

2024-06-06 00:48:23,924 - ==> Confusion:
[[  848     0     1     1     9     0     0     2     3    35     0     3     0     4     6     2     3     5     3     1     5]
 [    2   951     1     2    13    15     5    21     1     3     6     3     3     2     7     0     3     3     8     3    11]
 [   11     0   861    20     2     2    22     9     0     4     5     4     2     6     4     2     1     0     3     2    10]
 [    7     1     2   919     2     2     4     2     1     1    10     2     7     4    29     2     1     5    12     0     3]
 [   29     9     4     4   944     4     2     2     1     6     1     5     2     1    17     4     3     0     6     2     8]
 [    5    21     1     5    18   865     9    32     1     2     5    24     4    10     2     6     4     1     5     8    15]
 [    4     3    11     4     2     2  1015     3     0     0     4     3     3     3     0     7     2     3     0     9     8]
 [    6     6     9     2     0    19     6   949     0     3     5    14     8     3     0     1     0     6    22     8    10]
 [   14     4     0     1     1     3     0     1   830    55    14     2     2    19    35     1     1     2    11     0     6]
 [   94     0     3     1     4     2     0     1    43   811     1     1     0    18    15     1     1     2     3     0     0]
 [    1     3     7    20     2     3     4     3    12     1   952     2     2     8    21     1     1     0    13     0     8]
 [    6     3     0     0     2     2     4     6     0     2     0   902    35     5     1    15     1    20     1     2     4]
 [    4     2     1     9     2     1     2     0     1     2     3    58   841     1     4    11     3    35     4     5     6]
 [    7     1     3     2    10     8     0     1    10    10     6    18     9   884     8     5     2     4     1     2    10]
 [   11     2     1    10     3     2     0     2    10     6     8     1     5     5  1010     0     0     1    15     2     4]
 [    8     0     3     0     2     0     8     0     0     2     1    20     5     0     1   992     2    13     1     3     5]
 [    7     5     1     8    11     4     1     1     3     1     5     6     4     3     3    13   963     3     5     7    18]
 [    4     0     2     2     1     1     0     1     1     3     0    19    14     9     3    10     2   922     2     2     7]
 [    7     3     2    14     0     0     0    19     5     0     1     0     2     1    22     0     0     2   973     3     4]
 [    1     5     3     0     0     6    12     9     1     0     2    27     8     4     1     7     5     5     4   976    12]
 [  217   128   129   160   156   132   107   179    92   104   143   206   302   265   271   166   130   153   238   152 10502]]

2024-06-06 00:48:23,930 - ==> Best [Top1: 83.828   Top5: 97.644   Sparsity:0.00   Params: 424448 on epoch: 65]
2024-06-06 00:48:23,931 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:48:23,956 - 

2024-06-06 00:48:23,957 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:48:30,858 - Epoch: [69][  100/ 1218]    Overall Loss 0.337901    Objective Loss 0.337901                                        LR 0.001000    Time 0.068973    
2024-06-06 00:48:35,994 - Epoch: [69][  200/ 1218]    Overall Loss 0.338881    Objective Loss 0.338881                                        LR 0.001000    Time 0.060156    
2024-06-06 00:48:41,039 - Epoch: [69][  300/ 1218]    Overall Loss 0.337093    Objective Loss 0.337093                                        LR 0.001000    Time 0.056911    
2024-06-06 00:48:46,332 - Epoch: [69][  400/ 1218]    Overall Loss 0.338088    Objective Loss 0.338088                                        LR 0.001000    Time 0.055906    
2024-06-06 00:48:51,619 - Epoch: [69][  500/ 1218]    Overall Loss 0.336044    Objective Loss 0.336044                                        LR 0.001000    Time 0.055295    
2024-06-06 00:48:56,839 - Epoch: [69][  600/ 1218]    Overall Loss 0.337864    Objective Loss 0.337864                                        LR 0.001000    Time 0.054775    
2024-06-06 00:49:01,945 - Epoch: [69][  700/ 1218]    Overall Loss 0.337483    Objective Loss 0.337483                                        LR 0.001000    Time 0.054241    
2024-06-06 00:49:06,981 - Epoch: [69][  800/ 1218]    Overall Loss 0.337529    Objective Loss 0.337529                                        LR 0.001000    Time 0.053752    
2024-06-06 00:49:12,016 - Epoch: [69][  900/ 1218]    Overall Loss 0.336723    Objective Loss 0.336723                                        LR 0.001000    Time 0.053371    
2024-06-06 00:49:16,976 - Epoch: [69][ 1000/ 1218]    Overall Loss 0.336911    Objective Loss 0.336911                                        LR 0.001000    Time 0.052991    
2024-06-06 00:49:22,035 - Epoch: [69][ 1100/ 1218]    Overall Loss 0.337443    Objective Loss 0.337443                                        LR 0.001000    Time 0.052771    
2024-06-06 00:49:27,265 - Epoch: [69][ 1200/ 1218]    Overall Loss 0.337571    Objective Loss 0.337571                                        LR 0.001000    Time 0.052729    
2024-06-06 00:49:28,066 - Epoch: [69][ 1218/ 1218]    Overall Loss 0.337408    Objective Loss 0.337408    Top1 85.330073    Top5 97.555012    LR 0.001000    Time 0.052607    
2024-06-06 00:49:28,299 - --- validate (epoch=69)-----------
2024-06-06 00:49:28,299 - 34633 samples (256 per mini-batch)
2024-06-06 00:49:34,313 - Epoch: [69][  100/  136]    Loss 0.364898    Top1 82.753906    Top5 97.445312    
2024-06-06 00:49:36,284 - Epoch: [69][  136/  136]    Loss 0.366216    Top1 82.594635    Top5 97.438859    
2024-06-06 00:49:36,516 - ==> Top1: 82.595    Top5: 97.439    Loss: 0.366

2024-06-06 00:49:36,517 - ==> Confusion:
[[  830     0     4     0     7     1     2     0     6    60     0     0     4     4     3     1     2     1     1     0     5]
 [    1   949     4     3    15    23     1    18     5     2     4     0     6     2     9     1     4     3     7     1     5]
 [    8     3   860    11     1     4    30     8     1     8     7     1     5     4     3     3     1     0     1     3     8]
 [    6     2     6   913     0     9     2     3     1     1    13     2    12     5    24     2     2     3     7     1     2]
 [   26    14     4     1   927    20     1     2     1    13     1     2     5     8     8     3     7     0     2     1     8]
 [    3    26     3     4    12   890     3    33     4     3     3    12    11    17     1     1     5     1     1     7     3]
 [    3     7    18     2     1     6  1001     7     3     4     3     3     2     0     0     8     1     3     2     8     4]
 [    3    14     9     2     1    33     4   944     0     1     3     3     8     4     1     0     0     1    33     9     4]
 [   18     4     2     0     0     4     0     1   883    38    10     3     4     5    17     0     0     2     5     2     4]
 [   74     1     1     0     4     1     0     0    42   842     0     1     2    21     3     1     2     1     2     1     2]
 [    1     3     8    12     0     1     6     8    12     4   970     1     3     8    10     0     2     0     9     3     3]
 [    6     2     1     0     1    16     2     3     0     3     0   867    46    10     0    10     4    14     2    22     2]
 [    2     0     3     4     1     5     2     2     3     0     1    52   875     2     1     7     3    14     1     8     9]
 [    1     1     0     0     3    20     0     3    15    14     7     5     8   899     7     2     4     4     1     4     3]
 [   13     1     4    20     4     0     1     1    30     4     6     3     5     5   979     1     0     1    14     1     5]
 [    5     2     4     0     2     1     6     1     1     4     0    12    13     3     0   976    17    11     0     1     7]
 [    5     9     8     4     2     9     0     3     3     1     4     4     9     2     1    10   972     1     2    10    13]
 [    1     2     2     1     0     1     1     2     0     3     0    15    35     6     5    18     0   902     1     6     4]
 [    3     4     4    16     1     1     1    20     8     0     5     2     3     2    13     0     0     1   967     4     3]
 [    2     4     1     0     0    15    13     5     1     0     0    14     9     6     0     8     4     3     2   997     4]
 [  234   177   232   154   152   207   140   147   125   131   164   123   400   243   240   108   207    91   235   260 10162]]

2024-06-06 00:49:36,523 - ==> Best [Top1: 83.828   Top5: 97.644   Sparsity:0.00   Params: 424448 on epoch: 65]
2024-06-06 00:49:36,523 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:49:36,548 - 

2024-06-06 00:49:36,548 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:49:43,222 - Epoch: [70][  100/ 1218]    Overall Loss 0.338235    Objective Loss 0.338235                                        LR 0.001000    Time 0.066710    
2024-06-06 00:49:48,371 - Epoch: [70][  200/ 1218]    Overall Loss 0.325903    Objective Loss 0.325903                                        LR 0.001000    Time 0.059083    
2024-06-06 00:49:53,544 - Epoch: [70][  300/ 1218]    Overall Loss 0.328177    Objective Loss 0.328177                                        LR 0.001000    Time 0.056626    
2024-06-06 00:49:58,760 - Epoch: [70][  400/ 1218]    Overall Loss 0.327959    Objective Loss 0.327959                                        LR 0.001000    Time 0.055501    
2024-06-06 00:50:04,099 - Epoch: [70][  500/ 1218]    Overall Loss 0.330879    Objective Loss 0.330879                                        LR 0.001000    Time 0.055075    
2024-06-06 00:50:09,112 - Epoch: [70][  600/ 1218]    Overall Loss 0.330442    Objective Loss 0.330442                                        LR 0.001000    Time 0.054246    
2024-06-06 00:50:14,183 - Epoch: [70][  700/ 1218]    Overall Loss 0.333876    Objective Loss 0.333876                                        LR 0.001000    Time 0.053736    
2024-06-06 00:50:19,280 - Epoch: [70][  800/ 1218]    Overall Loss 0.334049    Objective Loss 0.334049                                        LR 0.001000    Time 0.053388    
2024-06-06 00:50:24,316 - Epoch: [70][  900/ 1218]    Overall Loss 0.334796    Objective Loss 0.334796                                        LR 0.001000    Time 0.053049    
2024-06-06 00:50:28,959 - Epoch: [70][ 1000/ 1218]    Overall Loss 0.336770    Objective Loss 0.336770                                        LR 0.001000    Time 0.052385    
2024-06-06 00:50:33,633 - Epoch: [70][ 1100/ 1218]    Overall Loss 0.336804    Objective Loss 0.336804                                        LR 0.001000    Time 0.051870    
2024-06-06 00:50:38,524 - Epoch: [70][ 1200/ 1218]    Overall Loss 0.337221    Objective Loss 0.337221                                        LR 0.001000    Time 0.051620    
2024-06-06 00:50:39,299 - Epoch: [70][ 1218/ 1218]    Overall Loss 0.336934    Objective Loss 0.336934    Top1 82.640587    Top5 98.288509    LR 0.001000    Time 0.051493    
2024-06-06 00:50:39,474 - --- validate (epoch=70)-----------
2024-06-06 00:50:39,474 - 34633 samples (256 per mini-batch)
2024-06-06 00:50:44,903 - Epoch: [70][  100/  136]    Loss 0.365685    Top1 83.394531    Top5 97.453125    
2024-06-06 00:50:46,578 - Epoch: [70][  136/  136]    Loss 0.363707    Top1 83.417550    Top5 97.493720    
2024-06-06 00:50:46,742 - ==> Top1: 83.418    Top5: 97.494    Loss: 0.364

2024-06-06 00:50:46,743 - ==> Confusion:
[[  831     1     2     1     5     1     0     0    14    56     1     2     0     3     4     1     3     1     0     0     5]
 [    6   940     3     2    17     9     2    18     9     2    10     3     3     2     7     1     7     3     9     2     8]
 [    7     0   884     5     0     1    19     3     1     5    12     3     3     5     2     3     3     1     4     4     5]
 [    5     3    11   897     0     6     5     0     2     5    19     3     2     3    25     1     3     9     9     2     6]
 [   28    20     4     0   929     8     0     1     0    15     2     1     1     7    19     2     7     2     3     1     4]
 [    7    33     2     1    11   844     5    47     6     9     5     8     1    32     5     1     6     1     7     6     6]
 [    7     3    24     0     2     2  1005     5     1     3     8     2     1     0     0     7     3     4     1     8     0]
 [    5     7    11     4     0    23     8   928     8     3     7    12     4     8     0     1     1     2    25    13     7]
 [    9     3     1     0     0     3     0     2   875    35    13     3     3    15    24     0     3     2    10     0     1]
 [   61     0     1     0     5     2     0     2    53   827     0     3     0    25     6     1     1     5     1     0     8]
 [    1     2     5     4     1     2     0     3    18     2   986     0     0     6    15     0     2     0    11     3     3]
 [    5     1     3     0     1    10     3     5     2     3     1   880    27    18     0     9     5    18     2    14     4]
 [    4     0     3     4     0     5     1     0     2     0     6    70   832     2     2     7     5    31     9     4     8]
 [    7     1     2     1     1     6     0     1    12     6    10     9     7   916     6     0     4     0     0     3     9]
 [    8     3     3    10     4     0     0     0    21     6     7     2     2     3  1000     1     2     1    14     2     9]
 [    7     0     4     0     3     0     6     0     0     2     0    18     9     0     0   992     7    10     0     3     5]
 [    5    11     4     0     7     2     0     0     7     1     3     6     2     1     4     9   984     1     6     7    12]
 [    6     1     0     4     0     3     0     0     4     1     0    13    26     4     2     6     0   927     3     0     5]
 [    7     4     6     8     1     2     0    14     7     0     6     0     2     1    13     0     1     0   976     1     9]
 [    6     5     5     1     2     8    11     3     0     0     1    14     5     6     0     7     5     6     5   992     6]
 [  188   209   206    99   167   113   125   138   134   109   182   155   326   294   197   134   175   104   188   244 10445]]

2024-06-06 00:50:46,745 - ==> Best [Top1: 83.828   Top5: 97.644   Sparsity:0.00   Params: 424448 on epoch: 65]
2024-06-06 00:50:46,745 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:50:46,764 - 

2024-06-06 00:50:46,764 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:50:53,157 - Epoch: [71][  100/ 1218]    Overall Loss 0.334040    Objective Loss 0.334040                                        LR 0.001000    Time 0.063907    
2024-06-06 00:50:57,884 - Epoch: [71][  200/ 1218]    Overall Loss 0.336860    Objective Loss 0.336860                                        LR 0.001000    Time 0.055575    
2024-06-06 00:51:02,720 - Epoch: [71][  300/ 1218]    Overall Loss 0.334999    Objective Loss 0.334999                                        LR 0.001000    Time 0.053164    
2024-06-06 00:51:07,454 - Epoch: [71][  400/ 1218]    Overall Loss 0.333047    Objective Loss 0.333047                                        LR 0.001000    Time 0.051702    
2024-06-06 00:51:12,051 - Epoch: [71][  500/ 1218]    Overall Loss 0.334292    Objective Loss 0.334292                                        LR 0.001000    Time 0.050551    
2024-06-06 00:51:17,085 - Epoch: [71][  600/ 1218]    Overall Loss 0.335336    Objective Loss 0.335336                                        LR 0.001000    Time 0.050512    
2024-06-06 00:51:21,790 - Epoch: [71][  700/ 1218]    Overall Loss 0.335585    Objective Loss 0.335585                                        LR 0.001000    Time 0.050014    
2024-06-06 00:51:26,535 - Epoch: [71][  800/ 1218]    Overall Loss 0.335264    Objective Loss 0.335264                                        LR 0.001000    Time 0.049692    
2024-06-06 00:51:31,128 - Epoch: [71][  900/ 1218]    Overall Loss 0.335499    Objective Loss 0.335499                                        LR 0.001000    Time 0.049272    
2024-06-06 00:51:35,723 - Epoch: [71][ 1000/ 1218]    Overall Loss 0.336213    Objective Loss 0.336213                                        LR 0.001000    Time 0.048937    
2024-06-06 00:51:40,501 - Epoch: [71][ 1100/ 1218]    Overall Loss 0.335718    Objective Loss 0.335718                                        LR 0.001000    Time 0.048830    
2024-06-06 00:51:45,291 - Epoch: [71][ 1200/ 1218]    Overall Loss 0.335997    Objective Loss 0.335997                                        LR 0.001000    Time 0.048751    
2024-06-06 00:51:46,068 - Epoch: [71][ 1218/ 1218]    Overall Loss 0.336203    Objective Loss 0.336203    Top1 84.596577    Top5 97.799511    LR 0.001000    Time 0.048668    
2024-06-06 00:51:46,236 - --- validate (epoch=71)-----------
2024-06-06 00:51:46,237 - 34633 samples (256 per mini-batch)
2024-06-06 00:51:51,773 - Epoch: [71][  100/  136]    Loss 0.380052    Top1 83.070312    Top5 97.328125    
2024-06-06 00:51:53,520 - Epoch: [71][  136/  136]    Loss 0.380554    Top1 83.235642    Top5 97.300263    
2024-06-06 00:51:53,685 - ==> Top1: 83.236    Top5: 97.300    Loss: 0.381

2024-06-06 00:51:53,686 - ==> Confusion:
[[  757     4     3     0    26     1     1     0     8    91     6     0     3     3    14     0     2     2     2     0     8]
 [    0   973     1     2    11    11     3     9     2     3     6     1     5     0    11     1     3     0    13     1     7]
 [    2     5   876     2     5     1    20     5     2    12    12     0     3     1     5     2     7     1     1     0     8]
 [    2     4    19   904     2     2     1     0     4     6    26     1     5     1    16     2     3     5     4     3     6]
 [   11    22     2     2   947     8     0     1     0    14     4     1     0     6    13     4     7     0     3     0     9]
 [    4    44     6    10    11   838     5    39     1     9    12    11     8    19     5     1     3     2     1     6     8]
 [    0     6    23     1     1     1  1011     4     0     6     8     6     0     0     0     5     4     1     1     3     5]
 [    0    20    16     3     3    20     4   935     2     7    11     2     7     7     4     2     4     0    25     2     3]
 [    8     4     1     0     0     1     0     2   858    40    33     1     4     9    26     1     3     2     2     2     5]
 [   28     1     3     0    12     0     0     1    54   842    10     0     2    16    26     0     2     1     0     1     2]
 [    2     3     2     5     0     1     5     3     2     4  1006     1     2     5     4     0     3     0    11     2     3]
 [    2     5     3     2     0     7     4     6     3     6     4   839    50    13     1    18     6    18     2    16     6]
 [    1     2     1     3     2     1     1     3     2     5     6    42   871     4     3     7     6    25     2     3     5]
 [    1     4     5     1     4     4     1     2    13    15    30     3     6   878    12     1     2     4     1     1    13]
 [    2     3     3    12     7     1     1     0    17     4    16     0     3     4  1010     0     0     0    10     1     4]
 [    2     1     4     0     3     0     5     0     1     7     1     8    13     3     0   994     5    14     1     0     4]
 [    6    18     4     1     5     2     3     2     4     3     5     3     3     2     1     9   981     1     0     4    15]
 [    1     4     1     4     0     2     3     1     2     6     2    10    25     3     5     9     1   919     1     2     4]
 [    1    10    10    16     1     1     1    24     4     3    11     0     1     1    21     1     1     0   942     1     8]
 [    1    10     5     1     1     4    21    10     1     3     5    14     6     9     0    10     9     2     4   962    10]
 [  149   270   212    91   129   105   109   127    97   137   286   123   356   231   271   129   210   111   161   144 10484]]

2024-06-06 00:51:53,689 - ==> Best [Top1: 83.828   Top5: 97.644   Sparsity:0.00   Params: 424448 on epoch: 65]
2024-06-06 00:51:53,689 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:51:53,713 - 

2024-06-06 00:51:53,713 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:51:59,960 - Epoch: [72][  100/ 1218]    Overall Loss 0.339595    Objective Loss 0.339595                                        LR 0.001000    Time 0.062444    
2024-06-06 00:52:04,769 - Epoch: [72][  200/ 1218]    Overall Loss 0.334714    Objective Loss 0.334714                                        LR 0.001000    Time 0.055260    
2024-06-06 00:52:09,461 - Epoch: [72][  300/ 1218]    Overall Loss 0.335219    Objective Loss 0.335219                                        LR 0.001000    Time 0.052472    
2024-06-06 00:52:14,131 - Epoch: [72][  400/ 1218]    Overall Loss 0.336020    Objective Loss 0.336020                                        LR 0.001000    Time 0.051024    
2024-06-06 00:52:18,935 - Epoch: [72][  500/ 1218]    Overall Loss 0.334978    Objective Loss 0.334978                                        LR 0.001000    Time 0.050422    
2024-06-06 00:52:23,621 - Epoch: [72][  600/ 1218]    Overall Loss 0.335819    Objective Loss 0.335819                                        LR 0.001000    Time 0.049827    
2024-06-06 00:52:28,235 - Epoch: [72][  700/ 1218]    Overall Loss 0.334591    Objective Loss 0.334591                                        LR 0.001000    Time 0.049297    
2024-06-06 00:52:32,841 - Epoch: [72][  800/ 1218]    Overall Loss 0.333887    Objective Loss 0.333887                                        LR 0.001000    Time 0.048890    
2024-06-06 00:52:37,442 - Epoch: [72][  900/ 1218]    Overall Loss 0.335667    Objective Loss 0.335667                                        LR 0.001000    Time 0.048568    
2024-06-06 00:52:42,138 - Epoch: [72][ 1000/ 1218]    Overall Loss 0.335779    Objective Loss 0.335779                                        LR 0.001000    Time 0.048405    
2024-06-06 00:52:47,040 - Epoch: [72][ 1100/ 1218]    Overall Loss 0.335648    Objective Loss 0.335648                                        LR 0.001000    Time 0.048459    
2024-06-06 00:52:52,311 - Epoch: [72][ 1200/ 1218]    Overall Loss 0.336959    Objective Loss 0.336959                                        LR 0.001000    Time 0.048811    
2024-06-06 00:52:53,099 - Epoch: [72][ 1218/ 1218]    Overall Loss 0.336790    Objective Loss 0.336790    Top1 88.019560    Top5 96.821516    LR 0.001000    Time 0.048737    
2024-06-06 00:52:53,278 - --- validate (epoch=72)-----------
2024-06-06 00:52:53,278 - 34633 samples (256 per mini-batch)
2024-06-06 00:52:58,808 - Epoch: [72][  100/  136]    Loss 0.360096    Top1 83.753906    Top5 97.292969    
2024-06-06 00:53:00,465 - Epoch: [72][  136/  136]    Loss 0.361741    Top1 83.885312    Top5 97.300263    
2024-06-06 00:53:00,680 - ==> Top1: 83.885    Top5: 97.300    Loss: 0.362

2024-06-06 00:53:00,681 - ==> Confusion:
[[  790     0     3     1    17     1     0     2     5    92     3     1     1     1     4     0     1     0     1     1     7]
 [    2   936     3     1    20    28     3    15     6     4     7     6     3     1     5     1     2     1     8     1    10]
 [    8     1   869     4     3     0    16     8     0     8    15     2     2     1     4     2     4     1     5     4    13]
 [    4     2    13   909     2     6     1     4     2     5    12     1     4     2    25     1     0     5    10     1     7]
 [   18    12     1     0   963    15     0     3     1    17     2     3     2     5     3     0     2     1     0     0     6]
 [    1    10     2     1    10   913     4    30     3     7     5    10     9    10     3     0     7     0     5     7     6]
 [    2     2    18     2     2     5  1017     3     1     4     5     7     1     0     0     3     3     0     3     4     4]
 [    1     8    11     1     2    30     6   934     0     5    10     7     2     4     1     0     2     2    34    11     6]
 [    8     2     3     3     2     2     0     6   834    80    17     4     4    14    11     0     6     0     4     0     2]
 [   47     1     1     0     8     2     2     1    23   882     1     0     0    17     7     0     1     2     2     1     3]
 [    1     1     2     4     0     5     3     3    13     3   998     1     0     7     9     0     0     0     7     0     7]
 [    1     0     2     1     3    10     2     5     2     7     2   910    23     3     0    10     3    10     1    13     3]
 [    0     1     8     7     0     6     0     2     0     1     6    68   832     6     2     3     1    36     5     3     8]
 [    4     0     2     3     8    21     0     2    10    18    20    14     2   871     3     2     3     4     0     8     6]
 [   13     1     2    13    15     1     0     0    28    14     4     0     1    11   969     0     1     3    10     1    11]
 [    1     1     6     0     6     0     7     1     0     4     0    15    20     5     0   968    13    11     0     0     8]
 [    2     5     3     1    13     7     1     0     3     3    10     6     5     2     3     8   982     0     1     2    15]
 [    3     0     0     3     3     1     0     1     2     2     2    13    14     3     1     5     2   943     3     0     4]
 [    2     3     5     9     6     5     0    15     6     2     7     4     2     0    17     0     0     1   964     3     7]
 [    3     2     4     0     2    10    19     9     0     2     4    14     6     4     0     5     2     1     5   985    11]
 [  178   142   223   102   209   210    82   140   101   177   202   166   281   238   172   100   189   100   154   183 10583]]

2024-06-06 00:53:00,684 - ==> Best [Top1: 83.885   Top5: 97.300   Sparsity:0.00   Params: 424448 on epoch: 72]
2024-06-06 00:53:00,684 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:53:00,717 - 

2024-06-06 00:53:00,717 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:53:07,278 - Epoch: [73][  100/ 1218]    Overall Loss 0.327117    Objective Loss 0.327117                                        LR 0.001000    Time 0.065581    
2024-06-06 00:53:12,082 - Epoch: [73][  200/ 1218]    Overall Loss 0.329773    Objective Loss 0.329773                                        LR 0.001000    Time 0.056800    
2024-06-06 00:53:16,621 - Epoch: [73][  300/ 1218]    Overall Loss 0.332272    Objective Loss 0.332272                                        LR 0.001000    Time 0.052991    
2024-06-06 00:53:21,260 - Epoch: [73][  400/ 1218]    Overall Loss 0.337944    Objective Loss 0.337944                                        LR 0.001000    Time 0.051336    
2024-06-06 00:53:26,099 - Epoch: [73][  500/ 1218]    Overall Loss 0.336747    Objective Loss 0.336747                                        LR 0.001000    Time 0.050742    
2024-06-06 00:53:30,931 - Epoch: [73][  600/ 1218]    Overall Loss 0.334919    Objective Loss 0.334919                                        LR 0.001000    Time 0.050335    
2024-06-06 00:53:35,541 - Epoch: [73][  700/ 1218]    Overall Loss 0.335272    Objective Loss 0.335272                                        LR 0.001000    Time 0.049728    
2024-06-06 00:53:40,261 - Epoch: [73][  800/ 1218]    Overall Loss 0.336193    Objective Loss 0.336193                                        LR 0.001000    Time 0.049409    
2024-06-06 00:53:44,933 - Epoch: [73][  900/ 1218]    Overall Loss 0.335858    Objective Loss 0.335858                                        LR 0.001000    Time 0.049108    
2024-06-06 00:53:49,529 - Epoch: [73][ 1000/ 1218]    Overall Loss 0.336405    Objective Loss 0.336405                                        LR 0.001000    Time 0.048791    
2024-06-06 00:53:54,238 - Epoch: [73][ 1100/ 1218]    Overall Loss 0.335934    Objective Loss 0.335934                                        LR 0.001000    Time 0.048635    
2024-06-06 00:53:59,072 - Epoch: [73][ 1200/ 1218]    Overall Loss 0.335507    Objective Loss 0.335507                                        LR 0.001000    Time 0.048608    
2024-06-06 00:53:59,860 - Epoch: [73][ 1218/ 1218]    Overall Loss 0.335930    Objective Loss 0.335930    Top1 83.129584    Top5 96.577017    LR 0.001000    Time 0.048536    
2024-06-06 00:54:00,036 - --- validate (epoch=73)-----------
2024-06-06 00:54:00,036 - 34633 samples (256 per mini-batch)
2024-06-06 00:54:05,540 - Epoch: [73][  100/  136]    Loss 0.372216    Top1 82.746094    Top5 97.480469    
2024-06-06 00:54:07,239 - Epoch: [73][  136/  136]    Loss 0.376143    Top1 82.767880    Top5 97.453296    
2024-06-06 00:54:07,392 - ==> Top1: 82.768    Top5: 97.453    Loss: 0.376

2024-06-06 00:54:07,394 - ==> Confusion:
[[  833     1     0     0     5     9     0     3     6    50     1     3     0     2     8     2     0     4     0     1     3]
 [    1   894     2     1    15    50     8    35     6     0     3     6     1     3     7     1     4     1    12     4     9]
 [    5     0   900     7     2     3     9     8     0     5     3     7     3     3     1     3     0     3     2     2     4]
 [    2     0    22   900     2     9     3     5     1     2     9     4     4     2    23     1     0     7    10     2     8]
 [   30     6     7     1   944     9     0     3     0    12     0     3     0     4    17     6     2     2     0     1     7]
 [    3     7     5     3    11   906    10    37     4     5     2    17     2    13     2     2     1     5     1     4     3]
 [    0     1    42     0     0     7   986     5     1     5     1     7     0     2     0    12     1     2     3     5     6]
 [    2     5    19     4     0    25     3   961     0     2     3    13     5     1     0     0     1     1    16     9     7]
 [    6     2     2     0     0     6     1     3   828    78    10     2     2    24    20     0     2     3     5     1     7]
 [   75     0     2     1     4     4     0     1    20   850     0     3     2    19     5     4     0     5     1     1     4]
 [    1     1    14    15     1     2     6    12     9     1   957     5     0    10    12     0     0     0    11     2     5]
 [    2     0     2     0     1    10     4     7     1     1     0   909    21    13     0    16     1     7     0    11     5]
 [    4     1     4     3     2     9     2     2     1     1     2    69   832     2     0     9     3    31     2     5    11]
 [    1     0     4     0     4    23     0     5     6    15    10    11     6   891     7     3     2     1     0     3     9]
 [    5     1     3     9     8     1     1     2    21     6     6     6     4     6   995     0     1     3    13     2     5]
 [    1     0     1     1     3     2     8     0     0     5     0    19     9     3     0   994     3     9     2     3     3]
 [    7     6     5     0     7    10     2     0     4     1     2     8     5     3     4    18   960     2     3     6    19]
 [    3     0     2     3     1     4     2     2     1     4     0     9    28     3     0    22     0   916     2     1     2]
 [    1     2     8     4     0     2     1    41     9     0     1     5     2     1    18     0     1     0   956     2     4]
 [    0     0     5     2     2    12    10    10     0     1     1    22     7     5     0     8     5     4     3   979    12]
 [  215    99   350   111   200   249    90   255    88   148   123   230   265   252   201   182   101   115   176   208 10274]]

2024-06-06 00:54:07,396 - ==> Best [Top1: 83.885   Top5: 97.300   Sparsity:0.00   Params: 424448 on epoch: 72]
2024-06-06 00:54:07,396 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:54:07,421 - 

2024-06-06 00:54:07,421 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:54:13,660 - Epoch: [74][  100/ 1218]    Overall Loss 0.326137    Objective Loss 0.326137                                        LR 0.001000    Time 0.062362    
2024-06-06 00:54:18,298 - Epoch: [74][  200/ 1218]    Overall Loss 0.325869    Objective Loss 0.325869                                        LR 0.001000    Time 0.054356    
2024-06-06 00:54:22,965 - Epoch: [74][  300/ 1218]    Overall Loss 0.327314    Objective Loss 0.327314                                        LR 0.001000    Time 0.051789    
2024-06-06 00:54:27,692 - Epoch: [74][  400/ 1218]    Overall Loss 0.328460    Objective Loss 0.328460                                        LR 0.001000    Time 0.050653    
2024-06-06 00:54:32,298 - Epoch: [74][  500/ 1218]    Overall Loss 0.330568    Objective Loss 0.330568                                        LR 0.001000    Time 0.049731    
2024-06-06 00:54:36,982 - Epoch: [74][  600/ 1218]    Overall Loss 0.330066    Objective Loss 0.330066                                        LR 0.001000    Time 0.049245    
2024-06-06 00:54:41,573 - Epoch: [74][  700/ 1218]    Overall Loss 0.330174    Objective Loss 0.330174                                        LR 0.001000    Time 0.048766    
2024-06-06 00:54:46,187 - Epoch: [74][  800/ 1218]    Overall Loss 0.329553    Objective Loss 0.329553                                        LR 0.001000    Time 0.048435    
2024-06-06 00:54:51,065 - Epoch: [74][  900/ 1218]    Overall Loss 0.331070    Objective Loss 0.331070                                        LR 0.001000    Time 0.048471    
2024-06-06 00:54:55,631 - Epoch: [74][ 1000/ 1218]    Overall Loss 0.330450    Objective Loss 0.330450                                        LR 0.001000    Time 0.048188    
2024-06-06 00:55:00,226 - Epoch: [74][ 1100/ 1218]    Overall Loss 0.330897    Objective Loss 0.330897                                        LR 0.001000    Time 0.047982    
2024-06-06 00:55:04,989 - Epoch: [74][ 1200/ 1218]    Overall Loss 0.331173    Objective Loss 0.331173                                        LR 0.001000    Time 0.047951    
2024-06-06 00:55:05,850 - Epoch: [74][ 1218/ 1218]    Overall Loss 0.331023    Objective Loss 0.331023    Top1 86.797066    Top5 97.310513    LR 0.001000    Time 0.047949    
2024-06-06 00:55:06,016 - --- validate (epoch=74)-----------
2024-06-06 00:55:06,016 - 34633 samples (256 per mini-batch)
2024-06-06 00:55:11,413 - Epoch: [74][  100/  136]    Loss 0.357540    Top1 83.566406    Top5 97.398438    
2024-06-06 00:55:13,108 - Epoch: [74][  136/  136]    Loss 0.358512    Top1 83.590795    Top5 97.424422    
2024-06-06 00:55:13,276 - ==> Top1: 83.591    Top5: 97.424    Loss: 0.359

2024-06-06 00:55:13,278 - ==> Confusion:
[[  823     1     3     0    19     5     0     2     5    51     0     3     0     1     4     0     3     1     0     6     4]
 [    0   962     2     2     6    27     2     7     4     3     6     4     3     0     4     1     1     2    13     7     7]
 [    3     3   870     9     3     1    34     7     0     5     3     4     1     1     1     3     3     1     3     4    11]
 [    1     2    15   902     1     9     4     4     0     2    17     0     8     3    17     1     2     6     9     5     8]
 [    8     8     1     2   975    15     1     1     1     9     0     3     0     6     4     3     5     2     2     2     6]
 [    1    27     5     2    13   888     5    19     3     6     3    12     6    20     3     3     6     2     2     7    10]
 [    0     3    11     2     3     6  1020     3     1     3     5     4     1     3     0     4     1     0     1    12     3]
 [    2    14    16     0     1    33     4   914     2     1     2     8     5     2     1     0     3     4    32    27     6]
 [   14     0     2     1     0     2     0     1   837    68    11     4     4    18    17     0     3     1     8     5     6]
 [   53     1     4     0     8     3     0     1    29   871     1     4     0    12     2     0     1     2     0     4     5]
 [    0     2     4     7     1     2     5     6    13     0   975     2     2     9     9     1     1     0    12     4     9]
 [    1     1     1     1     3    17     2     2     0     1     0   915    16    16     0     9     0     9     0    16     1]
 [    0     0     1     2     1     5     0     3     1     0     2    94   820     9     1     5     1    22     3    13    12]
 [    1     1     1     1     3    17     0     1     9    11     7    14     1   906     7     2     4     1     2     3     9]
 [    6     6     2    15    12     5     0     1    23    13     1     4     2     3   968     0     2     2    17     2    14]
 [    1     3     2     1     3     2    13     1     0     1     0    17     7     2     1   985     7     9     1     9     1]
 [    4    10     1     4     4     3     4     0     6     1     2    12     1     4     1     4   986     2     1    10    12]
 [    4     2     1     2     2     3     1     1     1     2     0    24    17     4     1     7     1   923     2     4     3]
 [    3     6     4     7     2     0     2    13     1     0     8     6     1     3    14     0     0     0   976     5     7]
 [    0     5     2     0     1     9    11     2     1     0     0    28     3     3     0     4     2     2     4  1005     6]
 [  167   213   164   105   184   212   126   119    87   113   179   265   263   266   172    99   184    96   184   305 10429]]

2024-06-06 00:55:13,281 - ==> Best [Top1: 83.885   Top5: 97.300   Sparsity:0.00   Params: 424448 on epoch: 72]
2024-06-06 00:55:13,281 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:55:13,310 - 

2024-06-06 00:55:13,310 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:55:19,440 - Epoch: [75][  100/ 1218]    Overall Loss 0.323396    Objective Loss 0.323396                                        LR 0.001000    Time 0.061260    
2024-06-06 00:55:24,008 - Epoch: [75][  200/ 1218]    Overall Loss 0.332853    Objective Loss 0.332853                                        LR 0.001000    Time 0.053461    
2024-06-06 00:55:28,752 - Epoch: [75][  300/ 1218]    Overall Loss 0.332957    Objective Loss 0.332957                                        LR 0.001000    Time 0.051447    
2024-06-06 00:55:33,499 - Epoch: [75][  400/ 1218]    Overall Loss 0.333621    Objective Loss 0.333621                                        LR 0.001000    Time 0.050447    
2024-06-06 00:55:38,206 - Epoch: [75][  500/ 1218]    Overall Loss 0.332674    Objective Loss 0.332674                                        LR 0.001000    Time 0.049767    
2024-06-06 00:55:42,811 - Epoch: [75][  600/ 1218]    Overall Loss 0.333044    Objective Loss 0.333044                                        LR 0.001000    Time 0.049145    
2024-06-06 00:55:47,552 - Epoch: [75][  700/ 1218]    Overall Loss 0.333897    Objective Loss 0.333897                                        LR 0.001000    Time 0.048893    
2024-06-06 00:55:52,173 - Epoch: [75][  800/ 1218]    Overall Loss 0.333270    Objective Loss 0.333270                                        LR 0.001000    Time 0.048555    
2024-06-06 00:55:56,886 - Epoch: [75][  900/ 1218]    Overall Loss 0.332779    Objective Loss 0.332779                                        LR 0.001000    Time 0.048395    
2024-06-06 00:56:01,737 - Epoch: [75][ 1000/ 1218]    Overall Loss 0.334332    Objective Loss 0.334332                                        LR 0.001000    Time 0.048405    
2024-06-06 00:56:06,844 - Epoch: [75][ 1100/ 1218]    Overall Loss 0.333879    Objective Loss 0.333879                                        LR 0.001000    Time 0.048645    
2024-06-06 00:56:11,579 - Epoch: [75][ 1200/ 1218]    Overall Loss 0.333061    Objective Loss 0.333061                                        LR 0.001000    Time 0.048535    
2024-06-06 00:56:12,353 - Epoch: [75][ 1218/ 1218]    Overall Loss 0.332880    Objective Loss 0.332880    Top1 84.841076    Top5 98.288509    LR 0.001000    Time 0.048453    
2024-06-06 00:56:12,529 - --- validate (epoch=75)-----------
2024-06-06 00:56:12,529 - 34633 samples (256 per mini-batch)
2024-06-06 00:56:18,081 - Epoch: [75][  100/  136]    Loss 0.368715    Top1 83.960938    Top5 97.441406    
2024-06-06 00:56:19,816 - Epoch: [75][  136/  136]    Loss 0.363188    Top1 83.966159    Top5 97.453296    
2024-06-06 00:56:19,990 - ==> Top1: 83.966    Top5: 97.453    Loss: 0.363

2024-06-06 00:56:19,991 - ==> Confusion:
[[  783     0     5     0    14     2     0     2     5    95     0     1     2     6     5     0     3     1     0     0     7]
 [    1   945     3     0    16    25     2    25     4     4     5     5     4     0     5     1     6     0     6     0     6]
 [    3     2   879     1     6     2    19     7     0     7     5     1     4     6     2     8     5     3     4     1     5]
 [    1     3    18   897     1     9     2     3     4     5    11     1    12     0    21     1     1     7     9     3     7]
 [   11     5     4     0   976    11     2     2     3    17     1     1     0     0     6     2     5     1     1     1     5]
 [    1    18     1     2     6   909     3    26     2     5     3    11     4    25     1     1     5     2     1     9     8]
 [    2     9    22     1     0     8   994     5     0     6     7     1     3     1     0     7     2     3     0    10     5]
 [    1     6    11     2     0    26     2   967     2     6     3    12     6     2     0     1     1     4    12     6     7]
 [    8     3     1     0     0     3     0     4   857    58    12     0     5    13    17     1     3     5     2     0    10]
 [   38     1     2     0     7     1     1     1    24   879     1     0     1    28     7     0     3     0     1     0     6]
 [    0     3    10     3     2     1     1     6    18     2   975     0     2    15     8     0     1     2     3     1    11]
 [    3     0     3     1     1    23     1     2     1     2     0   896    21    14     0    14     6    14     1     2     6]
 [    0     2     3     7     1     6     1     4     3     2     1    81   818     7     1     7     5    34     1     4     7]
 [    3     0     1     2     2    12     0     1     6    10     4     9     6   917     6     2     2     4     0     2    12]
 [    8     3     4    18    11     1     0     0    21    17     9     3     0     2   974     1     2     0    16     1     7]
 [    1     2     5     0     4     0     4     2     0     7     0    13     9     7     0   984    10    17     0     0     1]
 [    1    11     1     2     5     3     0     1     2     1     3    11     4     7     3     8   990     1     0     3    15]
 [    3     0     1     0     2     0     3     3     1     8     0    14    18     6     1    10     4   923     1     1     6]
 [    3     8    12     7     4     4     0    28     6     1     5     2     7     3     6     0     4     0   950     2     6]
 [    1     4     1     0     4    12    10     8     0     4     0    24     6     9     0     7     5     3     1   977    12]
 [  132   199   169    64   169   217    65   205    99   144   142   203   265   303   167   111   273   108   127   180 10590]]

2024-06-06 00:56:19,994 - ==> Best [Top1: 83.966   Top5: 97.453   Sparsity:0.00   Params: 424448 on epoch: 75]
2024-06-06 00:56:19,995 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:56:20,025 - 

2024-06-06 00:56:20,025 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:56:26,495 - Epoch: [76][  100/ 1218]    Overall Loss 0.328729    Objective Loss 0.328729                                        LR 0.001000    Time 0.064662    
2024-06-06 00:56:31,485 - Epoch: [76][  200/ 1218]    Overall Loss 0.330564    Objective Loss 0.330564                                        LR 0.001000    Time 0.057272    
2024-06-06 00:56:36,490 - Epoch: [76][  300/ 1218]    Overall Loss 0.335112    Objective Loss 0.335112                                        LR 0.001000    Time 0.054855    
2024-06-06 00:56:41,151 - Epoch: [76][  400/ 1218]    Overall Loss 0.332215    Objective Loss 0.332215                                        LR 0.001000    Time 0.052791    
2024-06-06 00:56:45,894 - Epoch: [76][  500/ 1218]    Overall Loss 0.332868    Objective Loss 0.332868                                        LR 0.001000    Time 0.051714    
2024-06-06 00:56:50,645 - Epoch: [76][  600/ 1218]    Overall Loss 0.332063    Objective Loss 0.332063                                        LR 0.001000    Time 0.051009    
2024-06-06 00:56:55,227 - Epoch: [76][  700/ 1218]    Overall Loss 0.329225    Objective Loss 0.329225                                        LR 0.001000    Time 0.050265    
2024-06-06 00:56:59,909 - Epoch: [76][  800/ 1218]    Overall Loss 0.330373    Objective Loss 0.330373                                        LR 0.001000    Time 0.049832    
2024-06-06 00:57:04,782 - Epoch: [76][  900/ 1218]    Overall Loss 0.330231    Objective Loss 0.330231                                        LR 0.001000    Time 0.049707    
2024-06-06 00:57:09,450 - Epoch: [76][ 1000/ 1218]    Overall Loss 0.330009    Objective Loss 0.330009                                        LR 0.001000    Time 0.049403    
2024-06-06 00:57:14,445 - Epoch: [76][ 1100/ 1218]    Overall Loss 0.330354    Objective Loss 0.330354                                        LR 0.001000    Time 0.049450    
2024-06-06 00:57:19,150 - Epoch: [76][ 1200/ 1218]    Overall Loss 0.329720    Objective Loss 0.329720                                        LR 0.001000    Time 0.049249    
2024-06-06 00:57:19,964 - Epoch: [76][ 1218/ 1218]    Overall Loss 0.329719    Objective Loss 0.329719    Top1 83.374083    Top5 97.310513    LR 0.001000    Time 0.049189    
2024-06-06 00:57:20,117 - --- validate (epoch=76)-----------
2024-06-06 00:57:20,117 - 34633 samples (256 per mini-batch)
2024-06-06 00:57:25,690 - Epoch: [76][  100/  136]    Loss 0.366393    Top1 82.699219    Top5 97.445312    
2024-06-06 00:57:27,369 - Epoch: [76][  136/  136]    Loss 0.368039    Top1 82.727456    Top5 97.421534    
2024-06-06 00:57:27,562 - ==> Top1: 82.727    Top5: 97.422    Loss: 0.368

2024-06-06 00:57:27,563 - ==> Confusion:
[[  814     0     3     0     9     4     0     0    14    67     1     3     0     4     3     0     1     0     2     1     5]
 [    2   922     3     1    29    35     3    17     5     1     6     2     1     3     3     1     7     3     5     7     7]
 [    2     2   877     0     3     1    27     9     0     7     5     3     2     7     1     4     4     1     2     6     7]
 [    3     4    18   887     3     2     4     2     1     2    25     3    13     5    21     2     2     5     9     1     4]
 [   13    10     5     1   963    12     2     2     2    10     4     1     2     5     7     6     5     1     3     0     0]
 [    2    15     4     1     9   899     2    17     1     3     5    18    13    25     2     2     7     4     0    11     3]
 [    0     3    15     1     2     2  1007     4     0     5     4     5     2     1     0    14     3     2     1     9     6]
 [    2    10    13     2     2    47     6   924     2     2     4    11     5     8     2     0     1     5    11    15     5]
 [    7     5     0     1     1     1     0     2   874    37     8     6     4    28    18     1     2     2     2     0     3]
 [   44     1     2     0     6     3     0     0    45   827     2     2     2    47    11     2     2     2     0     0     3]
 [    0     3    11     6     1     3     6     6    15     1   970     2     1    16     7     0     3     0     5     3     5]
 [    0     3     1     0     0     8     3     3     4     2     1   907    27    10     2     6     5    19     1     8     1]
 [    2     0     2     3     0     3     0     1     3     1     0    65   865     8     0     5     3    23     5     2     4]
 [    1     0     0     0     7     7     1     4     5     7     4    10     1   935     2     1     2     6     1     3     4]
 [    6     3     3     2     8     1     0     3    27     9     4     2     3    10   994     0     2     5     9     0     7]
 [    1     0     3     0     3     2     4     0     1     4     1    22     8     2     0   990     7    15     2     1     0]
 [    5     6     5     2     6     6     1     0     4     1     1     7     5    10     2     8   985     1     0     6    11]
 [    0     1     1     0     0     3     1     0     0     3     0    11    30     3     2    13     2   928     0     2     5]
 [    1     2    10    12     2     1     1    26    10     3    16     5     5     2    22     2     3     0   921     5     9]
 [    0     4     1     0     0     6     9     3     0     1     0    22    13    10     0     4    13     5     8   983     6]
 [  181   205   225    67   222   229    94   168    97   126   154   194   332   353   188   153   285   145   117   218 10179]]

2024-06-06 00:57:27,565 - ==> Best [Top1: 83.966   Top5: 97.453   Sparsity:0.00   Params: 424448 on epoch: 75]
2024-06-06 00:57:27,565 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:57:27,590 - 

2024-06-06 00:57:27,590 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:57:33,841 - Epoch: [77][  100/ 1218]    Overall Loss 0.317325    Objective Loss 0.317325                                        LR 0.001000    Time 0.062486    
2024-06-06 00:57:38,492 - Epoch: [77][  200/ 1218]    Overall Loss 0.321528    Objective Loss 0.321528                                        LR 0.001000    Time 0.054486    
2024-06-06 00:57:43,104 - Epoch: [77][  300/ 1218]    Overall Loss 0.324340    Objective Loss 0.324340                                        LR 0.001000    Time 0.051690    
2024-06-06 00:57:47,767 - Epoch: [77][  400/ 1218]    Overall Loss 0.325723    Objective Loss 0.325723                                        LR 0.001000    Time 0.050420    
2024-06-06 00:57:52,406 - Epoch: [77][  500/ 1218]    Overall Loss 0.325144    Objective Loss 0.325144                                        LR 0.001000    Time 0.049611    
2024-06-06 00:57:57,098 - Epoch: [77][  600/ 1218]    Overall Loss 0.326741    Objective Loss 0.326741                                        LR 0.001000    Time 0.049159    
2024-06-06 00:58:01,728 - Epoch: [77][  700/ 1218]    Overall Loss 0.328326    Objective Loss 0.328326                                        LR 0.001000    Time 0.048748    
2024-06-06 00:58:06,550 - Epoch: [77][  800/ 1218]    Overall Loss 0.327956    Objective Loss 0.327956                                        LR 0.001000    Time 0.048678    
2024-06-06 00:58:11,323 - Epoch: [77][  900/ 1218]    Overall Loss 0.329554    Objective Loss 0.329554                                        LR 0.001000    Time 0.048570    
2024-06-06 00:58:16,309 - Epoch: [77][ 1000/ 1218]    Overall Loss 0.329841    Objective Loss 0.329841                                        LR 0.001000    Time 0.048696    
2024-06-06 00:58:21,238 - Epoch: [77][ 1100/ 1218]    Overall Loss 0.330899    Objective Loss 0.330899                                        LR 0.001000    Time 0.048749    
2024-06-06 00:58:25,841 - Epoch: [77][ 1200/ 1218]    Overall Loss 0.330373    Objective Loss 0.330373                                        LR 0.001000    Time 0.048521    
2024-06-06 00:58:26,678 - Epoch: [77][ 1218/ 1218]    Overall Loss 0.330374    Objective Loss 0.330374    Top1 80.929095    Top5 98.533007    LR 0.001000    Time 0.048491    
2024-06-06 00:58:26,888 - --- validate (epoch=77)-----------
2024-06-06 00:58:26,889 - 34633 samples (256 per mini-batch)
2024-06-06 00:58:32,522 - Epoch: [77][  100/  136]    Loss 0.339636    Top1 84.417969    Top5 97.863281    
2024-06-06 00:58:34,254 - Epoch: [77][  136/  136]    Loss 0.346692    Top1 84.275113    Top5 97.802674    
2024-06-06 00:58:34,427 - ==> Top1: 84.275    Top5: 97.803    Loss: 0.347

2024-06-06 00:58:34,429 - ==> Confusion:
[[  801     0     8     1     4     3     0     4    15    61     1     1     4     0     5     3     2     2     0     3    13]
 [    1   969     5     1    14     6     4     9     3     4     6     3     1     2     2     0     5     0    10     4    14]
 [    6     1   894     9     1     0    14     8     0     4     9     4     2     3     1     3     1     0     1     2     7]
 [    4     2     7   921     3     3     4     1     2     1    15     0     8     2    18     3     4     5     6     0     7]
 [   12    12     7     3   964     3     1     3     1    13     3     5     1     1     8     1     6     0     1     1     8]
 [    5    34     2     4    19   826     4    44     6     6     6    16     3    15     4     3     8     4     7    15    12]
 [    2     7    13     2     1     1  1018     2     0     5     2     2     1     1     0    10     3     2     1     9     4]
 [    4    12    12     1     2    22    11   950     1     5     2     8     2     1     1     0     0     2    18    16     7]
 [    7     3     1     0     2     1     0     1   893    30    16     3     3    11    15     1     2     1     4     1     7]
 [   62     2     3     0     7     1     0     3    61   816     3     1     0    28     4     3     2     4     0     0     1]
 [    0     4     9     9     0     1     5     5     8     0   983     3     1    10     4     0     2     0    10     6     4]
 [    3     1     0     0     1     3     5     5     0     1     2   903    21     4     1    12     4    18     1    18     8]
 [    3     0     3     5     0     2     2     5     0     0     3    59   839     3     1     6     7    32     4     9    12]
 [    6     3     4     0     7     6     2     1    16     7     8    17     3   895     6     3     5     2     0     3     7]
 [    5     3     2    17     3     1     1     2    27     6    13     2     1     9   974     1     2     3    11     2    13]
 [    3     0     3     0     1     1    10     0     1     3     0    16     6     2     0   996     8     8     1     3     4]
 [    1     8     6     1     6     5     2     0     4     3     1     4     2     2     2     6   998     2     2     2    15]
 [    1     1     0     5     1     0     3     0     0     2     0    15    17     5     1    12     2   936     1     1     2]
 [    4     2     7    15     0     2     2    20     7     1     7     0     5     2     8     0     1     1   966     1     7]
 [    1     2     3     0     0     4     9     4     1     1     0     8     7     1     0     7     8     1     2  1017    12]
 [  166   207   227   100   146   133    91   160   112   104   188   147   241   288   185   113   225   100   136   235 10628]]

2024-06-06 00:58:34,431 - ==> Best [Top1: 84.275   Top5: 97.803   Sparsity:0.00   Params: 424448 on epoch: 77]
2024-06-06 00:58:34,431 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:58:34,461 - 

2024-06-06 00:58:34,461 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:58:40,613 - Epoch: [78][  100/ 1218]    Overall Loss 0.326346    Objective Loss 0.326346                                        LR 0.001000    Time 0.061490    
2024-06-06 00:58:45,185 - Epoch: [78][  200/ 1218]    Overall Loss 0.327757    Objective Loss 0.327757                                        LR 0.001000    Time 0.053594    
2024-06-06 00:58:49,887 - Epoch: [78][  300/ 1218]    Overall Loss 0.328723    Objective Loss 0.328723                                        LR 0.001000    Time 0.051397    
2024-06-06 00:58:54,482 - Epoch: [78][  400/ 1218]    Overall Loss 0.329365    Objective Loss 0.329365                                        LR 0.001000    Time 0.050030    
2024-06-06 00:58:59,309 - Epoch: [78][  500/ 1218]    Overall Loss 0.329405    Objective Loss 0.329405                                        LR 0.001000    Time 0.049673    
2024-06-06 00:59:03,905 - Epoch: [78][  600/ 1218]    Overall Loss 0.329794    Objective Loss 0.329794                                        LR 0.001000    Time 0.049051    
2024-06-06 00:59:08,716 - Epoch: [78][  700/ 1218]    Overall Loss 0.330078    Objective Loss 0.330078                                        LR 0.001000    Time 0.048913    
2024-06-06 00:59:13,391 - Epoch: [78][  800/ 1218]    Overall Loss 0.329602    Objective Loss 0.329602                                        LR 0.001000    Time 0.048640    
2024-06-06 00:59:18,055 - Epoch: [78][  900/ 1218]    Overall Loss 0.328429    Objective Loss 0.328429                                        LR 0.001000    Time 0.048416    
2024-06-06 00:59:22,970 - Epoch: [78][ 1000/ 1218]    Overall Loss 0.328276    Objective Loss 0.328276                                        LR 0.001000    Time 0.048487    
2024-06-06 00:59:27,642 - Epoch: [78][ 1100/ 1218]    Overall Loss 0.328059    Objective Loss 0.328059                                        LR 0.001000    Time 0.048325    
2024-06-06 00:59:32,182 - Epoch: [78][ 1200/ 1218]    Overall Loss 0.328006    Objective Loss 0.328006                                        LR 0.001000    Time 0.048079    
2024-06-06 00:59:33,022 - Epoch: [78][ 1218/ 1218]    Overall Loss 0.327752    Objective Loss 0.327752    Top1 85.330073    Top5 97.799511    LR 0.001000    Time 0.048058    
2024-06-06 00:59:33,205 - --- validate (epoch=78)-----------
2024-06-06 00:59:33,206 - 34633 samples (256 per mini-batch)
2024-06-06 00:59:38,809 - Epoch: [78][  100/  136]    Loss 0.366177    Top1 83.925781    Top5 97.570312    
2024-06-06 00:59:40,462 - Epoch: [78][  136/  136]    Loss 0.361860    Top1 84.052782    Top5 97.545693    
2024-06-06 00:59:40,619 - ==> Top1: 84.053    Top5: 97.546    Loss: 0.362

2024-06-06 00:59:40,620 - ==> Confusion:
[[  806     4     1     1    10     2     1     1     4    74     0     1     0     1     5     0     3     5     3     0     9]
 [    2   918     2     2    30    30     3    19     0     4     4     3     1     2     3     2     6     2    12     2    16]
 [    8     1   870     8     6     3    16    12     0     8     2     6     2     3     0     3     3     2     6     4     7]
 [    5     5    15   908     2     3     3     4     2     0    10     2     6     1    12     1     3     9    15     0    10]
 [   22     7     4     1   957     8     2     1     3    13     1     5     0     4     3     5     5     2     0     0    11]
 [    2    11     2     5    14   895     7    40     3     5     1    15     5     9     2     1     7     4     3     3     9]
 [    2     2    16     5     4     1  1014     7     0     2     4     4     2     0     1     3     1     3     2     6     7]
 [    3     6    15     1     4    19     4   954     1     4     4    13     5     1     2     0     4     5    19     7     6]
 [   13     2     0     2     1     0     0     2   879    56     5     6     3     9    10     0     2     3     4     0     5]
 [   47     0     0     0     4     2     0     3    34   882     1     2     0    11     2     1     3     4     1     0     4]
 [    1     3     3    17     3     1     3     6    23     2   939     3     3    20     7     1     2     0    16     2     9]
 [    3     2     2     0     2     6     4     4     0     3     0   918    19     2     0    10     3    20     0    10     3]
 [    1     1     2     2     2     4     0     2     2     0     1    87   804     2     2     7     4    48     3     3    18]
 [    2     1     3     1     7    12     1     2     7    20     5    23     3   886     6     0     3     3     0     4    12]
 [   10     2     1    24    10     0     0     0    36    18     4     4     4     4   949     0     3     5    16     0     8]
 [    1     1     6     0     6     1     6     0     0     0     0    20     5     2     0   986     8    18     0     2     4]
 [    6     5     3     2     8     8     0     2     5     5     2     6     1     3     2     9   986     0     1     4    14]
 [    2     1     0     1     3     1     1     1     0     1     0    19     9     2     1     2     2   953     0     2     4]
 [    3     3     3    11     2     2     0    20     4     0     2     3     6     1    15     0     1     2   973     0     7]
 [    0     6     6     2     6    10    11    14     1     0     0    30     4     1     0     8     5     7     0   970     7]
 [  183   106   212   101   207   170    94   204   108   148    96   228   248   210   153   109   174   161   176   181 10663]]

2024-06-06 00:59:40,623 - ==> Best [Top1: 84.275   Top5: 97.803   Sparsity:0.00   Params: 424448 on epoch: 77]
2024-06-06 00:59:40,623 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 00:59:40,647 - 

2024-06-06 00:59:40,647 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 00:59:46,828 - Epoch: [79][  100/ 1218]    Overall Loss 0.326451    Objective Loss 0.326451                                        LR 0.001000    Time 0.061780    
2024-06-06 00:59:51,657 - Epoch: [79][  200/ 1218]    Overall Loss 0.324629    Objective Loss 0.324629                                        LR 0.001000    Time 0.055024    
2024-06-06 00:59:56,521 - Epoch: [79][  300/ 1218]    Overall Loss 0.326282    Objective Loss 0.326282                                        LR 0.001000    Time 0.052889    
2024-06-06 01:00:01,190 - Epoch: [79][  400/ 1218]    Overall Loss 0.325423    Objective Loss 0.325423                                        LR 0.001000    Time 0.051336    
2024-06-06 01:00:06,057 - Epoch: [79][  500/ 1218]    Overall Loss 0.327706    Objective Loss 0.327706                                        LR 0.001000    Time 0.050798    
2024-06-06 01:00:10,878 - Epoch: [79][  600/ 1218]    Overall Loss 0.327572    Objective Loss 0.327572                                        LR 0.001000    Time 0.050364    
2024-06-06 01:00:15,587 - Epoch: [79][  700/ 1218]    Overall Loss 0.326820    Objective Loss 0.326820                                        LR 0.001000    Time 0.049893    
2024-06-06 01:00:20,590 - Epoch: [79][  800/ 1218]    Overall Loss 0.325520    Objective Loss 0.325520                                        LR 0.001000    Time 0.049907    
2024-06-06 01:00:25,401 - Epoch: [79][  900/ 1218]    Overall Loss 0.327470    Objective Loss 0.327470                                        LR 0.001000    Time 0.049705    
2024-06-06 01:00:30,008 - Epoch: [79][ 1000/ 1218]    Overall Loss 0.328213    Objective Loss 0.328213                                        LR 0.001000    Time 0.049340    
2024-06-06 01:00:34,586 - Epoch: [79][ 1100/ 1218]    Overall Loss 0.328354    Objective Loss 0.328354                                        LR 0.001000    Time 0.049014    
2024-06-06 01:00:39,174 - Epoch: [79][ 1200/ 1218]    Overall Loss 0.328783    Objective Loss 0.328783                                        LR 0.001000    Time 0.048752    
2024-06-06 01:00:40,020 - Epoch: [79][ 1218/ 1218]    Overall Loss 0.328782    Objective Loss 0.328782    Top1 86.063570    Top5 97.555012    LR 0.001000    Time 0.048726    
2024-06-06 01:00:40,190 - --- validate (epoch=79)-----------
2024-06-06 01:00:40,191 - 34633 samples (256 per mini-batch)
2024-06-06 01:00:45,718 - Epoch: [79][  100/  136]    Loss 0.357075    Top1 84.335938    Top5 97.605469    
2024-06-06 01:00:47,391 - Epoch: [79][  136/  136]    Loss 0.361422    Top1 84.353074    Top5 97.583230    
2024-06-06 01:00:47,573 - ==> Top1: 84.353    Top5: 97.583    Loss: 0.361

2024-06-06 01:00:47,575 - ==> Confusion:
[[  836     1     0     0    11     3     0     1     9    42     3     1     3     2     1     3     0     4     0     0    11]
 [    4   986     2     1    11     9     1     4     3     1     6     2     1     0     2     0     2     3    14     5     6]
 [    9     2   862    11     1     2    10    11     2     2     9     3     4    10     2     7     3     4     6     1     9]
 [    5     4     5   908     1     4     0     4     2     2    24     1     9     1    19     1     1    10     5     2     8]
 [   17    12     2     3   959     9     1     0     1     7     1     1     1     6    11     1     2     5     4     1    10]
 [    5    75     0     2    15   825     3    28     3     2     2    12     6    23     3     2     5     8     4    10    10]
 [    4     7    16     1     0     3   988     7     1     4     9     7     2     1     0     2     3     7     2     8    14]
 [    2    17    10     0     2    20     3   931     2     1     9    10     3     3     0     0     4     3    40    11     6]
 [    7     3     0     0     0     1     0     0   883    32    12     1     3    26    18     0     1     3     4     0     8]
 [   78     2     0     0     6     2     2     0    53   818     2     0     0    26     4     1     1     4     0     0     2]
 [    0     5     6     7     1     1     2     4    15     3   980     0     1    12     9     0     1     1     7     2     7]
 [    1     4     1     0     1     9     1     1     2     2     0   885    37    12     0     7     2    31     0     7     8]
 [    0     3     2     5     1     3     2     1     7     2     3    55   849     3     2     6     6    33     4     3     5]
 [    2     3     2     0     5     3     0     0    18     8     9     9     8   911     4     1     2     6     0     3     7]
 [   13     3     1    18     3     0     0     0    29    10    14     1     6     6   968     0     0     6    11     1     8]
 [    2     2     2     0     4     3     2     0     4     3     1     9     9     0     0   989     8    22     0     1     5]
 [    2     7     2     2     7     2     1     3     8     4     2     5     2     2     4    10   981     3     1     6    18]
 [    2     1     3     0     0     0     0     1     3     4     1    10    10     6     4     5     2   943     3     3     4]
 [    4    10     4     9     3     1     1     8     3     1    11     3     6     2    11     0     0     1   971     3     6]
 [    1     3     4     0     1     8     7     5     1     3     0    19     8     3     1     1     3     7     5   993    15]
 [  178   231   124    87   176   110    54   133   111   102   202   145   317   216   202    97   156   152   187   204 10748]]

2024-06-06 01:00:47,578 - ==> Best [Top1: 84.353   Top5: 97.583   Sparsity:0.00   Params: 424448 on epoch: 79]
2024-06-06 01:00:47,578 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:00:47,614 - 

2024-06-06 01:00:47,615 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:00:53,755 - Epoch: [80][  100/ 1218]    Overall Loss 0.329858    Objective Loss 0.329858                                        LR 0.001000    Time 0.061373    
2024-06-06 01:00:58,437 - Epoch: [80][  200/ 1218]    Overall Loss 0.322246    Objective Loss 0.322246                                        LR 0.001000    Time 0.054087    
2024-06-06 01:01:03,110 - Epoch: [80][  300/ 1218]    Overall Loss 0.325786    Objective Loss 0.325786                                        LR 0.001000    Time 0.051630    
2024-06-06 01:01:07,806 - Epoch: [80][  400/ 1218]    Overall Loss 0.326347    Objective Loss 0.326347                                        LR 0.001000    Time 0.050457    
2024-06-06 01:01:12,531 - Epoch: [80][  500/ 1218]    Overall Loss 0.325862    Objective Loss 0.325862                                        LR 0.001000    Time 0.049811    
2024-06-06 01:01:17,475 - Epoch: [80][  600/ 1218]    Overall Loss 0.327466    Objective Loss 0.327466                                        LR 0.001000    Time 0.049745    
2024-06-06 01:01:22,349 - Epoch: [80][  700/ 1218]    Overall Loss 0.326796    Objective Loss 0.326796                                        LR 0.001000    Time 0.049600    
2024-06-06 01:01:26,918 - Epoch: [80][  800/ 1218]    Overall Loss 0.327052    Objective Loss 0.327052                                        LR 0.001000    Time 0.049108    
2024-06-06 01:01:31,738 - Epoch: [80][  900/ 1218]    Overall Loss 0.326711    Objective Loss 0.326711                                        LR 0.001000    Time 0.049005    
2024-06-06 01:01:36,517 - Epoch: [80][ 1000/ 1218]    Overall Loss 0.326627    Objective Loss 0.326627                                        LR 0.001000    Time 0.048881    
2024-06-06 01:01:41,370 - Epoch: [80][ 1100/ 1218]    Overall Loss 0.326554    Objective Loss 0.326554                                        LR 0.001000    Time 0.048847    
2024-06-06 01:01:46,097 - Epoch: [80][ 1200/ 1218]    Overall Loss 0.325991    Objective Loss 0.325991                                        LR 0.001000    Time 0.048715    
2024-06-06 01:01:46,880 - Epoch: [80][ 1218/ 1218]    Overall Loss 0.326103    Objective Loss 0.326103    Top1 85.085575    Top5 98.533007    LR 0.001000    Time 0.048637    
2024-06-06 01:01:47,043 - --- validate (epoch=80)-----------
2024-06-06 01:01:47,043 - 34633 samples (256 per mini-batch)
2024-06-06 01:01:52,620 - Epoch: [80][  100/  136]    Loss 0.350058    Top1 83.574219    Top5 97.449219    
2024-06-06 01:01:54,483 - Epoch: [80][  136/  136]    Loss 0.350470    Top1 83.622557    Top5 97.447521    
2024-06-06 01:01:54,652 - ==> Top1: 83.623    Top5: 97.448    Loss: 0.350

2024-06-06 01:01:54,654 - ==> Confusion:
[[  839     0     1     0     8     0     0     0    11    52     1     0     3     4     3     0     0     1     2     3     3]
 [    1   939     4     0    17    28     4    13     3     5     3     5     2     2     6     0    11     2     6     5     7]
 [    9     1   871     3     2     3    15    10     1     6     9     3     3     4     2     3     7     2     4     4     8]
 [    3     1     8   894     3     9     1     6     2     4    10     0     4     3    32     4     2    10     6     4    10]
 [   15     6     1     1   961    10     1     2     1    14     1     1     1     4    15     3     8     1     2     2     4]
 [    4    18     1     2    10   890     3    29     3     3     0     8     5    26     4     2     2     2     2    16    13]
 [    1     4    13     3     1     4  1004     6     1     4     3     3     2     2     0    11     3     3     0    12     6]
 [    4    13    13     1     3    31     4   923     3     4     4    13     4     4     0     0     0     5    23    16     9]
 [    6     1     2     0     2     0     0     3   885    39     6     1     5    19    15     1     2     1     6     4     4]
 [   64     1     2     0     1     1     0     0    47   843     2     0     2    20     4     2     2     4     0     0     6]
 [    0     7     7    10     2     1     6     2    18     2   955     2     0     9    14     0     1     0    14     4    10]
 [    4     2     1     0     1     8     1     6     2     6     1   888    21     9     0    16     1    28     1    12     3]
 [    2     0     0     3     2     1     3     2     2     3     2    63   831     8     4     7     3    46     2     3     8]
 [    1     1     1     1     4     4     0     3    12    15     2    11     5   920     3     1     4     2     0     7     4]
 [    9     4     2     5     7     2     0     2    29     8     0     2     2     8  1000     0     0     6     7     1     4]
 [    0     0     2     0     4     0     6     0     1     9     0     8     2     5     0  1000    10     9     1     5     4]
 [    6     7     3     2     2     7     3     0     7     4     0     6     7     6     5     7   983     0     2    13     2]
 [    6     0     1     2     0     1     2     1     1     2     0    11    13     3     2     9     0   942     0     5     4]
 [    2     8     6     5     2     3     0    19     9     2     3     1     3     1    23     0     0     1   953     7    10]
 [    0     4     4     0     0     3     7     7     0     3     2    16     8     7     0     5     5     6     2  1001     8]
 [  201   170   126    82   177   205    77   125   135   149   115   181   298   300   244   144   236   151   122   255 10439]]

2024-06-06 01:01:54,657 - ==> Best [Top1: 84.353   Top5: 97.583   Sparsity:0.00   Params: 424448 on epoch: 79]
2024-06-06 01:01:54,657 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:01:54,690 - 

2024-06-06 01:01:54,691 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:02:01,106 - Epoch: [81][  100/ 1218]    Overall Loss 0.327924    Objective Loss 0.327924                                        LR 0.001000    Time 0.064126    
2024-06-06 01:02:05,882 - Epoch: [81][  200/ 1218]    Overall Loss 0.326211    Objective Loss 0.326211                                        LR 0.001000    Time 0.055930    
2024-06-06 01:02:10,566 - Epoch: [81][  300/ 1218]    Overall Loss 0.327744    Objective Loss 0.327744                                        LR 0.001000    Time 0.052893    
2024-06-06 01:02:15,246 - Epoch: [81][  400/ 1218]    Overall Loss 0.328777    Objective Loss 0.328777                                        LR 0.001000    Time 0.051365    
2024-06-06 01:02:19,815 - Epoch: [81][  500/ 1218]    Overall Loss 0.325433    Objective Loss 0.325433                                        LR 0.001000    Time 0.050226    
2024-06-06 01:02:24,517 - Epoch: [81][  600/ 1218]    Overall Loss 0.325062    Objective Loss 0.325062                                        LR 0.001000    Time 0.049688    
2024-06-06 01:02:29,145 - Epoch: [81][  700/ 1218]    Overall Loss 0.324792    Objective Loss 0.324792                                        LR 0.001000    Time 0.049199    
2024-06-06 01:02:33,749 - Epoch: [81][  800/ 1218]    Overall Loss 0.326072    Objective Loss 0.326072                                        LR 0.001000    Time 0.048801    
2024-06-06 01:02:38,608 - Epoch: [81][  900/ 1218]    Overall Loss 0.326935    Objective Loss 0.326935                                        LR 0.001000    Time 0.048776    
2024-06-06 01:02:43,454 - Epoch: [81][ 1000/ 1218]    Overall Loss 0.327271    Objective Loss 0.327271                                        LR 0.001000    Time 0.048742    
2024-06-06 01:02:48,039 - Epoch: [81][ 1100/ 1218]    Overall Loss 0.327291    Objective Loss 0.327291                                        LR 0.001000    Time 0.048477    
2024-06-06 01:02:52,741 - Epoch: [81][ 1200/ 1218]    Overall Loss 0.326961    Objective Loss 0.326961                                        LR 0.001000    Time 0.048354    
2024-06-06 01:02:53,516 - Epoch: [81][ 1218/ 1218]    Overall Loss 0.327013    Objective Loss 0.327013    Top1 83.618582    Top5 98.044010    LR 0.001000    Time 0.048275    
2024-06-06 01:02:53,678 - --- validate (epoch=81)-----------
2024-06-06 01:02:53,678 - 34633 samples (256 per mini-batch)
2024-06-06 01:02:59,220 - Epoch: [81][  100/  136]    Loss 0.353123    Top1 85.488281    Top5 97.902344    
2024-06-06 01:03:00,902 - Epoch: [81][  136/  136]    Loss 0.357236    Top1 85.505154    Top5 97.926833    
2024-06-06 01:03:01,091 - ==> Top1: 85.505    Top5: 97.927    Loss: 0.357

2024-06-06 01:03:01,092 - ==> Confusion:
[[  780     0     3     0     8     1     0     1    12   101     0     3     4     4     6     1     0     0     1     1     5]
 [    2   909     4     0    22    31     2    29     2     0     2     3     2     1     2     0     9     2    22     4    15]
 [    6     2   877     3     1     1    17    11     0     3     2     6     4     6     1     7     5     4     3     3     8]
 [    4     3    17   902     3     1     4     2     3     2    12     2     4     5    15     3     2     6    11     2    13]
 [   20     4     4     0   948     9     1     1     1    20     3     4     2     5     4     3     7     2     2     2    12]
 [    7    12     3     4    12   889     2    32     3     5     3    14     4    18     2     3     3     2     3     7    15]
 [    1     2    16     0     0     4  1002     8     0     4     6     6     1     0     0    10     2     2     1    14     7]
 [    2     1    13     1     0    25     3   951     3     2     3    11     9     4     1     3     0     3    14    18    10]
 [    8     2     0     1     1     4     0     2   846    46    12     4     5    30    20     0     4     3     3     1    10]
 [   30     1     0     1     4     1     0     1    26   881     4     3     4    28     4     2     0     4     0     0     7]
 [    1     2    13     8     3     4     9     4     9     0   969     1     2    12    12     0     1     0    10     0     4]
 [    0     1     2     0     1     8     2     4     0     1     0   912    26     2     1    14     3    18     2     8     6]
 [    3     0     3     6     0     5     2     0     5     1     1    75   821     1     5     8     0    32     1     6    20]
 [    2     1     4     0     1     7     1     4     4    12    10    19     2   905     2     4     4     2     1     5    11]
 [    7     0     4    11     7     3     0     1    21     9     9     3     0     8   989     0     1     2    11     1    11]
 [    1     1     1     0     2     0     1     1     0     6     0    22     5     2     0   994     9     9     1     3     8]
 [    2     2     0     1     5     5     1     1     4     2     1     6     4     3     0     9   991     3     0     6    26]
 [    4     0     1     1     0     0     2     1     1     3     0    22    11     5     5    15     2   918     4     1     9]
 [    2     2     5     8     0     2     1    19     4     2     5     1     3     0    19     0     1     0   965     5    14]
 [    2     1     2     0     1     8     6     6     1     2     0    24     9     3     0     2     5     6     3   994    13]
 [  133    84   167    56   183   132    75   124    90   124   133   161   225   242   140   120   158    86   137   192 11170]]

2024-06-06 01:03:01,094 - ==> Best [Top1: 85.505   Top5: 97.927   Sparsity:0.00   Params: 424448 on epoch: 81]
2024-06-06 01:03:01,095 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:03:01,124 - 

2024-06-06 01:03:01,124 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:03:07,547 - Epoch: [82][  100/ 1218]    Overall Loss 0.319719    Objective Loss 0.319719                                        LR 0.001000    Time 0.064199    
2024-06-06 01:03:12,345 - Epoch: [82][  200/ 1218]    Overall Loss 0.325720    Objective Loss 0.325720                                        LR 0.001000    Time 0.056080    
2024-06-06 01:03:17,047 - Epoch: [82][  300/ 1218]    Overall Loss 0.325469    Objective Loss 0.325469                                        LR 0.001000    Time 0.053054    
2024-06-06 01:03:21,618 - Epoch: [82][  400/ 1218]    Overall Loss 0.323558    Objective Loss 0.323558                                        LR 0.001000    Time 0.051214    
2024-06-06 01:03:26,356 - Epoch: [82][  500/ 1218]    Overall Loss 0.325511    Objective Loss 0.325511                                        LR 0.001000    Time 0.050442    
2024-06-06 01:03:31,015 - Epoch: [82][  600/ 1218]    Overall Loss 0.325222    Objective Loss 0.325222                                        LR 0.001000    Time 0.049797    
2024-06-06 01:03:35,590 - Epoch: [82][  700/ 1218]    Overall Loss 0.325534    Objective Loss 0.325534                                        LR 0.001000    Time 0.049215    
2024-06-06 01:03:40,338 - Epoch: [82][  800/ 1218]    Overall Loss 0.327122    Objective Loss 0.327122                                        LR 0.001000    Time 0.048995    
2024-06-06 01:03:44,956 - Epoch: [82][  900/ 1218]    Overall Loss 0.325443    Objective Loss 0.325443                                        LR 0.001000    Time 0.048681    
2024-06-06 01:03:49,737 - Epoch: [82][ 1000/ 1218]    Overall Loss 0.325554    Objective Loss 0.325554                                        LR 0.001000    Time 0.048592    
2024-06-06 01:03:54,609 - Epoch: [82][ 1100/ 1218]    Overall Loss 0.324873    Objective Loss 0.324873                                        LR 0.001000    Time 0.048602    
2024-06-06 01:03:59,332 - Epoch: [82][ 1200/ 1218]    Overall Loss 0.324491    Objective Loss 0.324491                                        LR 0.001000    Time 0.048486    
2024-06-06 01:04:00,102 - Epoch: [82][ 1218/ 1218]    Overall Loss 0.324472    Objective Loss 0.324472    Top1 82.640587    Top5 95.354523    LR 0.001000    Time 0.048401    
2024-06-06 01:04:00,281 - --- validate (epoch=82)-----------
2024-06-06 01:04:00,281 - 34633 samples (256 per mini-batch)
2024-06-06 01:04:05,864 - Epoch: [82][  100/  136]    Loss 0.359090    Top1 83.144531    Top5 97.203125    
2024-06-06 01:04:07,546 - Epoch: [82][  136/  136]    Loss 0.358430    Top1 83.264517    Top5 97.297375    
2024-06-06 01:04:07,728 - ==> Top1: 83.265    Top5: 97.297    Loss: 0.358

2024-06-06 01:04:07,729 - ==> Confusion:
[[  803     2     5     3    21     2     0     3    12    57     2     3     5     1     3     1     0     0     2     0     6]
 [    0   929     5     3    24    27     5    16     2     0     4     4     6     1     1     4    10     2     6     3    11]
 [    6     2   864    12     3     3    19     4     0     6     6     8     9     3     1    11     3     0     1     3     6]
 [    9     0    14   923     1     7     3     2     4     1     9     1     7     3    16     1     2     2     9     1     1]
 [   12     3     4     1   972     4     0     1     0    13     1     1     7     4     6     7     6     0     2     2     8]
 [    5    14     3     5    19   881     2    23     1     1     6    22    15    13     3     2     3     2     4    11     8]
 [    2     1     9     1     1     4  1020     5     1     2     2     2     4     0     0     8     1     6     2    11     4]
 [    3     4    15     5     4    30     4   937     2     1     5    10     7     0     2     2     2     3    18    14     9]
 [   12     2     1     1     0     3     0     1   866    46    12     3     5    16    17     1     4     2     4     0     6]
 [   62     3     4     1     6     1     1     1    47   822     4     1     3    23    12     2     0     2     2     1     3]
 [    0     3     5     9     0     4     6     5    11     1   992     2     1     6     5     0     0     0     7     3     4]
 [    5     1     1     0     1     5     2     2     0     5     1   913    32     4     0    18     1     8     2     7     3]
 [    2     0     1     2     0     2     0     4     2     3     3    60   867     1     0    16     2    12     6     4     8]
 [    2     0     2     1     2    13     0     8     9     9     7    17     9   887    11     9     3     2     2     4     4]
 [    6     5     1    26    11     1     0     0    28     8     8     2     3     3   972     2     1     2    13     1     5]
 [    2     0     3     0     2     2     6     0     0     3     0    15    14     0     0   998     4    10     1     1     5]
 [    5     7     1     3     9     7     3     1     1     1     4     7     2     2     1    18   983     1     3     1    12]
 [    1     1     0     4     1     0     3     2     0     2     0    33    45     2     3    10     0   888     1     3     6]
 [    2     3     7    15     3     3     1    15     4     1     6     3     7     0     6     2     0     1   966     1    12]
 [    1     4     1     1     3     8    11     6     0     1     0    24    12     2     1     8     4     3     4   991     3]
 [  163   124   183   149   200   165   122   141   112    78   204   220   354   201   181   189   229    97   204   253 10363]]

2024-06-06 01:04:07,732 - ==> Best [Top1: 85.505   Top5: 97.927   Sparsity:0.00   Params: 424448 on epoch: 81]
2024-06-06 01:04:07,732 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:04:07,756 - 

2024-06-06 01:04:07,756 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:04:13,875 - Epoch: [83][  100/ 1218]    Overall Loss 0.313894    Objective Loss 0.313894                                        LR 0.001000    Time 0.061161    
2024-06-06 01:04:18,723 - Epoch: [83][  200/ 1218]    Overall Loss 0.316779    Objective Loss 0.316779                                        LR 0.001000    Time 0.054812    
2024-06-06 01:04:23,524 - Epoch: [83][  300/ 1218]    Overall Loss 0.318733    Objective Loss 0.318733                                        LR 0.001000    Time 0.052536    
2024-06-06 01:04:28,424 - Epoch: [83][  400/ 1218]    Overall Loss 0.320117    Objective Loss 0.320117                                        LR 0.001000    Time 0.051648    
2024-06-06 01:04:33,092 - Epoch: [83][  500/ 1218]    Overall Loss 0.320948    Objective Loss 0.320948                                        LR 0.001000    Time 0.050650    
2024-06-06 01:04:37,824 - Epoch: [83][  600/ 1218]    Overall Loss 0.320146    Objective Loss 0.320146                                        LR 0.001000    Time 0.050091    
2024-06-06 01:04:42,414 - Epoch: [83][  700/ 1218]    Overall Loss 0.321589    Objective Loss 0.321589                                        LR 0.001000    Time 0.049488    
2024-06-06 01:04:47,055 - Epoch: [83][  800/ 1218]    Overall Loss 0.323433    Objective Loss 0.323433                                        LR 0.001000    Time 0.049101    
2024-06-06 01:04:51,820 - Epoch: [83][  900/ 1218]    Overall Loss 0.323818    Objective Loss 0.323818                                        LR 0.001000    Time 0.048938    
2024-06-06 01:04:56,717 - Epoch: [83][ 1000/ 1218]    Overall Loss 0.323451    Objective Loss 0.323451                                        LR 0.001000    Time 0.048939    
2024-06-06 01:05:01,513 - Epoch: [83][ 1100/ 1218]    Overall Loss 0.323678    Objective Loss 0.323678                                        LR 0.001000    Time 0.048849    
2024-06-06 01:05:06,147 - Epoch: [83][ 1200/ 1218]    Overall Loss 0.324345    Objective Loss 0.324345                                        LR 0.001000    Time 0.048637    
2024-06-06 01:05:07,011 - Epoch: [83][ 1218/ 1218]    Overall Loss 0.324330    Objective Loss 0.324330    Top1 86.308068    Top5 97.066015    LR 0.001000    Time 0.048627    
2024-06-06 01:05:07,179 - --- validate (epoch=83)-----------
2024-06-06 01:05:07,180 - 34633 samples (256 per mini-batch)
2024-06-06 01:05:12,776 - Epoch: [83][  100/  136]    Loss 0.354402    Top1 83.335938    Top5 97.449219    
2024-06-06 01:05:14,455 - Epoch: [83][  136/  136]    Loss 0.354439    Top1 83.426212    Top5 97.531256    
2024-06-06 01:05:14,641 - ==> Top1: 83.426    Top5: 97.531    Loss: 0.354

2024-06-06 01:05:14,643 - ==> Confusion:
[[  825     1     2     0    12     6     0     2     7    50     0     3     5     3     1     2     3     2     0     1     6]
 [    2   936     2     1    22    37     3    17     1     1     5     3     5     2     3     1     5     2     5     5     5]
 [    5     0   871     5     3     2    27     4     0     7     4     2     5     7     5     4     7     0     4     1     7]
 [    3     3    10   907     3    10     0     2     1     3    15     0     8     4    17     3     3     8    10     2     4]
 [   14     3     4     2   967     9     1     1     0     9     0     4     0     6    11     4     4     1     3     3     8]
 [    4     9     5     1     6   921     2    17     1     2     0    17     6    22     3     1     6     2     4    11     3]
 [    1     2     7     1     0     2  1019     9     0     4     3     2     2     4     1     6     3     2     1    11     6]
 [    3     4    18     1     1    39     7   934     3     2     3     9     7     7     2     2     1     1    12    14     7]
 [   14     2     0     0     4     5     0     2   843    47    12     6     5    29    10     1     5     3     6     1     7]
 [   64     0     1     2     8     3     2     0    51   813     1     1     3    40     4     1     1     2     0     2     2]
 [    1     1     7    10     0     1     6     3    10     5   984     0     2     9     6     0     1     0    11     1     6]
 [    1     2     2     0     2    13     2     4     0     3     1   887    45     6     2    18     4     7     0    10     2]
 [    1     1     3     2     0     6     4     1     2     1     0    51   868     2     1    10     5    16     3     7    11]
 [    3     0     2     0     3    20     2     1     7     7     6    13     6   908     1     0     3     2     1    10     6]
 [    6     2     2     7     9     2     0     0    28     9    13     1     9    11   969     1     4     3    16     0     6]
 [    3     1     7     0     4     0     5     2     0     2     0    17    10     2     0   984     9    10     1     3     6]
 [    2     6     3     1     3     6     1     0     3     7     2     4     7     5     0     9   984     2     2    12    13]
 [    2     0     0     0     0     1     1     2     1     2     0    25    29     3     3     7     3   913     4     5     4]
 [    1     8     8     9     3     3     1    19     7     1     4     1     5     2    12     0     0     0   964     2     8]
 [    0     4     4     0     0     6     8     2     0     3     0    10    11     5     0     5     6     4     4  1006    10]
 [  184   182   216    92   176   251   113   139    98   116   187   164   361   310   166   121   181    80   148   257 10390]]

2024-06-06 01:05:14,645 - ==> Best [Top1: 85.505   Top5: 97.927   Sparsity:0.00   Params: 424448 on epoch: 81]
2024-06-06 01:05:14,645 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:05:14,670 - 

2024-06-06 01:05:14,670 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:05:21,124 - Epoch: [84][  100/ 1218]    Overall Loss 0.308919    Objective Loss 0.308919                                        LR 0.001000    Time 0.064513    
2024-06-06 01:05:25,876 - Epoch: [84][  200/ 1218]    Overall Loss 0.315807    Objective Loss 0.315807                                        LR 0.001000    Time 0.056005    
2024-06-06 01:05:30,867 - Epoch: [84][  300/ 1218]    Overall Loss 0.316461    Objective Loss 0.316461                                        LR 0.001000    Time 0.053967    
2024-06-06 01:05:35,808 - Epoch: [84][  400/ 1218]    Overall Loss 0.317586    Objective Loss 0.317586                                        LR 0.001000    Time 0.052821    
2024-06-06 01:05:40,446 - Epoch: [84][  500/ 1218]    Overall Loss 0.320287    Objective Loss 0.320287                                        LR 0.001000    Time 0.051530    
2024-06-06 01:05:45,206 - Epoch: [84][  600/ 1218]    Overall Loss 0.320469    Objective Loss 0.320469                                        LR 0.001000    Time 0.050871    
2024-06-06 01:05:49,821 - Epoch: [84][  700/ 1218]    Overall Loss 0.321140    Objective Loss 0.321140                                        LR 0.001000    Time 0.050194    
2024-06-06 01:05:54,484 - Epoch: [84][  800/ 1218]    Overall Loss 0.321969    Objective Loss 0.321969                                        LR 0.001000    Time 0.049746    
2024-06-06 01:05:59,264 - Epoch: [84][  900/ 1218]    Overall Loss 0.322678    Objective Loss 0.322678                                        LR 0.001000    Time 0.049527    
2024-06-06 01:06:03,894 - Epoch: [84][ 1000/ 1218]    Overall Loss 0.323150    Objective Loss 0.323150                                        LR 0.001000    Time 0.049203    
2024-06-06 01:06:08,491 - Epoch: [84][ 1100/ 1218]    Overall Loss 0.324068    Objective Loss 0.324068                                        LR 0.001000    Time 0.048907    
2024-06-06 01:06:13,288 - Epoch: [84][ 1200/ 1218]    Overall Loss 0.324114    Objective Loss 0.324114                                        LR 0.001000    Time 0.048827    
2024-06-06 01:06:14,075 - Epoch: [84][ 1218/ 1218]    Overall Loss 0.324392    Objective Loss 0.324392    Top1 87.775061    Top5 97.555012    LR 0.001000    Time 0.048751    
2024-06-06 01:06:14,244 - --- validate (epoch=84)-----------
2024-06-06 01:06:14,245 - 34633 samples (256 per mini-batch)
2024-06-06 01:06:19,789 - Epoch: [84][  100/  136]    Loss 0.376996    Top1 82.820312    Top5 97.523438    
2024-06-06 01:06:21,447 - Epoch: [84][  136/  136]    Loss 0.367443    Top1 83.042185    Top5 97.565905    
2024-06-06 01:06:21,623 - ==> Top1: 83.042    Top5: 97.566    Loss: 0.367

2024-06-06 01:06:21,624 - ==> Confusion:
[[  857     1     0     2     5     0     0     1     5    39     0     1     0     2     9     1     1     2     0     0     5]
 [    6   925     0     1    18    26     2    25     6     2     4     3     1     5     8     2     6     3     9     3     8]
 [   15     1   869     5     5     1    18    10     0     6     3     4     4     6     2     7     0     3     4     2     5]
 [    3     2    12   916     1     6     2     4     2     5    16     0    13     2    10     2     1     7     5     1     6]
 [   32     6     2     1   948     6     1     2     1    13     1     3     3     3     9     2     3     1     3     1    13]
 [    5    14     5     5     9   892     3    25     4     6     3    15     5    23     6     2     4     3     1     6     7]
 [    2     3    21     2     2     9   982     5     1     2     6     3     6     1     2    13     2     4     1    10     9]
 [    4     5     9     6     1    27     1   969     1     2     4    12     2     4     1     0     0     1    17     5     6]
 [    9     5     2     1     1     2     0     3   876    46     7     3     7    13    15     0     0     2     5     1     4]
 [  109     0     1     3     4     2     0     1    47   798     1     0     0    17     8     1     1     4     0     0     4]
 [    1     3     7    10     0     2     3     6    17     2   977     2     3    12     4     0     1     0     9     0     5]
 [    2     0     1     0     0    12     1     1     1     2     2   899    41    10     1     7     0    19     2     9     1]
 [    1     0     4     5     1     3     0     0     0     2     2    51   873     3     2     5     1    29     2     2     9]
 [    7     1     3     0     2     5     0     3     9    14     9    13     5   904     3     2     2     5     0     3    11]
 [   15     0     3    28    11     2     0     2    23    11     4     0     4    13   953     2     1     5     6     1    14]
 [    1     0     3     1     2     0     5     1     1     5     0    19    14     3     0   979     6    18     0     5     3]
 [    3     5     1     1     4     4     1     3     5     6     1     7     3    10     5    14   973     4     1     6    15]
 [    2     0     0     0     1     1     1     0     1     2     0    12    24     7     2     9     1   935     0     3     4]
 [    4    10     3    18     2     0     0    44     5     1     6     6     5     1    15     0     0     3   927     0     8]
 [    1     6     3     0     0     7     3     7     1     4     1    18     9    12     2     5     4     8     3   987     7]
 [  288   110   177   106   203   170    96   171   114   159   159   191   347   299   176   147   144   203   130   221 10321]]

2024-06-06 01:06:21,626 - ==> Best [Top1: 85.505   Top5: 97.927   Sparsity:0.00   Params: 424448 on epoch: 81]
2024-06-06 01:06:21,626 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:06:21,643 - 

2024-06-06 01:06:21,643 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:06:27,863 - Epoch: [85][  100/ 1218]    Overall Loss 0.327186    Objective Loss 0.327186                                        LR 0.001000    Time 0.062171    
2024-06-06 01:06:32,575 - Epoch: [85][  200/ 1218]    Overall Loss 0.328193    Objective Loss 0.328193                                        LR 0.001000    Time 0.054635    
2024-06-06 01:06:37,355 - Epoch: [85][  300/ 1218]    Overall Loss 0.328370    Objective Loss 0.328370                                        LR 0.001000    Time 0.052349    
2024-06-06 01:06:41,948 - Epoch: [85][  400/ 1218]    Overall Loss 0.327103    Objective Loss 0.327103                                        LR 0.001000    Time 0.050740    
2024-06-06 01:06:46,608 - Epoch: [85][  500/ 1218]    Overall Loss 0.327336    Objective Loss 0.327336                                        LR 0.001000    Time 0.049909    
2024-06-06 01:06:51,273 - Epoch: [85][  600/ 1218]    Overall Loss 0.326590    Objective Loss 0.326590                                        LR 0.001000    Time 0.049362    
2024-06-06 01:06:56,083 - Epoch: [85][  700/ 1218]    Overall Loss 0.327555    Objective Loss 0.327555                                        LR 0.001000    Time 0.049180    
2024-06-06 01:07:00,818 - Epoch: [85][  800/ 1218]    Overall Loss 0.325875    Objective Loss 0.325875                                        LR 0.001000    Time 0.048949    
2024-06-06 01:07:05,473 - Epoch: [85][  900/ 1218]    Overall Loss 0.325977    Objective Loss 0.325977                                        LR 0.001000    Time 0.048680    
2024-06-06 01:07:10,126 - Epoch: [85][ 1000/ 1218]    Overall Loss 0.324895    Objective Loss 0.324895                                        LR 0.001000    Time 0.048463    
2024-06-06 01:07:14,821 - Epoch: [85][ 1100/ 1218]    Overall Loss 0.324894    Objective Loss 0.324894                                        LR 0.001000    Time 0.048323    
2024-06-06 01:07:19,523 - Epoch: [85][ 1200/ 1218]    Overall Loss 0.325850    Objective Loss 0.325850                                        LR 0.001000    Time 0.048214    
2024-06-06 01:07:20,381 - Epoch: [85][ 1218/ 1218]    Overall Loss 0.325640    Objective Loss 0.325640    Top1 85.574572    Top5 99.022005    LR 0.001000    Time 0.048205    
2024-06-06 01:07:20,565 - --- validate (epoch=85)-----------
2024-06-06 01:07:20,565 - 34633 samples (256 per mini-batch)
2024-06-06 01:07:26,137 - Epoch: [85][  100/  136]    Loss 0.353044    Top1 82.257812    Top5 97.250000    
2024-06-06 01:07:27,777 - Epoch: [85][  136/  136]    Loss 0.350258    Top1 82.487801    Top5 97.248289    
2024-06-06 01:07:27,971 - ==> Top1: 82.488    Top5: 97.248    Loss: 0.350

2024-06-06 01:07:27,972 - ==> Confusion:
[[ 843    0    3    0    9    1    0    0    3   39    0    5    4    3    9    7    1    0    0    0    4]
 [   0  971    3    2   15   14    5    7    0    4    5    1    0    0    6    2    5    4   10    5    4]
 [   4    4  873    8    2    1   24    9    1    4    3    2    9    3    1    0   10    0    2    6    4]
 [   4    4   14  898    2    4    2    0    1    3   16    2   12    3   25    6    1    7    5    2    5]
 [  18   14    4    1  962   11    2    3    1    9    0    2    2    3    5    4    8    1    1    1    2]
 [   7   21    2    3   14  893    5   26    3    9    4   13    6   14    3    4    3    2    2    4    5]
 [   0    4   13    0    1    1 1028    3    0    4    3    2    2    3    1    7    3    1    1    8    1]
 [   5   14   23    2    3   32    5  909    3    4    3   10    5    3    1    1    2    4   31   10    7]
 [  15    3    2    0    2    4    1    1  824   59   19    1    8    5   40    3    1    3    6    2    3]
 [  90    0    1    0    6    0    1    0   30  846    1    0    1    9   11    2    2    1    0    0    0]
 [   1    4   11   11    0    2    4    3    4    1  996    2    0    5   12    0    1    0    4    0    3]
 [   4    3    2    0    1    9    3    6    1    3    0  882   26    5    1   15    3   21    2   18    6]
 [   0    1    2    3    0    2    1    2    2    2    1   63  862    2    1    8    5   25    5    5    3]
 [   1    1    1    0    2    8    0    1   13   25   10    9    6  901    5    1    3    2    2    6    4]
 [   9    1    2    6    7    1    0    0    6   10    2    4    4    8 1021    1    2    4    7    1    2]
 [   2    1    3    1    0    1   13    0    0    3    0   12   13    1    0  994    5   14    1    1    1]
 [   2    7    5    1    5    7    1    0    6    2    1    7    4    2    4   12  985    2    2    5   12]
 [   3    2    2    3    1    1    5    3    0    1    0   16   27    0    2    9    0  925    2    3    0]
 [   6    6    8    7    2    3    1   15    6    0    4    5    3    0   22    1    3    1  955    4    6]
 [   2    6    6    1    0    7   12    3    0    3    0   11    7    5    1    7    3    5    3 1002    4]
 [ 189  210  221   97  205  180  169  122   94  153  173  177  373  251  269  175  266  152  169  289 9998]]

2024-06-06 01:07:27,975 - ==> Best [Top1: 85.505   Top5: 97.927   Sparsity:0.00   Params: 424448 on epoch: 81]
2024-06-06 01:07:27,975 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:07:27,999 - 

2024-06-06 01:07:27,999 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:07:34,136 - Epoch: [86][  100/ 1218]    Overall Loss 0.324750    Objective Loss 0.324750                                        LR 0.001000    Time 0.061348    
2024-06-06 01:07:38,664 - Epoch: [86][  200/ 1218]    Overall Loss 0.327980    Objective Loss 0.327980                                        LR 0.001000    Time 0.053302    
2024-06-06 01:07:43,319 - Epoch: [86][  300/ 1218]    Overall Loss 0.321164    Objective Loss 0.321164                                        LR 0.001000    Time 0.051045    
2024-06-06 01:07:47,928 - Epoch: [86][  400/ 1218]    Overall Loss 0.318242    Objective Loss 0.318242                                        LR 0.001000    Time 0.049803    
2024-06-06 01:07:52,724 - Epoch: [86][  500/ 1218]    Overall Loss 0.318041    Objective Loss 0.318041                                        LR 0.001000    Time 0.049431    
2024-06-06 01:07:57,456 - Epoch: [86][  600/ 1218]    Overall Loss 0.318988    Objective Loss 0.318988                                        LR 0.001000    Time 0.049071    
2024-06-06 01:08:02,269 - Epoch: [86][  700/ 1218]    Overall Loss 0.320348    Objective Loss 0.320348                                        LR 0.001000    Time 0.048934    
2024-06-06 01:08:07,191 - Epoch: [86][  800/ 1218]    Overall Loss 0.320801    Objective Loss 0.320801                                        LR 0.001000    Time 0.048967    
2024-06-06 01:08:11,764 - Epoch: [86][  900/ 1218]    Overall Loss 0.321875    Objective Loss 0.321875                                        LR 0.001000    Time 0.048604    
2024-06-06 01:08:16,320 - Epoch: [86][ 1000/ 1218]    Overall Loss 0.322668    Objective Loss 0.322668                                        LR 0.001000    Time 0.048298    
2024-06-06 01:08:20,894 - Epoch: [86][ 1100/ 1218]    Overall Loss 0.321884    Objective Loss 0.321884                                        LR 0.001000    Time 0.048064    
2024-06-06 01:08:25,574 - Epoch: [86][ 1200/ 1218]    Overall Loss 0.321618    Objective Loss 0.321618                                        LR 0.001000    Time 0.047957    
2024-06-06 01:08:26,366 - Epoch: [86][ 1218/ 1218]    Overall Loss 0.321520    Objective Loss 0.321520    Top1 85.085575    Top5 98.533007    LR 0.001000    Time 0.047898    
2024-06-06 01:08:26,525 - --- validate (epoch=86)-----------
2024-06-06 01:08:26,525 - 34633 samples (256 per mini-batch)
2024-06-06 01:08:32,091 - Epoch: [86][  100/  136]    Loss 0.352620    Top1 83.781250    Top5 97.660156    
2024-06-06 01:08:33,772 - Epoch: [86][  136/  136]    Loss 0.353385    Top1 83.790027    Top5 97.499495    
2024-06-06 01:08:33,946 - ==> Top1: 83.790    Top5: 97.499    Loss: 0.353

2024-06-06 01:08:33,947 - ==> Confusion:
[[  803     0     7     0    26     5     2     2     5    50     0     5     2     3     5     0     4     4     0     1     7]
 [    0   958     1     2    27    12     3    14     3     1     4     7     2     2     3     1     8     2     5     3     5]
 [    5     1   876    13     5     3    17     9     1     9     0     6     2     3     1     4     5     0     1     4     5]
 [    1     2     8   932     3     5     6     3     1     0     9     2    10     4    11     3     0     4     7     0     5]
 [    9     7     1     1   984     6     1     5     3     8     1     0     4     7     3     3     4     0     0     2     5]
 [    1    25     1     1    13   908     5    24     1     1     3    13     6    15     4     3     5     2     0     6     6]
 [    1     7    11     3     3     7  1010     4     0     1     0     6     1     3     0     8     2     1     3     8     7]
 [    0    15     8     2     0    30     2   956     3     3     2     9     5     3     0     2     1     3    16    12     5]
 [    8     1     1     0     3     2     0     2   873    36     5     4     3    19    23     1     6     2     9     2     2]
 [   58     2     1     0    12     0     0     2    48   825     2     4     1    26    10     2     1     2     0     1     4]
 [    0     4     8    26     1     3     5     5    18     3   947     1     1    14     9     3     0     1     7     2     6]
 [    1     1     1     0     3    10     2     2     0     2     1   906    29     8     0    12     2    17     3     8     3]
 [    0     1     3     5     4     4     0     2     2     1     0    76   835     3     0     6     4    30     3     2    14]
 [    1     2     1     1     7    11     1     2    10    11     2    16     4   909     3     1     4     4     2     5     4]
 [    8     3     1    40    18     2     1     1    25     2     2     4     6     4   953     1     1     2    16     0     8]
 [    0     1     3     1     5     1     6     0     0     5     0    12     7     3     0   999     6    11     1     2     3]
 [    3     6     2     1     8     4     1     2     9     0     1     7    11     3     1    10   982     3     1     6    11]
 [    3     1     0     3     2     0     0     2     2     2     0    17    11     2     1     7     0   947     0     2     3]
 [    1     5     5    19     3     2     1    23     2     1     3     4     2     3    11     0     1     2   958     1    11]
 [    1     2     1     1     2    10     8    16     1     1     1    22     4     7     1     8     7     5     3   981     6]
 [  129   240   132   144   276   168    65   162   102   117    92   214   281   295   163   159   185   142   160   229 10477]]

2024-06-06 01:08:33,949 - ==> Best [Top1: 85.505   Top5: 97.927   Sparsity:0.00   Params: 424448 on epoch: 81]
2024-06-06 01:08:33,949 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:08:33,974 - 

2024-06-06 01:08:33,974 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:08:40,121 - Epoch: [87][  100/ 1218]    Overall Loss 0.340635    Objective Loss 0.340635                                        LR 0.001000    Time 0.061440    
2024-06-06 01:08:44,949 - Epoch: [87][  200/ 1218]    Overall Loss 0.331410    Objective Loss 0.331410                                        LR 0.001000    Time 0.054852    
2024-06-06 01:08:49,860 - Epoch: [87][  300/ 1218]    Overall Loss 0.327927    Objective Loss 0.327927                                        LR 0.001000    Time 0.052931    
2024-06-06 01:08:54,451 - Epoch: [87][  400/ 1218]    Overall Loss 0.325957    Objective Loss 0.325957                                        LR 0.001000    Time 0.051170    
2024-06-06 01:08:59,236 - Epoch: [87][  500/ 1218]    Overall Loss 0.325039    Objective Loss 0.325039                                        LR 0.001000    Time 0.050502    
2024-06-06 01:09:03,981 - Epoch: [87][  600/ 1218]    Overall Loss 0.323763    Objective Loss 0.323763                                        LR 0.001000    Time 0.049989    
2024-06-06 01:09:08,571 - Epoch: [87][  700/ 1218]    Overall Loss 0.323292    Objective Loss 0.323292                                        LR 0.001000    Time 0.049402    
2024-06-06 01:09:13,375 - Epoch: [87][  800/ 1218]    Overall Loss 0.323309    Objective Loss 0.323309                                        LR 0.001000    Time 0.049230    
2024-06-06 01:09:18,108 - Epoch: [87][  900/ 1218]    Overall Loss 0.322649    Objective Loss 0.322649                                        LR 0.001000    Time 0.049016    
2024-06-06 01:09:22,711 - Epoch: [87][ 1000/ 1218]    Overall Loss 0.321749    Objective Loss 0.321749                                        LR 0.001000    Time 0.048716    
2024-06-06 01:09:27,306 - Epoch: [87][ 1100/ 1218]    Overall Loss 0.322507    Objective Loss 0.322507                                        LR 0.001000    Time 0.048463    
2024-06-06 01:09:31,883 - Epoch: [87][ 1200/ 1218]    Overall Loss 0.323110    Objective Loss 0.323110                                        LR 0.001000    Time 0.048237    
2024-06-06 01:09:32,655 - Epoch: [87][ 1218/ 1218]    Overall Loss 0.323333    Objective Loss 0.323333    Top1 83.863081    Top5 97.799511    LR 0.001000    Time 0.048158    
2024-06-06 01:09:32,832 - --- validate (epoch=87)-----------
2024-06-06 01:09:32,833 - 34633 samples (256 per mini-batch)
2024-06-06 01:09:38,457 - Epoch: [87][  100/  136]    Loss 0.340580    Top1 84.289062    Top5 97.417969    
2024-06-06 01:09:40,174 - Epoch: [87][  136/  136]    Loss 0.349183    Top1 84.064332    Top5 97.360899    
2024-06-06 01:09:40,365 - ==> Top1: 84.064    Top5: 97.361    Loss: 0.349

2024-06-06 01:09:40,366 - ==> Confusion:
[[  831     0     6     0     8     2     1     2     5    55     0     3     3     4     5     0     0     1     1     0     4]
 [    3   982     3     1    10    18     2     8     2     0     6     1     3     1     5     0     2     1     8     4     3]
 [    6     3   886     7     6     7     9    10     0     3     0     1     5     1     4     5     3     1     3     2     8]
 [    1     3    15   901     4    11     2     2     3     3    12     3     3     2    30     1     3     4     8     1     4]
 [   16    11     3     2   958    12     0     2     2    13     1     5     2     4    11     5     2     1     0     0     4]
 [    3    26     4     4    15   877     2    42     0     4     1    12     5    17     5     5     5     3     5     4     4]
 [    0     3    22     1     0     7  1004     7     0     3     3     9     2     2     2     8     1     0     4     6     2]
 [    3    12     9     1     1    21     2   966     0     1     3     7     3     7     2     1     1     2    16    10     9]
 [    7     2     0     1     0     2     0     4   875    46    11     1     3    13    21     1     0     3     5     3     4]
 [   66     1     2     2    10     2     1     1    45   843     0     2     2     9     5     3     0     2     1     1     3]
 [    0     2     9    13     1     3     3     9    13     3   963     2     1     8    13     0     3     0    15     0     3]
 [    0     1     4     1     0    13     3     5     0     2     0   891    37     5     0    10     1    18     2    15     3]
 [    0     2     6     7     1     4     0     5     1     0     2    55   842     3     1     6     5    32     4     6    13]
 [    1     1     1     0     5     7     2     2    14    26    10    16     3   889     3     1     3     4     2     7     4]
 [    8     1     1     6    10     3     0     3    17     5     4     5     1     4  1009     0     2     3    12     1     3]
 [    0     4     3     0     1     1     5     0     0     2     0    17     7     2     0  1005     3    10     0     2     4]
 [    1     9     4     1     6     7     0     0     4     2     2     6     1     3     4     6   999     0     1     3    13]
 [    0     3     1     0     0     0     0     1     1     1     0    15    30     1     3    12     2   929     3     1     2]
 [    4     7     8     3     1     3     0    28     8     1     0     0     2     3    16     0     0     0   962     3     9]
 [    0     4     2     0     2     8     9    13     1     1     0    20     4     2     0     3     7     7     5   993     7]
 [  122   244   209    83   176   161    69   214   114   119   112   196   281   265   227   123   189   124   163   232 10509]]

2024-06-06 01:09:40,368 - ==> Best [Top1: 85.505   Top5: 97.927   Sparsity:0.00   Params: 424448 on epoch: 81]
2024-06-06 01:09:40,368 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:09:40,392 - 

2024-06-06 01:09:40,393 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:09:46,497 - Epoch: [88][  100/ 1218]    Overall Loss 0.325435    Objective Loss 0.325435                                        LR 0.001000    Time 0.061015    
2024-06-06 01:09:51,125 - Epoch: [88][  200/ 1218]    Overall Loss 0.324250    Objective Loss 0.324250                                        LR 0.001000    Time 0.053635    
2024-06-06 01:09:55,842 - Epoch: [88][  300/ 1218]    Overall Loss 0.319756    Objective Loss 0.319756                                        LR 0.001000    Time 0.051472    
2024-06-06 01:10:00,448 - Epoch: [88][  400/ 1218]    Overall Loss 0.316521    Objective Loss 0.316521                                        LR 0.001000    Time 0.050117    
2024-06-06 01:10:05,062 - Epoch: [88][  500/ 1218]    Overall Loss 0.316777    Objective Loss 0.316777                                        LR 0.001000    Time 0.049316    
2024-06-06 01:10:09,783 - Epoch: [88][  600/ 1218]    Overall Loss 0.317034    Objective Loss 0.317034                                        LR 0.001000    Time 0.048962    
2024-06-06 01:10:14,468 - Epoch: [88][  700/ 1218]    Overall Loss 0.317073    Objective Loss 0.317073                                        LR 0.001000    Time 0.048658    
2024-06-06 01:10:19,020 - Epoch: [88][  800/ 1218]    Overall Loss 0.317689    Objective Loss 0.317689                                        LR 0.001000    Time 0.048263    
2024-06-06 01:10:23,591 - Epoch: [88][  900/ 1218]    Overall Loss 0.317717    Objective Loss 0.317717                                        LR 0.001000    Time 0.047978    
2024-06-06 01:10:28,238 - Epoch: [88][ 1000/ 1218]    Overall Loss 0.317216    Objective Loss 0.317216                                        LR 0.001000    Time 0.047825    
2024-06-06 01:10:32,886 - Epoch: [88][ 1100/ 1218]    Overall Loss 0.316855    Objective Loss 0.316855                                        LR 0.001000    Time 0.047701    
2024-06-06 01:10:37,597 - Epoch: [88][ 1200/ 1218]    Overall Loss 0.318333    Objective Loss 0.318333                                        LR 0.001000    Time 0.047650    
2024-06-06 01:10:38,401 - Epoch: [88][ 1218/ 1218]    Overall Loss 0.318168    Objective Loss 0.318168    Top1 85.819071    Top5 98.044010    LR 0.001000    Time 0.047606    
2024-06-06 01:10:38,585 - --- validate (epoch=88)-----------
2024-06-06 01:10:38,585 - 34633 samples (256 per mini-batch)
2024-06-06 01:10:44,184 - Epoch: [88][  100/  136]    Loss 0.357853    Top1 84.074219    Top5 97.406250    
2024-06-06 01:10:45,856 - Epoch: [88][  136/  136]    Loss 0.358058    Top1 83.986371    Top5 97.381111    
2024-06-06 01:10:46,035 - ==> Top1: 83.986    Top5: 97.381    Loss: 0.358

2024-06-06 01:10:46,036 - ==> Confusion:
[[  777     2     4     1     4     3     0     1    14   101     0     2     4     2     7     1     1     1     0     0     6]
 [    2   973     3     4    10    20     2    10     0     2     5     0     7     1     3     1     2     1     4     3    10]
 [    6     2   871    12     5     3    14     7     4     8     3     2     3     2     0     0     3     4    12     1     8]
 [    0     3     9   942     3     6     1     3     2     2    12     0     8     1     8     1     0     3     4     5     3]
 [   15    17     2     2   944    12     3     2     2    17     3     1     5     2     6     4     5     0     6     0     6]
 [    1    21     2     7    12   906     3    24     6     5     6     9     4     5     4     1     2     1     4     9    11]
 [    0     1    15     2     4     5  1005     6     0     3     4     3     3     2     0     7     1     2     4    10     9]
 [    1    16     6     1     2    32     2   949     1     5     3     6     3     0     3     1     1     2    23     9    11]
 [   13     4     0     4     1     5     0     1   886    42    11     1     4     5    10     1     0     1     7     1     5]
 [   26     1     1     0     3     2     0     1    51   892     0     1     3     7     4     2     0     2     1     1     3]
 [    1     3     8    21     0     2     2     4    17     3   976     0     3     3     5     0     2     1     7     1     5]
 [    0     2     0     0     1    21     1     5     1     3     2   831    56     8     0    16     4    33     0    14    13]
 [    1     1     3     6     2     7     1     4     2     0     4    31   854     5     0    10     3    39     4     5    13]
 [    1     1     3     1     4    25     1     3    27    30    18     7     9   848     5     4     2     4     0     2     6]
 [    5     1     1    35     4     0     0     1    32    10     4     1     3     6   972     3     1     2    11     1     5]
 [    2     1     7     0     2     1     8     0     0     5     0     6    13     0     2   988     7    12     1     2     9]
 [    3    11     2     7     5     9     1     1     5     4     3     3     4     6     1    10   981     0     3     5     8]
 [    1     4     1     8     0     0     3     0     0     3     0     8    26     1     4    10     0   928     1     2     5]
 [    1     5     7    11     4     3     1    16     3     2     6     0     3     1     6     0     0     1   978     5     5]
 [    0     4     1     0     3     5     7     9     0     0     0    13    13     6     0     9     6     6     3   995     8]
 [  139   215   196   170   167   200    55   135   162   153   199    89   309   176   189   104   158    96   212   217 10591]]

2024-06-06 01:10:46,039 - ==> Best [Top1: 85.505   Top5: 97.927   Sparsity:0.00   Params: 424448 on epoch: 81]
2024-06-06 01:10:46,039 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:10:46,063 - 

2024-06-06 01:10:46,064 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:10:52,139 - Epoch: [89][  100/ 1218]    Overall Loss 0.327117    Objective Loss 0.327117                                        LR 0.001000    Time 0.060728    
2024-06-06 01:10:56,723 - Epoch: [89][  200/ 1218]    Overall Loss 0.324966    Objective Loss 0.324966                                        LR 0.001000    Time 0.053271    
2024-06-06 01:11:01,340 - Epoch: [89][  300/ 1218]    Overall Loss 0.324937    Objective Loss 0.324937                                        LR 0.001000    Time 0.050899    
2024-06-06 01:11:06,044 - Epoch: [89][  400/ 1218]    Overall Loss 0.323991    Objective Loss 0.323991                                        LR 0.001000    Time 0.049928    
2024-06-06 01:11:10,847 - Epoch: [89][  500/ 1218]    Overall Loss 0.322059    Objective Loss 0.322059                                        LR 0.001000    Time 0.049544    
2024-06-06 01:11:15,743 - Epoch: [89][  600/ 1218]    Overall Loss 0.322608    Objective Loss 0.322608                                        LR 0.001000    Time 0.049444    
2024-06-06 01:11:20,294 - Epoch: [89][  700/ 1218]    Overall Loss 0.321633    Objective Loss 0.321633                                        LR 0.001000    Time 0.048879    
2024-06-06 01:11:24,962 - Epoch: [89][  800/ 1218]    Overall Loss 0.320295    Objective Loss 0.320295                                        LR 0.001000    Time 0.048601    
2024-06-06 01:11:29,879 - Epoch: [89][  900/ 1218]    Overall Loss 0.321683    Objective Loss 0.321683                                        LR 0.001000    Time 0.048663    
2024-06-06 01:11:34,883 - Epoch: [89][ 1000/ 1218]    Overall Loss 0.321932    Objective Loss 0.321932                                        LR 0.001000    Time 0.048798    
2024-06-06 01:11:39,689 - Epoch: [89][ 1100/ 1218]    Overall Loss 0.322147    Objective Loss 0.322147                                        LR 0.001000    Time 0.048729    
2024-06-06 01:11:44,817 - Epoch: [89][ 1200/ 1218]    Overall Loss 0.321583    Objective Loss 0.321583                                        LR 0.001000    Time 0.048940    
2024-06-06 01:11:45,666 - Epoch: [89][ 1218/ 1218]    Overall Loss 0.321783    Objective Loss 0.321783    Top1 82.396088    Top5 96.332518    LR 0.001000    Time 0.048913    
2024-06-06 01:11:45,851 - --- validate (epoch=89)-----------
2024-06-06 01:11:45,851 - 34633 samples (256 per mini-batch)
2024-06-06 01:11:51,412 - Epoch: [89][  100/  136]    Loss 0.349755    Top1 83.781250    Top5 97.640625    
2024-06-06 01:11:53,077 - Epoch: [89][  136/  136]    Loss 0.344795    Top1 83.821788    Top5 97.658303    
2024-06-06 01:11:53,266 - ==> Top1: 83.822    Top5: 97.658    Loss: 0.345

2024-06-06 01:11:53,267 - ==> Confusion:
[[  849     0     5     0    11     1     0     2     8    33     1     0     1     4     5     1     2     0     0     1     7]
 [    2   965     2     4     9    22     1    10     5     1     3     1     3     3     4     1     3     3     8     3    10]
 [   12     4   877    11     1     6     7    14     2     3     9     1     2     3     1     2     3     0     5     5     2]
 [    1     2     6   947     0     2     0     2     1     4    11     3     6     3    17     1     1     3     3     1     2]
 [   27    13     0     2   952    14     0     2     2    10     1     2     4     4     7     1     3     2     1     0     7]
 [    5    16     5     7     6   886     2    29     2     4     1    11     8    21     5     1     5     3     1    12    13]
 [    2     3    18     6     0     3  1000     4     2     3     3     3     4     0     0     7     2     3     3    16     4]
 [    3    15    13     1     0    22     0   970     3     3     1     9     5     4     2     1     0     0     8    13     4]
 [   15     3     4     4     1     2     0     0   867    41    13     2     4     8    19     0     4     4     6     2     3]
 [   90     0     5     2     4     0     0     2    44   822     1     1     2    16     1     0     1     2     3     0     5]
 [    2     7    10    18     1     1     1     4    10     0   975     0     0     8    12     0     1     0     8     3     3]
 [    1     2     1     0     1    16     2     4     1     2     1   897    36     3     1     9     3    16     0     6     9]
 [    0     0     1     6     0     2     0     2     2     3     3    52   867     3     0     4     2    29     1     5    13]
 [    5     1     0     0     1    11     0     2    27    16    10    13     6   884     8     1     2     2     0     6     6]
 [    6     1     2    22     4     0     0     1    30     8     3     4     2     5   988     0     1     0    11     2     8]
 [    1     3     3     0     1     1     6     0     1     4     0    21    15     3     0   980     6    12     1     3     5]
 [    2    11     1     3     6     7     2     1     3     4     2     7     2     5     1     5   988     3     1     6    12]
 [    5     2     1     2     2     4     0     3     0     1     0    17    27     4     2     5     1   917     0     1    11]
 [    4     3     8    22     2     1     1    27     5     3     3     2     6     2     8     0     0     2   950     2     7]
 [    0     5     3     1     1     5     4     5     1     2     1    16    10     5     1     4     3     3     3  1007     8]
 [  231   199   230   225   128   161    64   194   108   114   155   148   307   224   190    86   192   130   134   270 10442]]

2024-06-06 01:11:53,269 - ==> Best [Top1: 85.505   Top5: 97.927   Sparsity:0.00   Params: 424448 on epoch: 81]
2024-06-06 01:11:53,269 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:11:53,293 - 

2024-06-06 01:11:53,294 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:11:59,440 - Epoch: [90][  100/ 1218]    Overall Loss 0.317359    Objective Loss 0.317359                                        LR 0.001000    Time 0.061442    
2024-06-06 01:12:04,196 - Epoch: [90][  200/ 1218]    Overall Loss 0.324201    Objective Loss 0.324201                                        LR 0.001000    Time 0.054490    
2024-06-06 01:12:09,004 - Epoch: [90][  300/ 1218]    Overall Loss 0.318462    Objective Loss 0.318462                                        LR 0.001000    Time 0.052347    
2024-06-06 01:12:13,816 - Epoch: [90][  400/ 1218]    Overall Loss 0.317567    Objective Loss 0.317567                                        LR 0.001000    Time 0.051283    
2024-06-06 01:12:18,483 - Epoch: [90][  500/ 1218]    Overall Loss 0.317280    Objective Loss 0.317280                                        LR 0.001000    Time 0.050358    
2024-06-06 01:12:23,118 - Epoch: [90][  600/ 1218]    Overall Loss 0.316783    Objective Loss 0.316783                                        LR 0.001000    Time 0.049686    
2024-06-06 01:12:27,724 - Epoch: [90][  700/ 1218]    Overall Loss 0.317102    Objective Loss 0.317102                                        LR 0.001000    Time 0.049165    
2024-06-06 01:12:32,307 - Epoch: [90][  800/ 1218]    Overall Loss 0.318503    Objective Loss 0.318503                                        LR 0.001000    Time 0.048746    
2024-06-06 01:12:36,894 - Epoch: [90][  900/ 1218]    Overall Loss 0.319097    Objective Loss 0.319097                                        LR 0.001000    Time 0.048425    
2024-06-06 01:12:41,701 - Epoch: [90][ 1000/ 1218]    Overall Loss 0.319381    Objective Loss 0.319381                                        LR 0.001000    Time 0.048387    
2024-06-06 01:12:46,411 - Epoch: [90][ 1100/ 1218]    Overall Loss 0.320178    Objective Loss 0.320178                                        LR 0.001000    Time 0.048268    
2024-06-06 01:12:51,444 - Epoch: [90][ 1200/ 1218]    Overall Loss 0.321084    Objective Loss 0.321084                                        LR 0.001000    Time 0.048438    
2024-06-06 01:12:52,210 - Epoch: [90][ 1218/ 1218]    Overall Loss 0.321037    Objective Loss 0.321037    Top1 84.596577    Top5 96.577017    LR 0.001000    Time 0.048351    
2024-06-06 01:12:52,371 - --- validate (epoch=90)-----------
2024-06-06 01:12:52,371 - 34633 samples (256 per mini-batch)
2024-06-06 01:12:57,865 - Epoch: [90][  100/  136]    Loss 0.358499    Top1 83.308594    Top5 97.378906    
2024-06-06 01:12:59,537 - Epoch: [90][  136/  136]    Loss 0.357008    Top1 83.229867    Top5 97.395548    
2024-06-06 01:12:59,729 - ==> Top1: 83.230    Top5: 97.396    Loss: 0.357

2024-06-06 01:12:59,730 - ==> Confusion:
[[  832     0     6     2    16     1     0     1     5    43     0     1     4     4     6     1     0     0     3     2     4]
 [    1   944     4     1    25    30     2    12     3     4     3     2     5     1     4     3     2     2     6     2     7]
 [    9     4   858     9     6     0    28     7     2     6     2     3     5     5     4    10     1     1     0     4     6]
 [    2     3    13   902     6     6     3     5     2     2    11     1    11     6    18     1     1     6     7     0    10]
 [   18     4     2     0   977     7     0     2     4     8     0     6     2     3     2     2     5     2     3     3     4]
 [    6    13     4     2    19   916     1    20     1     5     1    14     6    11     3     3     1     2     3     6     6]
 [    1     2    12     1     3     8  1022     7     0     0     1     2     6     0     0     3     3     2     0     9     4]
 [    2     5    16     0     3    36     7   956     3     3     4     8     5     1     0     0     0     4    10     8     6]
 [   10     2     0     4     0     7     0     2   890    30     8     4     6    15    11     0     3     3     4     0     3]
 [   81     0     1     1     8     3     1     1    64   806     1     2     2    19     5     0     2     0     0     1     3]
 [    0     2     5    12     3     3     1     8    14     5   978     2     2     9     3     3     0     0     5     5     4]
 [    1     0     2     2     3    11     1     4     3     4     0   888    30    10     0    12     3    11     2    21     3]
 [    3     0     3     4     1     6     1     4     0     1     2    54   868     2     1     8     5    18     2     8     4]
 [    3     0     1     0     8    14     1     1    11    13     5    11     5   897     1     5     5     2     1     6    11]
 [   11     2     3    15    18     4     0     3    38     8     6     5     4     7   954     0     1     1    12     2     4]
 [    1     1     1     0     2     2     5     2     2     3     0    22     9     3     0   988     7     8     0     6     4]
 [    3     4     1     1     6    13     1     2     4     1     1     8     4     7     2     5   991     1     2     7     8]
 [    3     3     0     4     0     3     2     2     3     4     0    16    26     2     4    11     3   913     1     2     3]
 [    1     9     7     9     2     5     1    31     5     1     7     3     3     2    11     0     0     0   953     0     8]
 [    1     3     3     1     1    12    10     4     0     1     0    16     8     4     1     4     3     3     4  1005     4]
 [  199   153   181   109   271   246   118   166   123   107   162   182   352   281   140   128   201    89   122   315 10287]]

2024-06-06 01:12:59,732 - ==> Best [Top1: 85.505   Top5: 97.927   Sparsity:0.00   Params: 424448 on epoch: 81]
2024-06-06 01:12:59,732 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:12:59,750 - 

2024-06-06 01:12:59,751 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:13:05,874 - Epoch: [91][  100/ 1218]    Overall Loss 0.322562    Objective Loss 0.322562                                        LR 0.001000    Time 0.061202    
2024-06-06 01:13:10,581 - Epoch: [91][  200/ 1218]    Overall Loss 0.319930    Objective Loss 0.319930                                        LR 0.001000    Time 0.054125    
2024-06-06 01:13:15,154 - Epoch: [91][  300/ 1218]    Overall Loss 0.320831    Objective Loss 0.320831                                        LR 0.001000    Time 0.051320    
2024-06-06 01:13:19,821 - Epoch: [91][  400/ 1218]    Overall Loss 0.322243    Objective Loss 0.322243                                        LR 0.001000    Time 0.050154    
2024-06-06 01:13:24,470 - Epoch: [91][  500/ 1218]    Overall Loss 0.319396    Objective Loss 0.319396                                        LR 0.001000    Time 0.049417    
2024-06-06 01:13:29,238 - Epoch: [91][  600/ 1218]    Overall Loss 0.320334    Objective Loss 0.320334                                        LR 0.001000    Time 0.049123    
2024-06-06 01:13:33,860 - Epoch: [91][  700/ 1218]    Overall Loss 0.320223    Objective Loss 0.320223                                        LR 0.001000    Time 0.048707    
2024-06-06 01:13:38,752 - Epoch: [91][  800/ 1218]    Overall Loss 0.320324    Objective Loss 0.320324                                        LR 0.001000    Time 0.048731    
2024-06-06 01:13:43,596 - Epoch: [91][  900/ 1218]    Overall Loss 0.320433    Objective Loss 0.320433                                        LR 0.001000    Time 0.048695    
2024-06-06 01:13:48,339 - Epoch: [91][ 1000/ 1218]    Overall Loss 0.319524    Objective Loss 0.319524                                        LR 0.001000    Time 0.048567    
2024-06-06 01:13:53,071 - Epoch: [91][ 1100/ 1218]    Overall Loss 0.319585    Objective Loss 0.319585                                        LR 0.001000    Time 0.048452    
2024-06-06 01:13:57,727 - Epoch: [91][ 1200/ 1218]    Overall Loss 0.319709    Objective Loss 0.319709                                        LR 0.001000    Time 0.048292    
2024-06-06 01:13:58,564 - Epoch: [91][ 1218/ 1218]    Overall Loss 0.319646    Objective Loss 0.319646    Top1 82.396088    Top5 96.088020    LR 0.001000    Time 0.048266    
2024-06-06 01:13:58,740 - --- validate (epoch=91)-----------
2024-06-06 01:13:58,740 - 34633 samples (256 per mini-batch)
2024-06-06 01:14:04,257 - Epoch: [91][  100/  136]    Loss 0.351048    Top1 84.484375    Top5 97.542969    
2024-06-06 01:14:05,966 - Epoch: [91][  136/  136]    Loss 0.354617    Top1 84.211590    Top5 97.508157    
2024-06-06 01:14:06,139 - ==> Top1: 84.212    Top5: 97.508    Loss: 0.355

2024-06-06 01:14:06,140 - ==> Confusion:
[[  821     1     4     0    15     4     0     2     6    42     0     2     2     6     4     4     4     2     0     2    10]
 [    5   966     0     1    15    30     0    13     3     1     4     0     3     0     0     0     6     1     4     5     6]
 [   11     3   849     9     3     4    19    18     0     6     2     2     2     5     4     3     7     0     9     5     9]
 [    6     2    11   912     3     6     3     6     1     2    12     0    10     2    20     2     2     7     1     2     6]
 [   17    12     0     1   965     9     2     2     2    10     0     0     0     5     8     3     3     3     1     0    11]
 [    8    19     5     4    10   902     2    32     3     4     1     5     5    10     2     2     7     5     5     8     4]
 [    0     4    13     2     1     8  1000    12     1     3     1     2     1     0     0     4     2     5     2    14    11]
 [    6     7     9     2     4    34     3   957     2     5     3     5     2     0     1     0     1     2    18    11     5]
 [   10     4     1     0     2     3     2     2   862    45     7     1     9    16    21     0     2     4     4     2     5]
 [   94     0     1     1    11     4     1     1    32   818     1     0     2    18     5     1     2     5     0     1     3]
 [    2     8     6    14     1    13     2     9    16     2   931     2     1    16    15     0     2     2     7     4    11]
 [    2     3     2     1     0    14     4    10     2     2     0   897    20     7     0     4     3    14     0    19     7]
 [    6     0     0     5     0    10     3    10     1     1     1    64   836     3     1     2     1    31     2    11     7]
 [    4     1     0     1     4    13     1     3     7    12     3    12     5   911     2     1     0     1     2     9     9]
 [    7     4     0     8    10     2     1     1    22     9     1     3     1     6   989     0     0     4    15     5    10]
 [    1     0     5     0     5     1     6     1     1     2     0    22     9     3     0   956    18    24     1     7     4]
 [    3     7     2     1     6     6     0     1     3     2     1     3     2     4     2     3  1003     1     0     9    13]
 [    2     3     1     3     0     1     0     3     0     3     0    16    18     1     0     6     0   936     2     5     5]
 [    4     6     5     9     3     1     1    32     9     2     1     2     0     2    14     0     2     2   957     1     5]
 [    5     2     2     0     1    12     7     8     0     1     0    12     3     5     0     2     7     5     1  1008     7]
 [  190   180   140    71   182   195    67   216    72   102    99   129   279   286   182    57   220   120   148   308 10689]]

2024-06-06 01:14:06,142 - ==> Best [Top1: 85.505   Top5: 97.927   Sparsity:0.00   Params: 424448 on epoch: 81]
2024-06-06 01:14:06,142 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:14:06,167 - 

2024-06-06 01:14:06,168 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:14:12,518 - Epoch: [92][  100/ 1218]    Overall Loss 0.310112    Objective Loss 0.310112                                        LR 0.001000    Time 0.063478    
2024-06-06 01:14:17,425 - Epoch: [92][  200/ 1218]    Overall Loss 0.310175    Objective Loss 0.310175                                        LR 0.001000    Time 0.056262    
2024-06-06 01:14:22,078 - Epoch: [92][  300/ 1218]    Overall Loss 0.312416    Objective Loss 0.312416                                        LR 0.001000    Time 0.053014    
2024-06-06 01:14:26,687 - Epoch: [92][  400/ 1218]    Overall Loss 0.315095    Objective Loss 0.315095                                        LR 0.001000    Time 0.051277    
2024-06-06 01:14:31,385 - Epoch: [92][  500/ 1218]    Overall Loss 0.316103    Objective Loss 0.316103                                        LR 0.001000    Time 0.050414    
2024-06-06 01:14:36,210 - Epoch: [92][  600/ 1218]    Overall Loss 0.314709    Objective Loss 0.314709                                        LR 0.001000    Time 0.050050    
2024-06-06 01:14:40,800 - Epoch: [92][  700/ 1218]    Overall Loss 0.315109    Objective Loss 0.315109                                        LR 0.001000    Time 0.049454    
2024-06-06 01:14:45,622 - Epoch: [92][  800/ 1218]    Overall Loss 0.317194    Objective Loss 0.317194                                        LR 0.001000    Time 0.049298    
2024-06-06 01:14:50,185 - Epoch: [92][  900/ 1218]    Overall Loss 0.318071    Objective Loss 0.318071                                        LR 0.001000    Time 0.048888    
2024-06-06 01:14:54,799 - Epoch: [92][ 1000/ 1218]    Overall Loss 0.317568    Objective Loss 0.317568                                        LR 0.001000    Time 0.048612    
2024-06-06 01:14:59,455 - Epoch: [92][ 1100/ 1218]    Overall Loss 0.317348    Objective Loss 0.317348                                        LR 0.001000    Time 0.048422    
2024-06-06 01:15:04,180 - Epoch: [92][ 1200/ 1218]    Overall Loss 0.316906    Objective Loss 0.316906                                        LR 0.001000    Time 0.048323    
2024-06-06 01:15:05,064 - Epoch: [92][ 1218/ 1218]    Overall Loss 0.316910    Objective Loss 0.316910    Top1 84.107579    Top5 98.044010    LR 0.001000    Time 0.048333    
2024-06-06 01:15:05,233 - --- validate (epoch=92)-----------
2024-06-06 01:15:05,233 - 34633 samples (256 per mini-batch)
2024-06-06 01:15:10,603 - Epoch: [92][  100/  136]    Loss 0.353933    Top1 83.617188    Top5 97.539062    
2024-06-06 01:15:12,272 - Epoch: [92][  136/  136]    Loss 0.350894    Top1 83.593682    Top5 97.557243    
2024-06-06 01:15:12,437 - ==> Top1: 83.594    Top5: 97.557    Loss: 0.351

2024-06-06 01:15:12,438 - ==> Confusion:
[[  795     4     4     2     8     0     1     1    10    84     2     0     1     2     3     0     3     1     0     2     8]
 [    0   979     4     1    16    11     2     5     5     6     3     1     2     0     2     1     4     0    11     3     7]
 [    4     3   877    10     4     1    12     5     0    12     9     1     4     3     3     3     6     2     7     2     2]
 [    0     5     5   900     1     3     6     1     0     5    13     1     6     2    24     1     2    10    24     0     7]
 [   12     9     4     2   959     9     0     1     3    24     1     0     0     4    13     1     5     1     0     0     6]
 [    1    36     3     3    14   853     1    53     3     9     3     6     6    25     0     3     5     4     2     3    10]
 [    0     8    11     0     2     4  1028     3     0     3     6     2     1     0     0     8     2     0     3     2     3]
 [    1    10    11     1     2    10     3   962     1    11     6     3     3     3     0     0     1     2    39     3     5]
 [    8     1     2     2     2     0     1     1   887    53    11     1     4     4    15     0     0     1     6     0     3]
 [   39     3     1     0     6     0     0     0    43   894     0     0     1     5     2     1     0     2     1     1     2]
 [    0     4     4     6     1     2     1     3    16     2   976     0     1    10     8     0     2     0    22     1     5]
 [    0     6     4     0     2    18     5     9     2     6     1   845    42     9     1    13     6    22     3    10     7]
 [    0     7     4     4     2     3     2     4     5     6     0    51   856     6     2     6     2    24     3     7     1]
 [    0     3     2     0     4     5     1     6    18    26     6     6     2   902     1     2     2     2     2     5     6]
 [    6     3     1    12     6     0     0     0    35    15     6     2     2     5   977     0     1     4    20     0     3]
 [    1     3     5     1     4     0     7     0     0     9     0     9     5     3     0   980    10    17     5     2     5]
 [    2    10     3     1     6     4     0     0     3     6     1     3     1     3     0     6  1002     0     2     3    16]
 [    2     4     1     0     0     1     2     1     4     4     1     8    18     4     1     7     3   935     3     3     3]
 [    0    15     7     3     1     0     1     9     7     3     3     0     0     2    10     0     3     0   990     1     3]
 [    1     9     4     0     2     9    23    26     2     4     2    14     3     5     0     8     8     0    11   950     7]
 [  116   224   188   108   169   114   126   183   148   197   157   131   282   257   205   116   229   129   241   208 10404]]

2024-06-06 01:15:12,440 - ==> Best [Top1: 85.505   Top5: 97.927   Sparsity:0.00   Params: 424448 on epoch: 81]
2024-06-06 01:15:12,440 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:15:12,461 - 

2024-06-06 01:15:12,461 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:15:18,801 - Epoch: [93][  100/ 1218]    Overall Loss 0.322112    Objective Loss 0.322112                                        LR 0.001000    Time 0.063377    
2024-06-06 01:15:23,654 - Epoch: [93][  200/ 1218]    Overall Loss 0.321404    Objective Loss 0.321404                                        LR 0.001000    Time 0.055940    
2024-06-06 01:15:28,365 - Epoch: [93][  300/ 1218]    Overall Loss 0.319492    Objective Loss 0.319492                                        LR 0.001000    Time 0.052991    
2024-06-06 01:15:32,981 - Epoch: [93][  400/ 1218]    Overall Loss 0.318632    Objective Loss 0.318632                                        LR 0.001000    Time 0.051274    
2024-06-06 01:15:37,703 - Epoch: [93][  500/ 1218]    Overall Loss 0.318288    Objective Loss 0.318288                                        LR 0.001000    Time 0.050458    
2024-06-06 01:15:42,445 - Epoch: [93][  600/ 1218]    Overall Loss 0.317677    Objective Loss 0.317677                                        LR 0.001000    Time 0.049948    
2024-06-06 01:15:47,157 - Epoch: [93][  700/ 1218]    Overall Loss 0.316953    Objective Loss 0.316953                                        LR 0.001000    Time 0.049541    
2024-06-06 01:15:51,823 - Epoch: [93][  800/ 1218]    Overall Loss 0.316338    Objective Loss 0.316338                                        LR 0.001000    Time 0.049177    
2024-06-06 01:15:56,664 - Epoch: [93][  900/ 1218]    Overall Loss 0.315400    Objective Loss 0.315400                                        LR 0.001000    Time 0.049090    
2024-06-06 01:16:01,432 - Epoch: [93][ 1000/ 1218]    Overall Loss 0.316450    Objective Loss 0.316450                                        LR 0.001000    Time 0.048947    
2024-06-06 01:16:06,024 - Epoch: [93][ 1100/ 1218]    Overall Loss 0.317051    Objective Loss 0.317051                                        LR 0.001000    Time 0.048670    
2024-06-06 01:16:10,758 - Epoch: [93][ 1200/ 1218]    Overall Loss 0.317278    Objective Loss 0.317278                                        LR 0.001000    Time 0.048558    
2024-06-06 01:16:11,576 - Epoch: [93][ 1218/ 1218]    Overall Loss 0.317234    Objective Loss 0.317234    Top1 82.640587    Top5 98.533007    LR 0.001000    Time 0.048511    
2024-06-06 01:16:11,780 - --- validate (epoch=93)-----------
2024-06-06 01:16:11,780 - 34633 samples (256 per mini-batch)
2024-06-06 01:16:17,430 - Epoch: [93][  100/  136]    Loss 0.351408    Top1 84.148438    Top5 97.578125    
2024-06-06 01:16:19,176 - Epoch: [93][  136/  136]    Loss 0.354358    Top1 84.197153    Top5 97.589005    
2024-06-06 01:16:19,355 - ==> Top1: 84.197    Top5: 97.589    Loss: 0.354

2024-06-06 01:16:19,356 - ==> Confusion:
[[  781     1     1     0     6     3     0     1    16    99     2     0     8     0     6     1     1     0     0     1     4]
 [    0   949     4     1    16    23     2    13     6     3     5     4     2     3     9     0     6     2     7     0     8]
 [    2     0   891     3     1     3    12     9     0     9    11     2     5     3     6     3     1     0     4     1     4]
 [    3     4     9   898     3     8     5     3     4     5    14     2     2     4    27     3     0     5    13     0     4]
 [   20     9     4     2   956    10     0     1     4    10     0     3     4     8     8     1     5     0     2     1     6]
 [    4    15     1     2     6   941     2    20     2     9     1     7     3     8     3     2     1     4     1     1    10]
 [    0     3    15     0     0    11  1015     4     0     3     6     6     2     4     0     4     2     0     4     3     4]
 [    2     6    14     0     1    55     6   938     4     6     6    10     1     4     0     1     0     2     9     5     7]
 [    9     1     3     1     1     1     0     0   894    37     6     0     4    17    16     0     0     3     3     2     4]
 [   34     1     0     0     2     2     0     0    34   896     2     1     4    13     5     1     0     3     0     0     3]
 [    1     6     4    10     1     6     3     8    16     3   976     0     0    11     5     0     3     0     6     0     5]
 [    3     0     0     0     1    26     5     6     1     3     1   879    27    11     0    11     3    20     1     9     4]
 [    1     1     5     3     1    10     1     4     3     1     5    76   824     4     1     9     3    29     2     2    10]
 [    0     1     3     0     3    18     1     4    21    20     6    11     5   880     2     3     3     1     2     7    10]
 [    4     4     5     3     7     4     0     2    20    10     5     4     3     6  1004     0     2     3     6     0     6]
 [    1     0     5     0     1     1     4     0     1     1     1    24     6     2     0   983    12    16     1     1     6]
 [    0     7     2     2     7     5     2     2     6     1     4     6     5     3     1     9   989     0     1     2    18]
 [    2     1     3     2     0     4     1     3     1     1     0    16    21     1     3     8     1   929     1     1     6]
 [    3     5    10     8     1     2     3    20    10     3     4     0     3     3    27     0     3     0   942     6     5]
 [    2     6     7     2     0    25    16    10     1     0     0    17     8     6     0     6     3     2     2   965    10]
 [  186   123   202    80   157   210    80   179   128   160   156   163   288   256   214    96   178   124   128   194 10630]]

2024-06-06 01:16:19,359 - ==> Best [Top1: 85.505   Top5: 97.927   Sparsity:0.00   Params: 424448 on epoch: 81]
2024-06-06 01:16:19,359 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:16:19,383 - 

2024-06-06 01:16:19,383 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:16:25,591 - Epoch: [94][  100/ 1218]    Overall Loss 0.308093    Objective Loss 0.308093                                        LR 0.001000    Time 0.062048    
2024-06-06 01:16:30,201 - Epoch: [94][  200/ 1218]    Overall Loss 0.302426    Objective Loss 0.302426                                        LR 0.001000    Time 0.054067    
2024-06-06 01:16:34,777 - Epoch: [94][  300/ 1218]    Overall Loss 0.308114    Objective Loss 0.308114                                        LR 0.001000    Time 0.051292    
2024-06-06 01:16:39,432 - Epoch: [94][  400/ 1218]    Overall Loss 0.310791    Objective Loss 0.310791                                        LR 0.001000    Time 0.050102    
2024-06-06 01:16:44,148 - Epoch: [94][  500/ 1218]    Overall Loss 0.312304    Objective Loss 0.312304                                        LR 0.001000    Time 0.049511    
2024-06-06 01:16:48,797 - Epoch: [94][  600/ 1218]    Overall Loss 0.313741    Objective Loss 0.313741                                        LR 0.001000    Time 0.049004    
2024-06-06 01:16:53,458 - Epoch: [94][  700/ 1218]    Overall Loss 0.314267    Objective Loss 0.314267                                        LR 0.001000    Time 0.048657    
2024-06-06 01:16:58,134 - Epoch: [94][  800/ 1218]    Overall Loss 0.313712    Objective Loss 0.313712                                        LR 0.001000    Time 0.048417    
2024-06-06 01:17:02,702 - Epoch: [94][  900/ 1218]    Overall Loss 0.313528    Objective Loss 0.313528                                        LR 0.001000    Time 0.048111    
2024-06-06 01:17:07,324 - Epoch: [94][ 1000/ 1218]    Overall Loss 0.314266    Objective Loss 0.314266                                        LR 0.001000    Time 0.047920    
2024-06-06 01:17:11,933 - Epoch: [94][ 1100/ 1218]    Overall Loss 0.314341    Objective Loss 0.314341                                        LR 0.001000    Time 0.047752    
2024-06-06 01:17:16,647 - Epoch: [94][ 1200/ 1218]    Overall Loss 0.314960    Objective Loss 0.314960                                        LR 0.001000    Time 0.047697    
2024-06-06 01:17:17,498 - Epoch: [94][ 1218/ 1218]    Overall Loss 0.315208    Objective Loss 0.315208    Top1 85.330073    Top5 97.310513    LR 0.001000    Time 0.047690    
2024-06-06 01:17:17,683 - --- validate (epoch=94)-----------
2024-06-06 01:17:17,683 - 34633 samples (256 per mini-batch)
2024-06-06 01:17:23,332 - Epoch: [94][  100/  136]    Loss 0.341731    Top1 84.226562    Top5 97.574219    
2024-06-06 01:17:25,038 - Epoch: [94][  136/  136]    Loss 0.346585    Top1 84.119193    Top5 97.531256    
2024-06-06 01:17:25,199 - ==> Top1: 84.119    Top5: 97.531    Loss: 0.347

2024-06-06 01:17:25,200 - ==> Confusion:
[[  724     1     4     1    18     2     0     4     8   129     0     4     2     5     7     2     3     3     2     1    11]
 [    2   967     2     0    15    14     1    14     4     4     3     6     0     5     2     1     5     1     8     2     7]
 [    3     1   838    16     3     4    21    15     0    11     9     4     4     7     3     8     5     2     5     4     7]
 [    3     3     4   922     2     6     1     4     3     4    11     2     4     5    22     3     1     1    10     2     3]
 [    6     8     2     1   981     4     0     3     2    18     0     1     2     4     5     7     3     0     2     1     4]
 [    1    17     3     4    10   884     5    53     1     6     3     6     2    20     4     0     6     3     3     5     7]
 [    1     2    14     1     1     3  1017     6     0     4     4     4     1     0     0     4     1     4     0    15     4]
 [    2     7     5     0     1    16     3   973     2     3     6     6     3     3     2     1     0     3    24    12     5]
 [    9     5     1     0     1     2     0     3   864    63     8     3     2    12    16     0     2     1     5     1     4]
 [   25     1     1     0     2     1     0     2    16   913     3     3     1    19     6     1     0     2     0     0     5]
 [    1     2     2     9     3     5     2     5    11     1   993     1     1     7     6     0     1     0     9     1     4]
 [    0     1     1     0     0    16     1     6     1     2     1   888    26    20     0    16     1    17     2    11     1]
 [    1     1     2     6     3    10     0     9     2     2     4    66   792     6     2    16     5    32     6    12    18]
 [    2     1     0     0     5    12     1     3     7    20     7     9     1   913     1     4     1     2     1     2     9]
 [    5     4     1    13    10     1     0     2    20    19     3     6     1     3   983     1     0     2    11     1    12]
 [    1     1     4     1     2     0     4     1     0     4     0     4     6     3     0  1013     7     7     0     2     6]
 [    1     6     8     3     4     3     1     1     4     3     4     1     2     8     3    11   982     4     0     6    17]
 [    2     2     2     3     1     2     2     3     0     4     1    16    11     7     5    14     0   921     1     4     4]
 [    2     3     1     5     2     1     1    21     4     2     3     4     3     2    15     1     1     0   980     2     5]
 [    0     3     2     0     1     6     5     8     1     2     1    18     3     9     1    10    10     4     2   993     9]
 [  113   196   160   105   221   139   118   168    75   166   173   178   230   272   195   157   161    79   179   255 10592]]

2024-06-06 01:17:25,202 - ==> Best [Top1: 85.505   Top5: 97.927   Sparsity:0.00   Params: 424448 on epoch: 81]
2024-06-06 01:17:25,202 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:17:25,228 - 

2024-06-06 01:17:25,228 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:17:31,320 - Epoch: [95][  100/ 1218]    Overall Loss 0.310889    Objective Loss 0.310889                                        LR 0.001000    Time 0.060888    
2024-06-06 01:17:35,956 - Epoch: [95][  200/ 1218]    Overall Loss 0.314699    Objective Loss 0.314699                                        LR 0.001000    Time 0.053614    
2024-06-06 01:17:40,617 - Epoch: [95][  300/ 1218]    Overall Loss 0.315789    Objective Loss 0.315789                                        LR 0.001000    Time 0.051273    
2024-06-06 01:17:45,214 - Epoch: [95][  400/ 1218]    Overall Loss 0.316499    Objective Loss 0.316499                                        LR 0.001000    Time 0.049941    
2024-06-06 01:17:49,825 - Epoch: [95][  500/ 1218]    Overall Loss 0.315986    Objective Loss 0.315986                                        LR 0.001000    Time 0.049172    
2024-06-06 01:17:54,708 - Epoch: [95][  600/ 1218]    Overall Loss 0.316034    Objective Loss 0.316034                                        LR 0.001000    Time 0.049111    
2024-06-06 01:17:59,338 - Epoch: [95][  700/ 1218]    Overall Loss 0.315471    Objective Loss 0.315471                                        LR 0.001000    Time 0.048706    
2024-06-06 01:18:04,139 - Epoch: [95][  800/ 1218]    Overall Loss 0.315967    Objective Loss 0.315967                                        LR 0.001000    Time 0.048617    
2024-06-06 01:18:08,966 - Epoch: [95][  900/ 1218]    Overall Loss 0.317013    Objective Loss 0.317013                                        LR 0.001000    Time 0.048576    
2024-06-06 01:18:13,774 - Epoch: [95][ 1000/ 1218]    Overall Loss 0.317721    Objective Loss 0.317721                                        LR 0.001000    Time 0.048525    
2024-06-06 01:18:18,570 - Epoch: [95][ 1100/ 1218]    Overall Loss 0.317605    Objective Loss 0.317605                                        LR 0.001000    Time 0.048472    
2024-06-06 01:18:23,257 - Epoch: [95][ 1200/ 1218]    Overall Loss 0.317760    Objective Loss 0.317760                                        LR 0.001000    Time 0.048336    
2024-06-06 01:18:24,070 - Epoch: [95][ 1218/ 1218]    Overall Loss 0.317533    Objective Loss 0.317533    Top1 85.085575    Top5 96.821516    LR 0.001000    Time 0.048289    
2024-06-06 01:18:24,242 - --- validate (epoch=95)-----------
2024-06-06 01:18:24,242 - 34633 samples (256 per mini-batch)
2024-06-06 01:18:29,656 - Epoch: [95][  100/  136]    Loss 0.349122    Top1 84.027344    Top5 97.601562    
2024-06-06 01:18:31,343 - Epoch: [95][  136/  136]    Loss 0.349696    Top1 83.925736    Top5 97.482170    
2024-06-06 01:18:31,553 - ==> Top1: 83.926    Top5: 97.482    Loss: 0.350

2024-06-06 01:18:31,554 - ==> Confusion:
[[  783     0     2     1     7     0     1     1     8    94     0     3     1     2    18     1     1     1     1     1     5]
 [    3   934     4     1    28    14     1    12     6     4     2     6     1     0     8     1     8     2    14     2    12]
 [    4     3   910     5     3     1     7     6     0     3     2     4     3     1     2     2     3     1     7     0     3]
 [    7     3    20   895     3     2     1     1     3     3    11     0     4     4    32     3     1     3    13     1     6]
 [   12     3     2     2   965     9     1     2     2    18     0     1     0     1    18     4     5     0     3     0     6]
 [    4    19     6     3    12   884     3    27     2     7     3     9     2    20    10     2     5     2     7     8     8]
 [    3     2    37     0     2     3  1001     1     0     5     2     5     0     1     2     6     0     5     4     4     3]
 [    2     7    14     3     2    33     0   931     3     6     6    10     5     3     3     0     0     4    23    16     6]
 [    3     2     1     0     1     1     0     0   881    53     8     2     2     9    23     0     5     2     6     0     3]
 [   35     0     0     1     5     1     0     0    38   882     1     2     0    17    13     0     0     1     2     0     3]
 [    0     4    12    16     1     2     6     4    12     4   960     2     0     8    12     1     2     0     9     1     8]
 [    2     3     2     2     3    12     3     8     2     2     1   873    29    15     1    11     5    19     2    15     1]
 [    1     1     6     4     2     3     2     2     2     3     0    54   850     3     5     7     6    21     2     4    17]
 [    4     1     2     0     2     7     0     2    12    14     5     5     4   913    14     2     2     0     1     5     6]
 [    3     0     2    10     6     0     1     2    22    12     3     1     1     3  1016     1     0     2     8     1     4]
 [    5     1     6     0     3     0     8     0     1     3     0    12     4     0     0  1008     4     5     1     3     2]
 [    2     8     3     2    12     5     3     1     3     4     4     5     1     1     1    11   989     1     3     3    10]
 [    3     2     3     2     2     3     5     0     1     1     0    13    18     2     3    12     3   922     2     2     6]
 [    1     3    12    10     4     2     0    14     8     2     2     3     4     2    23     1     0     0   958     1     8]
 [    3     3     6     0     1    10    18     8     0     2     0    17     6     3     1     6     7     2     6   978    11]
 [  180   128   260    85   218   113    90   109   117   186   121   180   258   244   313   155   177    89   165   211 10533]]

2024-06-06 01:18:31,557 - ==> Best [Top1: 85.505   Top5: 97.927   Sparsity:0.00   Params: 424448 on epoch: 81]
2024-06-06 01:18:31,558 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:18:31,591 - 

2024-06-06 01:18:31,591 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:18:37,854 - Epoch: [96][  100/ 1218]    Overall Loss 0.297036    Objective Loss 0.297036                                        LR 0.001000    Time 0.062606    
2024-06-06 01:18:42,657 - Epoch: [96][  200/ 1218]    Overall Loss 0.303007    Objective Loss 0.303007                                        LR 0.001000    Time 0.055308    
2024-06-06 01:18:47,342 - Epoch: [96][  300/ 1218]    Overall Loss 0.308866    Objective Loss 0.308866                                        LR 0.001000    Time 0.052481    
2024-06-06 01:18:52,195 - Epoch: [96][  400/ 1218]    Overall Loss 0.306691    Objective Loss 0.306691                                        LR 0.001000    Time 0.051487    
2024-06-06 01:18:56,802 - Epoch: [96][  500/ 1218]    Overall Loss 0.307107    Objective Loss 0.307107                                        LR 0.001000    Time 0.050400    
2024-06-06 01:19:01,494 - Epoch: [96][  600/ 1218]    Overall Loss 0.306427    Objective Loss 0.306427                                        LR 0.001000    Time 0.049816    
2024-06-06 01:19:06,063 - Epoch: [96][  700/ 1218]    Overall Loss 0.308383    Objective Loss 0.308383                                        LR 0.001000    Time 0.049225    
2024-06-06 01:19:10,912 - Epoch: [96][  800/ 1218]    Overall Loss 0.308538    Objective Loss 0.308538                                        LR 0.001000    Time 0.049130    
2024-06-06 01:19:15,519 - Epoch: [96][  900/ 1218]    Overall Loss 0.309958    Objective Loss 0.309958                                        LR 0.001000    Time 0.048787    
2024-06-06 01:19:20,291 - Epoch: [96][ 1000/ 1218]    Overall Loss 0.309946    Objective Loss 0.309946                                        LR 0.001000    Time 0.048678    
2024-06-06 01:19:24,983 - Epoch: [96][ 1100/ 1218]    Overall Loss 0.310790    Objective Loss 0.310790                                        LR 0.001000    Time 0.048517    
2024-06-06 01:19:29,531 - Epoch: [96][ 1200/ 1218]    Overall Loss 0.310925    Objective Loss 0.310925                                        LR 0.001000    Time 0.048262    
2024-06-06 01:19:30,319 - Epoch: [96][ 1218/ 1218]    Overall Loss 0.311090    Objective Loss 0.311090    Top1 86.063570    Top5 97.555012    LR 0.001000    Time 0.048195    
2024-06-06 01:19:30,487 - --- validate (epoch=96)-----------
2024-06-06 01:19:30,487 - 34633 samples (256 per mini-batch)
2024-06-06 01:19:36,031 - Epoch: [96][  100/  136]    Loss 0.341914    Top1 84.226562    Top5 97.773438    
2024-06-06 01:19:37,750 - Epoch: [96][  136/  136]    Loss 0.341204    Top1 84.263564    Top5 97.779574    
2024-06-06 01:19:37,928 - ==> Top1: 84.264    Top5: 97.780    Loss: 0.341

2024-06-06 01:19:37,929 - ==> Confusion:
[[  823     0     5     0    11     3     1     1    10    54     1     1     2     1     7     1     1     2     2     2     3]
 [    1   951     5     2    29    17     5    12     5     1     3     1     3     2     3     0     3     2     9     2     7]
 [    4     4   909     4     1     3     7     2     0     8     4     1     0     3     2     2     1     0     8     3     4]
 [    1     1    23   891     4     4     3     2     1     4    17     0     4     4    26     2     2     5    12     1     9]
 [    7     5     3     1   986     4     0     2     0    14     0     3     2     2    10     3     5     1     0     1     5]
 [    5    16     5     0    15   900     6    28     0     7     3     8     4    11     2     2     4     7     4     6    10]
 [    0     0    28     1     2     7  1008     2     0     4     2     0     3     1     0     9     2     1     1     9     6]
 [    0     9    23     3     2    29     5   936     1     6     2     7     3     2     1     1     1     2    28     7     9]
 [    8     2     0     2     4     2     0     4   849    77    17     2     4     6    12     1     1     0     6     0     5]
 [   46     1     3     0     9     0     0     0    22   893     1     3     1    12     4     0     0     1     0     0     5]
 [    1     4     6     8     2     2     4     7    10     4   975     0     1     9     9     0     1     0    12     2     7]
 [    4     1     4     0     1    16     2     3     0     3     0   878    32     6     0    14     3    21     1    16     6]
 [    1     1     7     1     4     3     0     3     0     1     2    55   831     4     2    10     0    57     2     1    10]
 [    5     1     4     0     4     6     3     4    16    33    12    10     3   873     4     4     1     3     1     3    11]
 [    5     1     5    13     8     1     1     0    32     9     8     0     4     5   988     0     0     4    12     0     2]
 [    1     0     6     0     4     1     7     1     0     5     0    15     2     1     0   995     8    13     2     2     3]
 [    4     7     7     1    13     3     0     0     3     3     4     4     4     4     2     4   980     3     1     5    20]
 [    3     2     5     2     4     0     0     0     0     0     0     5     8     0     6    23     1   939     1     1     5]
 [    1     3     8    12     2     1     1    12     2     1     4     2     1     0     8     0     1     1   990     1     7]
 [    0     6     9     0     5     7    15    10     1     3     1    13     7     3     0     3     4     4     4   981    12]
 [  170   184   282    80   261   152    76   116    87   156   171   128   287   207   215   155   128   122   160   188 10607]]

2024-06-06 01:19:37,933 - ==> Best [Top1: 85.505   Top5: 97.927   Sparsity:0.00   Params: 424448 on epoch: 81]
2024-06-06 01:19:37,933 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:19:37,964 - 

2024-06-06 01:19:37,965 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:19:44,338 - Epoch: [97][  100/ 1218]    Overall Loss 0.319031    Objective Loss 0.319031                                        LR 0.001000    Time 0.063706    
2024-06-06 01:19:49,221 - Epoch: [97][  200/ 1218]    Overall Loss 0.313357    Objective Loss 0.313357                                        LR 0.001000    Time 0.056254    
2024-06-06 01:19:53,837 - Epoch: [97][  300/ 1218]    Overall Loss 0.311065    Objective Loss 0.311065                                        LR 0.001000    Time 0.052883    
2024-06-06 01:19:58,615 - Epoch: [97][  400/ 1218]    Overall Loss 0.308335    Objective Loss 0.308335                                        LR 0.001000    Time 0.051603    
2024-06-06 01:20:03,238 - Epoch: [97][  500/ 1218]    Overall Loss 0.307036    Objective Loss 0.307036                                        LR 0.001000    Time 0.050524    
2024-06-06 01:20:08,086 - Epoch: [97][  600/ 1218]    Overall Loss 0.309979    Objective Loss 0.309979                                        LR 0.001000    Time 0.050181    
2024-06-06 01:20:12,678 - Epoch: [97][  700/ 1218]    Overall Loss 0.312110    Objective Loss 0.312110                                        LR 0.001000    Time 0.049568    
2024-06-06 01:20:17,409 - Epoch: [97][  800/ 1218]    Overall Loss 0.312906    Objective Loss 0.312906                                        LR 0.001000    Time 0.049284    
2024-06-06 01:20:22,141 - Epoch: [97][  900/ 1218]    Overall Loss 0.312954    Objective Loss 0.312954                                        LR 0.001000    Time 0.049062    
2024-06-06 01:20:26,962 - Epoch: [97][ 1000/ 1218]    Overall Loss 0.311929    Objective Loss 0.311929                                        LR 0.001000    Time 0.048976    
2024-06-06 01:20:31,726 - Epoch: [97][ 1100/ 1218]    Overall Loss 0.312628    Objective Loss 0.312628                                        LR 0.001000    Time 0.048852    
2024-06-06 01:20:36,618 - Epoch: [97][ 1200/ 1218]    Overall Loss 0.313610    Objective Loss 0.313610                                        LR 0.001000    Time 0.048856    
2024-06-06 01:20:37,508 - Epoch: [97][ 1218/ 1218]    Overall Loss 0.313626    Objective Loss 0.313626    Top1 85.330073    Top5 98.533007    LR 0.001000    Time 0.048864    
2024-06-06 01:20:37,706 - --- validate (epoch=97)-----------
2024-06-06 01:20:37,706 - 34633 samples (256 per mini-batch)
2024-06-06 01:20:43,154 - Epoch: [97][  100/  136]    Loss 0.342046    Top1 84.789062    Top5 97.703125    
2024-06-06 01:20:44,839 - Epoch: [97][  136/  136]    Loss 0.339335    Top1 84.618716    Top5 97.704501    
2024-06-06 01:20:44,998 - ==> Top1: 84.619    Top5: 97.705    Loss: 0.339

2024-06-06 01:20:44,999 - ==> Confusion:
[[  842     2     3     0    11     0     1     0     5    44     0     5     2     4     1     0     1     2     2     0     6]
 [    2   946     1     0    13    30     4    21     1     1    10     3     2     0    10     1     3     1     7     1     6]
 [    6     2   895     7     1     3    13     8     1     4     4     3     1     2     2     3     2     0     2     4     7]
 [    4     1    17   921     0     0     1     0     2     1    12     4     5     3    18     2     0     5     6     5     9]
 [   35    14     1     3   949     8     0     0     2    10     2     4     0     3     5     5     4     1     0     1     7]
 [    2    16     1     5     9   914     3    26     2     2     3    11     4     8     2     1     4     2     6    14     8]
 [    1     5    15     2     0     8  1006     3     0     2     3     4     0     1     0    13     3     3     2    10     5]
 [    5     6    11     3     1    30     5   946     0     2     5     8     2     2     1     2     1     1    25    15     6]
 [    7     4     0     0     2     1     1     1   858    37    18     4     3    20    22     3     2     3     9     4     3]
 [   66     0     0     0     2     2     0     1    37   850     2     2     1    18     7     2     2     2     0     3     4]
 [    1     4     9     6     0     3     1     6    15     3   965     2     1     8    14     0     3     0    11     1    11]
 [    1     1     2     0     0     9     1     7     0     1     2   893    38     4     1    13     4     6     4    19     5]
 [    0     3     1     6     0     3     1     1     0     1     3    63   833     3     2    13     3    24     6    15    14]
 [    1     0     2     2     4    16     0     2     8    13    11     8     9   898     1     4     6     1     1     9     5]
 [   10     2     1    19     4     0     0     2    16     9     4     6     1     6   989     2     2     0    19     0     6]
 [    3     0     2     1     2     2     7     0     0     1     0    17     8     0     2   996    11     7     2     2     3]
 [    3     5     1     5     3     6     0     3     2     0     3     4     3     2     2    15   998     1     2     4    10]
 [    4     3     1     3     0     2     0     1     0     0     0    25    33     1     2    14     4   897     4     5     6]
 [    2     3     8     9     2     2     0    19     8     0     3     1     1     1     9     1     0     1   971     4    13]
 [    1     4     4     0     0     9     5     5     0     1     0    12     1     0     2    10    10     0     7  1004    13]
 [  200   172   202   103   111   177    93   117    88   102   141   139   287   207   200   146   198    54   197   263 10735]]

2024-06-06 01:20:45,001 - ==> Best [Top1: 85.505   Top5: 97.927   Sparsity:0.00   Params: 424448 on epoch: 81]
2024-06-06 01:20:45,001 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:20:45,029 - 

2024-06-06 01:20:45,030 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:20:51,008 - Epoch: [98][  100/ 1218]    Overall Loss 0.318126    Objective Loss 0.318126                                        LR 0.001000    Time 0.059758    
2024-06-06 01:20:55,711 - Epoch: [98][  200/ 1218]    Overall Loss 0.317465    Objective Loss 0.317465                                        LR 0.001000    Time 0.053384    
2024-06-06 01:21:00,363 - Epoch: [98][  300/ 1218]    Overall Loss 0.314287    Objective Loss 0.314287                                        LR 0.001000    Time 0.051090    
2024-06-06 01:21:05,143 - Epoch: [98][  400/ 1218]    Overall Loss 0.311404    Objective Loss 0.311404                                        LR 0.001000    Time 0.050262    
2024-06-06 01:21:09,779 - Epoch: [98][  500/ 1218]    Overall Loss 0.312222    Objective Loss 0.312222                                        LR 0.001000    Time 0.049477    
2024-06-06 01:21:14,571 - Epoch: [98][  600/ 1218]    Overall Loss 0.312182    Objective Loss 0.312182                                        LR 0.001000    Time 0.049215    
2024-06-06 01:21:19,206 - Epoch: [98][  700/ 1218]    Overall Loss 0.312692    Objective Loss 0.312692                                        LR 0.001000    Time 0.048802    
2024-06-06 01:21:23,937 - Epoch: [98][  800/ 1218]    Overall Loss 0.311365    Objective Loss 0.311365                                        LR 0.001000    Time 0.048614    
2024-06-06 01:21:28,684 - Epoch: [98][  900/ 1218]    Overall Loss 0.311673    Objective Loss 0.311673                                        LR 0.001000    Time 0.048484    
2024-06-06 01:21:33,270 - Epoch: [98][ 1000/ 1218]    Overall Loss 0.311488    Objective Loss 0.311488                                        LR 0.001000    Time 0.048220    
2024-06-06 01:21:37,903 - Epoch: [98][ 1100/ 1218]    Overall Loss 0.312350    Objective Loss 0.312350                                        LR 0.001000    Time 0.048046    
2024-06-06 01:21:42,496 - Epoch: [98][ 1200/ 1218]    Overall Loss 0.312738    Objective Loss 0.312738                                        LR 0.001000    Time 0.047868    
2024-06-06 01:21:43,351 - Epoch: [98][ 1218/ 1218]    Overall Loss 0.312977    Objective Loss 0.312977    Top1 80.440098    Top5 96.577017    LR 0.001000    Time 0.047862    
2024-06-06 01:21:43,550 - --- validate (epoch=98)-----------
2024-06-06 01:21:43,550 - 34633 samples (256 per mini-batch)
2024-06-06 01:21:49,060 - Epoch: [98][  100/  136]    Loss 0.344896    Top1 84.742188    Top5 97.812500    
2024-06-06 01:21:50,785 - Epoch: [98][  136/  136]    Loss 0.346186    Top1 84.685127    Top5 97.773800    
2024-06-06 01:21:51,007 - ==> Top1: 84.685    Top5: 97.774    Loss: 0.346

2024-06-06 01:21:51,009 - ==> Confusion:
[[  805     0     1     1     4     1     0     1    10    76     0     3     5     5     5     3     0     1     1     2     7]
 [    3   961     2     1     9    20     5     7     3     3     6     2     4     2     5     2     4     1    10     1    12]
 [    4     2   888     2     1     1    22     3     1     9     9     2     3     4     1     1     5     0     2     1     9]
 [    1     2    15   910     2     5     1     2     3     4    14     0    10     6    12     2     1     4    14     0     8]
 [   16     8     1     1   942    11     1     1     1    20     2     6     2     5    10     9     7     1     1     2     7]
 [    7    22     6     1     6   879     7    36     6     6     2     8     3    22     1     1     3     0     2    11    14]
 [    1     1    12     1     2     3  1017     6     0     2     4     2     0     1     1     3     0     5     2    10    13]
 [    4     7     9     3     0    29     2   932     2     4     9     3     9     6     0     1     0     1    24    19    13]
 [    6     0     0     1     1     1     0     3   912    29     6     2     5    13     9     0     1     3     5     1     4]
 [   40     0     0     2     4     5     0     3    72   834     1     1     3    23     4     0     0     2     1     0     6]
 [    0     1     5     4     0     1     1     2    26     0   980     1     1    14     7     1     0     1     6     3    10]
 [    0     0     2     0     0    12     3     8     3     2     3   879    34    10     1    11     2    11     0    24     6]
 [    1     1     1     3     0     2     2     1     3     0     3    55   859     7     1     6     2    25     4    13     6]
 [    3     2     0     0     2     8     0     2    13    13     5     4     7   914     4     2     0     2     1     9    10]
 [   10     0     3    18     4     1     1     2    69    12    14     2     4     9   922     0     1     2    13     0    11]
 [    2     1     6     0     0     1     6     0     1     3     0    14     9     5     0   995     3    14     0     2     4]
 [    2     6     4     1     4     4     2     1    10     1     2     5     3     7     1     8   984     2     1     9    15]
 [    3     0     1     0     0     3     2     1     2     1     0    12    28     3     3     4     2   934     1     3     2]
 [    1     4     7    10     0     2     1    17     9     0     8     0     7     2    10     0     0     0   965     6     9]
 [    0     2     3     0     0     3     9     8     0     0     0    10     9     5     0     5     2     5     2  1018     7]
 [  167   146   192    86   129   135   103   141   150   134   154   128   304   237   148   109   148    92   132   298 10799]]

2024-06-06 01:21:51,012 - ==> Best [Top1: 85.505   Top5: 97.927   Sparsity:0.00   Params: 424448 on epoch: 81]
2024-06-06 01:21:51,012 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:21:51,044 - 

2024-06-06 01:21:51,045 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:21:57,476 - Epoch: [99][  100/ 1218]    Overall Loss 0.323392    Objective Loss 0.323392                                        LR 0.001000    Time 0.064273    
2024-06-06 01:22:02,561 - Epoch: [99][  200/ 1218]    Overall Loss 0.314841    Objective Loss 0.314841                                        LR 0.001000    Time 0.057552    
2024-06-06 01:22:07,416 - Epoch: [99][  300/ 1218]    Overall Loss 0.314286    Objective Loss 0.314286                                        LR 0.001000    Time 0.054545    
2024-06-06 01:22:12,149 - Epoch: [99][  400/ 1218]    Overall Loss 0.312946    Objective Loss 0.312946                                        LR 0.001000    Time 0.052735    
2024-06-06 01:22:16,786 - Epoch: [99][  500/ 1218]    Overall Loss 0.311152    Objective Loss 0.311152                                        LR 0.001000    Time 0.051460    
2024-06-06 01:22:21,520 - Epoch: [99][  600/ 1218]    Overall Loss 0.310941    Objective Loss 0.310941                                        LR 0.001000    Time 0.050769    
2024-06-06 01:22:26,456 - Epoch: [99][  700/ 1218]    Overall Loss 0.312166    Objective Loss 0.312166                                        LR 0.001000    Time 0.050566    
2024-06-06 01:22:31,105 - Epoch: [99][  800/ 1218]    Overall Loss 0.312549    Objective Loss 0.312549                                        LR 0.001000    Time 0.050052    
2024-06-06 01:22:35,809 - Epoch: [99][  900/ 1218]    Overall Loss 0.313746    Objective Loss 0.313746                                        LR 0.001000    Time 0.049716    
2024-06-06 01:22:40,451 - Epoch: [99][ 1000/ 1218]    Overall Loss 0.313557    Objective Loss 0.313557                                        LR 0.001000    Time 0.049384    
2024-06-06 01:22:45,088 - Epoch: [99][ 1100/ 1218]    Overall Loss 0.313576    Objective Loss 0.313576                                        LR 0.001000    Time 0.049109    
2024-06-06 01:22:49,909 - Epoch: [99][ 1200/ 1218]    Overall Loss 0.313775    Objective Loss 0.313775                                        LR 0.001000    Time 0.049032    
2024-06-06 01:22:50,775 - Epoch: [99][ 1218/ 1218]    Overall Loss 0.313720    Objective Loss 0.313720    Top1 87.530562    Top5 98.288509    LR 0.001000    Time 0.049018    
2024-06-06 01:22:50,985 - --- validate (epoch=99)-----------
2024-06-06 01:22:50,985 - 34633 samples (256 per mini-batch)
2024-06-06 01:22:56,292 - Epoch: [99][  100/  136]    Loss 0.341798    Top1 84.261719    Top5 97.718750    
2024-06-06 01:22:57,989 - Epoch: [99][  136/  136]    Loss 0.344408    Top1 84.188491    Top5 97.747813    
2024-06-06 01:22:58,170 - ==> Top1: 84.188    Top5: 97.748    Loss: 0.344

2024-06-06 01:22:58,172 - ==> Confusion:
[[  808     2     3     0    15     2     1     0     4    65     0     4     1     5     6     2     1     0     2     0    10]
 [    1   942     3     1    16    21     4    11     5     4     6     1     1     1    10     1     3     2    15     6     9]
 [    4     2   889     4     6     2    12    10     0     8     2     1     3     3     1     7     3     1     3     3     6]
 [    1     0    14   906     2     6     5     3     0     6    11     2     9     2    21     5     5     0    10     1     7]
 [    8     4     4     0   975     7     0     2     0    22     0     1     1     3    14     1     3     0     1     1     7]
 [    5    13     4     4    10   903     6    33     1     6     3    12     3     5     3     5     5     1     6     8     7]
 [    0     3    15     1     2     2  1015     7     0     5     8     4     0     1     1     7     0     1     1     7     6]
 [    3     5    14     1     3    31     6   945     3     5     4     3     3     1     0     3     2     4    23    10     8]
 [    5     1     3     1     3     0     0     2   845    62    16     2     2    14    28     0     2     2     6     2     6]
 [   46     0     2     0     1     0     1     1    25   881     2     1     0    19    13     0     2     2     2     0     3]
 [    1     1     6     5     0     1     3     5     6     1   997     1     1     3    11     0     0     0    10     2    10]
 [    2     0     4     0     0    10     1     6     1     4     1   891    30     4     2    15     3     9     2    18     8]
 [    0     3     3     2     2     4     0     8     3     2     2    54   871     1     1     9     2    11     4     6     7]
 [    0     3     2     3     4    16     2     3     5    25    11    14     2   873     5     1     8     3     2     9    10]
 [    8     2     2    13     8     3     1     0    19     4    11     3     1     7   999     0     0     1    11     0     5]
 [    3     1     2     1     5     1     5     1     0     7     0     9     7     0     1  1001    11     2     0     4     5]
 [    3     5     1     2     7     7     2     0     3     3     5     4     2     2     3    10   988     1     0     6    18]
 [    2     1     0     1     2     0     3     3     5     4     0    19    51     1     1    17     0   883     2     5     5]
 [    0     3     7     7     3     2     0    12     8     3     4     2     3     2    17     2     0     1   972     5     5]
 [    1     2     3     0     2     6    10     7     0     3     0    15     3     1     1     7     9     1     1  1009     7]
 [  187   124   191    75   196   157    97   154    94   165   157   137   310   216   251   158   213    67   174   245 10564]]

2024-06-06 01:22:58,175 - ==> Best [Top1: 85.505   Top5: 97.927   Sparsity:0.00   Params: 424448 on epoch: 81]
2024-06-06 01:22:58,176 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:22:58,206 - 

2024-06-06 01:22:58,207 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:23:04,328 - Epoch: [100][  100/ 1218]    Overall Loss 0.305859    Objective Loss 0.305859                                        LR 0.000500    Time 0.061178    
2024-06-06 01:23:08,932 - Epoch: [100][  200/ 1218]    Overall Loss 0.301760    Objective Loss 0.301760                                        LR 0.000500    Time 0.053596    
2024-06-06 01:23:13,506 - Epoch: [100][  300/ 1218]    Overall Loss 0.300137    Objective Loss 0.300137                                        LR 0.000500    Time 0.050972    
2024-06-06 01:23:18,066 - Epoch: [100][  400/ 1218]    Overall Loss 0.298835    Objective Loss 0.298835                                        LR 0.000500    Time 0.049623    
2024-06-06 01:23:22,831 - Epoch: [100][  500/ 1218]    Overall Loss 0.298351    Objective Loss 0.298351                                        LR 0.000500    Time 0.049224    
2024-06-06 01:23:27,702 - Epoch: [100][  600/ 1218]    Overall Loss 0.296729    Objective Loss 0.296729                                        LR 0.000500    Time 0.049136    
2024-06-06 01:23:32,386 - Epoch: [100][  700/ 1218]    Overall Loss 0.296092    Objective Loss 0.296092                                        LR 0.000500    Time 0.048805    
2024-06-06 01:23:37,097 - Epoch: [100][  800/ 1218]    Overall Loss 0.294999    Objective Loss 0.294999                                        LR 0.000500    Time 0.048591    
2024-06-06 01:23:41,779 - Epoch: [100][  900/ 1218]    Overall Loss 0.294112    Objective Loss 0.294112                                        LR 0.000500    Time 0.048392    
2024-06-06 01:23:46,366 - Epoch: [100][ 1000/ 1218]    Overall Loss 0.293971    Objective Loss 0.293971                                        LR 0.000500    Time 0.048137    
2024-06-06 01:23:50,962 - Epoch: [100][ 1100/ 1218]    Overall Loss 0.292717    Objective Loss 0.292717                                        LR 0.000500    Time 0.047938    
2024-06-06 01:23:55,556 - Epoch: [100][ 1200/ 1218]    Overall Loss 0.292760    Objective Loss 0.292760                                        LR 0.000500    Time 0.047770    
2024-06-06 01:23:56,407 - Epoch: [100][ 1218/ 1218]    Overall Loss 0.292688    Objective Loss 0.292688    Top1 86.552567    Top5 98.533007    LR 0.000500    Time 0.047761    
2024-06-06 01:23:56,591 - --- validate (epoch=100)-----------
2024-06-06 01:23:56,592 - 34633 samples (256 per mini-batch)
2024-06-06 01:24:02,166 - Epoch: [100][  100/  136]    Loss 0.322078    Top1 85.156250    Top5 97.753906    
2024-06-06 01:24:03,845 - Epoch: [100][  136/  136]    Loss 0.323568    Top1 85.193313    Top5 97.747813    
2024-06-06 01:24:04,034 - ==> Top1: 85.193    Top5: 97.748    Loss: 0.324

2024-06-06 01:24:04,035 - ==> Confusion:
[[  815     4     2     1    13     1     0     1     6    74     0     4     3     2     1     0     0     2     0     0     2]
 [    3   961     2     1    15    21     6    11     2     3     3     2     2     0     2     2     4     1    11     6     5]
 [    3     3   888     9     3     2    17    10     0     5     0     3     3     6     1     3     2     0     4     2     6]
 [    2     1     9   942     0     8     2     2     1     3     7     3     5     1    15     1     0     5     2     0     7]
 [   16     9     5     2   950    17     0     2     0    18     0     1     0     0     7     6     5     1     3     1    11]
 [    3    19     3     2     9   908     1    30     0     7     3    10     4    14     1     0     6     1     7     6     9]
 [    1     3    13     0     2     7  1028     7     0     4     3     0     0     0     1     4     4     0     1     6     2]
 [    2     9    13     1     3    23     8   953     1     9     4     7     1     2     0     1     1     3    19    12     5]
 [    9     2     1     2     2     0     2     1   841    76    16     2     6    10    19     1     0     0     6     1     5]
 [   47     2     1     0     2     1     0     2    23   903     0     0     1    13     3     1     0     0     0     0     2]
 [    0     1    10    12     0     5     5     7    10     8   969     2     1     6     7     0     2     0     9     1     9]
 [    3     3     3     1     2    17     2     5     0     4     0   889    28     9     0    10     3    17     1    11     3]
 [    2     1     0     5     3     7     3     1     3     2     0    47   863     1     2     1     2    33     2     6    11]
 [    0     2     2     1     4    13     1     3    14    32     8    10     2   887     3     2     1     5     1     2     8]
 [    9     4     2    25    10     1     0     3    20    14     4     2     3     3   979     0     3     0     5     0    11]
 [    4     2     3     1     3     3     7     1     1     8     0    10     8     2     0   994     5     9     0     2     3]
 [    3     6     5     3     7     6     3     2     4     1     1     7     2     2     1     8   990     4     0     5    12]
 [    2     2     0     1     0     0     4     1     0     2     0    13    18     1     0    12     2   941     1     1     4]
 [    2     4     8    14     2     1     1    16     5     3     1     1     2     1    13     2     3     0   968     2     9]
 [    1     6     1     0     1     9    13    12     0     2     0    11     7     0     0     5     3     3     2  1003     9]
 [  156   164   213   120   145   190   107   154    84   185   128   148   256   204   147    87   173   104   120   214 10833]]

2024-06-06 01:24:04,038 - ==> Best [Top1: 85.505   Top5: 97.927   Sparsity:0.00   Params: 424448 on epoch: 81]
2024-06-06 01:24:04,038 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:24:04,062 - 

2024-06-06 01:24:04,062 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:24:10,011 - Epoch: [101][  100/ 1218]    Overall Loss 0.279885    Objective Loss 0.279885                                        LR 0.000500    Time 0.059460    
2024-06-06 01:24:14,737 - Epoch: [101][  200/ 1218]    Overall Loss 0.285463    Objective Loss 0.285463                                        LR 0.000500    Time 0.053348    
2024-06-06 01:24:19,290 - Epoch: [101][  300/ 1218]    Overall Loss 0.286970    Objective Loss 0.286970                                        LR 0.000500    Time 0.050737    
2024-06-06 01:24:23,903 - Epoch: [101][  400/ 1218]    Overall Loss 0.286337    Objective Loss 0.286337                                        LR 0.000500    Time 0.049580    
2024-06-06 01:24:28,517 - Epoch: [101][  500/ 1218]    Overall Loss 0.286309    Objective Loss 0.286309                                        LR 0.000500    Time 0.048888    
2024-06-06 01:24:33,354 - Epoch: [101][  600/ 1218]    Overall Loss 0.285007    Objective Loss 0.285007                                        LR 0.000500    Time 0.048798    
2024-06-06 01:24:38,042 - Epoch: [101][  700/ 1218]    Overall Loss 0.286007    Objective Loss 0.286007                                        LR 0.000500    Time 0.048521    
2024-06-06 01:24:42,722 - Epoch: [101][  800/ 1218]    Overall Loss 0.285921    Objective Loss 0.285921                                        LR 0.000500    Time 0.048304    
2024-06-06 01:24:47,410 - Epoch: [101][  900/ 1218]    Overall Loss 0.287135    Objective Loss 0.287135                                        LR 0.000500    Time 0.048143    
2024-06-06 01:24:51,964 - Epoch: [101][ 1000/ 1218]    Overall Loss 0.287023    Objective Loss 0.287023                                        LR 0.000500    Time 0.047880    
2024-06-06 01:24:56,904 - Epoch: [101][ 1100/ 1218]    Overall Loss 0.287917    Objective Loss 0.287917                                        LR 0.000500    Time 0.048017    
2024-06-06 01:25:01,515 - Epoch: [101][ 1200/ 1218]    Overall Loss 0.288015    Objective Loss 0.288015                                        LR 0.000500    Time 0.047856    
2024-06-06 01:25:02,321 - Epoch: [101][ 1218/ 1218]    Overall Loss 0.288341    Objective Loss 0.288341    Top1 84.841076    Top5 97.310513    LR 0.000500    Time 0.047810    
2024-06-06 01:25:02,488 - --- validate (epoch=101)-----------
2024-06-06 01:25:02,488 - 34633 samples (256 per mini-batch)
2024-06-06 01:25:07,998 - Epoch: [101][  100/  136]    Loss 0.321288    Top1 85.089844    Top5 97.691406    
2024-06-06 01:25:09,715 - Epoch: [101][  136/  136]    Loss 0.322458    Top1 85.126902    Top5 97.684290    
2024-06-06 01:25:09,904 - ==> Top1: 85.127    Top5: 97.684    Loss: 0.322

2024-06-06 01:25:09,905 - ==> Confusion:
[[  828     2     1     1    12     0     0     2     5    60     0     6     1     7     3     0     0     0     0     0     3]
 [    2   965     3     2    16    21     3    12     4     0     4     5     2     1     3     1     5     3     4     2     5]
 [    7     2   874     6     2     0    19    13     2     6     8     2     3     4     3     3     5     1     4     0     6]
 [    7     4     8   910     1     4     2     2     3     4    19     1     7     4    18     2     0     6     5     3     6]
 [   15    13     2     0   956     4     2     0     2    19     2     5     1     5     6     6     5     0     1     0    10]
 [    5    17     4     2    15   893     4    29     4     6     2    16     4    18     1     2     5     2     3     5     6]
 [    0     5     8     4     1     8  1008     7     1     2     6     8     1     1     1     6     3     2     2    11     1]
 [    1     8     6     0     1    22     3   955     1     3     7    14     3     6     0     1     1     0    28    10     7]
 [    6     1     0     1     3     1     0     1   889    39     8     6     6    11    15     2     2     2     8     0     1]
 [   49     0     2     0     3     2     0     1    41   873     3     1     3    19     1     0     0     0     0     0     3]
 [    0     1     3     3     0     6     4     7    13     4   987     2     3     7     3     1     0     0    13     2     5]
 [    5     0     1     0     1     3     3     6     1     2     4   930    18     3     0     8     1     7     1    12     5]
 [    0     0     1     3     0     2     0     5     1     2     0    70   850     6     1     9     4    19     5     5    12]
 [    1     1     1     0     1    12     0     3    13    16     9    14     6   905     1     1     2     3     0     7     5]
 [    6     1     0    16     8     0     0     1    32     6     5     2     2     5   992     0     4     1     9     1     7]
 [    0     0     1     2     3     1     9     1     0     4     0    20     5     3     0   996     9     5     1     1     5]
 [    3    11     3     4     5     9     1     1     6     2     1     4     2     5     0    12   980     1     0     7    15]
 [    1     4     0     0     1     0     2     0     1     3     0    17    30     3     1    15     1   917     2     3     4]
 [    2     7     6     5     4     2     1    17     7     2     3     1     2     2     9     1     1     0   980     1     5]
 [    1     5     2     1     3    10    10    10     0     0     0    18     6     8     0    10     4     3     2   987     8]
 [  153   186   118    92   173   194    76   157   129   141   167   192   264   230   155    99   164    76   155   204 10807]]

2024-06-06 01:25:09,907 - ==> Best [Top1: 85.505   Top5: 97.927   Sparsity:0.00   Params: 424448 on epoch: 81]
2024-06-06 01:25:09,907 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:25:09,931 - 

2024-06-06 01:25:09,932 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:25:16,303 - Epoch: [102][  100/ 1218]    Overall Loss 0.282082    Objective Loss 0.282082                                        LR 0.000500    Time 0.063682    
2024-06-06 01:25:20,952 - Epoch: [102][  200/ 1218]    Overall Loss 0.282618    Objective Loss 0.282618                                        LR 0.000500    Time 0.055076    
2024-06-06 01:25:25,547 - Epoch: [102][  300/ 1218]    Overall Loss 0.283643    Objective Loss 0.283643                                        LR 0.000500    Time 0.052026    
2024-06-06 01:25:30,291 - Epoch: [102][  400/ 1218]    Overall Loss 0.283050    Objective Loss 0.283050                                        LR 0.000500    Time 0.050875    
2024-06-06 01:25:34,984 - Epoch: [102][  500/ 1218]    Overall Loss 0.282198    Objective Loss 0.282198                                        LR 0.000500    Time 0.050070    
2024-06-06 01:25:39,707 - Epoch: [102][  600/ 1218]    Overall Loss 0.281880    Objective Loss 0.281880                                        LR 0.000500    Time 0.049592    
2024-06-06 01:25:44,308 - Epoch: [102][  700/ 1218]    Overall Loss 0.283934    Objective Loss 0.283934                                        LR 0.000500    Time 0.049079    
2024-06-06 01:25:48,895 - Epoch: [102][  800/ 1218]    Overall Loss 0.284621    Objective Loss 0.284621                                        LR 0.000500    Time 0.048675    
2024-06-06 01:25:53,610 - Epoch: [102][  900/ 1218]    Overall Loss 0.284589    Objective Loss 0.284589                                        LR 0.000500    Time 0.048503    
2024-06-06 01:25:58,351 - Epoch: [102][ 1000/ 1218]    Overall Loss 0.284528    Objective Loss 0.284528                                        LR 0.000500    Time 0.048392    
2024-06-06 01:26:03,154 - Epoch: [102][ 1100/ 1218]    Overall Loss 0.285014    Objective Loss 0.285014                                        LR 0.000500    Time 0.048355    
2024-06-06 01:26:07,723 - Epoch: [102][ 1200/ 1218]    Overall Loss 0.285075    Objective Loss 0.285075                                        LR 0.000500    Time 0.048132    
2024-06-06 01:26:08,547 - Epoch: [102][ 1218/ 1218]    Overall Loss 0.285211    Objective Loss 0.285211    Top1 86.308068    Top5 98.044010    LR 0.000500    Time 0.048096    
2024-06-06 01:26:08,713 - --- validate (epoch=102)-----------
2024-06-06 01:26:08,714 - 34633 samples (256 per mini-batch)
2024-06-06 01:26:14,339 - Epoch: [102][  100/  136]    Loss 0.321007    Top1 85.746094    Top5 97.875000    
2024-06-06 01:26:16,010 - Epoch: [102][  136/  136]    Loss 0.318334    Top1 85.663962    Top5 97.837323    
2024-06-06 01:26:16,194 - ==> Top1: 85.664    Top5: 97.837    Loss: 0.318

2024-06-06 01:26:16,195 - ==> Confusion:
[[  822     0     4     0     8     2     0     1     7    69     1     2     3     1     3     2     2     1     1     0     2]
 [    1   961     3     3    17    13     2    12     1     1     2     3     3     1     7     0    11     0    10     4     8]
 [   11     0   881    11     1     3    11     8     1     4     5     0     0     1     3     1     4     3     6     8     8]
 [    7     1    10   948     2     2     2     2     1     1     8     2     2     1    13     2     1     2     4     1     4]
 [   10     6     3     2   967    10     0     5     0    10     2     2     1     2    10     3     5     0     5     3     8]
 [    2    29     3     5    14   879     5    26     2     7     0     9     7    14     3     0     6     2     3    12    15]
 [    3     4    12     2     0     2  1032     3     1     2     3     0     2     0     1     2     3     2     0     5     7]
 [    3    10    11     3     3    21     6   957     2     5     3     3     7     2     1     2     1     2    17    10     8]
 [    8     2     0     1     2     3     0     1   879    44     9     3     4    10    17     0     3     2     7     0     7]
 [   47     0     3     0     9     0     0     0    31   882     0     3     1    11     6     2     1     0     0     0     5]
 [    0     2     8    11     1     2     3     5    13     0   983     0     1     6     5     0     3     0    10     0    11]
 [    1     1     4     0     3    11     2     8     0     2     0   892    28     4     1    12     4    14     1    19     4]
 [    1     4     2     9     2     4     3     3     1     2     1    45   856     4     0     9     6    22     3     9     9]
 [    5     1     2     2     6     5     1     2    12    14     6     7     4   899     5     2     3     5     0     7    13]
 [    4     2     1    20     8     0     1     1    19     6     4     1     6     5  1002     2     2     2    10     0     2]
 [    2     1     4     0     2     1     6     2     0     1     0    10     9     3     0  1002     8     8     2     2     3]
 [    3    12     7     2     2     1     0     1     4     2     2     3     0     2     1     7  1003     3     2     5    10]
 [    0     2     2     5     0     0     3     0     1     1     0     8    34     5     4    18     3   911     0     1     7]
 [    3     4     5     7     1     1     0    17     7     1     6     4     1     0    10     1     1     1   975     2    11]
 [    2     5     5     1     3     2     9     9     1     0     2     7     9     5     0     5     7     2     2  1004     8]
 [  162   165   185   135   167   117    94   156    92   114   120   103   279   168   173   108   184    85   176   216 10933]]

2024-06-06 01:26:16,198 - ==> Best [Top1: 85.664   Top5: 97.837   Sparsity:0.00   Params: 424448 on epoch: 102]
2024-06-06 01:26:16,198 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:26:16,227 - 

2024-06-06 01:26:16,228 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:26:22,371 - Epoch: [103][  100/ 1218]    Overall Loss 0.288617    Objective Loss 0.288617                                        LR 0.000500    Time 0.061403    
2024-06-06 01:26:27,127 - Epoch: [103][  200/ 1218]    Overall Loss 0.287939    Objective Loss 0.287939                                        LR 0.000500    Time 0.054473    
2024-06-06 01:26:31,681 - Epoch: [103][  300/ 1218]    Overall Loss 0.285239    Objective Loss 0.285239                                        LR 0.000500    Time 0.051489    
2024-06-06 01:26:36,368 - Epoch: [103][  400/ 1218]    Overall Loss 0.282617    Objective Loss 0.282617                                        LR 0.000500    Time 0.050328    
2024-06-06 01:26:41,036 - Epoch: [103][  500/ 1218]    Overall Loss 0.282593    Objective Loss 0.282593                                        LR 0.000500    Time 0.049597    
2024-06-06 01:26:45,752 - Epoch: [103][  600/ 1218]    Overall Loss 0.282593    Objective Loss 0.282593                                        LR 0.000500    Time 0.049187    
2024-06-06 01:26:50,396 - Epoch: [103][  700/ 1218]    Overall Loss 0.284022    Objective Loss 0.284022                                        LR 0.000500    Time 0.048790    
2024-06-06 01:26:55,198 - Epoch: [103][  800/ 1218]    Overall Loss 0.283853    Objective Loss 0.283853                                        LR 0.000500    Time 0.048692    
2024-06-06 01:26:59,765 - Epoch: [103][  900/ 1218]    Overall Loss 0.283870    Objective Loss 0.283870                                        LR 0.000500    Time 0.048354    
2024-06-06 01:27:04,361 - Epoch: [103][ 1000/ 1218]    Overall Loss 0.284287    Objective Loss 0.284287                                        LR 0.000500    Time 0.048112    
2024-06-06 01:27:09,209 - Epoch: [103][ 1100/ 1218]    Overall Loss 0.284985    Objective Loss 0.284985                                        LR 0.000500    Time 0.048144    
2024-06-06 01:27:13,792 - Epoch: [103][ 1200/ 1218]    Overall Loss 0.284770    Objective Loss 0.284770                                        LR 0.000500    Time 0.047950    
2024-06-06 01:27:14,635 - Epoch: [103][ 1218/ 1218]    Overall Loss 0.284940    Objective Loss 0.284940    Top1 88.753056    Top5 99.511002    LR 0.000500    Time 0.047932    
2024-06-06 01:27:14,797 - --- validate (epoch=103)-----------
2024-06-06 01:27:14,797 - 34633 samples (256 per mini-batch)
2024-06-06 01:27:20,309 - Epoch: [103][  100/  136]    Loss 0.320475    Top1 85.632812    Top5 97.914062    
2024-06-06 01:27:22,012 - Epoch: [103][  136/  136]    Loss 0.317990    Top1 85.744810    Top5 97.883521    
2024-06-06 01:27:22,207 - ==> Top1: 85.745    Top5: 97.884    Loss: 0.318

2024-06-06 01:27:22,208 - ==> Confusion:
[[  819     1     5     1     5     5     0     0     2    67     0     2     0     1     5     0     2     3     0     4     9]
 [    3   977     0     0     8    19     2    12     4     3     2     2     1     1     2     1     1     2     6     4    13]
 [    2     0   887     8     3     2    22    11     0     6     4     5     2     2     0     2     6     1     1     4     2]
 [    2     3     5   925     1     2     3     1     2     2     9     0     9     1    23     5     0     2    13     0     8]
 [   14    13     4     0   961     7     2     2     1    12     0     2     0     6     7     5     6     2     3     1     6]
 [    4    28     4     3     8   883     8    33     2     4     2     8     6    13     2     4     2     3     3     8    15]
 [    2     3     3     1     2     4  1028     5     1     2     1     1     0     1     0     7     3     3     2     8     9]
 [    1    12     6     5     0    20     5   965     1     4     2     6     5     4     0     1     0     1    17    16     6]
 [    9     7     1     1     0     2     0     3   854    49     9     1     3    10    28     1     1     5     9     2     7]
 [   38     2     1     0     4     3     0     2    35   880     1     1     2    15     8     0     1     0     3     1     4]
 [    0     4     9     9     1     2     2     6     7     0   989     0     2     9     7     0     2     0     7     1     7]
 [    2     2     1     0     1    13     2     7     3     3     0   868    39    11     3    17     6    16     0     8     9]
 [    0     1     7     4     1     3     1     4     2     1     1    31   866     5     1    14     1    24     4    10    14]
 [    2     1     2     1     3     6     1     2     6    13    14     3     7   904     7     3     2     2     1     7    14]
 [    8     4     4    21     9     1     0     1    13    10     8     2     1     4   988     0     0     4     9     4     7]
 [    0     4     3     0     1     0     5     1     0     5     0    10     6     4     2  1000     6    10     0     2     7]
 [    2     9     4     1     3     5     0     2     6     3     1     3     5     1     1     4  1007     1     1     4     9]
 [    1     1     2     6     0     0     4     1     0     4     0    10     9     3     5     6     2   939     3     6     3]
 [    2     9     7    15     1     2     0    23     3     0     3     0     1     1    10     0     0     1   971     3     6]
 [    1     5     2     0     1     6     9     8     0     3     0     8     3     4     0     3     1     4     3  1013    14]
 [  113   181   155   109   127   146   106   164    69   132   124    99   268   218   160   104   156   102   190   237 10972]]

2024-06-06 01:27:22,211 - ==> Best [Top1: 85.745   Top5: 97.884   Sparsity:0.00   Params: 424448 on epoch: 103]
2024-06-06 01:27:22,211 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:27:22,236 - 

2024-06-06 01:27:22,236 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:27:28,276 - Epoch: [104][  100/ 1218]    Overall Loss 0.282235    Objective Loss 0.282235                                        LR 0.000500    Time 0.060368    
2024-06-06 01:27:32,887 - Epoch: [104][  200/ 1218]    Overall Loss 0.282585    Objective Loss 0.282585                                        LR 0.000500    Time 0.053229    
2024-06-06 01:27:37,681 - Epoch: [104][  300/ 1218]    Overall Loss 0.278197    Objective Loss 0.278197                                        LR 0.000500    Time 0.051460    
2024-06-06 01:27:42,527 - Epoch: [104][  400/ 1218]    Overall Loss 0.278824    Objective Loss 0.278824                                        LR 0.000500    Time 0.050705    
2024-06-06 01:27:47,321 - Epoch: [104][  500/ 1218]    Overall Loss 0.281373    Objective Loss 0.281373                                        LR 0.000500    Time 0.050147    
2024-06-06 01:27:52,039 - Epoch: [104][  600/ 1218]    Overall Loss 0.281142    Objective Loss 0.281142                                        LR 0.000500    Time 0.049649    
2024-06-06 01:27:56,767 - Epoch: [104][  700/ 1218]    Overall Loss 0.281998    Objective Loss 0.281998                                        LR 0.000500    Time 0.049308    
2024-06-06 01:28:01,305 - Epoch: [104][  800/ 1218]    Overall Loss 0.282900    Objective Loss 0.282900                                        LR 0.000500    Time 0.048815    
2024-06-06 01:28:05,984 - Epoch: [104][  900/ 1218]    Overall Loss 0.283181    Objective Loss 0.283181                                        LR 0.000500    Time 0.048588    
2024-06-06 01:28:10,579 - Epoch: [104][ 1000/ 1218]    Overall Loss 0.282171    Objective Loss 0.282171                                        LR 0.000500    Time 0.048322    
2024-06-06 01:28:15,126 - Epoch: [104][ 1100/ 1218]    Overall Loss 0.282456    Objective Loss 0.282456                                        LR 0.000500    Time 0.048062    
2024-06-06 01:28:19,757 - Epoch: [104][ 1200/ 1218]    Overall Loss 0.282552    Objective Loss 0.282552                                        LR 0.000500    Time 0.047913    
2024-06-06 01:28:20,606 - Epoch: [104][ 1218/ 1218]    Overall Loss 0.282641    Objective Loss 0.282641    Top1 83.374083    Top5 98.777506    LR 0.000500    Time 0.047902    
2024-06-06 01:28:20,776 - --- validate (epoch=104)-----------
2024-06-06 01:28:20,777 - 34633 samples (256 per mini-batch)
2024-06-06 01:28:26,350 - Epoch: [104][  100/  136]    Loss 0.311175    Top1 85.675781    Top5 97.875000    
2024-06-06 01:28:28,048 - Epoch: [104][  136/  136]    Loss 0.309639    Top1 85.724598    Top5 97.889296    
2024-06-06 01:28:28,205 - ==> Top1: 85.725    Top5: 97.889    Loss: 0.310

2024-06-06 01:28:28,206 - ==> Confusion:
[[  832     1     1     1    10     4     2     1     6    55     1     3     1     1     4     0     0     3     0     0     5]
 [    0   964     2     1    14    19     4    13     6     3     3     3     2     1     4     1     2     3    14     1     3]
 [    3     1   888     6     0     2    22     8     0     8     2     3     1     2     5     1     3     0     4     3     8]
 [    4     3     9   912     0     5     2     0     0     5     9     3     2     3    30     1     2     6     7     1    12]
 [   22    11     3     0   959     9     1     3     0    14     1     1     0     3    10     4     6     0     1     1     5]
 [    5    22     8     2     4   910     5    22     5     5     2     9     5    14     4     1     5     1     1     6     7]
 [    0     3    13     0     2     1  1021     5     0     3     1     4     3     1     0     6     3     2     1     8     9]
 [    1     8    10     2     1    19     2   961     2     1     4     6     5     5     2     2     3     3    23    12     5]
 [    8     1     1     1     1     1     1     0   861    64    13     4     3     8    13     0     0     8     7     0     7]
 [   51     1     3     0     3     3     1     1    25   892     1     1     2     7     3     0     1     1     0     0     5]
 [    1     3     6     8     1     4     4     5    12     0   990     2     0     5    10     0     1     1     7     0     4]
 [    2     2     1     0     0     7     2     2     3     4     2   896    29    10     0    11     2    20     1    13     4]
 [    1     1     4     8     0     8     1     3     3     0     1    48   855     5     5     3     1    25     4    11     8]
 [    3     0     2     1     2     8     0     2     9    25     7     8     1   917     4     2     2     1     0     1     6]
 [    7     4     1    12     6     0     0     2    26     8     1     1     4     4   999     0     2     1    13     2     5]
 [    3     1     3     0     1     1     9     1     0     2     0    20     6     3     0   987     9    15     0     2     3]
 [    4     6     3     1     4     7     0     0     1     2     5     5     1     2     3     9  1002     2     6     3     6]
 [    1     2     1     0     0     1     2     3     0     0     0    15    19     5     2     3     0   945     0     1     5]
 [    3     5     7    12     3     1     0    18     2     4     2     2     3     0    19     0     1     1   965     5     5]
 [    1     4     4     0     0     6     7     8     0     3     0    17     8     1     1     7     1     4     0  1006    10]
 [  169   153   164    83   156   142    72   144    75   127   133   145   264   220   212   101   187   109   150   199 10927]]

2024-06-06 01:28:28,209 - ==> Best [Top1: 85.745   Top5: 97.884   Sparsity:0.00   Params: 424448 on epoch: 103]
2024-06-06 01:28:28,209 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:28:28,233 - 

2024-06-06 01:28:28,233 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:28:34,551 - Epoch: [105][  100/ 1218]    Overall Loss 0.271736    Objective Loss 0.271736                                        LR 0.000500    Time 0.063152    
2024-06-06 01:28:39,227 - Epoch: [105][  200/ 1218]    Overall Loss 0.271372    Objective Loss 0.271372                                        LR 0.000500    Time 0.054948    
2024-06-06 01:28:43,961 - Epoch: [105][  300/ 1218]    Overall Loss 0.274922    Objective Loss 0.274922                                        LR 0.000500    Time 0.052404    
2024-06-06 01:28:48,811 - Epoch: [105][  400/ 1218]    Overall Loss 0.276517    Objective Loss 0.276517                                        LR 0.000500    Time 0.051424    
2024-06-06 01:28:53,444 - Epoch: [105][  500/ 1218]    Overall Loss 0.276693    Objective Loss 0.276693                                        LR 0.000500    Time 0.050401    
2024-06-06 01:28:58,141 - Epoch: [105][  600/ 1218]    Overall Loss 0.277843    Objective Loss 0.277843                                        LR 0.000500    Time 0.049826    
2024-06-06 01:29:02,824 - Epoch: [105][  700/ 1218]    Overall Loss 0.279339    Objective Loss 0.279339                                        LR 0.000500    Time 0.049395    
2024-06-06 01:29:07,520 - Epoch: [105][  800/ 1218]    Overall Loss 0.280344    Objective Loss 0.280344                                        LR 0.000500    Time 0.049089    
2024-06-06 01:29:12,362 - Epoch: [105][  900/ 1218]    Overall Loss 0.280992    Objective Loss 0.280992                                        LR 0.000500    Time 0.049012    
2024-06-06 01:29:17,197 - Epoch: [105][ 1000/ 1218]    Overall Loss 0.281142    Objective Loss 0.281142                                        LR 0.000500    Time 0.048944    
2024-06-06 01:29:22,027 - Epoch: [105][ 1100/ 1218]    Overall Loss 0.280443    Objective Loss 0.280443                                        LR 0.000500    Time 0.048883    
2024-06-06 01:29:26,644 - Epoch: [105][ 1200/ 1218]    Overall Loss 0.281414    Objective Loss 0.281414                                        LR 0.000500    Time 0.048655    
2024-06-06 01:29:27,432 - Epoch: [105][ 1218/ 1218]    Overall Loss 0.281683    Objective Loss 0.281683    Top1 88.508557    Top5 98.288509    LR 0.000500    Time 0.048583    
2024-06-06 01:29:27,597 - --- validate (epoch=105)-----------
2024-06-06 01:29:27,597 - 34633 samples (256 per mini-batch)
2024-06-06 01:29:33,273 - Epoch: [105][  100/  136]    Loss 0.322320    Top1 85.460938    Top5 97.750000    
2024-06-06 01:29:34,940 - Epoch: [105][  136/  136]    Loss 0.319388    Top1 85.663962    Top5 97.799786    
2024-06-06 01:29:35,106 - ==> Top1: 85.664    Top5: 97.800    Loss: 0.319

2024-06-06 01:29:35,107 - ==> Confusion:
[[  819     0     4     1    18     1     0     0     4    60     0     3     0     2     3     0     2     0     2     2    10]
 [    0   944     3     4    23    21     1    19     3     5     5     2     2     0     1     2     5     1     9     3    10]
 [    1     3   893     5     0     5    13    12     0    12     6     2     1     3     1     0     2     1     0     2     8]
 [    2     6    12   917     0     9     3     2     2     3    11     4     5     2    22     2     1     3     5     0     5]
 [   16     6     2     0   969     4     0     5     2    13     4     2     1     2     6     2     9     0     0     0    11]
 [    2    15     4     3    14   905     3    26     0     5     1    11     4    16     5     3     4     3     1     8    10]
 [    0     2    14     1     1     9  1016     5     1     4     4     3     3     0     0     2     2     0     1    11     7]
 [    0    11    12     2     2    32     2   960     1     3     5     5     4     1     0     2     1     3    11    11     9]
 [    9     2     1     1     0     4     0     2   875    48     6     4     5     9    19     0     1     4     1     1    10]
 [   49     0     2     0     6     0     1     2    26   880     0     1     1    14    10     0     0     4     1     0     4]
 [    0     5    10     9     2     4     4     5     8     2   984     1     0     7    12     0     0     0     5     2     4]
 [    2     1     2     0     2     7     4     5     5     1     1   904    21     4     0     9     5    16     2    16     4]
 [    1     2     3     3     0     4     3     2     5     2     0    51   871     3     0     4     3    31     0     4     3]
 [    2     0     1     0     3    10     0     4    13    18     5    15     5   900     4     1     2     3     1     8     6]
 [    5     5     2    16    15     4     0     2    22     9     6     2     2     5   972     0     4     5     9     1    12]
 [    0     1     5     0     2     1     7     0     0     6     0    16    10     2     0   987    11     8     0     2     8]
 [    1     6     3     2     9     2     0     2     6     2     4     5     0     0     2     6  1001     1     1     5    14]
 [    2     0     0     1     0     3     1     1     2     2     1    13    22     5     0    10     1   932     1     2     6]
 [    0     9     4    10     4     2     0    26     9     1     4     3     1     2     6     0     0     0   969     1     7]
 [    0     5     2     0     3     7     8     5     2     2     1    18     9     1     0     5     4     1     0  1005    10]
 [  102   161   175    80   186   168    92   147    94   113   136   150   303   206   162    78   171    93   136   214 10965]]

2024-06-06 01:29:35,110 - ==> Best [Top1: 85.745   Top5: 97.884   Sparsity:0.00   Params: 424448 on epoch: 103]
2024-06-06 01:29:35,110 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:29:35,134 - 

2024-06-06 01:29:35,135 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:29:41,083 - Epoch: [106][  100/ 1218]    Overall Loss 0.278843    Objective Loss 0.278843                                        LR 0.000500    Time 0.059453    
2024-06-06 01:29:45,709 - Epoch: [106][  200/ 1218]    Overall Loss 0.283111    Objective Loss 0.283111                                        LR 0.000500    Time 0.052849    
2024-06-06 01:29:50,410 - Epoch: [106][  300/ 1218]    Overall Loss 0.279764    Objective Loss 0.279764                                        LR 0.000500    Time 0.050894    
2024-06-06 01:29:55,115 - Epoch: [106][  400/ 1218]    Overall Loss 0.278901    Objective Loss 0.278901                                        LR 0.000500    Time 0.049928    
2024-06-06 01:29:59,862 - Epoch: [106][  500/ 1218]    Overall Loss 0.279642    Objective Loss 0.279642                                        LR 0.000500    Time 0.049432    
2024-06-06 01:30:04,624 - Epoch: [106][  600/ 1218]    Overall Loss 0.280869    Objective Loss 0.280869                                        LR 0.000500    Time 0.049127    
2024-06-06 01:30:09,281 - Epoch: [106][  700/ 1218]    Overall Loss 0.280773    Objective Loss 0.280773                                        LR 0.000500    Time 0.048759    
2024-06-06 01:30:14,016 - Epoch: [106][  800/ 1218]    Overall Loss 0.279147    Objective Loss 0.279147                                        LR 0.000500    Time 0.048580    
2024-06-06 01:30:18,872 - Epoch: [106][  900/ 1218]    Overall Loss 0.279340    Objective Loss 0.279340                                        LR 0.000500    Time 0.048575    
2024-06-06 01:30:23,700 - Epoch: [106][ 1000/ 1218]    Overall Loss 0.280275    Objective Loss 0.280275                                        LR 0.000500    Time 0.048544    
2024-06-06 01:30:28,654 - Epoch: [106][ 1100/ 1218]    Overall Loss 0.281398    Objective Loss 0.281398                                        LR 0.000500    Time 0.048633    
2024-06-06 01:30:33,274 - Epoch: [106][ 1200/ 1218]    Overall Loss 0.281282    Objective Loss 0.281282                                        LR 0.000500    Time 0.048428    
2024-06-06 01:30:34,131 - Epoch: [106][ 1218/ 1218]    Overall Loss 0.281334    Objective Loss 0.281334    Top1 87.041565    Top5 98.288509    LR 0.000500    Time 0.048416    
2024-06-06 01:30:34,291 - --- validate (epoch=106)-----------
2024-06-06 01:30:34,291 - 34633 samples (256 per mini-batch)
2024-06-06 01:30:39,832 - Epoch: [106][  100/  136]    Loss 0.315266    Top1 85.722656    Top5 97.902344    
2024-06-06 01:30:41,566 - Epoch: [106][  136/  136]    Loss 0.313339    Top1 85.551353    Top5 97.967257    
2024-06-06 01:30:41,751 - ==> Top1: 85.551    Top5: 97.967    Loss: 0.313

2024-06-06 01:30:41,752 - ==> Confusion:
[[  825     0     5     3    11     1     0     1     6    62     0     2     0     1     4     1     1     0     0     0     8]
 [    2   960     2     1    19    17     0    10     4     2     4     2     2     3     2     0     6     2    13     4     8]
 [    2     5   878     7     7     1     8    11     1     5     7     3     3     1     5     1     7     2     1     2    13]
 [    1     2     6   927     1     1     2     1     3     4    10     0     7     2    22     2     0     3    10     2    10]
 [   15     5     1     1   982     1     2     1     2    11     0     3     1     2    10     1     9     1     0     1     5]
 [    1    17     4     3    18   889     2    25     6     6     2    10    10    18     4     0     8     1     2     6    11]
 [    1     3    17     2     3     3  1022     4     0     3     2     2     1     0     1     6     1     1     1     8     5]
 [    2    10     8     3     2    18     3   957     0     1     4     8     5     4     2     1     1     2    29    10     7]
 [   11     0     1     1     1     1     1     0   901    36     9     1     1    13    13     0     2     4     4     0     2]
 [   50     0     2     0     5     0     1     2    38   878     0     1     1    12     4     1     1     0     1     1     3]
 [    0     1     3    14     3     2     3     3    14     0   979     0     1     8    17     1     0     0    13     1     1]
 [    2     2     0     0     1    10     1     5     0     2     1   892    38     5     2    11     3    15     1    13     7]
 [    1     2     1     3     1     5     1     2     4     2     3    50   869     7     0     2     5    20     7     2     8]
 [    1     0     1     2     1     9     1     1    16    18     5    10     4   898     8     1     4     2     0     9    10]
 [    6     0     5    13     9     1     0     1    34     7     6     4     2     7   980     0     1     1    13     1     7]
 [    4     1     2     1     3     0     4     0     0     4     0    19     8     3     1   987    10     9     2     2     6]
 [    1     5     3     0     6     5     2     1     3     3     2     5     2     6     2     6   997     1     2     3    17]
 [    6     0     2     1     2     1     0     1     1     1     0     9    32     2     4     8     3   925     1     1     5]
 [    3     5     4    11     4     3     0    10    10     2     5     0     2     1    15     0     1     0   966     3    13]
 [    1     5     4     1     0     6     6     6     0     1     1    12     8     3     0     7     6     2     4  1003    12]
 [  162   149   162    79   180   133    44   123   130   153   164   144   281   209   208    99   165    79   178   176 10914]]

2024-06-06 01:30:41,755 - ==> Best [Top1: 85.745   Top5: 97.884   Sparsity:0.00   Params: 424448 on epoch: 103]
2024-06-06 01:30:41,755 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:30:41,772 - 

2024-06-06 01:30:41,772 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:30:48,081 - Epoch: [107][  100/ 1218]    Overall Loss 0.278092    Objective Loss 0.278092                                        LR 0.000500    Time 0.063057    
2024-06-06 01:30:52,915 - Epoch: [107][  200/ 1218]    Overall Loss 0.282461    Objective Loss 0.282461                                        LR 0.000500    Time 0.055687    
2024-06-06 01:30:57,763 - Epoch: [107][  300/ 1218]    Overall Loss 0.282680    Objective Loss 0.282680                                        LR 0.000500    Time 0.053279    
2024-06-06 01:31:02,499 - Epoch: [107][  400/ 1218]    Overall Loss 0.281079    Objective Loss 0.281079                                        LR 0.000500    Time 0.051794    
2024-06-06 01:31:07,072 - Epoch: [107][  500/ 1218]    Overall Loss 0.283057    Objective Loss 0.283057                                        LR 0.000500    Time 0.050576    
2024-06-06 01:31:11,867 - Epoch: [107][  600/ 1218]    Overall Loss 0.282417    Objective Loss 0.282417                                        LR 0.000500    Time 0.050135    
2024-06-06 01:31:16,790 - Epoch: [107][  700/ 1218]    Overall Loss 0.284076    Objective Loss 0.284076                                        LR 0.000500    Time 0.050003    
2024-06-06 01:31:21,582 - Epoch: [107][  800/ 1218]    Overall Loss 0.285540    Objective Loss 0.285540                                        LR 0.000500    Time 0.049740    
2024-06-06 01:31:26,252 - Epoch: [107][  900/ 1218]    Overall Loss 0.285429    Objective Loss 0.285429                                        LR 0.000500    Time 0.049400    
2024-06-06 01:31:30,826 - Epoch: [107][ 1000/ 1218]    Overall Loss 0.285312    Objective Loss 0.285312                                        LR 0.000500    Time 0.049032    
2024-06-06 01:31:35,496 - Epoch: [107][ 1100/ 1218]    Overall Loss 0.283945    Objective Loss 0.283945                                        LR 0.000500    Time 0.048818    
2024-06-06 01:31:40,297 - Epoch: [107][ 1200/ 1218]    Overall Loss 0.284765    Objective Loss 0.284765                                        LR 0.000500    Time 0.048749    
2024-06-06 01:31:41,077 - Epoch: [107][ 1218/ 1218]    Overall Loss 0.284965    Objective Loss 0.284965    Top1 86.797066    Top5 98.044010    LR 0.000500    Time 0.048668    
2024-06-06 01:31:41,249 - --- validate (epoch=107)-----------
2024-06-06 01:31:41,250 - 34633 samples (256 per mini-batch)
2024-06-06 01:31:46,807 - Epoch: [107][  100/  136]    Loss 0.318736    Top1 85.632812    Top5 97.820312    
2024-06-06 01:31:48,496 - Epoch: [107][  136/  136]    Loss 0.316285    Top1 85.900731    Top5 97.892184    
2024-06-06 01:31:48,660 - ==> Top1: 85.901    Top5: 97.892    Loss: 0.316

2024-06-06 01:31:48,661 - ==> Confusion:
[[  797     3     3     1     8     4     0     0     9    82     1     2     5     1     2     1     3     1     0     2     6]
 [    2   970     3     1    21    17     2    10     1     0     7     1     2     1     3     1     5     2     6     2     6]
 [    3     2   872    10     2     1    27     7     1     3     8     8     2     2     1     3     1     0     5     5     7]
 [    3     1     7   930     1     5     2     0     0     2    17     5     6     4    15     4     0     4     5     1     4]
 [   10     4     2     0   986     6     0     1     1     9     1     2     0     4     4     6     4     1     1     4     8]
 [    2    31     6     2     7   903     6    19     2     2     3    10     7    13     3     2     4     1     2    10     8]
 [    0     4     6     0     1     3  1032     4     0     2     5     3     3     1     0     5     1     3     1     7     5]
 [    0     9     9     5     0    27     6   960     4     1     2     8     4     0     0     0     1     1    15    15    10]
 [    8     3     1     1     1     3     2     1   890    38    12     1     7     7    13     0     1     3     5     0     5]
 [   43     1     1     0     3     1     0     4    45   853     3     4     1    18     8     3     2     2     1     0     8]
 [    0     2     4     5     0     0     5     1     9     0  1011     0     1     5     1     0     2     0     8     4     6]
 [    0     2     2     0     0    10     4     3     2     1     1   902    30     6     0     8     3    15     3    12     7]
 [    0     4     4     2     0     4     1     1     1     1     1    64   852     7     2     4     3    26     2     9     7]
 [    1     0     2     0     2    12     0     3    12    17     7    16     3   904     2     0     3     2     3     5     7]
 [    5     4     3    14     4     0     1     1    26     8     8     2     1     5   996     0     1     4     6     2     7]
 [    0     3     3     0     1     1     8     0     1     2     0    19     5     2     0   991     5    15     0     5     5]
 [    4     9     2     2     6     6     1     0     3     0     3     5     3     2     5     8   988     1     0    13    11]
 [    1     2     0     0     0     0     0     3     0     3     1    17    17     1     2     5     2   946     1     2     2]
 [    2     6     6     6     3     2     1    18     6     1     5     0     2     1    13     0     0     0   970     7     9]
 [    0     4     3     0     1     3    14    11     0     1     2    15     6     4     0     6     6     1     3  1005     3]
 [  125   187   169    87   130   132    99   134   107    90   146   143   270   194   151   110   164    94   133   275 10992]]

2024-06-06 01:31:48,663 - ==> Best [Top1: 85.901   Top5: 97.892   Sparsity:0.00   Params: 424448 on epoch: 107]
2024-06-06 01:31:48,663 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:31:48,693 - 

2024-06-06 01:31:48,693 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:31:54,752 - Epoch: [108][  100/ 1218]    Overall Loss 0.285246    Objective Loss 0.285246                                        LR 0.000500    Time 0.060565    
2024-06-06 01:31:59,418 - Epoch: [108][  200/ 1218]    Overall Loss 0.282481    Objective Loss 0.282481                                        LR 0.000500    Time 0.053599    
2024-06-06 01:32:04,063 - Epoch: [108][  300/ 1218]    Overall Loss 0.281330    Objective Loss 0.281330                                        LR 0.000500    Time 0.051202    
2024-06-06 01:32:09,098 - Epoch: [108][  400/ 1218]    Overall Loss 0.283105    Objective Loss 0.283105                                        LR 0.000500    Time 0.050985    
2024-06-06 01:32:14,050 - Epoch: [108][  500/ 1218]    Overall Loss 0.282100    Objective Loss 0.282100                                        LR 0.000500    Time 0.050688    
2024-06-06 01:32:18,858 - Epoch: [108][  600/ 1218]    Overall Loss 0.282613    Objective Loss 0.282613                                        LR 0.000500    Time 0.050250    
2024-06-06 01:32:23,581 - Epoch: [108][  700/ 1218]    Overall Loss 0.282533    Objective Loss 0.282533                                        LR 0.000500    Time 0.049814    
2024-06-06 01:32:28,325 - Epoch: [108][  800/ 1218]    Overall Loss 0.283266    Objective Loss 0.283266                                        LR 0.000500    Time 0.049515    
2024-06-06 01:32:32,991 - Epoch: [108][  900/ 1218]    Overall Loss 0.284229    Objective Loss 0.284229                                        LR 0.000500    Time 0.049196    
2024-06-06 01:32:37,834 - Epoch: [108][ 1000/ 1218]    Overall Loss 0.285386    Objective Loss 0.285386                                        LR 0.000500    Time 0.049116    
2024-06-06 01:32:42,580 - Epoch: [108][ 1100/ 1218]    Overall Loss 0.285679    Objective Loss 0.285679                                        LR 0.000500    Time 0.048964    
2024-06-06 01:32:47,439 - Epoch: [108][ 1200/ 1218]    Overall Loss 0.284889    Objective Loss 0.284889                                        LR 0.000500    Time 0.048931    
2024-06-06 01:32:48,338 - Epoch: [108][ 1218/ 1218]    Overall Loss 0.285029    Objective Loss 0.285029    Top1 87.041565    Top5 98.288509    LR 0.000500    Time 0.048946    
2024-06-06 01:32:48,534 - --- validate (epoch=108)-----------
2024-06-06 01:32:48,534 - 34633 samples (256 per mini-batch)
2024-06-06 01:32:53,975 - Epoch: [108][  100/  136]    Loss 0.305395    Top1 86.640625    Top5 98.046875    
2024-06-06 01:32:55,627 - Epoch: [108][  136/  136]    Loss 0.309047    Top1 86.654347    Top5 98.068316    
2024-06-06 01:32:55,802 - ==> Top1: 86.654    Top5: 98.068    Loss: 0.309

2024-06-06 01:32:55,803 - ==> Confusion:
[[  849     0     2     0    16     1     1     1     8    29     0     1     5     3     4     2     0     1     1     0     7]
 [    2   950     0     3    20    27     6     5     4     4     1     0     4     0     5     0     7     1    11     3    10]
 [    7     2   884     5     2     2    11    14     0     8     2     2     3     2     1     5     5     1     4     2     8]
 [    3     2     6   928     0     4     1     3     2     3    11     0     9     3    14     1     2     7     5     2    10]
 [    9     6     3     1   984     9     0     2     1     7     2     3     3     1     8     4     2     0     2     1     6]
 [    6    11     2     2    15   898     4    24     3     5     2    10     5    15     2     2     7     0     1    10    19]
 [    0     2     5     0     3     1  1019     9     0     2     3     5     2     0     0     8     1     4     2    12     8]
 [    1    13    11     3     2    27     3   955     1     4     6    11     3     2     0     1     2     0    11     8    13]
 [   11     3     0     1     3     0     0     3   892    31     8     1     4    11    15     1     2     2     5     2     7]
 [   74     1     4     1    10     0     0     0    42   836     1     0     6    10     4     3     1     2     0     0     6]
 [    1     2     4    10     1     2     3     9    14     1   982     0     1    10     0     0     2     1     6     1    14]
 [    1     1     0     0     1    10     1     2     2     3     0   909    29     5     0     8     4    12     0    16     7]
 [    0     1     0     0     1     3     2     2     1     3     1    45   888     1     0    11     2    19     3     4     8]
 [    2     1     2     1     7    15     1     4    10    17     6    13     4   892     2     1     2     1     3     4    13]
 [    5     3     7    16     8     2     0     1    25     5     8     1     3     4   988     0     2     2    10     2     6]
 [    1     1     0     1     1     1     5     2     0     1     0    11     8     0     1  1006     3    13     2     4     5]
 [    2     6     2     1     4     5     0     1     5     1     0     5     3     1     3     8   997     3     1     6    18]
 [    2     1     1     0     1     2     4     1     0     0     0    15    18     1     2    11     3   935     0     1     7]
 [    4     6     4     5     1     2     0    18     5     0     1     1     6     1     6     2     0     0   982     2    12]
 [    1     3     0     0     1     8    11     3     0     1     0     8     9     2     1     9     1     1     3  1015    11]
 [  121   145   111    62   163   153    81   145    78   101   139   118   283   202   147    97   119    90   125   230 11222]]

2024-06-06 01:32:55,806 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:32:55,806 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:32:55,828 - 

2024-06-06 01:32:55,828 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:33:01,946 - Epoch: [109][  100/ 1218]    Overall Loss 0.272762    Objective Loss 0.272762                                        LR 0.000500    Time 0.061155    
2024-06-06 01:33:06,781 - Epoch: [109][  200/ 1218]    Overall Loss 0.280326    Objective Loss 0.280326                                        LR 0.000500    Time 0.054741    
2024-06-06 01:33:11,649 - Epoch: [109][  300/ 1218]    Overall Loss 0.279683    Objective Loss 0.279683                                        LR 0.000500    Time 0.052714    
2024-06-06 01:33:16,240 - Epoch: [109][  400/ 1218]    Overall Loss 0.280105    Objective Loss 0.280105                                        LR 0.000500    Time 0.051008    
2024-06-06 01:33:20,987 - Epoch: [109][  500/ 1218]    Overall Loss 0.280285    Objective Loss 0.280285                                        LR 0.000500    Time 0.050298    
2024-06-06 01:33:25,810 - Epoch: [109][  600/ 1218]    Overall Loss 0.278325    Objective Loss 0.278325                                        LR 0.000500    Time 0.049949    
2024-06-06 01:33:30,468 - Epoch: [109][  700/ 1218]    Overall Loss 0.278537    Objective Loss 0.278537                                        LR 0.000500    Time 0.049465    
2024-06-06 01:33:35,014 - Epoch: [109][  800/ 1218]    Overall Loss 0.279575    Objective Loss 0.279575                                        LR 0.000500    Time 0.048962    
2024-06-06 01:33:39,842 - Epoch: [109][  900/ 1218]    Overall Loss 0.279999    Objective Loss 0.279999                                        LR 0.000500    Time 0.048884    
2024-06-06 01:33:44,597 - Epoch: [109][ 1000/ 1218]    Overall Loss 0.279925    Objective Loss 0.279925                                        LR 0.000500    Time 0.048749    
2024-06-06 01:33:49,289 - Epoch: [109][ 1100/ 1218]    Overall Loss 0.279813    Objective Loss 0.279813                                        LR 0.000500    Time 0.048581    
2024-06-06 01:33:53,934 - Epoch: [109][ 1200/ 1218]    Overall Loss 0.280381    Objective Loss 0.280381                                        LR 0.000500    Time 0.048401    
2024-06-06 01:33:54,779 - Epoch: [109][ 1218/ 1218]    Overall Loss 0.280221    Objective Loss 0.280221    Top1 88.264059    Top5 97.555012    LR 0.000500    Time 0.048379    
2024-06-06 01:33:54,966 - --- validate (epoch=109)-----------
2024-06-06 01:33:54,966 - 34633 samples (256 per mini-batch)
2024-06-06 01:34:00,502 - Epoch: [109][  100/  136]    Loss 0.316940    Top1 85.718750    Top5 98.027344    
2024-06-06 01:34:02,165 - Epoch: [109][  136/  136]    Loss 0.316598    Top1 85.848757    Top5 98.004793    
2024-06-06 01:34:02,353 - ==> Top1: 85.849    Top5: 98.005    Loss: 0.317

2024-06-06 01:34:02,354 - ==> Confusion:
[[  828     1     4     0    11     1     0     2     4    60     0     8     0     2     4     1     1     0     1     0     3]
 [    2   973     0     1    15    15     2    10     3     0     5     5     2     4     6     0     3     1    10     1     5]
 [    2     0   879     9     4     1    16     5     1     7    14     5     4     6     0     1     3     2     2     6     3]
 [    1     2    13   901     3     6     1     2     3     7    21     2     5     3    19     1     0     7    10     0     9]
 [   17     3     3     0   968     6     1     2     2    14     5     4     2     3     5     3     2     1     4     2     7]
 [    4    24     2     2     2   881     4    33     2     3     6    13     7    22     6     2     7     1     1     9    12]
 [    1     4    11     1     0     2  1022     3     2     2     5     4     3     1     0     3     2     3     1    14     2]
 [    0    14    11     1     0     9     3   961     1     4    10     9     4     5     2     0     0     3    21    10     9]
 [   10     5     0     0     1     2     1     1   866    43    28     3     4     9    19     0     2     1     4     0     3]
 [   63     2     0     0     5     0     0     1    28   873     0     5     0    15     6     0     0     1     0     0     2]
 [    0     2     4     6     1     1     1     3     7     3  1004     1     1     5     6     0     2     0     6     3     8]
 [    5     0     2     0     3    14     2     2     0     3     2   889    36    13     1    14     0    10     1    12     2]
 [    1     1     0     5     1     3     2     2     2     0     5    46   865     4     1     4     3    26     2     5    17]
 [    2     0     0     1     2    12     1     0     7    13     5     8     6   918     2     2     5     3     1     5     8]
 [    7     2     4    22     5     1     1     2    14     7     5     4     3     4   996     1     1     2     8     1     8]
 [    2     1     1     0     4     0     6     0     1     5     1    15     5     2     0  1005     6     7     0     2     3]
 [    3     7     3     1     2     7     3     4     3     4     3     4     2     3     0     9   998     1     1     4    10]
 [    0     3     2     3     1     1     1     1     2     2     1    11    26     2     0    17     3   917     0     3     9]
 [    2     8     5     7     1     4     2    14     4     1     7     2     1     1     6     0     0     0   985     2     6]
 [    1     2     7     0     2     5     7     4     1     1     2     9    11     2     0     6     4     3     2  1011     8]
 [  132   174   149    84   150   144    85   163    80   127   184   135   257   229   138    88   154    97   142   228 10992]]

2024-06-06 01:34:02,356 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:34:02,357 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:34:02,373 - 

2024-06-06 01:34:02,374 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:34:08,906 - Epoch: [110][  100/ 1218]    Overall Loss 0.284723    Objective Loss 0.284723                                        LR 0.000500    Time 0.065299    
2024-06-06 01:34:13,909 - Epoch: [110][  200/ 1218]    Overall Loss 0.280725    Objective Loss 0.280725                                        LR 0.000500    Time 0.057653    
2024-06-06 01:34:18,736 - Epoch: [110][  300/ 1218]    Overall Loss 0.278042    Objective Loss 0.278042                                        LR 0.000500    Time 0.054518    
2024-06-06 01:34:23,679 - Epoch: [110][  400/ 1218]    Overall Loss 0.278199    Objective Loss 0.278199                                        LR 0.000500    Time 0.053241    
2024-06-06 01:34:28,450 - Epoch: [110][  500/ 1218]    Overall Loss 0.279063    Objective Loss 0.279063                                        LR 0.000500    Time 0.052129    
2024-06-06 01:34:33,151 - Epoch: [110][  600/ 1218]    Overall Loss 0.279104    Objective Loss 0.279104                                        LR 0.000500    Time 0.051273    
2024-06-06 01:34:37,904 - Epoch: [110][  700/ 1218]    Overall Loss 0.278718    Objective Loss 0.278718                                        LR 0.000500    Time 0.050735    
2024-06-06 01:34:42,786 - Epoch: [110][  800/ 1218]    Overall Loss 0.279263    Objective Loss 0.279263                                        LR 0.000500    Time 0.050494    
2024-06-06 01:34:47,694 - Epoch: [110][  900/ 1218]    Overall Loss 0.279430    Objective Loss 0.279430                                        LR 0.000500    Time 0.050334    
2024-06-06 01:34:52,422 - Epoch: [110][ 1000/ 1218]    Overall Loss 0.279981    Objective Loss 0.279981                                        LR 0.000500    Time 0.050024    
2024-06-06 01:34:57,200 - Epoch: [110][ 1100/ 1218]    Overall Loss 0.280214    Objective Loss 0.280214                                        LR 0.000500    Time 0.049818    
2024-06-06 01:35:01,985 - Epoch: [110][ 1200/ 1218]    Overall Loss 0.280586    Objective Loss 0.280586                                        LR 0.000500    Time 0.049652    
2024-06-06 01:35:02,810 - Epoch: [110][ 1218/ 1218]    Overall Loss 0.280436    Objective Loss 0.280436    Top1 87.775061    Top5 98.533007    LR 0.000500    Time 0.049595    
2024-06-06 01:35:02,974 - --- validate (epoch=110)-----------
2024-06-06 01:35:02,974 - 34633 samples (256 per mini-batch)
2024-06-06 01:35:08,497 - Epoch: [110][  100/  136]    Loss 0.320149    Top1 85.093750    Top5 97.703125    
2024-06-06 01:35:10,286 - Epoch: [110][  136/  136]    Loss 0.320327    Top1 85.141339    Top5 97.753588    
2024-06-06 01:35:10,467 - ==> Top1: 85.141    Top5: 97.754    Loss: 0.320

2024-06-06 01:35:10,468 - ==> Confusion:
[[  822     3     4     1    10     1     0     0     4    68     0     4     1     3     3     1     2     1     2     0     1]
 [    0   974     1     1    15    14     3     7     4     2     5     2     4     0     7     0     4     2     8     2     8]
 [    6     0   864    13     3     5    16    14     1     6     4     3     2     6     4     3     4     1     4     5     6]
 [    2     3     5   926     1     4     2     2     3     3    10     1    10     1    21     1     1     5     8     1     6]
 [   21    10     1     0   967     8     1     1     0    13     2     3     2     5     6     1     4     3     2     0     4]
 [    3    30     2     4    12   891     2    28     7     2     2     9     7    16     0     1     1     1     3    12    10]
 [    0     0    10     2     1     2  1021     3     1     2     6     2     2     0     0     5     3     7     2    13     4]
 [    2    12     8     4     1    18     3   947     2     4     8     7     7     2     0     0     1     2    28    13     8]
 [   10     2     0     0     2     1     0     1   889    50     8     4     3     7    14     0     2     2     3     0     4]
 [   44     0     1     2     3     0     0     0    34   891     1     1     4     9     5     1     2     1     1     1     0]
 [    1     3     4     9     1     2     3     4    17     2   975     0     0    10    10     0     0     0    15     2     6]
 [    1     0     2     0     0    12     1     3     3     2     1   862    47    10     1     8     5    29     0    18     6]
 [    1     0     2     6     1     3     1     2     4     1     3    39   863     3     3     6     1    39     5     5     7]
 [    1     2     0     0     4    11     0     3    14    19     9     9     9   894     4     1     3     1     0     9     8]
 [    5     4     3    11     9     1     0     0    21    12     3     2     1     3   999     0     2     1    12     3     6]
 [    1     2     1     2     1     1     5     0     0     1     1    15    14     2     2   990     6    14     1     3     4]
 [    3    11     2     2    11     4     0     1     5     3     2     4     1     2     2     8   990     3     1     4    13]
 [    1     2     1     2     0     0     1     0     2     2     0     6    16     1     4     5     1   953     2     1     5]
 [    1     6     3    14     2     2     2    14     8     0     8     2     1     1    13     0     0     1   971     2     7]
 [    1     7     3     0     0     3     5     7     0     0     0    15     8     5     0     9     8     3     3  1000    11]
 [  161   184   111   111   174   141    75   138   114   155   141   115   294   187   192   112   187   128   176   238 10798]]

2024-06-06 01:35:10,471 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:35:10,471 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:35:10,499 - 

2024-06-06 01:35:10,499 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:35:16,717 - Epoch: [111][  100/ 1218]    Overall Loss 0.285492    Objective Loss 0.285492                                        LR 0.000500    Time 0.062155    
2024-06-06 01:35:21,712 - Epoch: [111][  200/ 1218]    Overall Loss 0.285269    Objective Loss 0.285269                                        LR 0.000500    Time 0.056041    
2024-06-06 01:35:26,403 - Epoch: [111][  300/ 1218]    Overall Loss 0.282256    Objective Loss 0.282256                                        LR 0.000500    Time 0.052989    
2024-06-06 01:35:31,308 - Epoch: [111][  400/ 1218]    Overall Loss 0.281385    Objective Loss 0.281385                                        LR 0.000500    Time 0.052000    
2024-06-06 01:35:36,105 - Epoch: [111][  500/ 1218]    Overall Loss 0.280486    Objective Loss 0.280486                                        LR 0.000500    Time 0.051190    
2024-06-06 01:35:40,741 - Epoch: [111][  600/ 1218]    Overall Loss 0.280673    Objective Loss 0.280673                                        LR 0.000500    Time 0.050382    
2024-06-06 01:35:45,382 - Epoch: [111][  700/ 1218]    Overall Loss 0.281341    Objective Loss 0.281341                                        LR 0.000500    Time 0.049812    
2024-06-06 01:35:50,124 - Epoch: [111][  800/ 1218]    Overall Loss 0.280485    Objective Loss 0.280485                                        LR 0.000500    Time 0.049510    
2024-06-06 01:35:54,812 - Epoch: [111][  900/ 1218]    Overall Loss 0.281667    Objective Loss 0.281667                                        LR 0.000500    Time 0.049215    
2024-06-06 01:35:59,457 - Epoch: [111][ 1000/ 1218]    Overall Loss 0.282609    Objective Loss 0.282609                                        LR 0.000500    Time 0.048937    
2024-06-06 01:36:04,292 - Epoch: [111][ 1100/ 1218]    Overall Loss 0.282137    Objective Loss 0.282137                                        LR 0.000500    Time 0.048882    
2024-06-06 01:36:09,015 - Epoch: [111][ 1200/ 1218]    Overall Loss 0.281462    Objective Loss 0.281462                                        LR 0.000500    Time 0.048742    
2024-06-06 01:36:09,794 - Epoch: [111][ 1218/ 1218]    Overall Loss 0.281671    Objective Loss 0.281671    Top1 84.596577    Top5 97.066015    LR 0.000500    Time 0.048661    
2024-06-06 01:36:10,021 - --- validate (epoch=111)-----------
2024-06-06 01:36:10,021 - 34633 samples (256 per mini-batch)
2024-06-06 01:36:15,505 - Epoch: [111][  100/  136]    Loss 0.317668    Top1 85.777344    Top5 97.988281    
2024-06-06 01:36:17,157 - Epoch: [111][  136/  136]    Loss 0.317235    Top1 85.767909    Top5 97.990356    
2024-06-06 01:36:17,350 - ==> Top1: 85.768    Top5: 97.990    Loss: 0.317

2024-06-06 01:36:17,351 - ==> Confusion:
[[  829     0     1     1     9     0     0     1    10    54     1     3     1     4     2     1     2     1     1     4     6]
 [    5   976     2     0    13    22     3     5     7     1     3     1     1     2     5     0     5     2     5     0     5]
 [    6     2   889     6     3     1    21     8     0     7     4     2     2     2     0     1     2     2     3     3     6]
 [    3     2    10   921     0     4     4     2     3     4    17     2     5     5    14     1     2     2     7     1     7]
 [   13    11     1     0   974     3     1     1     2    11     1     4     2     4     9     3     5     1     3     3     2]
 [    4    17     4     0    12   888     2    30     4     6     1    13     7    21     2     0     5     1     3    11    12]
 [    0     2     3     0     1     2  1034     3     2     1     4     3     0     1     0     7     2     4     2     7     8]
 [    6    10     9     2     1    27     4   951     1     2     7     6     6     3     1     0     1     2    20    11     7]
 [    9     5     3     0     1     2     0     3   891    28    15     3     5    10    10     0     4     4     2     1     6]
 [   56     1     6     0     4     5     1     1    51   846     2     0     3    19     4     1     0     0     0     0     1]
 [    2     3     5     8     1     4     4     5    13     3   997     0     0     7     4     0     1     0     3     0     4]
 [    2     4     0     0     1     7     2     5     1     3     0   892    32    10     0    13     4    12     0    16     7]
 [    0     0     2     6     0     1     3     4     3     4     4    46   867     0     0     8     3    25     2     2    15]
 [    1     0     0     2     3     6     2     2     6    11    12    11     5   916     4     2     3     1     1     7     6]
 [    9     1     4    12     9     3     0     2    35     9     1     0     4     3   977     1     2     2    12     1    11]
 [    2     3     2     2     3     0     8     1     0     2     1    11     5     1     0   994    16     9     1     2     3]
 [    3    10     6     0     5     6     1     2     3     1     1     6     4     4     1     6   994     1     3     7     8]
 [    3     0     0     0     0     1     2     0     2     2     0     8    22     0     2    12     1   936     3     5     6]
 [    3     5     7     7     4     1     1    19     7     0    10     1     2     3    13     0     1     0   963     4     7]
 [    1     4     3     1     1     6    11     6     0     0     1    12     8     5     0     3     4     3     5  1001    13]
 [  152   176   161    89   172   123   102   114   104   116   153   149   260   224   167    99   170   100   148   185 10968]]

2024-06-06 01:36:17,354 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:36:17,354 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:36:17,372 - 

2024-06-06 01:36:17,372 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:36:23,734 - Epoch: [112][  100/ 1218]    Overall Loss 0.279147    Objective Loss 0.279147                                        LR 0.000500    Time 0.063594    
2024-06-06 01:36:28,548 - Epoch: [112][  200/ 1218]    Overall Loss 0.280017    Objective Loss 0.280017                                        LR 0.000500    Time 0.055858    
2024-06-06 01:36:33,146 - Epoch: [112][  300/ 1218]    Overall Loss 0.280353    Objective Loss 0.280353                                        LR 0.000500    Time 0.052559    
2024-06-06 01:36:37,943 - Epoch: [112][  400/ 1218]    Overall Loss 0.279914    Objective Loss 0.279914                                        LR 0.000500    Time 0.051406    
2024-06-06 01:36:42,665 - Epoch: [112][  500/ 1218]    Overall Loss 0.278595    Objective Loss 0.278595                                        LR 0.000500    Time 0.050566    
2024-06-06 01:36:47,343 - Epoch: [112][  600/ 1218]    Overall Loss 0.278699    Objective Loss 0.278699                                        LR 0.000500    Time 0.049930    
2024-06-06 01:36:52,022 - Epoch: [112][  700/ 1218]    Overall Loss 0.277416    Objective Loss 0.277416                                        LR 0.000500    Time 0.049479    
2024-06-06 01:36:56,581 - Epoch: [112][  800/ 1218]    Overall Loss 0.277012    Objective Loss 0.277012                                        LR 0.000500    Time 0.048991    
2024-06-06 01:37:01,283 - Epoch: [112][  900/ 1218]    Overall Loss 0.278273    Objective Loss 0.278273                                        LR 0.000500    Time 0.048769    
2024-06-06 01:37:05,951 - Epoch: [112][ 1000/ 1218]    Overall Loss 0.278589    Objective Loss 0.278589                                        LR 0.000500    Time 0.048558    
2024-06-06 01:37:10,474 - Epoch: [112][ 1100/ 1218]    Overall Loss 0.278637    Objective Loss 0.278637                                        LR 0.000500    Time 0.048254    
2024-06-06 01:37:15,183 - Epoch: [112][ 1200/ 1218]    Overall Loss 0.278936    Objective Loss 0.278936                                        LR 0.000500    Time 0.048155    
2024-06-06 01:37:16,021 - Epoch: [112][ 1218/ 1218]    Overall Loss 0.278857    Objective Loss 0.278857    Top1 89.242054    Top5 97.799511    LR 0.000500    Time 0.048131    
2024-06-06 01:37:16,178 - --- validate (epoch=112)-----------
2024-06-06 01:37:16,178 - 34633 samples (256 per mini-batch)
2024-06-06 01:37:21,716 - Epoch: [112][  100/  136]    Loss 0.312550    Top1 85.878906    Top5 97.855469    
2024-06-06 01:37:23,421 - Epoch: [112][  136/  136]    Loss 0.318115    Top1 85.816995    Top5 97.854647    
2024-06-06 01:37:23,586 - ==> Top1: 85.817    Top5: 97.855    Loss: 0.318

2024-06-06 01:37:23,587 - ==> Confusion:
[[  830     0     0     0     9     4     1     3     7    56     0     1     2     2     4     3     1     1     0     1     6]
 [    0   950     0     2    16    24     2    11     3     2     3     4     3     3     6     0     6     2    12     5     9]
 [    4     3   879     7     2     2    10     9     0     6     8     3     3     2     2     6     6     2     4     6     6]
 [    3     1     9   917     3     7     3     0     2     4    14     1     5     1    19     2     2     4     5     2    12]
 [   19     7     6     0   964     1     0     5     3    15     2     1     1     3     9     1     8     1     2     0     6]
 [    3    26     2     1    18   900     0    26     4     6     3     8     4    14     4     2     5     1     1     6     9]
 [    0     0    14     3     4     4  1018     4     2     2     5     1     2     1     0     5     3     2     2     9     5]
 [    0     9     8     1     1    25     4   970     3     3     5     4     3     2     2     0     4     0    19     7     7]
 [    8     6     0     2     0     3     0     4   877    49     9     1     3    11    16     0     3     3     1     1     5]
 [   51     0     4     0     4     3     0     0    30   877     1     2     2    13     5     0     2     0     0     2     5]
 [    0     2    11    11     0     2     2     2    10     4   987     3     1     6    15     1     1     0     2     1     3]
 [    1     1     1     0     2     8     2     4     0     1     1   919    22     4     0    18     0    14     0     8     5]
 [    1     1     1     7     2     3     0     1     2     3     3    82   835     2     1    11     1    17     4     5    13]
 [    1     1     0     1     4    16     0     5     8    17     7    11     2   902     4     3     2     1     2     8     6]
 [    7     3     0    10     7     3     0     0    25    14     3     0     2     3  1003     1     1     1     8     1     6]
 [    0     1     3     0     1     2     6     2     1     7     0    10     5     0     0  1010     6     5     1     2     4]
 [    1     8     1     1     4     4     2     2     7     2     1     3     4     1     1    11   999     0     1     3    16]
 [    1     3     0     1     2     3     3     1     1     1     0    15    23     1     1    17     1   923     0     2     6]
 [    1     7     9     9     1     3     2    14     2     1     4     1     3     1    19     0     0     1   974     2     4]
 [    1     5     1     1     0    10     5     6     1     1     1    20     8     2     1     8     6     2     6   988    15]
 [  136   168   154    96   159   159    79   140   102   128   118   133   202   211   191   101   229    72   165   190 10999]]

2024-06-06 01:37:23,590 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:37:23,590 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:37:23,616 - 

2024-06-06 01:37:23,616 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:37:29,555 - Epoch: [113][  100/ 1218]    Overall Loss 0.287055    Objective Loss 0.287055                                        LR 0.000500    Time 0.059360    
2024-06-06 01:37:34,282 - Epoch: [113][  200/ 1218]    Overall Loss 0.283579    Objective Loss 0.283579                                        LR 0.000500    Time 0.053305    
2024-06-06 01:37:38,980 - Epoch: [113][  300/ 1218]    Overall Loss 0.283153    Objective Loss 0.283153                                        LR 0.000500    Time 0.051189    
2024-06-06 01:37:43,995 - Epoch: [113][  400/ 1218]    Overall Loss 0.283342    Objective Loss 0.283342                                        LR 0.000500    Time 0.050924    
2024-06-06 01:37:48,672 - Epoch: [113][  500/ 1218]    Overall Loss 0.281610    Objective Loss 0.281610                                        LR 0.000500    Time 0.050090    
2024-06-06 01:37:53,345 - Epoch: [113][  600/ 1218]    Overall Loss 0.281495    Objective Loss 0.281495                                        LR 0.000500    Time 0.049526    
2024-06-06 01:37:58,071 - Epoch: [113][  700/ 1218]    Overall Loss 0.280752    Objective Loss 0.280752                                        LR 0.000500    Time 0.049200    
2024-06-06 01:38:02,613 - Epoch: [113][  800/ 1218]    Overall Loss 0.281750    Objective Loss 0.281750                                        LR 0.000500    Time 0.048725    
2024-06-06 01:38:07,278 - Epoch: [113][  900/ 1218]    Overall Loss 0.282044    Objective Loss 0.282044                                        LR 0.000500    Time 0.048493    
2024-06-06 01:38:11,899 - Epoch: [113][ 1000/ 1218]    Overall Loss 0.282690    Objective Loss 0.282690                                        LR 0.000500    Time 0.048261    
2024-06-06 01:38:16,582 - Epoch: [113][ 1100/ 1218]    Overall Loss 0.282854    Objective Loss 0.282854                                        LR 0.000500    Time 0.048129    
2024-06-06 01:38:21,245 - Epoch: [113][ 1200/ 1218]    Overall Loss 0.281542    Objective Loss 0.281542                                        LR 0.000500    Time 0.048003    
2024-06-06 01:38:22,042 - Epoch: [113][ 1218/ 1218]    Overall Loss 0.281402    Objective Loss 0.281402    Top1 85.574572    Top5 97.555012    LR 0.000500    Time 0.047947    
2024-06-06 01:38:22,224 - --- validate (epoch=113)-----------
2024-06-06 01:38:22,224 - 34633 samples (256 per mini-batch)
2024-06-06 01:38:27,854 - Epoch: [113][  100/  136]    Loss 0.318562    Top1 85.984375    Top5 97.933594    
2024-06-06 01:38:29,512 - Epoch: [113][  136/  136]    Loss 0.314917    Top1 86.065313    Top5 97.921058    
2024-06-06 01:38:29,673 - ==> Top1: 86.065    Top5: 97.921    Loss: 0.315

2024-06-06 01:38:29,675 - ==> Confusion:
[[  822     4     5     0    13     1     0     1     5    60     1     1     0     2     5     0     2     1     0     1     7]
 [    0   947     1     1    11    23     2    20     4     1     5     2     5     2     5     1     5     0    16     4     8]
 [    3     3   895     9     2     2    10     4     1     9     1     5     3     2     2     2     2     1     3     4     7]
 [    7     1     6   913     1     4     1     1     1     2    13     4     5     4    24     1     4     2    13     0     9]
 [   17    12     2     0   969    10     0     3     0     8     1     2     0     7     5     1     6     0     3     0     8]
 [    1    15     3     5    11   915     3    23     2     6     4     9     5    10     1     1     5     4     3     5    12]
 [    1     5    24     1     3     2  1015     7     0     3     3     3     1     0     0     5     2     1     1     3     6]
 [    1    10     8     4     4    25     1   958     1     2     5     9     2     4     0     0     3     1    26     6     7]
 [    6     3     0     0     1     5     0     0   889    37    17     1     2    15    10     0     4     2     7     0     3]
 [   46     0     0     0     2     1     1     0    26   895     1     1     1    12     6     1     1     2     0     2     3]
 [    0     4     4    10     0     1     1     6    13     2   992     0     0     3    10     0     2     1     9     0     6]
 [    1     3     4     0     0     7     2     4     0     3     1   889    32    10     0    10     6    23     1    11     4]
 [    2     2     8     6     2     5     0     3     0     0     0    66   842     4     1     2     5    29     8     3     7]
 [    2     2     1     1     3    11     1     3    13    22     7    10     6   886     4     0     2     6     2     6    13]
 [    5     4     1    16    11     4     2     0    18     8     6     2     1     2   987     0     2     3    14     2    10]
 [    0     1     4     0     1     3     5     2     1     7     0    15     4     1     0   990     7    12     2     6     5]
 [    3     6     4     1     5     6     1     1     5     0     2     5     3     1     2    10   994     2     1     6    14]
 [    2     0     0     2     3     1     0     1     1     1     1     8    13     1     5     7     0   952     1     2     4]
 [    3     3     1     5     4     1     0    19     0     0     0     1     2     1    12     0     1     1   995     1     8]
 [    0     3     2     2     3    10    12     9     0     0     1    11     6     0     0     7     7     4     3   992    16]
 [  127   121   165    90   141   142    88   147    87   151   135   131   282   196   152    97   136    99   201   174 11070]]

2024-06-06 01:38:29,678 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:38:29,678 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:38:29,711 - 

2024-06-06 01:38:29,711 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:38:35,839 - Epoch: [114][  100/ 1218]    Overall Loss 0.282352    Objective Loss 0.282352                                        LR 0.000500    Time 0.061242    
2024-06-06 01:38:40,484 - Epoch: [114][  200/ 1218]    Overall Loss 0.278930    Objective Loss 0.278930                                        LR 0.000500    Time 0.053836    
2024-06-06 01:38:45,037 - Epoch: [114][  300/ 1218]    Overall Loss 0.279237    Objective Loss 0.279237                                        LR 0.000500    Time 0.051063    
2024-06-06 01:38:49,656 - Epoch: [114][  400/ 1218]    Overall Loss 0.278890    Objective Loss 0.278890                                        LR 0.000500    Time 0.049840    
2024-06-06 01:38:54,341 - Epoch: [114][  500/ 1218]    Overall Loss 0.276897    Objective Loss 0.276897                                        LR 0.000500    Time 0.049238    
2024-06-06 01:38:59,175 - Epoch: [114][  600/ 1218]    Overall Loss 0.276874    Objective Loss 0.276874                                        LR 0.000500    Time 0.049085    
2024-06-06 01:39:03,856 - Epoch: [114][  700/ 1218]    Overall Loss 0.276810    Objective Loss 0.276810                                        LR 0.000500    Time 0.048757    
2024-06-06 01:39:08,505 - Epoch: [114][  800/ 1218]    Overall Loss 0.277392    Objective Loss 0.277392                                        LR 0.000500    Time 0.048471    
2024-06-06 01:39:13,228 - Epoch: [114][  900/ 1218]    Overall Loss 0.277439    Objective Loss 0.277439                                        LR 0.000500    Time 0.048331    
2024-06-06 01:39:17,799 - Epoch: [114][ 1000/ 1218]    Overall Loss 0.278011    Objective Loss 0.278011                                        LR 0.000500    Time 0.048067    
2024-06-06 01:39:22,482 - Epoch: [114][ 1100/ 1218]    Overall Loss 0.277996    Objective Loss 0.277996                                        LR 0.000500    Time 0.047953    
2024-06-06 01:39:27,155 - Epoch: [114][ 1200/ 1218]    Overall Loss 0.278444    Objective Loss 0.278444                                        LR 0.000500    Time 0.047844    
2024-06-06 01:39:28,043 - Epoch: [114][ 1218/ 1218]    Overall Loss 0.278349    Objective Loss 0.278349    Top1 88.753056    Top5 97.799511    LR 0.000500    Time 0.047866    
2024-06-06 01:39:28,266 - --- validate (epoch=114)-----------
2024-06-06 01:39:28,266 - 34633 samples (256 per mini-batch)
2024-06-06 01:39:33,779 - Epoch: [114][  100/  136]    Loss 0.320317    Top1 85.394531    Top5 97.851562    
2024-06-06 01:39:35,402 - Epoch: [114][  136/  136]    Loss 0.318547    Top1 85.539803    Top5 97.848872    
2024-06-06 01:39:35,587 - ==> Top1: 85.540    Top5: 97.849    Loss: 0.319

2024-06-06 01:39:35,588 - ==> Confusion:
[[  837     3     4     0    10     3     0     0     5    48     1     2     0     1     4     2     2     0     1     2     6]
 [    2   990     3     2    11     9     2     7     5     1     4     1     2     0     3     2     2     2     5     2     8]
 [    5     2   901     7     6     0     8     6     0     2     6     3     5     0     2     3     1     0     3     3     7]
 [    4     5     8   925     2     3     0     2     1     0    11     6     2     2    14     3     2     3    12     3     8]
 [   18     9     4     0   974     5     2     3     6     7     1     1     1     6     4     2     3     1     3     1     3]
 [    4    32     3     6    17   884     3    23     6     2     5    14     4    14     3     0     5     3     3     3     9]
 [    0     7    20     3     4     3  1003     5     0     1     8     1     0     1     0     5     1     4     2    13     5]
 [    1    13    13     0     1    21     2   939     2     6     6    11     3     1     1     2     3     0    34    11     7]
 [    8     4     0     0     0     4     0     2   893    33    11     2     3    11    17     1     3     1     5     1     3]
 [   63     2     2     0     2     1     0     2    29   859     2     1     0    18     8     3     1     0     2     2     4]
 [    0     1     6     8     0     1     1     3    20     0   982     1     1     7    14     0     2     0     9     2     6]
 [    1     2     1     0     3     7     1     2     0     3     0   904    33    11     0     5     3    15     1    10     9]
 [    0     0     1     1     0     4     1     2     3     2     1    52   869     4     3     6     1    22     6     7    10]
 [    1     2     2     0     2     9     0     3     9    15     7     8     6   914     2     3     2     1     1     3    11]
 [    4     1     3    18     8     1     0     2    21     7     5     5     4     3   994     0     2     1    12     0     7]
 [    3     0     3     1     3     1     3     1     0     4     0    12    10     1     0  1002     3    13     0     1     5]
 [    1    13     1     1     8     4     0     0     6     1     4     2     5     1     3     6   991     0     5     6    14]
 [    0     4     1     2     1     1     2     0     2     2     1     7    19     1     2    12     2   937     1     0     8]
 [    3    12     4    11     3     1     1    18     5     0     3     3     0     2    13     0     1     1   974     0     3]
 [    2     7     1     0     3    11     6     6     0     1     4    20     7     2     0     4     2     1     1  1004     6]
 [  180   226   199   117   182   153    72   118   101    91   158   145   282   204   200    78   159    85   157   176 10849]]

2024-06-06 01:39:35,591 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:39:35,591 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:39:35,608 - 

2024-06-06 01:39:35,608 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:39:42,029 - Epoch: [115][  100/ 1218]    Overall Loss 0.275443    Objective Loss 0.275443                                        LR 0.000500    Time 0.064180    
2024-06-06 01:39:46,790 - Epoch: [115][  200/ 1218]    Overall Loss 0.273952    Objective Loss 0.273952                                        LR 0.000500    Time 0.055884    
2024-06-06 01:39:51,683 - Epoch: [115][  300/ 1218]    Overall Loss 0.275813    Objective Loss 0.275813                                        LR 0.000500    Time 0.053559    
2024-06-06 01:39:56,612 - Epoch: [115][  400/ 1218]    Overall Loss 0.275102    Objective Loss 0.275102                                        LR 0.000500    Time 0.052486    
2024-06-06 01:40:01,346 - Epoch: [115][  500/ 1218]    Overall Loss 0.275307    Objective Loss 0.275307                                        LR 0.000500    Time 0.051454    
2024-06-06 01:40:06,106 - Epoch: [115][  600/ 1218]    Overall Loss 0.276509    Objective Loss 0.276509                                        LR 0.000500    Time 0.050809    
2024-06-06 01:40:10,801 - Epoch: [115][  700/ 1218]    Overall Loss 0.278429    Objective Loss 0.278429                                        LR 0.000500    Time 0.050254    
2024-06-06 01:40:15,489 - Epoch: [115][  800/ 1218]    Overall Loss 0.278764    Objective Loss 0.278764                                        LR 0.000500    Time 0.049830    
2024-06-06 01:40:20,142 - Epoch: [115][  900/ 1218]    Overall Loss 0.278950    Objective Loss 0.278950                                        LR 0.000500    Time 0.049461    
2024-06-06 01:40:24,820 - Epoch: [115][ 1000/ 1218]    Overall Loss 0.278913    Objective Loss 0.278913                                        LR 0.000500    Time 0.049190    
2024-06-06 01:40:29,580 - Epoch: [115][ 1100/ 1218]    Overall Loss 0.279286    Objective Loss 0.279286                                        LR 0.000500    Time 0.049044    
2024-06-06 01:40:34,345 - Epoch: [115][ 1200/ 1218]    Overall Loss 0.279184    Objective Loss 0.279184                                        LR 0.000500    Time 0.048926    
2024-06-06 01:40:35,125 - Epoch: [115][ 1218/ 1218]    Overall Loss 0.279473    Objective Loss 0.279473    Top1 87.041565    Top5 96.821516    LR 0.000500    Time 0.048843    
2024-06-06 01:40:35,308 - --- validate (epoch=115)-----------
2024-06-06 01:40:35,309 - 34633 samples (256 per mini-batch)
2024-06-06 01:40:40,722 - Epoch: [115][  100/  136]    Loss 0.310238    Top1 85.296875    Top5 97.757812    
2024-06-06 01:40:42,375 - Epoch: [115][  136/  136]    Loss 0.312864    Top1 85.150001    Top5 97.791124    
2024-06-06 01:40:42,549 - ==> Top1: 85.150    Top5: 97.791    Loss: 0.313

2024-06-06 01:40:42,550 - ==> Confusion:
[[  839     2     1     0    13     2     0     2     7    45     1     3     4     4     0     0     1     1     0     0     6]
 [    0   982     0     0    10    16     2     8     5     2     5     4     1     3     3     3     2     1    10     2     4]
 [    5     3   880     8     4     4    15     6     3     4     6     3     4     2     2     3     2     1     7     5     3]
 [    3     5    10   915     2     4     0     4     0     2    11     1     7     2    27     4     0     5     4     1     9]
 [   15     9     4     1   966    11     1     1     1     8     4     4     8     1     4     3     3     0     2     0     8]
 [    1    27     1     2    11   910     4    24     2     3     1     6    10    10     3     2     3     4     1     9     9]
 [    1     1    14     1     2     6  1009     6     1     4     6     4     3     0     0     7     3     3     1    10     4]
 [    1     7     7     0     2    20     3   979     3     2     6     8     1     0     0     1     2     1    20     9     5]
 [   12     6     0     0     4     5     0     1   875    35    15     2     5     8    21     2     0     5     0     2     4]
 [   59     0     0     1     9     3     0     1    40   854     1     2     2    12     7     1     0     4     0     1     4]
 [    0     2     6    10     1     1     1     5     5     2   994     2     1     7    12     0     3     1     4     1     6]
 [    1     1     1     1     1    12     2     8     0     1     0   880    47     5     0    14     1    19     0    13     4]
 [    1     0     1     3     3     6     0     3     3     0     2    34   881     2     1     8     2    23     1     9    12]
 [    4     0     0     0     4    15     2     2    19    15    10     7     5   898     2     3     2     3     0     8     2]
 [    9     3     2    10     8     4     0     0    20    12     3     3     0     4  1009     0     1     1     6     1     2]
 [    1     5     4     0     2     3     2     0     0     2     0    13     8     1     1   992     4    19     2     6     1]
 [    3    11     3     4     4     6     3     3     2     1     3     5     3     3     1    14   989     0     2     4     8]
 [    2     3     0     3     2     1     0     2     0     2     0     4    29     2     0     8     0   943     1     2     1]
 [    0    14     6    11     3     1     0    11     4     2     7     1     3     1    19     0     0     2   964     1     8]
 [    0     4     0     0     2     9    10     7     0     0     0    13     8     7     0    10     7     5     3   999     4]
 [  149   190   155    91   203   175    77   151    86   118   165   142   319   204   188   113   189   126   148   211 10732]]

2024-06-06 01:40:42,552 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:40:42,553 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:40:42,577 - 

2024-06-06 01:40:42,577 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:40:48,905 - Epoch: [116][  100/ 1218]    Overall Loss 0.272469    Objective Loss 0.272469                                        LR 0.000500    Time 0.063248    
2024-06-06 01:40:53,624 - Epoch: [116][  200/ 1218]    Overall Loss 0.274543    Objective Loss 0.274543                                        LR 0.000500    Time 0.055210    
2024-06-06 01:40:58,236 - Epoch: [116][  300/ 1218]    Overall Loss 0.276492    Objective Loss 0.276492                                        LR 0.000500    Time 0.052172    
2024-06-06 01:41:02,959 - Epoch: [116][  400/ 1218]    Overall Loss 0.275084    Objective Loss 0.275084                                        LR 0.000500    Time 0.050931    
2024-06-06 01:41:07,755 - Epoch: [116][  500/ 1218]    Overall Loss 0.277244    Objective Loss 0.277244                                        LR 0.000500    Time 0.050333    
2024-06-06 01:41:12,396 - Epoch: [116][  600/ 1218]    Overall Loss 0.275794    Objective Loss 0.275794                                        LR 0.000500    Time 0.049675    
2024-06-06 01:41:17,178 - Epoch: [116][  700/ 1218]    Overall Loss 0.278281    Objective Loss 0.278281                                        LR 0.000500    Time 0.049408    
2024-06-06 01:41:21,975 - Epoch: [116][  800/ 1218]    Overall Loss 0.278425    Objective Loss 0.278425                                        LR 0.000500    Time 0.049225    
2024-06-06 01:41:26,819 - Epoch: [116][  900/ 1218]    Overall Loss 0.277780    Objective Loss 0.277780                                        LR 0.000500    Time 0.049136    
2024-06-06 01:41:31,542 - Epoch: [116][ 1000/ 1218]    Overall Loss 0.278179    Objective Loss 0.278179                                        LR 0.000500    Time 0.048944    
2024-06-06 01:41:36,150 - Epoch: [116][ 1100/ 1218]    Overall Loss 0.279271    Objective Loss 0.279271                                        LR 0.000500    Time 0.048681    
2024-06-06 01:41:40,968 - Epoch: [116][ 1200/ 1218]    Overall Loss 0.278906    Objective Loss 0.278906                                        LR 0.000500    Time 0.048638    
2024-06-06 01:41:41,739 - Epoch: [116][ 1218/ 1218]    Overall Loss 0.278957    Objective Loss 0.278957    Top1 86.308068    Top5 98.044010    LR 0.000500    Time 0.048552    
2024-06-06 01:41:41,937 - --- validate (epoch=116)-----------
2024-06-06 01:41:41,937 - 34633 samples (256 per mini-batch)
2024-06-06 01:41:47,690 - Epoch: [116][  100/  136]    Loss 0.311338    Top1 85.746094    Top5 97.925781    
2024-06-06 01:41:49,383 - Epoch: [116][  136/  136]    Loss 0.315394    Top1 85.539803    Top5 97.889296    
2024-06-06 01:41:49,566 - ==> Top1: 85.540    Top5: 97.889    Loss: 0.315

2024-06-06 01:41:49,567 - ==> Confusion:
[[  818     1     4     2     9     0     0     1     4    67     0     2     1     1     7     4     0     0     2     1     7]
 [    0   966     1     1    13    20     6    14     7     1     0     1     4     4     6     0     2     2     7     1     7]
 [    7     6   877     6     3     0    24    11     2     9     3     1     1     2     0     5     1     1     5     4     2]
 [    2     0    12   917     0     5     3     2     2     2    21     1     4     3    17     2     1     7     5     1     9]
 [   16     9     1     1   973     8     1     2     0    15     0     2     0     1    10     3     5     0     3     0     4]
 [    4    13     1     1     7   922     2    25     3     5     2    10     3    12     4     3     3     2     1     8    12]
 [    2     2    11     0     4     3  1027     7     2     2     7     1     3     1     0     5     0     1     0     5     3]
 [    0    10    13     1     1    24     3   962     2     4     4     8     2     3     0     0     0     2    20     9     9]
 [   11     1     0     1     5     2     0     3   857    54    10     2     4    13    23     1     3     0     8     0     4]
 [   55     1     3     1     5     1     0     2    30   877     1     1     1    12     5     0     0     1     1     0     4]
 [    0     2     9     9     1     1     4     4    15     1   984     1     0     4    13     0     0     0     8     1     7]
 [    3     2     1     1     1     7     4     5     0     3     1   901    33     5     0    13     4    14     1     9     3]
 [    3     0     1     6     2     1     0     1     2     2     3    65   851     3     1     7     1    31     2     4     9]
 [    4     1     0     2     4     7     0     4     7    25     8    13     2   894     5     1     5     3     0     3    13]
 [    6     0     1    14     7     2     0     1    20     9     7     0     1     3  1003     1     1     1    12     0     9]
 [    1     0     1     0     2     2     3     1     1     8     1    12     7     2     0  1009     6     6     1     1     2]
 [    4     8     3     1     9     4     2     2     1     2     5     6     3     5     1    11   992     2     0     2     9]
 [    2     1     1     3     1     2     0     0     1     1     0    15    14     2     3    16     1   940     1     1     0]
 [    3     7     4    12     1     2     1    24     4     3     4     2     2     1     9     0     1     1   965     2    10]
 [    0     2     2     0     0     3    12    10     1     4     2    16     8     1     1     5     3     6     4   995    13]
 [  149   146   175    97   193   158    93   162    86   141   143   153   242   205   158   125   169   128   152   162 10895]]

2024-06-06 01:41:49,570 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:41:49,570 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:41:49,594 - 

2024-06-06 01:41:49,594 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:41:55,630 - Epoch: [117][  100/ 1218]    Overall Loss 0.270639    Objective Loss 0.270639                                        LR 0.000500    Time 0.060321    
2024-06-06 01:42:00,407 - Epoch: [117][  200/ 1218]    Overall Loss 0.273303    Objective Loss 0.273303                                        LR 0.000500    Time 0.054034    
2024-06-06 01:42:05,027 - Epoch: [117][  300/ 1218]    Overall Loss 0.276498    Objective Loss 0.276498                                        LR 0.000500    Time 0.051419    
2024-06-06 01:42:09,785 - Epoch: [117][  400/ 1218]    Overall Loss 0.277505    Objective Loss 0.277505                                        LR 0.000500    Time 0.050453    
2024-06-06 01:42:14,520 - Epoch: [117][  500/ 1218]    Overall Loss 0.276883    Objective Loss 0.276883                                        LR 0.000500    Time 0.049828    
2024-06-06 01:42:19,198 - Epoch: [117][  600/ 1218]    Overall Loss 0.276918    Objective Loss 0.276918                                        LR 0.000500    Time 0.049317    
2024-06-06 01:42:23,791 - Epoch: [117][  700/ 1218]    Overall Loss 0.277787    Objective Loss 0.277787                                        LR 0.000500    Time 0.048831    
2024-06-06 01:42:28,389 - Epoch: [117][  800/ 1218]    Overall Loss 0.278359    Objective Loss 0.278359                                        LR 0.000500    Time 0.048472    
2024-06-06 01:42:33,052 - Epoch: [117][  900/ 1218]    Overall Loss 0.278689    Objective Loss 0.278689                                        LR 0.000500    Time 0.048262    
2024-06-06 01:42:37,769 - Epoch: [117][ 1000/ 1218]    Overall Loss 0.279782    Objective Loss 0.279782                                        LR 0.000500    Time 0.048151    
2024-06-06 01:42:42,341 - Epoch: [117][ 1100/ 1218]    Overall Loss 0.279292    Objective Loss 0.279292                                        LR 0.000500    Time 0.047927    
2024-06-06 01:42:47,029 - Epoch: [117][ 1200/ 1218]    Overall Loss 0.279408    Objective Loss 0.279408                                        LR 0.000500    Time 0.047838    
2024-06-06 01:42:47,810 - Epoch: [117][ 1218/ 1218]    Overall Loss 0.279609    Objective Loss 0.279609    Top1 86.552567    Top5 99.022005    LR 0.000500    Time 0.047772    
2024-06-06 01:42:47,985 - --- validate (epoch=117)-----------
2024-06-06 01:42:47,985 - 34633 samples (256 per mini-batch)
2024-06-06 01:42:53,725 - Epoch: [117][  100/  136]    Loss 0.318597    Top1 85.550781    Top5 97.781250    
2024-06-06 01:42:55,378 - Epoch: [117][  136/  136]    Loss 0.315634    Top1 85.574452    Top5 97.794011    
2024-06-06 01:42:55,567 - ==> Top1: 85.574    Top5: 97.794    Loss: 0.316

2024-06-06 01:42:55,568 - ==> Confusion:
[[  832     1     2     1     8     0     0     1     7    52     2     2     2     2     7     1     3     0     0     1     7]
 [    3   965     2     3    17    16     3    11     0     1     3     6     4     1     2     0     7     1     7     5     6]
 [    5     1   901     8     3     5     7     6     0     6     1     3     2     4     3     5     2     0     2     3     3]
 [    3     3    19   920     1     4     1     3     1     2    11     0    10     1    15     3     1     3     7     1     7]
 [   19     7     6     1   981     3     3     2     1     8     1     2     2     4     4     1     4     0     1     0     4]
 [    2    19     1     4    11   898     5    32     3     1     1    13     5    20     1     1     6     3     2     5    10]
 [    0     3    20     1     2     3  1009     4     2     2     2     8     2     1     0    10     4     4     1     3     5]
 [    0     8    14     2     2    22     2   954     1     3     6     9     6     4     1     1     1     2    20    12     7]
 [   14     5     1     0     1     3     0     0   863    41    19     6     5    12    16     1     1     3     6     0     5]
 [   53     0     3     0     2     2     0     1    22   883     0     4     0    20     1     2     0     2     1     0     5]
 [    1    10     9     8     4     3     4     1     8     1   986     1     1     9     8     0     1     0     7     1     1]
 [    1     2     2     0     3     8     1     1     1     2     0   917    28    11     1     8     4    12     0     4     5]
 [    0     2     4     2     1     1     1     3     1     1     2    51   873     6     2     4     2    23     2     3    11]
 [    3     1     3     0     5     7     0     2    10    14     5     7     7   912     5     1     6     0     2     4     7]
 [   11     2     1    16     8     2     0     0    13     6     6     4     1     2   995     1     2     1    19     2     6]
 [    2     0     3     1     4     0     4     1     0     4     2    12    11     2     0   996     8    15     0     0     1]
 [    3     7     6     1     7     1     1     0     2     1     3     3     4     4     2    15   998     2     2     2     8]
 [    1     0     0     1     2     0     0     1     1     1     0    11    33     3     0     9     0   935     2     0     5]
 [    2     9     8     9     4     3     0    16     4     0     3     1     4     1    10     1     1     1   977     0     4]
 [    2     4     8     2     0     9    11     7     1     0     1     9    11     8     0     3     8     0     4   988    12]
 [  164   179   228    86   213   114    78   131    73    96   136   132   285   247   150   121   211    93   145   196 10854]]

2024-06-06 01:42:55,571 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:42:55,571 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:42:55,595 - 

2024-06-06 01:42:55,595 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:43:01,936 - Epoch: [118][  100/ 1218]    Overall Loss 0.264932    Objective Loss 0.264932                                        LR 0.000500    Time 0.063386    
2024-06-06 01:43:06,506 - Epoch: [118][  200/ 1218]    Overall Loss 0.270801    Objective Loss 0.270801                                        LR 0.000500    Time 0.054531    
2024-06-06 01:43:11,167 - Epoch: [118][  300/ 1218]    Overall Loss 0.270602    Objective Loss 0.270602                                        LR 0.000500    Time 0.051883    
2024-06-06 01:43:15,965 - Epoch: [118][  400/ 1218]    Overall Loss 0.271470    Objective Loss 0.271470                                        LR 0.000500    Time 0.050888    
2024-06-06 01:43:20,632 - Epoch: [118][  500/ 1218]    Overall Loss 0.271209    Objective Loss 0.271209                                        LR 0.000500    Time 0.050041    
2024-06-06 01:43:25,267 - Epoch: [118][  600/ 1218]    Overall Loss 0.272317    Objective Loss 0.272317                                        LR 0.000500    Time 0.049422    
2024-06-06 01:43:30,060 - Epoch: [118][  700/ 1218]    Overall Loss 0.272084    Objective Loss 0.272084                                        LR 0.000500    Time 0.049206    
2024-06-06 01:43:34,603 - Epoch: [118][  800/ 1218]    Overall Loss 0.272736    Objective Loss 0.272736                                        LR 0.000500    Time 0.048731    
2024-06-06 01:43:39,167 - Epoch: [118][  900/ 1218]    Overall Loss 0.274176    Objective Loss 0.274176                                        LR 0.000500    Time 0.048386    
2024-06-06 01:43:43,853 - Epoch: [118][ 1000/ 1218]    Overall Loss 0.274961    Objective Loss 0.274961                                        LR 0.000500    Time 0.048232    
2024-06-06 01:43:48,604 - Epoch: [118][ 1100/ 1218]    Overall Loss 0.276420    Objective Loss 0.276420                                        LR 0.000500    Time 0.048164    
2024-06-06 01:43:53,155 - Epoch: [118][ 1200/ 1218]    Overall Loss 0.276891    Objective Loss 0.276891                                        LR 0.000500    Time 0.047941    
2024-06-06 01:43:54,005 - Epoch: [118][ 1218/ 1218]    Overall Loss 0.276954    Objective Loss 0.276954    Top1 89.242054    Top5 99.511002    LR 0.000500    Time 0.047930    
2024-06-06 01:43:54,200 - --- validate (epoch=118)-----------
2024-06-06 01:43:54,200 - 34633 samples (256 per mini-batch)
2024-06-06 01:43:59,745 - Epoch: [118][  100/  136]    Loss 0.313003    Top1 85.511719    Top5 97.789062    
2024-06-06 01:44:01,432 - Epoch: [118][  136/  136]    Loss 0.310999    Top1 85.479167    Top5 97.828661    
2024-06-06 01:44:01,590 - ==> Top1: 85.479    Top5: 97.829    Loss: 0.311

2024-06-06 01:44:01,591 - ==> Confusion:
[[  841     0     2     2    10     1     0     1     8    40     1     4     1     2     5     2     2     3     0     3     3]
 [    1   990     0     1    12    12     1     6     1     0     4     1     4     2     8     1     4     0     8     1     6]
 [    3     7   885    11     4     0    14     4     0     5     8     3     1     7     2     2     3     3     2     2     4]
 [    2     3    11   922     1     6     3     1     2     1    11     1     9     5    13     2     3     7     5     2     6]
 [   18     7     1     1   960     7     0     2     4     9     0     1     3     5    11     1     4     2     2     0    16]
 [    3    36     2     9    11   872     4    20     2     5     2    19     6    17     3     3     2     4     5     9     9]
 [    1     3    19     2     3     2  1024     4     1     1     2     0     0     2     1     4     1     3     2     5     6]
 [    1    17     7     2     1    13     7   940     1     2     8     8     3     3     2     0     2     0    44    10     6]
 [    7     5     2     1     2     1     1     0   887    41    12     2     2    14    11     0     1     5     5     0     3]
 [   71     0     1     1     5     0     1     2    27   852     1     0     0    15     9     2     1     5     0     1     7]
 [    2     5     4     8     0     7     5     2    10     2   982     0     1    11     6     0     0     1     7     3     8]
 [    0     4     3     0     1     5     3     5     0     1     0   929    23     8     1     6     1    11     0     7     3]
 [    0     2     2     2     1     2     3     1     0     1     3    69   853     3     1     7     4    24     8     3     6]
 [    1     2     2     0     5     5     1     5    16    13     4    10     5   906     3     4     2     4     0     5     8]
 [    1     2     1    16    10     1     1     0    19     4     5     0     2     5  1017     0     0     0     7     1     6]
 [    1     1     4     2     4     2     4     1     0     1     0    18     7     5     2   982    13    13     3     1     2]
 [    3     6     3     1     6     6     1     1     7     2     4     5     4     2     3     7   990     3     1     4    13]
 [    2     3     0     3     2     1     0     1     0     4     0    14    20     1     3     3     0   936     3     3     6]
 [    1     9     5    13     2     1     0    10     5     1     2     2     3     0    10     0     2     1   981     4     6]
 [    0     4     3     0     3     6     9     4     1     0     3    16     3     5     2     5     1     1     6  1009     7]
 [  154   202   170    96   167   118    82   118    88   120   148   150   306   241   188    85   149   115   166   223 10846]]

2024-06-06 01:44:01,594 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:44:01,594 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:44:01,611 - 

2024-06-06 01:44:01,612 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:44:07,608 - Epoch: [119][  100/ 1218]    Overall Loss 0.270074    Objective Loss 0.270074                                        LR 0.000500    Time 0.059932    
2024-06-06 01:44:12,313 - Epoch: [119][  200/ 1218]    Overall Loss 0.271030    Objective Loss 0.271030                                        LR 0.000500    Time 0.053483    
2024-06-06 01:44:16,950 - Epoch: [119][  300/ 1218]    Overall Loss 0.271562    Objective Loss 0.271562                                        LR 0.000500    Time 0.051107    
2024-06-06 01:44:21,657 - Epoch: [119][  400/ 1218]    Overall Loss 0.273740    Objective Loss 0.273740                                        LR 0.000500    Time 0.050094    
2024-06-06 01:44:26,430 - Epoch: [119][  500/ 1218]    Overall Loss 0.274413    Objective Loss 0.274413                                        LR 0.000500    Time 0.049617    
2024-06-06 01:44:31,050 - Epoch: [119][  600/ 1218]    Overall Loss 0.273718    Objective Loss 0.273718                                        LR 0.000500    Time 0.049043    
2024-06-06 01:44:35,641 - Epoch: [119][  700/ 1218]    Overall Loss 0.274089    Objective Loss 0.274089                                        LR 0.000500    Time 0.048592    
2024-06-06 01:44:40,290 - Epoch: [119][  800/ 1218]    Overall Loss 0.274775    Objective Loss 0.274775                                        LR 0.000500    Time 0.048327    
2024-06-06 01:44:44,917 - Epoch: [119][  900/ 1218]    Overall Loss 0.275218    Objective Loss 0.275218                                        LR 0.000500    Time 0.048096    
2024-06-06 01:44:49,490 - Epoch: [119][ 1000/ 1218]    Overall Loss 0.275436    Objective Loss 0.275436                                        LR 0.000500    Time 0.047858    
2024-06-06 01:44:54,061 - Epoch: [119][ 1100/ 1218]    Overall Loss 0.275141    Objective Loss 0.275141                                        LR 0.000500    Time 0.047661    
2024-06-06 01:44:58,780 - Epoch: [119][ 1200/ 1218]    Overall Loss 0.274922    Objective Loss 0.274922                                        LR 0.000500    Time 0.047620    
2024-06-06 01:44:59,555 - Epoch: [119][ 1218/ 1218]    Overall Loss 0.274845    Objective Loss 0.274845    Top1 86.797066    Top5 97.799511    LR 0.000500    Time 0.047552    
2024-06-06 01:44:59,721 - --- validate (epoch=119)-----------
2024-06-06 01:44:59,721 - 34633 samples (256 per mini-batch)
2024-06-06 01:45:05,402 - Epoch: [119][  100/  136]    Loss 0.324141    Top1 85.023438    Top5 97.710938    
2024-06-06 01:45:07,156 - Epoch: [119][  136/  136]    Loss 0.316244    Top1 85.048942    Top5 97.794011    
2024-06-06 01:45:07,341 - ==> Top1: 85.049    Top5: 97.794    Loss: 0.316

2024-06-06 01:45:07,342 - ==> Confusion:
[[  830     0     2     0     8     1     0     1     6    55     1     3     4     1     4     3     3     3     1     0     5]
 [    0   990     3     2    13    15     2    11     5     0     1     3     0     1     2     0     1     2     4     2     6]
 [    5     2   900     5     5     2    12     5     0     1     9     2     2     5     0     1     3     2     1     3     5]
 [    3     3    10   920     2     3     0     4     1     2    11     4     4     3    15     4     4     6     7     0    10]
 [   18     9     1     2   973     8     0     2     0    10     1     3     3     4     6     0     4     4     0     0     6]
 [    4    18     1     1    14   903     4    26     2     1     8    12     3    15     3     3     3     1     1    11     9]
 [    0     8    11     0     3     1  1020     5     0     1     4     3     1     1     2     5     2     6     2     7     4]
 [    1    10     8     0     3    19     4   975     1     3     4     7     6     5     0     2     0     1    15     8     5]
 [    9     5     0     0     5     2     0     3   879    43     4     4     4    13    12     0     1     3    10     0     5]
 [   47     1     3     0     2     3     0     0    45   860     2     3     0    18     4     1     1     1     1     3     6]
 [    0     3     8     4     1     0     1     7    10     1   989     0     1    13    10     1     1     0     5     2     7]
 [    1     2     0     1     2     8     3     4     1     0     3   918    23     7     0    10     3    12     1     9     3]
 [    1     1     3     4     2     8     0     4     1     0     1    59   847     3     1     9     4    29     5     8     5]
 [    1     0     0     2     5     4     0     2    11    10     3     9     3   927     3     2     2     1     1     6     9]
 [    4     4     1    18    15     3     0     0    23     9     4     4     2     4   984     0     3     4     6     1     9]
 [    0     1     3     0     5     2     2     0     1     2     0    16     4     3     0  1007     4     8     1     5     2]
 [    1    12     2     1     5     7     0     1     2     1     2     4     2     7     2    11   989     1     0     8    14]
 [    1     0     0     2     0     3     0     2     1     4     0    17    19     1     1     5     0   939     1     5     4]
 [    1     6     9    11     2     1     0    21     5     0     5     1     1     2    15     2     7     0   959     2     8]
 [    0     4     3     1     0    14     6     6     2     0     2    16     4     4     1     5     6     1     0  1006     7]
 [  148   252   182    88   155   170    90   168   106   117   147   176   256   250   162   129   174   126   143   253 10640]]

2024-06-06 01:45:07,344 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:45:07,344 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:45:07,369 - 

2024-06-06 01:45:07,369 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:45:13,665 - Epoch: [120][  100/ 1218]    Overall Loss 0.279204    Objective Loss 0.279204                                        LR 0.000500    Time 0.062934    
2024-06-06 01:45:18,340 - Epoch: [120][  200/ 1218]    Overall Loss 0.282170    Objective Loss 0.282170                                        LR 0.000500    Time 0.054832    
2024-06-06 01:45:23,047 - Epoch: [120][  300/ 1218]    Overall Loss 0.280999    Objective Loss 0.280999                                        LR 0.000500    Time 0.052235    
2024-06-06 01:45:27,782 - Epoch: [120][  400/ 1218]    Overall Loss 0.279296    Objective Loss 0.279296                                        LR 0.000500    Time 0.051010    
2024-06-06 01:45:32,559 - Epoch: [120][  500/ 1218]    Overall Loss 0.278039    Objective Loss 0.278039                                        LR 0.000500    Time 0.050358    
2024-06-06 01:45:37,245 - Epoch: [120][  600/ 1218]    Overall Loss 0.277670    Objective Loss 0.277670                                        LR 0.000500    Time 0.049772    
2024-06-06 01:45:41,822 - Epoch: [120][  700/ 1218]    Overall Loss 0.278958    Objective Loss 0.278958                                        LR 0.000500    Time 0.049198    
2024-06-06 01:45:46,475 - Epoch: [120][  800/ 1218]    Overall Loss 0.278369    Objective Loss 0.278369                                        LR 0.000500    Time 0.048861    
2024-06-06 01:45:51,204 - Epoch: [120][  900/ 1218]    Overall Loss 0.277377    Objective Loss 0.277377                                        LR 0.000500    Time 0.048684    
2024-06-06 01:45:55,768 - Epoch: [120][ 1000/ 1218]    Overall Loss 0.277169    Objective Loss 0.277169                                        LR 0.000500    Time 0.048378    
2024-06-06 01:46:00,683 - Epoch: [120][ 1100/ 1218]    Overall Loss 0.276855    Objective Loss 0.276855                                        LR 0.000500    Time 0.048447    
2024-06-06 01:46:05,493 - Epoch: [120][ 1200/ 1218]    Overall Loss 0.275637    Objective Loss 0.275637                                        LR 0.000500    Time 0.048416    
2024-06-06 01:46:06,312 - Epoch: [120][ 1218/ 1218]    Overall Loss 0.275702    Objective Loss 0.275702    Top1 84.352078    Top5 97.799511    LR 0.000500    Time 0.048372    
2024-06-06 01:46:06,491 - --- validate (epoch=120)-----------
2024-06-06 01:46:06,491 - 34633 samples (256 per mini-batch)
2024-06-06 01:46:12,115 - Epoch: [120][  100/  136]    Loss 0.313348    Top1 86.468750    Top5 98.015625    
2024-06-06 01:46:13,861 - Epoch: [120][  136/  136]    Loss 0.313071    Top1 86.469552    Top5 98.056767    
2024-06-06 01:46:14,028 - ==> Top1: 86.470    Top5: 98.057    Loss: 0.313

2024-06-06 01:46:14,029 - ==> Confusion:
[[  814     1     7     0    13     1     0     1     6    63     1     3     1     2     5     2     1     1     2     1     6]
 [    4   960     3     2    12    19     3     9     3     1     2     1     2     1     6     0     4     4    13     3    11]
 [    4     3   882    14     2     1    13    10     0     8     6     3     1     0     1     2     1     1     6     4     8]
 [    7     1    10   931     4     5     3     1     0     1     9     2     4     2    12     4     3     2    13     0     2]
 [   15    11     3     2   972     4     0     1     0    13     1     1     2     4     6     3     4     1     4     1     6]
 [    3    23     4     4    13   899     5    30     1     4     0     8     3    12     4     2     5     2     4     6    11]
 [    3     3    11     1     3     4  1022     4     1     3     3     3     0     1     0     2     1     3     1    10     7]
 [    2    14    14     1     2    24     3   942     1     6     2     5     4     7     2     1     0     1    31     9     6]
 [    7     3     3     1     3     1     1     1   875    34    13     3     3     9    24     0     0     5    11     0     5]
 [   50     0     4     0     5     0     0     0    38   877     0     1     0    11     6     0     1     2     1     1     4]
 [    1     1     3    19     1     2     0     4    12     1   990     0     0     7    10     0     1     0     7     0     5]
 [    2     1     3     0     2    14     2     2     0     1     1   890    26     8     0    12     2    20     1    17     7]
 [    1     1     3     2     2     2     1     4     0     2     3    34   859     2     1     9     2    40     8     7    12]
 [    0     0     2     3     3    12     1     3     3     9     9    12     2   911     6     2     6     3     1     2    11]
 [    7     2     1    21     5     0     0     3    17     8     3     1     3     5   997     0     2     2    16     0     5]
 [    1     2     2     1     0     1     6     1     1     4     1    10     6     1     0  1002     8    11     2     4     2]
 [    3     9     1     3     5     3     1     0     2     3     3     1     0     0     0     8  1005     0     2     3    20]
 [    2     1     0     0     0     1     4     2     0     2     1     6    15     2     1     6     2   944     7     0     9]
 [    1     8     7    14     1     2     1    14     2     1     4     2     0     1    13     0     2     0   979     0     6]
 [    1     2     2     1     1     6     2     7     0     2     0    14     2     2     1     5     4     4     6  1017     9]
 [  137   167   192   123   163   153    81   136    70   112   140   101   195   137   137   109   141    82   188   189 11179]]

2024-06-06 01:46:14,032 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:46:14,032 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:46:14,056 - 

2024-06-06 01:46:14,056 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:46:20,309 - Epoch: [121][  100/ 1218]    Overall Loss 0.284094    Objective Loss 0.284094                                        LR 0.000500    Time 0.062495    
2024-06-06 01:46:25,066 - Epoch: [121][  200/ 1218]    Overall Loss 0.280656    Objective Loss 0.280656                                        LR 0.000500    Time 0.055022    
2024-06-06 01:46:29,642 - Epoch: [121][  300/ 1218]    Overall Loss 0.276852    Objective Loss 0.276852                                        LR 0.000500    Time 0.051928    
2024-06-06 01:46:34,291 - Epoch: [121][  400/ 1218]    Overall Loss 0.276869    Objective Loss 0.276869                                        LR 0.000500    Time 0.050563    
2024-06-06 01:46:39,022 - Epoch: [121][  500/ 1218]    Overall Loss 0.276044    Objective Loss 0.276044                                        LR 0.000500    Time 0.049910    
2024-06-06 01:46:43,851 - Epoch: [121][  600/ 1218]    Overall Loss 0.275893    Objective Loss 0.275893                                        LR 0.000500    Time 0.049635    
2024-06-06 01:46:48,732 - Epoch: [121][  700/ 1218]    Overall Loss 0.275181    Objective Loss 0.275181                                        LR 0.000500    Time 0.049515    
2024-06-06 01:46:53,731 - Epoch: [121][  800/ 1218]    Overall Loss 0.276331    Objective Loss 0.276331                                        LR 0.000500    Time 0.049571    
2024-06-06 01:46:58,720 - Epoch: [121][  900/ 1218]    Overall Loss 0.277200    Objective Loss 0.277200                                        LR 0.000500    Time 0.049604    
2024-06-06 01:47:03,737 - Epoch: [121][ 1000/ 1218]    Overall Loss 0.277681    Objective Loss 0.277681                                        LR 0.000500    Time 0.049658    
2024-06-06 01:47:08,517 - Epoch: [121][ 1100/ 1218]    Overall Loss 0.277509    Objective Loss 0.277509                                        LR 0.000500    Time 0.049488    
2024-06-06 01:47:13,132 - Epoch: [121][ 1200/ 1218]    Overall Loss 0.277088    Objective Loss 0.277088                                        LR 0.000500    Time 0.049207    
2024-06-06 01:47:13,963 - Epoch: [121][ 1218/ 1218]    Overall Loss 0.277359    Objective Loss 0.277359    Top1 85.574572    Top5 98.288509    LR 0.000500    Time 0.049162    
2024-06-06 01:47:14,125 - --- validate (epoch=121)-----------
2024-06-06 01:47:14,125 - 34633 samples (256 per mini-batch)
2024-06-06 01:47:19,663 - Epoch: [121][  100/  136]    Loss 0.321384    Top1 85.031250    Top5 97.742188    
2024-06-06 01:47:21,386 - Epoch: [121][  136/  136]    Loss 0.313729    Top1 85.219300    Top5 97.819998    
2024-06-06 01:47:21,559 - ==> Top1: 85.219    Top5: 97.820    Loss: 0.314

2024-06-06 01:47:21,560 - ==> Confusion:
[[  804     3     3     0     8     3     0     0    12    70     1     0     0     4    10     1     2     1     1     2     6]
 [    2   975     3     0    16    12     2     7     2     1     5     4     2     0     2     0     6     1    11     3     9]
 [    3     4   887    16     4     4    11     1     0     5     5     1     2     4     2     4     3     0     3     3     8]
 [    6     1    11   924     2     6     1     0     1     4    12     2     6     1    17     3     0     5     7     1     6]
 [   10     6     1     0   981     4     1     1     1     9     1     3     3     6     6     3     9     0     4     1     4]
 [    5    29     4     1    12   887     3    26     1     4     6    11     1    20     1     1     7     2     4    13     5]
 [    0     3    15     1     1     4  1018     2     0     3     3     2     4     0     1     6     1     5     0     7    10]
 [    1    18    19     3     3    34     5   930     1     1     4     6     4     6     3     1     3     1    21     8     5]
 [    7     6     1     0     1     1     0     2   873    37    15     8     3    15    19     0     2     1     5     0     6]
 [   42     1     4     0     4     3     0     0    48   860     0     0     0    24     8     0     2     2     1     1     1]
 [    1     3     5     6     1     2     2     5    11     0   992     0     1     8    11     0     4     0    10     0     2]
 [    1     1     5     1     3    14     2     0     1     4     0   905    19     8     3     4     1    16     5    15     3]
 [    0     3     8     4     2     6     1     2     3     1     2    58   851     3     3     3     1    23     8     6     7]
 [    1     2     1     2     0     8     0     3     5     8     6    11     6   926     6     3     3     1     0     7     2]
 [    3     1     1    16     7     3     0     0    19    11     7     2     3     5  1002     0     0     3    10     0     5]
 [    5     3     6     0     3     0     4     1     0     5     0    17     5     3     0   988     7    14     0     2     3]
 [    5     4     2     2     5     4     1     1     4     1     3     3     2     1     5     6   998     2     2     9    12]
 [    4     5     3     2     2     1     2     0     2     2     0    13    21     2     3     5     2   932     1     0     3]
 [    0     1     9     5     2     1     1     9     7     1     2     2     1     0    17     0     2     0   992     0     6]
 [    2     5     6     0     1    13    10     4     0     3     0    15     3     3     0     2     8     2     5  1000     6]
 [  136   204   180   121   187   160    68   124    86   102   162   152   257   229   259    78   209    97   156   176 10789]]

2024-06-06 01:47:21,562 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:47:21,563 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:47:21,582 - 

2024-06-06 01:47:21,582 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:47:27,682 - Epoch: [122][  100/ 1218]    Overall Loss 0.279274    Objective Loss 0.279274                                        LR 0.000500    Time 0.060977    
2024-06-06 01:47:32,223 - Epoch: [122][  200/ 1218]    Overall Loss 0.274784    Objective Loss 0.274784                                        LR 0.000500    Time 0.053182    
2024-06-06 01:47:36,793 - Epoch: [122][  300/ 1218]    Overall Loss 0.277962    Objective Loss 0.277962                                        LR 0.000500    Time 0.050682    
2024-06-06 01:47:41,357 - Epoch: [122][  400/ 1218]    Overall Loss 0.279267    Objective Loss 0.279267                                        LR 0.000500    Time 0.049415    
2024-06-06 01:47:46,074 - Epoch: [122][  500/ 1218]    Overall Loss 0.278572    Objective Loss 0.278572                                        LR 0.000500    Time 0.048963    
2024-06-06 01:47:50,746 - Epoch: [122][  600/ 1218]    Overall Loss 0.278119    Objective Loss 0.278119                                        LR 0.000500    Time 0.048586    
2024-06-06 01:47:55,574 - Epoch: [122][  700/ 1218]    Overall Loss 0.278386    Objective Loss 0.278386                                        LR 0.000500    Time 0.048540    
2024-06-06 01:48:00,237 - Epoch: [122][  800/ 1218]    Overall Loss 0.279152    Objective Loss 0.279152                                        LR 0.000500    Time 0.048299    
2024-06-06 01:48:04,879 - Epoch: [122][  900/ 1218]    Overall Loss 0.279701    Objective Loss 0.279701                                        LR 0.000500    Time 0.048088    
2024-06-06 01:48:09,671 - Epoch: [122][ 1000/ 1218]    Overall Loss 0.280630    Objective Loss 0.280630                                        LR 0.000500    Time 0.048068    
2024-06-06 01:48:14,373 - Epoch: [122][ 1100/ 1218]    Overall Loss 0.280001    Objective Loss 0.280001                                        LR 0.000500    Time 0.047971    
2024-06-06 01:48:19,001 - Epoch: [122][ 1200/ 1218]    Overall Loss 0.279558    Objective Loss 0.279558                                        LR 0.000500    Time 0.047829    
2024-06-06 01:48:19,810 - Epoch: [122][ 1218/ 1218]    Overall Loss 0.279680    Objective Loss 0.279680    Top1 86.308068    Top5 97.555012    LR 0.000500    Time 0.047786    
2024-06-06 01:48:19,980 - --- validate (epoch=122)-----------
2024-06-06 01:48:19,981 - 34633 samples (256 per mini-batch)
2024-06-06 01:48:25,568 - Epoch: [122][  100/  136]    Loss 0.310673    Top1 85.898438    Top5 98.066406    
2024-06-06 01:48:27,262 - Epoch: [122][  136/  136]    Loss 0.306399    Top1 85.903618    Top5 98.076979    
2024-06-06 01:48:27,421 - ==> Top1: 85.904    Top5: 98.077    Loss: 0.306

2024-06-06 01:48:27,422 - ==> Confusion:
[[  832     0     5     1    10     1     2     0     7    48     0     5     4     1     6     1     1     0     1     2     4]
 [    1   972     1     0    15    19     4    11     1     1     2     2     2     0     3     2     3     3    12     2     7]
 [    3     2   892     7     2     5    14     7     1     4     3     2     3     4     2     4     4     0     1     3     7]
 [    2     0     6   934     1     5     3     4     1     4    14     2     7     0    14     3     3     4     2     1     6]
 [   14     5     1     1   978     6     1     0     1     9     0     1     1     4     9     6     3     0     3     2     9]
 [    2    12     5     3     9   920     2    28     1     2     1    20     7     9     3     0     6     0     1    10     2]
 [    1     1    11     0     2     6  1010     7     1     3     5     4     3     0     0     9     4     3     2    10     4]
 [    0     8    13     2     1    19     1   964     4     2     2    12     0     6     1     0     1     0    21    15     5]
 [    3     3     0     1     1     3     0     1   886    42     5     3     5    18    17     1     2     2     4     1     4]
 [   62     2     4     1     3     1     0     0    38   845     2     1     1    23     5     0     2     2     0     1     8]
 [    2     1     9    18     2     0     1     3     8     0   974     1     1    15    11     0     2     0     5     3     8]
 [    3     0     1     0     2     4     3     1     0     4     0   908    28     8     0    11     2    16     1    16     3]
 [    1     0     2     3     1     2     2     4     0     2     0    58   858     3     2     6     2    30     5     2    12]
 [    1     0     3     1     4    15     0     2    11    14     6    13     5   904     4     3     2     4     0     3     6]
 [    6     0     4    18     4     1     0     0    24     9     5     7     3     7   992     0     0     1    10     1     6]
 [    1     1     3     0     0     1     2     0     1     5     0    15    10     0     0   998     9    10     2     5     3]
 [    3     4     2     0    11     6     0     0     1     2     2     9     4     1     2     4  1000     2     2     3    14]
 [    4     1     2     2     1     0     1     1     1     0     1    18    27     2     2    12     0   920     1     6     3]
 [    0     4     5     7     1     3     1    21     7     2     3     2     1     1     7     0     2     2   978     3     8]
 [    0     2     3     0     1     4     4     4     0     0     0    14     8     2     0     4    10     1     3  1016    12]
 [  132   140   188    81   153   153    77   136    73    98   149   161   283   236   173   101   163    85   130   250 10970]]

2024-06-06 01:48:27,426 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:48:27,426 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:48:27,456 - 

2024-06-06 01:48:27,456 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:48:33,785 - Epoch: [123][  100/ 1218]    Overall Loss 0.271056    Objective Loss 0.271056                                        LR 0.000500    Time 0.063257    
2024-06-06 01:48:38,661 - Epoch: [123][  200/ 1218]    Overall Loss 0.273164    Objective Loss 0.273164                                        LR 0.000500    Time 0.056000    
2024-06-06 01:48:43,420 - Epoch: [123][  300/ 1218]    Overall Loss 0.276694    Objective Loss 0.276694                                        LR 0.000500    Time 0.053188    
2024-06-06 01:48:48,089 - Epoch: [123][  400/ 1218]    Overall Loss 0.276167    Objective Loss 0.276167                                        LR 0.000500    Time 0.051558    
2024-06-06 01:48:52,883 - Epoch: [123][  500/ 1218]    Overall Loss 0.274962    Objective Loss 0.274962                                        LR 0.000500    Time 0.050831    
2024-06-06 01:48:57,601 - Epoch: [123][  600/ 1218]    Overall Loss 0.274554    Objective Loss 0.274554                                        LR 0.000500    Time 0.050220    
2024-06-06 01:49:02,274 - Epoch: [123][  700/ 1218]    Overall Loss 0.275552    Objective Loss 0.275552                                        LR 0.000500    Time 0.049717    
2024-06-06 01:49:06,959 - Epoch: [123][  800/ 1218]    Overall Loss 0.276237    Objective Loss 0.276237                                        LR 0.000500    Time 0.049356    
2024-06-06 01:49:11,568 - Epoch: [123][  900/ 1218]    Overall Loss 0.276034    Objective Loss 0.276034                                        LR 0.000500    Time 0.048992    
2024-06-06 01:49:16,308 - Epoch: [123][ 1000/ 1218]    Overall Loss 0.276490    Objective Loss 0.276490                                        LR 0.000500    Time 0.048830    
2024-06-06 01:49:20,878 - Epoch: [123][ 1100/ 1218]    Overall Loss 0.275658    Objective Loss 0.275658                                        LR 0.000500    Time 0.048544    
2024-06-06 01:49:25,601 - Epoch: [123][ 1200/ 1218]    Overall Loss 0.276727    Objective Loss 0.276727                                        LR 0.000500    Time 0.048434    
2024-06-06 01:49:26,393 - Epoch: [123][ 1218/ 1218]    Overall Loss 0.276665    Objective Loss 0.276665    Top1 83.374083    Top5 98.533007    LR 0.000500    Time 0.048367    
2024-06-06 01:49:26,578 - --- validate (epoch=123)-----------
2024-06-06 01:49:26,579 - 34633 samples (256 per mini-batch)
2024-06-06 01:49:32,200 - Epoch: [123][  100/  136]    Loss 0.312304    Top1 85.726562    Top5 97.917969    
2024-06-06 01:49:33,872 - Epoch: [123][  136/  136]    Loss 0.311942    Top1 85.713048    Top5 97.938382    
2024-06-06 01:49:34,064 - ==> Top1: 85.713    Top5: 97.938    Loss: 0.312

2024-06-06 01:49:34,066 - ==> Confusion:
[[  847     0     2     2     8     3     1     1     4    46     1     1     4     3     3     0     0     1     1     1     2]
 [    1   963     2     1    12    24     3    13     5     4     3     3     4     2     2     1     2     0     9     1     8]
 [    8     2   869    12     3     4    18    10     0     6     2     2     4     5     2     3     6     0     1     3    10]
 [    0     4    14   937     2     3     4     2     2     3     9     1     6     3    11     1     2     3     5     0     4]
 [   15     6     3     3   965    10     0     0     2    12     2     2     2     1     6     5    10     0     0     0    10]
 [    5    14     2     1    10   913     7    24     4     1     4     9     9    14     2     1     1     1     3     9     9]
 [    2     2    14     0     0     1  1017     5     0     6     4     6     5     0     0     5     1     1     0    12     5]
 [    3     3     8     0     1    30     3   974     1     3     5     6     6     1     1     1     2     0    19     6     4]
 [   10     5     2     1     1     2     0     1   861    45    14     2     7    17    12     2     1     3     7     0     9]
 [   78     0     1     0     5     0     0     1    27   848     2     1     3    25     7     0     1     1     1     0     0]
 [    2     2     3    13     0     1     4     6    10     1   986     1     2     7    11     0     2     0     6     1     6]
 [    0     1     1     0     0    19     3     5     0     4     1   910    35     2     2     4     1    13     0     6     4]
 [    3     1     2     3     1     5     1     1     1     2     0    55   877     1     2     5     3    18     1     7     6]
 [    0     0     3     0     2    13     0     5     8    10     9     8    10   911     2     0     3     3     0     7     7]
 [    6     3     3    25     7     1     0     1    26     6     7     0     6     4   982     1     0     1     9     1     9]
 [    2     2     4     0     2     1     6     0     0     5     2    14    11     2     0   996     6     8     3     0     2]
 [    2     9     1     0     4     6     3     0     3     2     6     4     4     1     1     7  1000     1     1     7    10]
 [    4     1     0     3     0     2     1     2     1     3     0     9    41     3     1    12     1   910     2     5     4]
 [    2     8     5     7     0     5     1    20     6     2     3     0     3     3     8     0     0     0   979     2     4]
 [    4     5     2     0     2     5    11     7     0     1     2    15     9     2     0     4     3     2     3  1004     7]
 [  254   127   164    99   157   150    81   151    68   105   132   144   342   196   141   102   159    73   143   208 10936]]

2024-06-06 01:49:34,070 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:49:34,070 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:49:34,100 - 

2024-06-06 01:49:34,101 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:49:40,175 - Epoch: [124][  100/ 1218]    Overall Loss 0.276909    Objective Loss 0.276909                                        LR 0.000500    Time 0.060714    
2024-06-06 01:49:44,868 - Epoch: [124][  200/ 1218]    Overall Loss 0.275311    Objective Loss 0.275311                                        LR 0.000500    Time 0.053809    
2024-06-06 01:49:49,629 - Epoch: [124][  300/ 1218]    Overall Loss 0.273767    Objective Loss 0.273767                                        LR 0.000500    Time 0.051737    
2024-06-06 01:49:54,368 - Epoch: [124][  400/ 1218]    Overall Loss 0.276549    Objective Loss 0.276549                                        LR 0.000500    Time 0.050644    
2024-06-06 01:49:59,208 - Epoch: [124][  500/ 1218]    Overall Loss 0.274238    Objective Loss 0.274238                                        LR 0.000500    Time 0.050192    
2024-06-06 01:50:03,877 - Epoch: [124][  600/ 1218]    Overall Loss 0.275283    Objective Loss 0.275283                                        LR 0.000500    Time 0.049604    
2024-06-06 01:50:08,542 - Epoch: [124][  700/ 1218]    Overall Loss 0.274577    Objective Loss 0.274577                                        LR 0.000500    Time 0.049177    
2024-06-06 01:50:13,150 - Epoch: [124][  800/ 1218]    Overall Loss 0.273824    Objective Loss 0.273824                                        LR 0.000500    Time 0.048787    
2024-06-06 01:50:17,752 - Epoch: [124][  900/ 1218]    Overall Loss 0.274823    Objective Loss 0.274823                                        LR 0.000500    Time 0.048478    
2024-06-06 01:50:22,290 - Epoch: [124][ 1000/ 1218]    Overall Loss 0.275319    Objective Loss 0.275319                                        LR 0.000500    Time 0.048166    
2024-06-06 01:50:27,114 - Epoch: [124][ 1100/ 1218]    Overall Loss 0.274739    Objective Loss 0.274739                                        LR 0.000500    Time 0.048171    
2024-06-06 01:50:31,955 - Epoch: [124][ 1200/ 1218]    Overall Loss 0.274324    Objective Loss 0.274324                                        LR 0.000500    Time 0.048190    
2024-06-06 01:50:32,768 - Epoch: [124][ 1218/ 1218]    Overall Loss 0.274305    Objective Loss 0.274305    Top1 86.308068    Top5 98.044010    LR 0.000500    Time 0.048145    
2024-06-06 01:50:32,942 - --- validate (epoch=124)-----------
2024-06-06 01:50:32,942 - 34633 samples (256 per mini-batch)
2024-06-06 01:50:38,440 - Epoch: [124][  100/  136]    Loss 0.313701    Top1 86.039062    Top5 98.074219    
2024-06-06 01:50:40,081 - Epoch: [124][  136/  136]    Loss 0.317119    Top1 86.137499    Top5 98.062542    
2024-06-06 01:50:40,241 - ==> Top1: 86.137    Top5: 98.063    Loss: 0.317

2024-06-06 01:50:40,243 - ==> Confusion:
[[  813     0     1     1    18     3     0     3     6    54     2     2     2     6     6     0     2     0     1     0    11]
 [    1   959     2     1    17    28     5    17     2     0     3     5     3     0     5     0     6     1     1     4     3]
 [    6     0   888     5     4     1    14    10     0     5     7     2     1     5     3     2     4     0     3     4     6]
 [    1     4    14   904     2     8     0     6     2     4     5     1     6     5    27     1     1     5     8     1    11]
 [   16    12     1     0   970     8     0     3     1     8     0     0     5     2     7     3     7     1     3     3     4]
 [    3    19     4     2     7   939     2    22     0     4     1     8     5     9     1     1     0     2     2     4     8]
 [    1     1    14     1     0     6  1017    10     0     4     1     1     2     0     0     4     2     5     1     9     7]
 [    2     7    10     0     2    19     3   980     1     5     2     8     4     2     0     0     1     4    13     9     5]
 [    4     3     2     0     0     3     0     2   855    52    18     4     5    14    20     1     1     1     7     0    10]
 [   50     1     4     2     5     3     0     1    38   847     4     1     1    23     9     3     0     1     1     0     7]
 [    2     1     6     9     0     3     1     3     2     1   998     2     2     6    13     1     0     0     8     3     3]
 [    1     3     1     0     0    12     2     3     0     4     1   907    38     6     0     7     2    11     2     6     5]
 [    2     0     2     2     0     6     3     4     3     1     2    42   879     3     2     4     0    20     4     3    13]
 [    4     1     0     1     3    16     1     2    12    14     8     8     3   905     4     1     1     3     0     4    10]
 [    4     5     3     9    12     3     1     1    15     9     4     5     5     6   992     1     1     0    14     1     7]
 [    1     0     1     1     2     1     4     0     2     5     0    19    15     5     1   985    10     7     1     3     3]
 [    2     7     3     1     3     7     1     0     4     3     3     5     1     2     2     8   994     1     1     5    19]
 [    2     3     2     0     0     3     0     0     0     1     1     9    20     1     4    10     1   933     2     2    11]
 [    2     3     6     7     2     2     1    18     2     2     4     0     4     2     8     0     0     1   981     2    11]
 [    1     2     3     1     0    13     9     6     0     1     0     6     5     2     0     6     2     5     3  1014     9]
 [  130   145   187    72   158   213    90   150    54    99   138   132   252   208   161    84   156    80   155   196 11072]]

2024-06-06 01:50:40,245 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:50:40,245 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:50:40,269 - 

2024-06-06 01:50:40,270 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:50:46,636 - Epoch: [125][  100/ 1218]    Overall Loss 0.273939    Objective Loss 0.273939                                        LR 0.000500    Time 0.063634    
2024-06-06 01:50:51,181 - Epoch: [125][  200/ 1218]    Overall Loss 0.272259    Objective Loss 0.272259                                        LR 0.000500    Time 0.054534    
2024-06-06 01:50:55,827 - Epoch: [125][  300/ 1218]    Overall Loss 0.273771    Objective Loss 0.273771                                        LR 0.000500    Time 0.051835    
2024-06-06 01:51:00,420 - Epoch: [125][  400/ 1218]    Overall Loss 0.274337    Objective Loss 0.274337                                        LR 0.000500    Time 0.050353    
2024-06-06 01:51:05,130 - Epoch: [125][  500/ 1218]    Overall Loss 0.275850    Objective Loss 0.275850                                        LR 0.000500    Time 0.049698    
2024-06-06 01:51:09,964 - Epoch: [125][  600/ 1218]    Overall Loss 0.276032    Objective Loss 0.276032                                        LR 0.000500    Time 0.049469    
2024-06-06 01:51:14,559 - Epoch: [125][  700/ 1218]    Overall Loss 0.276922    Objective Loss 0.276922                                        LR 0.000500    Time 0.048964    
2024-06-06 01:51:19,303 - Epoch: [125][  800/ 1218]    Overall Loss 0.276709    Objective Loss 0.276709                                        LR 0.000500    Time 0.048770    
2024-06-06 01:51:23,970 - Epoch: [125][  900/ 1218]    Overall Loss 0.276835    Objective Loss 0.276835                                        LR 0.000500    Time 0.048535    
2024-06-06 01:51:28,675 - Epoch: [125][ 1000/ 1218]    Overall Loss 0.277096    Objective Loss 0.277096                                        LR 0.000500    Time 0.048384    
2024-06-06 01:51:33,329 - Epoch: [125][ 1100/ 1218]    Overall Loss 0.277350    Objective Loss 0.277350                                        LR 0.000500    Time 0.048214    
2024-06-06 01:51:37,968 - Epoch: [125][ 1200/ 1218]    Overall Loss 0.277424    Objective Loss 0.277424                                        LR 0.000500    Time 0.048060    
2024-06-06 01:51:38,792 - Epoch: [125][ 1218/ 1218]    Overall Loss 0.277607    Objective Loss 0.277607    Top1 86.063570    Top5 97.799511    LR 0.000500    Time 0.048027    
2024-06-06 01:51:38,975 - --- validate (epoch=125)-----------
2024-06-06 01:51:38,975 - 34633 samples (256 per mini-batch)
2024-06-06 01:51:44,448 - Epoch: [125][  100/  136]    Loss 0.302547    Top1 85.679688    Top5 97.910156    
2024-06-06 01:51:46,154 - Epoch: [125][  136/  136]    Loss 0.306274    Top1 85.557128    Top5 97.926833    
2024-06-06 01:51:46,348 - ==> Top1: 85.557    Top5: 97.927    Loss: 0.306

2024-06-06 01:51:46,349 - ==> Confusion:
[[  839     1     1     2     9     2     0     0     7    46     0     3     1     3     3     3     3     2     1     2     3]
 [    1   970     0     2    13    12     4    13     1     1     6     3     5     1     2     0     7     1     9     5     7]
 [    7     2   887     8     4     2    19     5     0     4     4     3     2     0     1     4     3     0     3     6     6]
 [    4     3    11   923     2     5     3     2     0     2    12     2     6     4    13     2     1     5     8     2     6]
 [   16     5     2     0   975     6     2     1     2    12     1     1     2     4    10     2     6     0     1     0     6]
 [    4    20     3     4    11   906     3    35     0     4     0    10     7     9     0     2     6     3     2     7     7]
 [    1     7     6     0     3     6  1025     4     0     2     3     2     8     0     0     6     2     2     0     5     4]
 [    4     5     7     2     2    13     2   973     3     2     7     9     6     1     1     1     0     1    22    10     6]
 [    8     2     1     1     1     3     0     1   902    34     9     1     6     7    11     1     0     2     7     1     4]
 [   57     0     1     0     6     2     0     1    44   864     0     1     1     9     1     4     0     5     1     1     3]
 [    2     4     4    10     0     1     4     5     9     2   992     2     2     6     7     0     2     1     3     3     5]
 [    3     0     0     0     1    11     1     7     1     0     0   905    38     3     1    10     3    13     1     8     5]
 [    1     2     2     4     2     3     0     3     0     1     2    51   878     1     1     7     2    18     2     5    10]
 [    2     0     2     0     3    18     0     4    10    12     7    10     7   903     2     2     3     2     2     8     4]
 [    7     1     2    16     4     0     0     1    18     5     7     0     5     8   996     0     1     4    13     1     9]
 [    5     2     3     1     2     0     0     1     0     3     0    13     8     1     0  1002     5    10     0     4     6]
 [    4    13     4     0     7     3     0     1     3     2     6     4     9     2     2     7   984     1     2     4    14]
 [    4     1     1     1     0     2     0     1     2     1     0    11    34     3     1     7     0   931     0     3     2]
 [    2     6     5     7     3     1     2    18     6     0     6     1     4     2     8     0     0     1   982     0     4]
 [    0     4     1     0     0     5    11     8     0     0     0    18    13     2     1     6     5     3     1  1006     4]
 [  172   184   191    98   162   138    89   150    91   116   152   118   308   201   172    94   170   112   185   241 10788]]

2024-06-06 01:51:46,351 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:51:46,351 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:51:46,376 - 

2024-06-06 01:51:46,376 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:51:52,484 - Epoch: [126][  100/ 1218]    Overall Loss 0.273417    Objective Loss 0.273417                                        LR 0.000500    Time 0.061053    
2024-06-06 01:51:57,107 - Epoch: [126][  200/ 1218]    Overall Loss 0.275542    Objective Loss 0.275542                                        LR 0.000500    Time 0.053633    
2024-06-06 01:52:01,793 - Epoch: [126][  300/ 1218]    Overall Loss 0.276690    Objective Loss 0.276690                                        LR 0.000500    Time 0.051369    
2024-06-06 01:52:06,601 - Epoch: [126][  400/ 1218]    Overall Loss 0.274911    Objective Loss 0.274911                                        LR 0.000500    Time 0.050543    
2024-06-06 01:52:11,467 - Epoch: [126][  500/ 1218]    Overall Loss 0.276040    Objective Loss 0.276040                                        LR 0.000500    Time 0.050161    
2024-06-06 01:52:16,048 - Epoch: [126][  600/ 1218]    Overall Loss 0.277676    Objective Loss 0.277676                                        LR 0.000500    Time 0.049433    
2024-06-06 01:52:20,838 - Epoch: [126][  700/ 1218]    Overall Loss 0.275484    Objective Loss 0.275484                                        LR 0.000500    Time 0.049211    
2024-06-06 01:52:25,634 - Epoch: [126][  800/ 1218]    Overall Loss 0.274518    Objective Loss 0.274518                                        LR 0.000500    Time 0.049052    
2024-06-06 01:52:30,633 - Epoch: [126][  900/ 1218]    Overall Loss 0.274101    Objective Loss 0.274101                                        LR 0.000500    Time 0.049154    
2024-06-06 01:52:35,237 - Epoch: [126][ 1000/ 1218]    Overall Loss 0.273765    Objective Loss 0.273765                                        LR 0.000500    Time 0.048840    
2024-06-06 01:52:39,845 - Epoch: [126][ 1100/ 1218]    Overall Loss 0.274016    Objective Loss 0.274016                                        LR 0.000500    Time 0.048588    
2024-06-06 01:52:44,483 - Epoch: [126][ 1200/ 1218]    Overall Loss 0.274530    Objective Loss 0.274530                                        LR 0.000500    Time 0.048402    
2024-06-06 01:52:45,309 - Epoch: [126][ 1218/ 1218]    Overall Loss 0.274564    Objective Loss 0.274564    Top1 86.308068    Top5 98.533007    LR 0.000500    Time 0.048364    
2024-06-06 01:52:45,475 - --- validate (epoch=126)-----------
2024-06-06 01:52:45,476 - 34633 samples (256 per mini-batch)
2024-06-06 01:52:51,076 - Epoch: [126][  100/  136]    Loss 0.314533    Top1 85.855469    Top5 97.980469    
2024-06-06 01:52:52,729 - Epoch: [126][  136/  136]    Loss 0.318688    Top1 85.825658    Top5 97.984581    
2024-06-06 01:52:52,911 - ==> Top1: 85.826    Top5: 97.985    Loss: 0.319

2024-06-06 01:52:52,912 - ==> Confusion:
[[  819     2     5     1     7     1     0     2     6    71     0     1     1     3     2     2     1     0     2     1     4]
 [    3   952     4     0    15    28     3    16     5     2     5     3     3     3     1     1     3     1     9     4     2]
 [    5     5   893     2     1     4    16     7     0     6     4     5     3     2     1     4     3     0     2     2     5]
 [    2     2    13   919     0     6     2     1     0     2    10     2     7     4    16     3     3     3    13     2     6]
 [   17     4     3     3   979     3     0     5     0     8     0     3     2     3     6     3     3     0     4     0     8]
 [    7    13     4     5    10   906     2    31     1     4     2    11     5    13     1     3     3     3     3     9     7]
 [    2     6    18     0     3     3  1016     5     0     3     2     0     1     1     0     4     1     1     4    10     6]
 [    3     9     6     2     0    20     4   983     2     2     3     7     5     3     0     1     1     1    12    10     3]
 [   12     3     2     1     2     5     0     1   854    52    10     2     5    11    23     1     5     2     7     2     2]
 [   49     1     3     0     4     4     0     5    43   854     2     2     2    12     4     2     3     4     0     0     7]
 [    2     5     8    10     1     6     5    13     9     2   958     2     1     8    10     0     2     2     5     2    13]
 [    4     0     2     1     1     5     2     7     0     1     0   913    25     4     0    18     2     9     0    10     7]
 [    2     1     2     7     1     1     0     5     0     1     0    60   858     2     3     7     4    19     4     5    13]
 [    3     1     2     0     6    10     0     3     9    20     4    11     6   899     3     4     4     1     0     6     9]
 [   10     3     4    10    11     6     0     2    16     2     3     3     1     5  1001     1     3     0     6     4     7]
 [    1     1     2     2     3     1     6     0     0     2     0    12    11     0     0  1008     7     4     0     2     4]
 [    2     7     4     0     6     6     2     0     2     1     1     4     2     2     1     8  1008     0     1     3    12]
 [    5     0     0     2     0     0     2     0     0     2     0    18    21     3     4    14     3   919     1     6     5]
 [    3     6     6     5     1     1     2    13     1     0     2     1     2     0    17     1     3     1   976     5    12]
 [    0     2     2     0     3     7     8     5     2     1     0    10    10     2     1     5     5     2     2  1011    10]
 [  146   174   177    83   160   169    85   146    68   112   117   121   247   239   151   137   201    71   136   194 10998]]

2024-06-06 01:52:52,915 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:52:52,915 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:52:52,939 - 

2024-06-06 01:52:52,939 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:52:59,110 - Epoch: [127][  100/ 1218]    Overall Loss 0.271027    Objective Loss 0.271027                                        LR 0.000500    Time 0.061680    
2024-06-06 01:53:03,766 - Epoch: [127][  200/ 1218]    Overall Loss 0.273773    Objective Loss 0.273773                                        LR 0.000500    Time 0.054112    
2024-06-06 01:53:08,614 - Epoch: [127][  300/ 1218]    Overall Loss 0.273584    Objective Loss 0.273584                                        LR 0.000500    Time 0.052226    
2024-06-06 01:53:13,231 - Epoch: [127][  400/ 1218]    Overall Loss 0.273099    Objective Loss 0.273099                                        LR 0.000500    Time 0.050706    
2024-06-06 01:53:17,930 - Epoch: [127][  500/ 1218]    Overall Loss 0.274633    Objective Loss 0.274633                                        LR 0.000500    Time 0.049960    
2024-06-06 01:53:22,805 - Epoch: [127][  600/ 1218]    Overall Loss 0.275162    Objective Loss 0.275162                                        LR 0.000500    Time 0.049755    
2024-06-06 01:53:27,743 - Epoch: [127][  700/ 1218]    Overall Loss 0.275428    Objective Loss 0.275428                                        LR 0.000500    Time 0.049698    
2024-06-06 01:53:32,880 - Epoch: [127][  800/ 1218]    Overall Loss 0.275573    Objective Loss 0.275573                                        LR 0.000500    Time 0.049905    
2024-06-06 01:53:37,503 - Epoch: [127][  900/ 1218]    Overall Loss 0.276460    Objective Loss 0.276460                                        LR 0.000500    Time 0.049494    
2024-06-06 01:53:42,304 - Epoch: [127][ 1000/ 1218]    Overall Loss 0.275813    Objective Loss 0.275813                                        LR 0.000500    Time 0.049344    
2024-06-06 01:53:47,154 - Epoch: [127][ 1100/ 1218]    Overall Loss 0.275015    Objective Loss 0.275015                                        LR 0.000500    Time 0.049265    
2024-06-06 01:53:51,825 - Epoch: [127][ 1200/ 1218]    Overall Loss 0.275573    Objective Loss 0.275573                                        LR 0.000500    Time 0.049051    
2024-06-06 01:53:52,624 - Epoch: [127][ 1218/ 1218]    Overall Loss 0.275461    Objective Loss 0.275461    Top1 86.552567    Top5 97.310513    LR 0.000500    Time 0.048981    
2024-06-06 01:53:52,800 - --- validate (epoch=127)-----------
2024-06-06 01:53:52,800 - 34633 samples (256 per mini-batch)
2024-06-06 01:53:58,365 - Epoch: [127][  100/  136]    Loss 0.314587    Top1 86.039062    Top5 97.804688    
2024-06-06 01:54:00,011 - Epoch: [127][  136/  136]    Loss 0.315535    Top1 85.805446    Top5 97.811336    
2024-06-06 01:54:00,181 - ==> Top1: 85.805    Top5: 97.811    Loss: 0.316

2024-06-06 01:54:00,183 - ==> Confusion:
[[  841     1     1     1     8     1     0     3    13    44     0     5     4     3     1     1     0     2     0     0     2]
 [    1   967     2     1    16    18     1    16     2     2     2     0     6     2     5     0     5     0    10     0     7]
 [    6     3   882    10     3     2    14     6     0     8     7     1     3     2     3     6     2     0     5     2     5]
 [    5     0     7   919     1     9     2     1     3     2     7     3     4     2    25     1     2     2    12     3     6]
 [   24     9     0     2   968    12     0     1     2    11     1     1     2     3     7     2     3     0     2     0     4]
 [    6    20     1     0     5   912     1    26     1     5     1    11     7    16     3     4     5     1     7     5     6]
 [    0     4    13     0     2     4  1019     6     2     4     2     4     3     1     2     1     2     5     2     5     5]
 [    3     3     9     2     1    25     1   970     2     5     5     5     3     0     1     0     2     0    24     9     7]
 [    9     1     1     1     0     4     0     2   879    52     8     2     3    13    11     0     0     1     6     3     6]
 [   56     0     1     0     1     2     1     2    29   869     2     0     5    18     3     0     2     1     1     0     8]
 [    0     2     2    12     0     4     3     6    15     1   980     0     2     6     9     0     2     1    13     0     6]
 [    2     0     0     0     0     5     1     6     1     2     1   924    24     2     1     6     4    13     2    12     5]
 [    0     1     1     3     0     6     2     3     2     1     4    58   859     3     3     5     3    24     4     5     8]
 [    3     1     0     1     5    15     0     4    11    14     8     9     7   895     5     2     4     3     4     2     8]
 [    4     3     6     9     7     1     0     1    22    12     5     1     2     5  1001     1     1     1    11     1     4]
 [    3     1     6     1     2     0     4     0     0     2     0    16    11     0     0   978    13    17     0     4     8]
 [    4     9     0     2     5     5     0     3     3     2     3     8     2     1     2     8  1001     2     4     1     7]
 [    3     1     1     2     0     1     2     4     2     2     0    11    18     1     2     6     1   942     1     0     5]
 [    3     7     3     5     2     1     0    18     3     1     7     0     4     1    14     0     0     0   979     4     6]
 [    1     3     0     1     2    11     7    12     1     3     1    11    14     5     0     5     6     1     2   988    14]
 [  180   173   140   101   166   187    63   179   103   123   114   125   258   198   185    84   158    74   192   185 10944]]

2024-06-06 01:54:00,185 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:54:00,185 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:54:00,209 - 

2024-06-06 01:54:00,209 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:54:06,663 - Epoch: [128][  100/ 1218]    Overall Loss 0.266550    Objective Loss 0.266550                                        LR 0.000500    Time 0.064508    
2024-06-06 01:54:11,260 - Epoch: [128][  200/ 1218]    Overall Loss 0.269926    Objective Loss 0.269926                                        LR 0.000500    Time 0.055230    
2024-06-06 01:54:15,900 - Epoch: [128][  300/ 1218]    Overall Loss 0.271341    Objective Loss 0.271341                                        LR 0.000500    Time 0.052278    
2024-06-06 01:54:20,585 - Epoch: [128][  400/ 1218]    Overall Loss 0.271227    Objective Loss 0.271227                                        LR 0.000500    Time 0.050916    
2024-06-06 01:54:25,368 - Epoch: [128][  500/ 1218]    Overall Loss 0.269641    Objective Loss 0.269641                                        LR 0.000500    Time 0.050296    
2024-06-06 01:54:30,129 - Epoch: [128][  600/ 1218]    Overall Loss 0.270673    Objective Loss 0.270673                                        LR 0.000500    Time 0.049844    
2024-06-06 01:54:34,845 - Epoch: [128][  700/ 1218]    Overall Loss 0.271928    Objective Loss 0.271928                                        LR 0.000500    Time 0.049457    
2024-06-06 01:54:39,746 - Epoch: [128][  800/ 1218]    Overall Loss 0.274276    Objective Loss 0.274276                                        LR 0.000500    Time 0.049399    
2024-06-06 01:54:44,615 - Epoch: [128][  900/ 1218]    Overall Loss 0.274316    Objective Loss 0.274316                                        LR 0.000500    Time 0.049318    
2024-06-06 01:54:49,188 - Epoch: [128][ 1000/ 1218]    Overall Loss 0.274738    Objective Loss 0.274738                                        LR 0.000500    Time 0.048951    
2024-06-06 01:54:53,730 - Epoch: [128][ 1100/ 1218]    Overall Loss 0.274679    Objective Loss 0.274679                                        LR 0.000500    Time 0.048628    
2024-06-06 01:54:58,672 - Epoch: [128][ 1200/ 1218]    Overall Loss 0.274175    Objective Loss 0.274175                                        LR 0.000500    Time 0.048693    
2024-06-06 01:54:59,496 - Epoch: [128][ 1218/ 1218]    Overall Loss 0.274157    Objective Loss 0.274157    Top1 85.574572    Top5 98.533007    LR 0.000500    Time 0.048649    
2024-06-06 01:54:59,667 - --- validate (epoch=128)-----------
2024-06-06 01:54:59,667 - 34633 samples (256 per mini-batch)
2024-06-06 01:55:05,314 - Epoch: [128][  100/  136]    Loss 0.308631    Top1 85.667969    Top5 97.917969    
2024-06-06 01:55:07,012 - Epoch: [128][  136/  136]    Loss 0.311158    Top1 85.597551    Top5 97.851760    
2024-06-06 01:55:07,209 - ==> Top1: 85.598    Top5: 97.852    Loss: 0.311

2024-06-06 01:55:07,210 - ==> Confusion:
[[  837     2     2     1     9     1     2     3    11    39     1     3     6     2     1     2     3     1     0     2     3]
 [    1   957     1     3    14    13     2    14     3     1     4     3     2     3     6     1    10     4     7     2    12]
 [    3     2   890     9     5     1    13     1     2     5     7     5     2     3     2     7     5     0     0     5     3]
 [    2     5    11   913     4     2     2     1     2     2    14     2     3     1    25     3     2     4     4     4    10]
 [   13    12     0     0   990     4     1     3     0     7     1     2     2     2     4     6     3     2     0     2     0]
 [    3    30     3     3    10   896     3    25     3     0     0    10     7    16     0     0     9     5     1     9    10]
 [    0     3     8     0     2     1  1034     2     0     1     3     4     1     1     0     7     4     1     0     6     8]
 [    1     3    13     2     4    22     8   960     2     0     5     9     5     3     1     1     1     3    15    12     7]
 [    8     3     0     1     3     3     0     2   877    48    12     6     3     9    12     2     2     5     3     1     2]
 [   49     0     2     0     3     3     0     1    38   871     0     5     3    17     4     1     0     3     0     0     1]
 [    0     3     4     8     0     3     5     2    16     1   987     0     1     8    11     0     0     1     7     1     6]
 [    1     1     3     1     2     4     3     6     0     3     0   906    38     3     0     6     2    16     2    12     2]
 [    0     2     4     3     2     2     2     2     2     0     2    39   882     2     1     4     5    26     2     5     8]
 [    1     0     0     1     2    15     0     1    17     9     6    11     6   904     6     2     4     2     0     4    10]
 [    8     1     1     6    14     0     0     1    26     8     4     2     1     3   999     0     2     0    10     1    11]
 [    3     0     3     0     1     2     2     0     0     4     1    22     8     5     0   992     6    10     0     3     4]
 [    0     6     3     1     7     2     1     2     6     1     0     5     4     2     0    10  1012     0     1     4     5]
 [    1     3     2     1     1     2     1     1     0     1     0    12    31     1     1     6     2   933     1     1     4]
 [    0    10    12    11     3     2     0    10     2     0     5     5     5     3    19     1     1     1   955     3    10]
 [    0     4     2     0     0     4    11     5     0     0     0    15     8     0     0     6     4     3     1  1020     5]
 [  133   187   166    81   203   136    79   128   108   105   143   140   321   215   161   121   228    97    98   252 10830]]

2024-06-06 01:55:07,213 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:55:07,213 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:55:07,231 - 

2024-06-06 01:55:07,231 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:55:13,442 - Epoch: [129][  100/ 1218]    Overall Loss 0.270637    Objective Loss 0.270637                                        LR 0.000500    Time 0.062081    
2024-06-06 01:55:18,207 - Epoch: [129][  200/ 1218]    Overall Loss 0.274734    Objective Loss 0.274734                                        LR 0.000500    Time 0.054855    
2024-06-06 01:55:22,801 - Epoch: [129][  300/ 1218]    Overall Loss 0.274343    Objective Loss 0.274343                                        LR 0.000500    Time 0.051876    
2024-06-06 01:55:27,506 - Epoch: [129][  400/ 1218]    Overall Loss 0.274808    Objective Loss 0.274808                                        LR 0.000500    Time 0.050664    
2024-06-06 01:55:32,306 - Epoch: [129][  500/ 1218]    Overall Loss 0.275192    Objective Loss 0.275192                                        LR 0.000500    Time 0.050128    
2024-06-06 01:55:37,007 - Epoch: [129][  600/ 1218]    Overall Loss 0.276374    Objective Loss 0.276374                                        LR 0.000500    Time 0.049605    
2024-06-06 01:55:41,826 - Epoch: [129][  700/ 1218]    Overall Loss 0.277011    Objective Loss 0.277011                                        LR 0.000500    Time 0.049400    
2024-06-06 01:55:46,665 - Epoch: [129][  800/ 1218]    Overall Loss 0.278134    Objective Loss 0.278134                                        LR 0.000500    Time 0.049270    
2024-06-06 01:55:51,475 - Epoch: [129][  900/ 1218]    Overall Loss 0.277455    Objective Loss 0.277455                                        LR 0.000500    Time 0.049132    
2024-06-06 01:55:56,394 - Epoch: [129][ 1000/ 1218]    Overall Loss 0.276820    Objective Loss 0.276820                                        LR 0.000500    Time 0.049135    
2024-06-06 01:56:01,078 - Epoch: [129][ 1100/ 1218]    Overall Loss 0.275275    Objective Loss 0.275275                                        LR 0.000500    Time 0.048925    
2024-06-06 01:56:05,873 - Epoch: [129][ 1200/ 1218]    Overall Loss 0.275172    Objective Loss 0.275172                                        LR 0.000500    Time 0.048842    
2024-06-06 01:56:06,807 - Epoch: [129][ 1218/ 1218]    Overall Loss 0.275551    Objective Loss 0.275551    Top1 84.596577    Top5 96.577017    LR 0.000500    Time 0.048886    
2024-06-06 01:56:06,966 - --- validate (epoch=129)-----------
2024-06-06 01:56:06,966 - 34633 samples (256 per mini-batch)
2024-06-06 01:56:12,472 - Epoch: [129][  100/  136]    Loss 0.311360    Top1 86.550781    Top5 98.207031    
2024-06-06 01:56:14,142 - Epoch: [129][  136/  136]    Loss 0.308059    Top1 86.628360    Top5 98.166489    
2024-06-06 01:56:14,338 - ==> Top1: 86.628    Top5: 98.166    Loss: 0.308

2024-06-06 01:56:14,339 - ==> Confusion:
[[  827     0     4     1     9     2     0     0     9    59     0     3     2     1     4     1     2     1     0     0     6]
 [    1   957     2     4    14    30     4     8     1     2     3     3     4     0     4     0     3     3    10     1     9]
 [    4     3   879    10     3     4    21    11     0     4     6     0     2     3     2     4     3     0     3     2     6]
 [    4     0     6   940     1     2     5     2     1     0    10     0    10     1    19     1     2     2     4     0     6]
 [   18     8     2     0   972    10     1     0     1    10     2     2     3     3     8     2     3     0     0     0     9]
 [    4     9     1     7    15   923     5    10     0     5     2     9     8    14     2     1     6     1     5     6    10]
 [    1     1     6     4     1     4  1029     3     1     1     2     3     1     1     2     6     1     0     1     9     9]
 [    3     9     8     3     4    42     6   935     3     2     4     6     5     0     1     1     1     2    18    12    12]
 [    5     2     1     1     1     3     0     4   879    52    13     1     2    11    11     1     4     2     4     0     5]
 [   53     0     4     0     3     1     0     3    22   876     1     2     2    17     7     3     1     1     0     0     5]
 [    1     0     8     6     0     4     6     3     5     1   997     0     0     5    18     0     0     0     4     0     6]
 [    4     1     5     0     2     7     5     3     0     1     1   884    42     6     1    13     5     9     1    13     8]
 [    1     1     1     5     0     1     0     3     2     4     2    34   911     1     0     4     1    15     0     5     4]
 [    8     0     1     0     3    11     0     1     8    16     7    11     5   900     1     3     3     5     0    12     6]
 [    6     0     2    13     5     0     0     1    17     5     6     2     0     4  1015     0     1     4     6     2     9]
 [    1     0     2     1     0     2     3     0     0     2     0    14     7     2     0  1011     5     7     1     4     4]
 [    4     8     2     2     8     6     1     0     2     0     2     7     2     1     3     8   994     2     0     5    15]
 [    2     1     1     2     0     2     2     1     1     2     0     8    32     0     1    13     1   924     0     2    10]
 [    1     2     7    18     3     3     0    18     5     0     3     2     6     1    22     0     3     1   949     3    11]
 [    3     3     3     0     2     8     9     6     0     1     0    12    11     1     0     7     4     7     3   986    22]
 [  152   104   149   121   146   174    86    89    99   100   129   102   317   158   179   131   109    94   104   175 11214]]

2024-06-06 01:56:14,341 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:56:14,341 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:56:14,358 - 

2024-06-06 01:56:14,358 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:56:21,021 - Epoch: [130][  100/ 1218]    Overall Loss 0.270114    Objective Loss 0.270114                                        LR 0.000500    Time 0.066593    
2024-06-06 01:56:25,670 - Epoch: [130][  200/ 1218]    Overall Loss 0.273822    Objective Loss 0.273822                                        LR 0.000500    Time 0.056532    
2024-06-06 01:56:30,346 - Epoch: [130][  300/ 1218]    Overall Loss 0.273124    Objective Loss 0.273124                                        LR 0.000500    Time 0.053270    
2024-06-06 01:56:35,121 - Epoch: [130][  400/ 1218]    Overall Loss 0.271453    Objective Loss 0.271453                                        LR 0.000500    Time 0.051883    
2024-06-06 01:56:39,794 - Epoch: [130][  500/ 1218]    Overall Loss 0.270054    Objective Loss 0.270054                                        LR 0.000500    Time 0.050849    
2024-06-06 01:56:44,581 - Epoch: [130][  600/ 1218]    Overall Loss 0.271579    Objective Loss 0.271579                                        LR 0.000500    Time 0.050349    
2024-06-06 01:56:49,312 - Epoch: [130][  700/ 1218]    Overall Loss 0.272260    Objective Loss 0.272260                                        LR 0.000500    Time 0.049911    
2024-06-06 01:56:54,204 - Epoch: [130][  800/ 1218]    Overall Loss 0.271412    Objective Loss 0.271412                                        LR 0.000500    Time 0.049785    
2024-06-06 01:56:58,790 - Epoch: [130][  900/ 1218]    Overall Loss 0.271022    Objective Loss 0.271022                                        LR 0.000500    Time 0.049347    
2024-06-06 01:57:03,618 - Epoch: [130][ 1000/ 1218]    Overall Loss 0.271375    Objective Loss 0.271375                                        LR 0.000500    Time 0.049239    
2024-06-06 01:57:08,415 - Epoch: [130][ 1100/ 1218]    Overall Loss 0.271705    Objective Loss 0.271705                                        LR 0.000500    Time 0.049121    
2024-06-06 01:57:13,082 - Epoch: [130][ 1200/ 1218]    Overall Loss 0.272287    Objective Loss 0.272287                                        LR 0.000500    Time 0.048915    
2024-06-06 01:57:13,917 - Epoch: [130][ 1218/ 1218]    Overall Loss 0.272389    Objective Loss 0.272389    Top1 85.574572    Top5 97.799511    LR 0.000500    Time 0.048878    
2024-06-06 01:57:14,088 - --- validate (epoch=130)-----------
2024-06-06 01:57:14,089 - 34633 samples (256 per mini-batch)
2024-06-06 01:57:19,725 - Epoch: [130][  100/  136]    Loss 0.303302    Top1 86.171875    Top5 97.984375    
2024-06-06 01:57:21,367 - Epoch: [130][  136/  136]    Loss 0.305834    Top1 85.915168    Top5 97.929720    
2024-06-06 01:57:21,545 - ==> Top1: 85.915    Top5: 97.930    Loss: 0.306

2024-06-06 01:57:21,546 - ==> Confusion:
[[  831     0     3     1     5     1     0     1     8    59     0     4     4     3     3     0     3     0     0     1     4]
 [    1   959     1     0    17    23     3    10     4     0     7     2     4     3     3     0    11     0    10     2     3]
 [    5     1   886     9     1     4    16    10     0     5     5     1     2     2     1     4     6     2     2     2     6]
 [    1     2     7   934     1     8     2     2     0     1     7     1    11     5    15     0     2     5     6     1     5]
 [   15     6     1     2   971     6     1     6     0    10     0     1     3     0     3     6     7     1     1     3    11]
 [    3    14     6     1    11   914     5    21     2     2     1    16     5    12     2     3     3     3     0     9    10]
 [    1     3    14     3     0     3  1020     8     1     0     6     2     3     2     0     1     2     5     0     6     6]
 [    0     7    11     1     1    29     2   971     0     5     5     5     6     2     0     0     2     2    10     6    12]
 [    8     4     1     1     2     6     0     2   863    56    10     4     5     9    15     1     3     3     1     1     7]
 [   59     0     3     0     9     4     1     2    26   861     0     1     1    20     5     0     0     2     0     0     7]
 [    0     0     6    12     1     1     4     4    15     3   985     0     1     8     9     0     1     0     7     0     7]
 [    0     2     3     0     1    11     2     1     1     2     1   908    38     5     0     8     3    13     0     8     4]
 [    2     0     2     7     3     5     1     1     0     0     2    44   881     1     0     8     2    23     1     8     4]
 [    1     0     1     1     3    14     1     3     9     3    11    11     5   907     6     1     2     4     2     6    10]
 [    9     2     1    12    14     2     1     0    20    13     3     1     3     7   999     0     1     1     3     0     6]
 [    2     2     1     1     5     1     4     0     0     3     0    23     9     1     0   995     7     9     0     1     2]
 [    1     5     0     2     2     7     0     0     6     2     3     4     0     1     1    12  1003     2     0     7    14]
 [    2     1     0     0     1     2     0     1     0     2     1     6    24     0     4     2     2   954     0     2     1]
 [    0     3     4     6     6     2     0    17     5     1     7     4     2     2    13     1     1     1   969     4    10]
 [    0     2     4     0     0    12     8    10     0     1     0    12     9     0     0     5     3     6     3  1006     7]
 [  147   143   131    98   168   173    86   162    98   114   143   146   327   193   172    90   163   112   114   214 10938]]

2024-06-06 01:57:21,549 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:57:21,549 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:57:21,573 - 

2024-06-06 01:57:21,574 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:57:27,668 - Epoch: [131][  100/ 1218]    Overall Loss 0.269761    Objective Loss 0.269761                                        LR 0.000500    Time 0.060916    
2024-06-06 01:57:32,560 - Epoch: [131][  200/ 1218]    Overall Loss 0.271351    Objective Loss 0.271351                                        LR 0.000500    Time 0.054907    
2024-06-06 01:57:37,376 - Epoch: [131][  300/ 1218]    Overall Loss 0.269851    Objective Loss 0.269851                                        LR 0.000500    Time 0.052651    
2024-06-06 01:57:42,281 - Epoch: [131][  400/ 1218]    Overall Loss 0.271879    Objective Loss 0.271879                                        LR 0.000500    Time 0.051747    
2024-06-06 01:57:46,858 - Epoch: [131][  500/ 1218]    Overall Loss 0.272045    Objective Loss 0.272045                                        LR 0.000500    Time 0.050547    
2024-06-06 01:57:51,548 - Epoch: [131][  600/ 1218]    Overall Loss 0.271859    Objective Loss 0.271859                                        LR 0.000500    Time 0.049937    
2024-06-06 01:57:56,279 - Epoch: [131][  700/ 1218]    Overall Loss 0.271428    Objective Loss 0.271428                                        LR 0.000500    Time 0.049558    
2024-06-06 01:58:01,152 - Epoch: [131][  800/ 1218]    Overall Loss 0.272398    Objective Loss 0.272398                                        LR 0.000500    Time 0.049451    
2024-06-06 01:58:05,769 - Epoch: [131][  900/ 1218]    Overall Loss 0.272123    Objective Loss 0.272123                                        LR 0.000500    Time 0.049085    
2024-06-06 01:58:10,631 - Epoch: [131][ 1000/ 1218]    Overall Loss 0.273545    Objective Loss 0.273545                                        LR 0.000500    Time 0.049037    
2024-06-06 01:58:15,286 - Epoch: [131][ 1100/ 1218]    Overall Loss 0.273310    Objective Loss 0.273310                                        LR 0.000500    Time 0.048809    
2024-06-06 01:58:20,188 - Epoch: [131][ 1200/ 1218]    Overall Loss 0.273202    Objective Loss 0.273202                                        LR 0.000500    Time 0.048824    
2024-06-06 01:58:21,045 - Epoch: [131][ 1218/ 1218]    Overall Loss 0.273399    Objective Loss 0.273399    Top1 86.308068    Top5 98.533007    LR 0.000500    Time 0.048806    
2024-06-06 01:58:21,198 - --- validate (epoch=131)-----------
2024-06-06 01:58:21,199 - 34633 samples (256 per mini-batch)
2024-06-06 01:58:26,747 - Epoch: [131][  100/  136]    Loss 0.308790    Top1 85.906250    Top5 98.066406    
2024-06-06 01:58:28,351 - Epoch: [131][  136/  136]    Loss 0.306199    Top1 85.938267    Top5 98.053879    
2024-06-06 01:58:28,540 - ==> Top1: 85.938    Top5: 98.054    Loss: 0.306

2024-06-06 01:58:28,541 - ==> Confusion:
[[  833     1     3     0     6     2     0     1     9    53     0     1     1     1     6     3     0     2     1     0     8]
 [    2   992     1     2    15     7     1     5     2     2     5     2     1     0     5     0     4     2     6     1     8]
 [    6     3   883     8     1     2    13     9     0     7     7     4     1     3     6     5     5     2     1     0     4]
 [    3     3    10   933     3     3     1     2     2     0    14     0     2     5    16     1     3     5     4     1     5]
 [   13     9     4     0   987     5     0     3     1    10     0     3     0     2     3     2     5     0     1     0     6]
 [    4    20     5     2    10   893     3    38     2     2     1     8     7    23     0     3     3     0     2     7    10]
 [    1     4    11     1     4     2  1018     4     1     0     2     5     2     0     0     5     3     4     2    11     6]
 [    1    17    12     3     4    20     2   959     3     1     8     7     3     1     1     1     2     3    13    10     6]
 [   12     1     2     1     1     3     0     3   900    26     9     1     6     9    14     0     1     2     5     0     6]
 [   56     1     0     0     3     3     0     1    53   855     2     0     0    13     3     1     1     2     0     2     5]
 [    2     2     8     9     0     1     4     4    19     1   982     1     1     8    10     0     1     0     8     0     3]
 [    1     1     3     0     1     8     3     4     0     0     0   906    24     8     1    12     4    17     2    13     3]
 [    0     2     3     0     1     4     0     3     2     1     1    59   865     3     0    10     3    20     3     6     9]
 [    4     2     4     1     3    10     0     2    17    15     4    17     3   892     2     2     4     3     1     5    10]
 [    4     3     1    10     7     3     0     0    25     9     8     2     5     4   997     0     2     0    10     1     7]
 [    3     0     4     0     3     0     2     2     0     5     0    10     7     3     0  1011     3     6     1     1     5]
 [    2     4     2     1     6     5     1     2     1     1     1     4     4     1     1     9  1006     0     2     1    18]
 [    4     0     1     3     1     2     1     0     1     2     0    15    23     1     1    16     1   925     1     1     6]
 [    3     3     5     7     3     4     0    21     9     1     4     3     0     0    13     0     2     1   971     2     6]
 [    0     6     2     1     2     6    10     6     1     1     1     7     8     1     1     9     6     2     3  1005    10]
 [  130   196   174    85   154   160    73   158   100    95   148   134   251   212   171   130   166    97   147   201 10950]]

2024-06-06 01:58:28,544 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:58:28,544 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:58:28,568 - 

2024-06-06 01:58:28,568 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:58:34,814 - Epoch: [132][  100/ 1218]    Overall Loss 0.274105    Objective Loss 0.274105                                        LR 0.000500    Time 0.062422    
2024-06-06 01:58:39,666 - Epoch: [132][  200/ 1218]    Overall Loss 0.270513    Objective Loss 0.270513                                        LR 0.000500    Time 0.055462    
2024-06-06 01:58:44,259 - Epoch: [132][  300/ 1218]    Overall Loss 0.271089    Objective Loss 0.271089                                        LR 0.000500    Time 0.052278    
2024-06-06 01:58:49,057 - Epoch: [132][  400/ 1218]    Overall Loss 0.272367    Objective Loss 0.272367                                        LR 0.000500    Time 0.051198    
2024-06-06 01:58:53,657 - Epoch: [132][  500/ 1218]    Overall Loss 0.272572    Objective Loss 0.272572                                        LR 0.000500    Time 0.050154    
2024-06-06 01:58:58,328 - Epoch: [132][  600/ 1218]    Overall Loss 0.272689    Objective Loss 0.272689                                        LR 0.000500    Time 0.049577    
2024-06-06 01:59:03,174 - Epoch: [132][  700/ 1218]    Overall Loss 0.271691    Objective Loss 0.271691                                        LR 0.000500    Time 0.049414    
2024-06-06 01:59:07,977 - Epoch: [132][  800/ 1218]    Overall Loss 0.271745    Objective Loss 0.271745                                        LR 0.000500    Time 0.049239    
2024-06-06 01:59:12,551 - Epoch: [132][  900/ 1218]    Overall Loss 0.271395    Objective Loss 0.271395                                        LR 0.000500    Time 0.048848    
2024-06-06 01:59:17,246 - Epoch: [132][ 1000/ 1218]    Overall Loss 0.271532    Objective Loss 0.271532                                        LR 0.000500    Time 0.048657    
2024-06-06 01:59:21,924 - Epoch: [132][ 1100/ 1218]    Overall Loss 0.271352    Objective Loss 0.271352                                        LR 0.000500    Time 0.048484    
2024-06-06 01:59:26,930 - Epoch: [132][ 1200/ 1218]    Overall Loss 0.270728    Objective Loss 0.270728                                        LR 0.000500    Time 0.048613    
2024-06-06 01:59:27,869 - Epoch: [132][ 1218/ 1218]    Overall Loss 0.271165    Objective Loss 0.271165    Top1 86.797066    Top5 97.310513    LR 0.000500    Time 0.048666    
2024-06-06 01:59:28,049 - --- validate (epoch=132)-----------
2024-06-06 01:59:28,049 - 34633 samples (256 per mini-batch)
2024-06-06 01:59:33,494 - Epoch: [132][  100/  136]    Loss 0.312789    Top1 86.300781    Top5 98.195312    
2024-06-06 01:59:35,163 - Epoch: [132][  136/  136]    Loss 0.310701    Top1 86.322294    Top5 98.097191    
2024-06-06 01:59:35,348 - ==> Top1: 86.322    Top5: 98.097    Loss: 0.311

2024-06-06 01:59:35,349 - ==> Confusion:
[[  837     0     1     1     5     3     1     1     4    58     1     4     1     1     6     1     1     1     1     0     3]
 [    1   962     0     2    21    16     3    11     2     0     6     4     1     1     7     0     2     1    10     5     8]
 [    3     1   885    10     4     6     7     5     0     9     2     6     2     4     2     3     2     3     2     4    10]
 [    3     2     8   931     3     7     2     2     1     2    10     1     3     0    19     1     1     4     8     0     8]
 [   12     8     1     2   969    12     0     0     2    16     1     2     1     5     8     1     2     1     1     1     9]
 [    6    19     2     6     9   915     1    22     0     3     6    11     3     9     6     2     1     2     3     7    10]
 [    0     4    11     2     2     3  1025     6     1     1     3     3     0     1     1     2     0     3     0     4    14]
 [    4    11     8     1     1    43     2   938     3     4     4     5     4     4     2     1     1     1    25    10     5]
 [    7     3     0     0     0     5     0     1   893    34     2     3     5     6    24     0     1     4     6     1     7]
 [   46     0     0     0     4     1     0     0    57   862     0     4     1    10    10     0     1     0     1     0     4]
 [    1     4    10     6     3     3     2     3    16     0   977     0     0     6    12     1     0     0     9     2     9]
 [    2     1     1     0     1     8     3     1     1     5     2   896    23    11     0     9     1    23     2    10    11]
 [    0     0     1     6     1     6     0     1     1     3     0    54   861     4     2     9     2    25     2     9     8]
 [    4     0     1     1     3    12     1     0    19    25     7     8     4   890     4     2     3     1     1     0    15]
 [    4     0     1    13     9     2     0     1    16     8     2     5     0     3  1020     0     1     1     6     1     5]
 [    2     1     2     0     1     4     5     1     0     3     0    15     5     5     0  1001     4    11     1     1     4]
 [    2    10     1     1     7     7     1     0     7     0     0     9     2     1     2     6   993     0     0     5    18]
 [    2     2     0     6     0     2     1     1     2     2     1    13    13     2     2     5     1   946     1     1     2]
 [    1     4     6    10     2     1     0    20     6     1     6     5     1     0    17     1     0     1   960     6    10]
 [    2     5     0     0     0     9    10     4     0     2     1    14     1     3     0     4     5     4     2  1002    20]
 [  144   157   135   106   159   166    81   128    95   102   106   135   236   155   219   102    93   114   133   233 11133]]

2024-06-06 01:59:35,352 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 01:59:35,352 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 01:59:35,377 - 

2024-06-06 01:59:35,377 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 01:59:41,613 - Epoch: [133][  100/ 1218]    Overall Loss 0.279626    Objective Loss 0.279626                                        LR 0.000500    Time 0.062334    
2024-06-06 01:59:46,357 - Epoch: [133][  200/ 1218]    Overall Loss 0.278740    Objective Loss 0.278740                                        LR 0.000500    Time 0.054877    
2024-06-06 01:59:50,985 - Epoch: [133][  300/ 1218]    Overall Loss 0.276900    Objective Loss 0.276900                                        LR 0.000500    Time 0.052006    
2024-06-06 01:59:55,712 - Epoch: [133][  400/ 1218]    Overall Loss 0.273553    Objective Loss 0.273553                                        LR 0.000500    Time 0.050817    
2024-06-06 02:00:00,304 - Epoch: [133][  500/ 1218]    Overall Loss 0.270258    Objective Loss 0.270258                                        LR 0.000500    Time 0.049833    
2024-06-06 02:00:05,301 - Epoch: [133][  600/ 1218]    Overall Loss 0.269061    Objective Loss 0.269061                                        LR 0.000500    Time 0.049852    
2024-06-06 02:00:10,188 - Epoch: [133][  700/ 1218]    Overall Loss 0.269152    Objective Loss 0.269152                                        LR 0.000500    Time 0.049709    
2024-06-06 02:00:14,759 - Epoch: [133][  800/ 1218]    Overall Loss 0.269997    Objective Loss 0.269997                                        LR 0.000500    Time 0.049207    
2024-06-06 02:00:19,393 - Epoch: [133][  900/ 1218]    Overall Loss 0.270024    Objective Loss 0.270024                                        LR 0.000500    Time 0.048885    
2024-06-06 02:00:24,049 - Epoch: [133][ 1000/ 1218]    Overall Loss 0.270777    Objective Loss 0.270777                                        LR 0.000500    Time 0.048651    
2024-06-06 02:00:28,906 - Epoch: [133][ 1100/ 1218]    Overall Loss 0.271485    Objective Loss 0.271485                                        LR 0.000500    Time 0.048641    
2024-06-06 02:00:33,708 - Epoch: [133][ 1200/ 1218]    Overall Loss 0.272450    Objective Loss 0.272450                                        LR 0.000500    Time 0.048588    
2024-06-06 02:00:34,507 - Epoch: [133][ 1218/ 1218]    Overall Loss 0.272364    Objective Loss 0.272364    Top1 83.863081    Top5 97.555012    LR 0.000500    Time 0.048526    
2024-06-06 02:00:34,677 - --- validate (epoch=133)-----------
2024-06-06 02:00:34,678 - 34633 samples (256 per mini-batch)
2024-06-06 02:00:39,982 - Epoch: [133][  100/  136]    Loss 0.303683    Top1 86.339844    Top5 98.082031    
2024-06-06 02:00:41,642 - Epoch: [133][  136/  136]    Loss 0.310413    Top1 85.996015    Top5 97.978806    
2024-06-06 02:00:41,819 - ==> Top1: 85.996    Top5: 97.979    Loss: 0.310

2024-06-06 02:00:41,820 - ==> Confusion:
[[  789     0     5     2    12     1     0     3    13    83     0     6     2     3     4     1     0     2     0     1     4]
 [    0   979     1     1    12     9     4    15     4     0     3     4     3     2     1     5     2     0    12     3     3]
 [    0     1   888     1     6     2    16     5     0     9     4     6     4     4     1     4     1     0     7     5     6]
 [    1     3     5   909     1     5     5     4     1     4    14     1     6     1    21     3     3     4    17     0     8]
 [    6    10     2     1   987     3     0     3     1    11     2     0     2     4     4     5     4     0     0     3     6]
 [    5    22     2     1    18   906     1    21     3     3     4    18     1    15     0     0     2     1     3     7    10]
 [    0     1    12     0     0     8  1015     4     2     2     2     6     5     1     0     9     2     4     1     6     6]
 [    1     7     9     1     1    20     5   963     1     6     5    10     4     2     1     0     2     0    27     8     4]
 [    5     2     1     0     0     2     0     1   874    57     9     6     7    10    14     1     2     0     4     0     7]
 [   48     0     3     0     3     2     1     1    25   892     1     1     1    10     6     1     0     0     1     2     3]
 [    0     3     4     8     0     1     3     5    15     0   988     2     3     5    10     0     3     0     6     1     7]
 [    2     3     2     0     0     8     2     2     0     3     0   914    29     5     0     8     0    16     1    13     3]
 [    1     1     5     4     0     4     0     2     3     1     1    47   871     3     1     4     6    29     2     5     5]
 [    4     0     0     0     5    10     1     3    14    20     1     9     6   889     9     1     3     2     0     6    18]
 [    5     2     1     8     7     3     0     0    18     9     9     4     4     0  1008     0     0     0    13     1     6]
 [    2     0     5     1     0     2     6     0     1     1     0    16    12     4     0   996     7     6     1     3     3]
 [    2     7     2     0     7     5     1     2     6     2     0     6     2     2     6    10   993     1     2     5    11]
 [    2     0     1     1     0     0     1     0     2     1     0    22    20     1     3     8     1   934     1     4     3]
 [    1     8     2     6     5     2     0    12     3     1     4     1     3     2     9     0     0     0   989     4     6]
 [    1     2     1     0     0     7    10     6     0     1     0    21    10     7     1     8     3     3     1   999     7]
 [  145   193   151    58   158   155    68   151    73   132   134   158   287   171   175   122   160    80   148   213 11000]]

2024-06-06 02:00:41,823 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 02:00:41,823 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 02:00:41,855 - 

2024-06-06 02:00:41,855 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:00:48,086 - Epoch: [134][  100/ 1218]    Overall Loss 0.274487    Objective Loss 0.274487                                        LR 0.000500    Time 0.062274    
2024-06-06 02:00:52,902 - Epoch: [134][  200/ 1218]    Overall Loss 0.271140    Objective Loss 0.271140                                        LR 0.000500    Time 0.055208    
2024-06-06 02:00:57,721 - Epoch: [134][  300/ 1218]    Overall Loss 0.271082    Objective Loss 0.271082                                        LR 0.000500    Time 0.052862    
2024-06-06 02:01:02,521 - Epoch: [134][  400/ 1218]    Overall Loss 0.271269    Objective Loss 0.271269                                        LR 0.000500    Time 0.051641    
2024-06-06 02:01:07,145 - Epoch: [134][  500/ 1218]    Overall Loss 0.269569    Objective Loss 0.269569                                        LR 0.000500    Time 0.050556    
2024-06-06 02:01:11,822 - Epoch: [134][  600/ 1218]    Overall Loss 0.270178    Objective Loss 0.270178                                        LR 0.000500    Time 0.049921    
2024-06-06 02:01:16,396 - Epoch: [134][  700/ 1218]    Overall Loss 0.272186    Objective Loss 0.272186                                        LR 0.000500    Time 0.049322    
2024-06-06 02:01:20,992 - Epoch: [134][  800/ 1218]    Overall Loss 0.272662    Objective Loss 0.272662                                        LR 0.000500    Time 0.048898    
2024-06-06 02:01:25,616 - Epoch: [134][  900/ 1218]    Overall Loss 0.273118    Objective Loss 0.273118                                        LR 0.000500    Time 0.048601    
2024-06-06 02:01:30,239 - Epoch: [134][ 1000/ 1218]    Overall Loss 0.273522    Objective Loss 0.273522                                        LR 0.000500    Time 0.048363    
2024-06-06 02:01:34,937 - Epoch: [134][ 1100/ 1218]    Overall Loss 0.273300    Objective Loss 0.273300                                        LR 0.000500    Time 0.048235    
2024-06-06 02:01:39,501 - Epoch: [134][ 1200/ 1218]    Overall Loss 0.272827    Objective Loss 0.272827                                        LR 0.000500    Time 0.048017    
2024-06-06 02:01:40,325 - Epoch: [134][ 1218/ 1218]    Overall Loss 0.273022    Objective Loss 0.273022    Top1 84.596577    Top5 98.777506    LR 0.000500    Time 0.047983    
2024-06-06 02:01:40,498 - --- validate (epoch=134)-----------
2024-06-06 02:01:40,498 - 34633 samples (256 per mini-batch)
2024-06-06 02:01:46,008 - Epoch: [134][  100/  136]    Loss 0.316670    Top1 85.964844    Top5 98.105469    
2024-06-06 02:01:47,676 - Epoch: [134][  136/  136]    Loss 0.309068    Top1 86.059539    Top5 98.117402    
2024-06-06 02:01:47,838 - ==> Top1: 86.060    Top5: 98.117    Loss: 0.309

2024-06-06 02:01:47,839 - ==> Confusion:
[[  804     0     3     0     7     0     0     0     4    90     1     2     3     3     4     1     1     3     0     0     5]
 [    1   969     0     0    10    22     2     9     3     4     3     2     1     1     4     1     7     4     9     3     8]
 [    3     1   878     5     1     1    13     8     2     7     5     2     3     4     4     5     5     1     4    10     8]
 [    5     1     6   922     2     5     3     4     0     5    12     2    11     2     9     1     2     2    11     3     8]
 [    9    14     2     3   965     3     1     1     3    12     4     1     2     4    12     2     8     2     2     0     4]
 [    2    26     3     1    15   880     2    26     5     1     1     9     9    29     3     1     6     5     4     7     8]
 [    1     3    10     1     2     4  1020     3     2     5     1     1     4     0     1     7     3     5     2     7     4]
 [    1    16    13     3     1    19     3   944     1     5     4     4     3     5     3     0     0     1    35    12     4]
 [    2     2     0     1     3     0     0     1   873    48    11     2     5    11    27     0     3     3     5     0     5]
 [   29     0     2     0     5     0     0     1    29   901     2     2     2    10     6     1     0     3     0     1     7]
 [    1     1     4     4     0     0     3     3     6     2  1003     1     2     7     7     0     0     0     9     2     9]
 [    0     0     2     1     3     5     2     3     2     4     2   888    41     7     1    12     2    16     1    13     6]
 [    1     1     2     1     0     1     0     1     2     0     0    43   897     3     1     3     2    28     1     1     7]
 [    0     0     1     0     5     5     0     1    13    10     8     5     7   921     3     1     5     2     0     6     8]
 [    2     2     1    20     4     1     0     1    20    12     7     0     4     7   991     1     2     1    13     0     9]
 [    4     0     1     0     2     3     3     1     0     4     0    13    11     0     0  1005     6     7     0     2     4]
 [    2    11     2     2    10     2     2     2     1     2     1     5     6     7     1     8   992     0     2     8     6]
 [    1     1     0     2     0     1     1     0     3     2     0    13    17     1     1     3     3   950     2     2     2]
 [    2     3     3     6     1     1     0    20     5     3     4     3     5     2     8     0     1     1   983     2     5]
 [    0     2     2     0     0     7     5     7     1     1     0    18    10     6     1     4     5     5     3  1001    10]
 [  131   157   156    78   148   128    76   103    88   132   138   115   334   218   178    82   179    88   167   218 11018]]

2024-06-06 02:01:47,842 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 02:01:47,842 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 02:01:47,866 - 

2024-06-06 02:01:47,866 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:01:53,884 - Epoch: [135][  100/ 1218]    Overall Loss 0.268268    Objective Loss 0.268268                                        LR 0.000500    Time 0.060152    
2024-06-06 02:01:58,553 - Epoch: [135][  200/ 1218]    Overall Loss 0.271712    Objective Loss 0.271712                                        LR 0.000500    Time 0.053413    
2024-06-06 02:02:03,278 - Epoch: [135][  300/ 1218]    Overall Loss 0.273412    Objective Loss 0.273412                                        LR 0.000500    Time 0.051353    
2024-06-06 02:02:08,040 - Epoch: [135][  400/ 1218]    Overall Loss 0.275818    Objective Loss 0.275818                                        LR 0.000500    Time 0.050414    
2024-06-06 02:02:12,899 - Epoch: [135][  500/ 1218]    Overall Loss 0.275702    Objective Loss 0.275702                                        LR 0.000500    Time 0.050045    
2024-06-06 02:02:17,611 - Epoch: [135][  600/ 1218]    Overall Loss 0.274670    Objective Loss 0.274670                                        LR 0.000500    Time 0.049553    
2024-06-06 02:02:22,163 - Epoch: [135][  700/ 1218]    Overall Loss 0.275052    Objective Loss 0.275052                                        LR 0.000500    Time 0.048975    
2024-06-06 02:02:26,990 - Epoch: [135][  800/ 1218]    Overall Loss 0.275038    Objective Loss 0.275038                                        LR 0.000500    Time 0.048884    
2024-06-06 02:02:31,533 - Epoch: [135][  900/ 1218]    Overall Loss 0.274716    Objective Loss 0.274716                                        LR 0.000500    Time 0.048499    
2024-06-06 02:02:36,126 - Epoch: [135][ 1000/ 1218]    Overall Loss 0.275353    Objective Loss 0.275353                                        LR 0.000500    Time 0.048239    
2024-06-06 02:02:40,920 - Epoch: [135][ 1100/ 1218]    Overall Loss 0.276016    Objective Loss 0.276016                                        LR 0.000500    Time 0.048208    
2024-06-06 02:02:45,450 - Epoch: [135][ 1200/ 1218]    Overall Loss 0.276589    Objective Loss 0.276589                                        LR 0.000500    Time 0.047964    
2024-06-06 02:02:46,253 - Epoch: [135][ 1218/ 1218]    Overall Loss 0.276555    Objective Loss 0.276555    Top1 87.530562    Top5 97.799511    LR 0.000500    Time 0.047914    
2024-06-06 02:02:46,432 - --- validate (epoch=135)-----------
2024-06-06 02:02:46,432 - 34633 samples (256 per mini-batch)
2024-06-06 02:02:52,162 - Epoch: [135][  100/  136]    Loss 0.313779    Top1 85.339844    Top5 97.738281    
2024-06-06 02:02:53,804 - Epoch: [135][  136/  136]    Loss 0.315775    Top1 85.461843    Top5 97.802674    
2024-06-06 02:02:53,990 - ==> Top1: 85.462    Top5: 97.803    Loss: 0.316

2024-06-06 02:02:53,991 - ==> Confusion:
[[  829     2     6     0    11     6     0     0    13    45     1     1     2     1     4     1     2     1     1     0     5]
 [    0   990     0     2    13     8     1     4     1     2     4     2     2     1     5     1     4     0    14     4     5]
 [    3     8   893     8     2     3    10     4     0     6     8     1     1     0     2     3     3     1     4     6     4]
 [    3     4     8   934     2     2     0     1     2     5    10     0     8     2    11     2     2     5    10     1     4]
 [   19    20     2     0   963     9     1     3     2     8     3     2     1     1     5     3     3     0     1     1     7]
 [    0    32     4     2     8   897     2    23     1     3     2     5     7    17     7     0     7     2     6     9     9]
 [    2     3    13     4     1     9   998     8     0     3     7     2     3     0     2     9     2     2     2     9     7]
 [    2    20     7     2     0    29     1   941     1     1     8     4     5     1     0     1     1     0    35    11     7]
 [    8     6     2     0     1     1     0     1   885    33    11     2     4    10    15     0     4     3     8     1     7]
 [   53     3     0     0     6     2     0     2    43   851     3     2     3    18     7     0     1     1     0     0     6]
 [    0     5     2    12     0     0     1     3     9     0   996     0     0     2    14     0     1     0    14     1     4]
 [    2     3     0     0     1    17     1     8     1     1     2   869    47    10     1    12     1    12     0    16     7]
 [    2     2     2     3     2     5     1     2     0     3     1    43   887     5     1     5     2    17     1     3     8]
 [    2     1     2     1     2    12     1     4     9    15    13     7     7   890    10     1     4     0     2     5    13]
 [    3     5     3    15     8     0     0     2    16     4     6     1     1     4  1005     1     2     2    13     0     7]
 [    2     0     3     0     5     5     3     1     0     5     0    15     6     3     0   993    13     7     0     3     2]
 [    2    11     6     1     5     4     1     2     5     2     1     6     1     3     1     6   996     2     2     7     8]
 [    3     1     0     2     1     0     0     0     2     1     0    13    30     6     3     7     1   923     3     2     7]
 [    0     7     5     5     0     0     0     5     4     1     3     3     2     1    12     0     0     0  1000     4     6]
 [    2     6     2     0     0     5     8     5     0     1     2    12     5     5     2     6     2     1     0  1013    11]
 [  148   241   147    93   184   174    60   120   128   109   153   106   304   177   180    95   182    86   203   197 10845]]

2024-06-06 02:02:53,994 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 02:02:53,994 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 02:02:54,018 - 

2024-06-06 02:02:54,018 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:03:00,218 - Epoch: [136][  100/ 1218]    Overall Loss 0.278583    Objective Loss 0.278583                                        LR 0.000500    Time 0.061970    
2024-06-06 02:03:04,949 - Epoch: [136][  200/ 1218]    Overall Loss 0.279228    Objective Loss 0.279228                                        LR 0.000500    Time 0.054630    
2024-06-06 02:03:09,859 - Epoch: [136][  300/ 1218]    Overall Loss 0.275687    Objective Loss 0.275687                                        LR 0.000500    Time 0.052780    
2024-06-06 02:03:14,657 - Epoch: [136][  400/ 1218]    Overall Loss 0.276082    Objective Loss 0.276082                                        LR 0.000500    Time 0.051574    
2024-06-06 02:03:19,269 - Epoch: [136][  500/ 1218]    Overall Loss 0.275071    Objective Loss 0.275071                                        LR 0.000500    Time 0.050480    
2024-06-06 02:03:23,956 - Epoch: [136][  600/ 1218]    Overall Loss 0.274723    Objective Loss 0.274723                                        LR 0.000500    Time 0.049875    
2024-06-06 02:03:28,703 - Epoch: [136][  700/ 1218]    Overall Loss 0.274021    Objective Loss 0.274021                                        LR 0.000500    Time 0.049528    
2024-06-06 02:03:33,477 - Epoch: [136][  800/ 1218]    Overall Loss 0.273737    Objective Loss 0.273737                                        LR 0.000500    Time 0.049303    
2024-06-06 02:03:38,143 - Epoch: [136][  900/ 1218]    Overall Loss 0.272704    Objective Loss 0.272704                                        LR 0.000500    Time 0.049006    
2024-06-06 02:03:42,899 - Epoch: [136][ 1000/ 1218]    Overall Loss 0.272754    Objective Loss 0.272754                                        LR 0.000500    Time 0.048861    
2024-06-06 02:03:47,734 - Epoch: [136][ 1100/ 1218]    Overall Loss 0.273279    Objective Loss 0.273279                                        LR 0.000500    Time 0.048812    
2024-06-06 02:03:52,575 - Epoch: [136][ 1200/ 1218]    Overall Loss 0.273468    Objective Loss 0.273468                                        LR 0.000500    Time 0.048777    
2024-06-06 02:03:53,424 - Epoch: [136][ 1218/ 1218]    Overall Loss 0.273424    Objective Loss 0.273424    Top1 87.286064    Top5 98.533007    LR 0.000500    Time 0.048752    
2024-06-06 02:03:53,589 - --- validate (epoch=136)-----------
2024-06-06 02:03:53,589 - 34633 samples (256 per mini-batch)
2024-06-06 02:03:59,152 - Epoch: [136][  100/  136]    Loss 0.315166    Top1 85.722656    Top5 97.929688    
2024-06-06 02:04:00,817 - Epoch: [136][  136/  136]    Loss 0.316428    Top1 85.816995    Top5 97.932608    
2024-06-06 02:04:01,011 - ==> Top1: 85.817    Top5: 97.933    Loss: 0.316

2024-06-06 02:04:01,012 - ==> Confusion:
[[  826     1     1     0    10     1     1     0    10    56     1     0     0     3     4     1     1     3     1     1    10]
 [    2   981     1     1    23    14     0     7     2     4     2     0     2     1     2     0     6     2     5     2     6]
 [    7     3   884     6     5     2    13     6     2     5     7     3     1     3     1     4     2     2     7     1     6]
 [    4     4     9   927     4     5     1     3     2     2     6     2     6     5    12     2     0     6    10     1     5]
 [   16     6     4     1   965     4     0     3     2    13     0     2     1     4     7     3     4     1     4     2    12]
 [    2    24     0     5    21   882     4    29     5     1     2     6     8    22     3     0     2     3     3     3    18]
 [    2     2    16     0     1     6  1017     7     0     3     4     2     0     1     1     7     4     3     0     6     4]
 [    4    11     6     3     1    14     2   957     2     4     7     7     4     3     1     0     0     2    24    14    11]
 [    9     4     0     1     2     2     1     0   890    38    11     3     4    10     9     0     2     4     7     0     5]
 [   49     0     1     1     5     4     1     1    45   863     1     0     0    15     6     0     0     3     3     0     3]
 [    0     6     4    11     0     1     0     1     9     0   997     0     2     9    11     0     0     1     9     0     3]
 [    2     2     0     1     0     9     3     3     0     3     0   862    67     9     2    14     2    17     3     9     3]
 [    6     1     3     6     0     3     0     1     1     0     2    25   887     7     2     4     3    25     2     5    12]
 [    4     1     1     1     2     4     1     2    13    14     6     6     3   916     4     0     6     4     2     4     7]
 [    7     2     1    17     9     1     0     0    22    14     6     0     2     6   985     1     0     0    20     0     5]
 [    4     2     2     0     2     1     6     0     0     4     1     9    11     4     1   985     6    21     0     3     4]
 [    4     8     1     2    10     5     0     3     2     0     4     2     2     6     5     5   990     1     0     8    14]
 [    5     1     1     3     0     3     0     1     0     2     0     4    26     0     4     7     1   941     1     1     4]
 [    2     7     3     8     2     2     0    17     5     0     5     2     3     2     9     0     1     1   980     3     6]
 [    4     5     3     0     0    10    10     5     0     1     3    10     2     3     0     3     2     5     4  1008    10]
 [  169   177   129   105   197   126    77   127    89   119   160    99   300   214   172    96   137   112   160   189 10978]]

2024-06-06 02:04:01,016 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 02:04:01,016 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 02:04:01,048 - 

2024-06-06 02:04:01,048 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:04:07,288 - Epoch: [137][  100/ 1218]    Overall Loss 0.264841    Objective Loss 0.264841                                        LR 0.000500    Time 0.062367    
2024-06-06 02:04:12,311 - Epoch: [137][  200/ 1218]    Overall Loss 0.273116    Objective Loss 0.273116                                        LR 0.000500    Time 0.056289    
2024-06-06 02:04:17,040 - Epoch: [137][  300/ 1218]    Overall Loss 0.270936    Objective Loss 0.270936                                        LR 0.000500    Time 0.053284    
2024-06-06 02:04:21,783 - Epoch: [137][  400/ 1218]    Overall Loss 0.271273    Objective Loss 0.271273                                        LR 0.000500    Time 0.051815    
2024-06-06 02:04:26,594 - Epoch: [137][  500/ 1218]    Overall Loss 0.271538    Objective Loss 0.271538                                        LR 0.000500    Time 0.051069    
2024-06-06 02:04:31,364 - Epoch: [137][  600/ 1218]    Overall Loss 0.270958    Objective Loss 0.270958                                        LR 0.000500    Time 0.050504    
2024-06-06 02:04:35,911 - Epoch: [137][  700/ 1218]    Overall Loss 0.270721    Objective Loss 0.270721                                        LR 0.000500    Time 0.049782    
2024-06-06 02:04:40,558 - Epoch: [137][  800/ 1218]    Overall Loss 0.270556    Objective Loss 0.270556                                        LR 0.000500    Time 0.049366    
2024-06-06 02:04:45,336 - Epoch: [137][  900/ 1218]    Overall Loss 0.270419    Objective Loss 0.270419                                        LR 0.000500    Time 0.049188    
2024-06-06 02:04:50,064 - Epoch: [137][ 1000/ 1218]    Overall Loss 0.269710    Objective Loss 0.269710                                        LR 0.000500    Time 0.048994    
2024-06-06 02:04:54,910 - Epoch: [137][ 1100/ 1218]    Overall Loss 0.269453    Objective Loss 0.269453                                        LR 0.000500    Time 0.048944    
2024-06-06 02:04:59,552 - Epoch: [137][ 1200/ 1218]    Overall Loss 0.269650    Objective Loss 0.269650                                        LR 0.000500    Time 0.048732    
2024-06-06 02:05:00,443 - Epoch: [137][ 1218/ 1218]    Overall Loss 0.269658    Objective Loss 0.269658    Top1 87.041565    Top5 97.799511    LR 0.000500    Time 0.048738    
2024-06-06 02:05:00,611 - --- validate (epoch=137)-----------
2024-06-06 02:05:00,611 - 34633 samples (256 per mini-batch)
2024-06-06 02:05:06,092 - Epoch: [137][  100/  136]    Loss 0.303231    Top1 86.246094    Top5 98.136719    
2024-06-06 02:05:07,824 - Epoch: [137][  136/  136]    Loss 0.303850    Top1 86.255883    Top5 98.120290    
2024-06-06 02:05:07,989 - ==> Top1: 86.256    Top5: 98.120    Loss: 0.304

2024-06-06 02:05:07,990 - ==> Confusion:
[[  838     0     3     0     6     0     0     0     5    58     0     4     2     0     3     0     3     2     1     2     4]
 [    1   979     3     0    15    11     0    10     5     3     4     5     4     0     3     3     1     2     7     4     3]
 [    4     0   907     5     2     0     6     7     1     7     4     4     3     4     0     4     3     1     1     1     6]
 [    6     1     8   922     1     2     1     0     1     4    12     3     6     2    20     2     3     9     7     0     6]
 [   14     5     4     1   973     5     0     3     1    14     0     2     4     2     8     2     7     0     3     0     6]
 [    4    14     6     4    12   909     2    33     1     7     2     7     3     6     2     1     2     6     5     4    13]
 [    0     4    21     1     2     1  1016     5     1     4     3     4     0     3     1    10     1     2     2     5     0]
 [    3    13     7     2     2    16     2   979     2     2     2     8     6     2     0     0     3     2    11     9     6]
 [   12     4     1     2     2     1     0     1   882    44     6     4     3     7    18     0     1     4     3     2     5]
 [   34     0     7     0     6     2     0     1    42   884     1     1     3     7     4     2     2     0     1     1     3]
 [    1     0     2     5     0     0     1     8    13     1   999     1     1     4     6     0     0     0    11     0    11]
 [    0     0     1     0     1    13     1     5     1     3     0   924    17     5     0     5     4    17     0     9     5]
 [    0     1     1     6     0     2     0     5     5     3     3    71   835     2     2     3     3    26     6     3    18]
 [    2     1     2     1     6     7     0     1    24    24    10    11     3   881     2     1     5     4     0     4    12]
 [    6     3     2     5    11     1     1     2    26    13     3     2     4     4   996     0     1     2    10     1     5]
 [    1     2     1     1     3     2     6     1     0     7     0    14     7     3     0   993     7    13     0     1     4]
 [    2     7    11     3     5     4     1     1     4     4     1     6     1     2     3     9   982     2     1     4    19]
 [    5     1     2     0     0     2     1     2     1     1     0    12    11     2     3     6     2   944     1     2     7]
 [    4     4     5     7     2     1     1    21     4     0     2     5     4     0    17     0     0     1   967     3    10]
 [    2     3     3     2     1     4    12     5     0     2     1    15     7     3     0     5     3     3     4  1005     8]
 [  144   154   207    68   224   143    74   130    95   131   123   148   222   155   159    93   201   120   112   171 11058]]

2024-06-06 02:05:07,992 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 02:05:07,993 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 02:05:08,017 - 

2024-06-06 02:05:08,017 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:05:14,275 - Epoch: [138][  100/ 1218]    Overall Loss 0.269768    Objective Loss 0.269768                                        LR 0.000500    Time 0.062552    
2024-06-06 02:05:19,087 - Epoch: [138][  200/ 1218]    Overall Loss 0.264279    Objective Loss 0.264279                                        LR 0.000500    Time 0.055324    
2024-06-06 02:05:23,801 - Epoch: [138][  300/ 1218]    Overall Loss 0.263891    Objective Loss 0.263891                                        LR 0.000500    Time 0.052588    
2024-06-06 02:05:28,590 - Epoch: [138][  400/ 1218]    Overall Loss 0.265555    Objective Loss 0.265555                                        LR 0.000500    Time 0.051408    
2024-06-06 02:05:33,223 - Epoch: [138][  500/ 1218]    Overall Loss 0.266395    Objective Loss 0.266395                                        LR 0.000500    Time 0.050390    
2024-06-06 02:05:37,927 - Epoch: [138][  600/ 1218]    Overall Loss 0.266718    Objective Loss 0.266718                                        LR 0.000500    Time 0.049827    
2024-06-06 02:05:42,593 - Epoch: [138][  700/ 1218]    Overall Loss 0.268149    Objective Loss 0.268149                                        LR 0.000500    Time 0.049372    
2024-06-06 02:05:47,321 - Epoch: [138][  800/ 1218]    Overall Loss 0.268843    Objective Loss 0.268843                                        LR 0.000500    Time 0.049107    
2024-06-06 02:05:52,195 - Epoch: [138][  900/ 1218]    Overall Loss 0.269267    Objective Loss 0.269267                                        LR 0.000500    Time 0.049065    
2024-06-06 02:05:57,124 - Epoch: [138][ 1000/ 1218]    Overall Loss 0.270114    Objective Loss 0.270114                                        LR 0.000500    Time 0.049085    
2024-06-06 02:06:01,693 - Epoch: [138][ 1100/ 1218]    Overall Loss 0.270007    Objective Loss 0.270007                                        LR 0.000500    Time 0.048775    
2024-06-06 02:06:06,303 - Epoch: [138][ 1200/ 1218]    Overall Loss 0.271235    Objective Loss 0.271235                                        LR 0.000500    Time 0.048550    
2024-06-06 02:06:07,150 - Epoch: [138][ 1218/ 1218]    Overall Loss 0.271307    Objective Loss 0.271307    Top1 81.418093    Top5 96.821516    LR 0.000500    Time 0.048527    
2024-06-06 02:06:07,338 - --- validate (epoch=138)-----------
2024-06-06 02:06:07,339 - 34633 samples (256 per mini-batch)
2024-06-06 02:06:12,939 - Epoch: [138][  100/  136]    Loss 0.302344    Top1 86.011719    Top5 97.898438    
2024-06-06 02:06:14,643 - Epoch: [138][  136/  136]    Loss 0.301733    Top1 86.073976    Top5 97.819998    
2024-06-06 02:06:14,830 - ==> Top1: 86.074    Top5: 97.820    Loss: 0.302

2024-06-06 02:06:14,831 - ==> Confusion:
[[  831     1     3     0    15     1     1     2    11    49     2     5     0     3     1     0     0     0     0     2     4]
 [    4   972     4     0    10    22     2     8     3     1     4     3     1     1     1     0     9     1    11     2     4]
 [    7     3   886     7     2     1    16    10     0     3     3     3     3     5     1     5     1     1     2     7     4]
 [    5     1    12   941     1     3     1     2     0     2    11     2     6     1    10     1     1     5     6     1     4]
 [    9     6     3     0   983    11     0     1     3     7     1     1     3     4     2     2     3     2     6     4     3]
 [    3    16     3     5     7   890     3    33     0     2     4    15     3    15     5     3     9     5     7    11     4]
 [    0     3    17     1     0     2  1020     5     3     2     3     3     3     0     3     4     0     0     4     8     5]
 [    1     8    13     0     1    17     2   976     0     3     4    11     0     2     0     1     1     2    20    11     4]
 [    6     1     2     1     3     1     0     2   892    35     8     5     3    10    12     0     3     1     8     1     8]
 [   60     0     3     0     3     3     0     1    35   864     0     2     3    14     5     1     0     3     2     0     2]
 [    2     1     6    13     0     2     2     5     5     1   995     0     1     7     9     0     1     0     6     4     4]
 [    2     1     1     1     2    11     3     2     1     3     1   885    44     6     0    13     2    13     1    12     7]
 [    3     1     7     7     0     4     1     4     0     1     2    28   882     0     1     6     2    23     3     9    11]
 [    3     0     3     2     2     9     0     6    15    12     8     8     4   912     2     2     2     2     1     5     3]
 [    6     2     3    22     8     2     0     1    21     8     9     3     0     3   991     0     0     5     9     0     5]
 [    3     1     4     0     3     0     7     1     0     4     0    12     6     0     0  1011     5     8     0     1     0]
 [    0     4     3     0     8     6     1     1     6     2     4     5     4     2     2    10   998     1     2     3    10]
 [    2     4     0     0     0     0     1     2     2     1     0    12    32     3     1     3     0   934     1     3     4]
 [    5     7     5     3     1     0     0    15     3     0     5     1     1     0    15     0     0     2   987     3     5]
 [    0     1     2     0     1     4     6     4     0     1     0    11    11     3     0     7     6     4     4  1013    10]
 [  146   157   168    91   158   168    76   165    83   112   146   133   305   196   153   114   144   102   153   215 10947]]

2024-06-06 02:06:14,833 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 02:06:14,834 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 02:06:14,858 - 

2024-06-06 02:06:14,858 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:06:20,921 - Epoch: [139][  100/ 1218]    Overall Loss 0.279497    Objective Loss 0.279497                                        LR 0.000500    Time 0.060603    
2024-06-06 02:06:25,672 - Epoch: [139][  200/ 1218]    Overall Loss 0.273099    Objective Loss 0.273099                                        LR 0.000500    Time 0.054044    
2024-06-06 02:06:30,573 - Epoch: [139][  300/ 1218]    Overall Loss 0.271145    Objective Loss 0.271145                                        LR 0.000500    Time 0.052360    
2024-06-06 02:06:35,387 - Epoch: [139][  400/ 1218]    Overall Loss 0.272375    Objective Loss 0.272375                                        LR 0.000500    Time 0.051293    
2024-06-06 02:06:40,099 - Epoch: [139][  500/ 1218]    Overall Loss 0.271561    Objective Loss 0.271561                                        LR 0.000500    Time 0.050453    
2024-06-06 02:06:44,910 - Epoch: [139][  600/ 1218]    Overall Loss 0.272295    Objective Loss 0.272295                                        LR 0.000500    Time 0.050060    
2024-06-06 02:06:49,766 - Epoch: [139][  700/ 1218]    Overall Loss 0.272164    Objective Loss 0.272164                                        LR 0.000500    Time 0.049843    
2024-06-06 02:06:54,757 - Epoch: [139][  800/ 1218]    Overall Loss 0.271058    Objective Loss 0.271058                                        LR 0.000500    Time 0.049848    
2024-06-06 02:06:59,578 - Epoch: [139][  900/ 1218]    Overall Loss 0.269633    Objective Loss 0.269633                                        LR 0.000500    Time 0.049664    
2024-06-06 02:07:04,460 - Epoch: [139][ 1000/ 1218]    Overall Loss 0.270619    Objective Loss 0.270619                                        LR 0.000500    Time 0.049577    
2024-06-06 02:07:09,209 - Epoch: [139][ 1100/ 1218]    Overall Loss 0.271059    Objective Loss 0.271059                                        LR 0.000500    Time 0.049385    
2024-06-06 02:07:13,889 - Epoch: [139][ 1200/ 1218]    Overall Loss 0.272107    Objective Loss 0.272107                                        LR 0.000500    Time 0.049168    
2024-06-06 02:07:14,699 - Epoch: [139][ 1218/ 1218]    Overall Loss 0.271958    Objective Loss 0.271958    Top1 85.574572    Top5 98.044010    LR 0.000500    Time 0.049106    
2024-06-06 02:07:14,871 - --- validate (epoch=139)-----------
2024-06-06 02:07:14,871 - 34633 samples (256 per mini-batch)
2024-06-06 02:07:20,541 - Epoch: [139][  100/  136]    Loss 0.319190    Top1 85.722656    Top5 97.984375    
2024-06-06 02:07:22,267 - Epoch: [139][  136/  136]    Loss 0.313924    Top1 85.811221    Top5 97.947045    
2024-06-06 02:07:22,460 - ==> Top1: 85.811    Top5: 97.947    Loss: 0.314

2024-06-06 02:07:22,461 - ==> Confusion:
[[  796     3     5     0     9     1     1     1     3    83     0     3     3     6     5     2     2     0     4     0     4]
 [    4   975     0     0    14    13     1    15     3     2     4     2     1     0     8     1     6     1     9     0     4]
 [    4     5   902     0     1     0     8    14     1     4     8     3     2     1     4     0     3     2     2     0     6]
 [    2     2    11   912     4     9     0     4     3     2    12     1     4     2    29     2     2     4     6     0     5]
 [    8     4     4     1   987     5     0     4     1    13     1     2     1     3     4     2     4     1     0     0     9]
 [    2    24     4     1    16   874     2    44     2     3     4    15     3    17     5     2     2     1     4     6    12]
 [    2     3    21     3     1     2  1014     5     1     4     6     2     0     1     0     4     1     1     1     9     5]
 [    1     9     9     0     2    10     5   985     3     4     4     6     2     3     0     1     3     1    15     7     7]
 [   10     5     1     0     0     0     1     3   873    42     8     4     5    11    21     0     3     3     6     0     6]
 [   35     1     1     1     4     0     1     1    33   887     1     1     3    15     4     1     3     2     2     0     5]
 [    2     3     4     5     2     0     1     5    19     1   990     2     1     6     7     1     1     0     7     1     6]
 [    3     0     2     1     1    12     3     9     4     4     1   900    27     6     0    10     2    14     2     6     4]
 [    3     3     5     3     0     4     1     6     2     1     1    70   841     3     0     6     5    26     0     6     9]
 [    0     1     3     0     5    12     0     6    11    19    11     8     4   902     4     0     2     2     0     5     6]
 [    3     0     2     4     5     3     0     0    21     8     8     1     1     3  1024     0     2     0     8     1     4]
 [    3     1     5     0     1     4     6     1     0     3     0    20     5     2     0   989     7    11     0     2     6]
 [    0     6     6     4     7     4     1     0     7     2     2     5     1     2     0     4  1000     1     1    10     9]
 [    2     1     0     1     2     2     0     2     1     4     0    11    15     3     4     3     3   943     1     3     4]
 [    2     9     4     9     2     1     0    24     7     2     1     2     3     0    11     0     0     0   974     5     2]
 [    2     7     6     1     0     2    15    19     0     1     0     8     5     4     1     8     6     4     2   988     9]
 [  128   185   207    69   179   124    70   197    99   136   147   118   262   214   206    69   155    85   141   178 10963]]

2024-06-06 02:07:22,463 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 02:07:22,464 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 02:07:22,493 - 

2024-06-06 02:07:22,493 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:07:28,895 - Epoch: [140][  100/ 1218]    Overall Loss 0.277837    Objective Loss 0.277837                                        LR 0.000250    Time 0.063997    
2024-06-06 02:07:33,703 - Epoch: [140][  200/ 1218]    Overall Loss 0.268961    Objective Loss 0.268961                                        LR 0.000250    Time 0.056028    
2024-06-06 02:07:38,410 - Epoch: [140][  300/ 1218]    Overall Loss 0.264222    Objective Loss 0.264222                                        LR 0.000250    Time 0.053032    
2024-06-06 02:07:43,004 - Epoch: [140][  400/ 1218]    Overall Loss 0.263707    Objective Loss 0.263707                                        LR 0.000250    Time 0.051256    
2024-06-06 02:07:47,647 - Epoch: [140][  500/ 1218]    Overall Loss 0.264242    Objective Loss 0.264242                                        LR 0.000250    Time 0.050281    
2024-06-06 02:07:52,320 - Epoch: [140][  600/ 1218]    Overall Loss 0.264174    Objective Loss 0.264174                                        LR 0.000250    Time 0.049686    
2024-06-06 02:07:56,906 - Epoch: [140][  700/ 1218]    Overall Loss 0.264270    Objective Loss 0.264270                                        LR 0.000250    Time 0.049137    
2024-06-06 02:08:01,681 - Epoch: [140][  800/ 1218]    Overall Loss 0.262938    Objective Loss 0.262938                                        LR 0.000250    Time 0.048961    
2024-06-06 02:08:06,381 - Epoch: [140][  900/ 1218]    Overall Loss 0.263253    Objective Loss 0.263253                                        LR 0.000250    Time 0.048741    
2024-06-06 02:08:11,401 - Epoch: [140][ 1000/ 1218]    Overall Loss 0.263422    Objective Loss 0.263422                                        LR 0.000250    Time 0.048884    
2024-06-06 02:08:16,106 - Epoch: [140][ 1100/ 1218]    Overall Loss 0.262724    Objective Loss 0.262724                                        LR 0.000250    Time 0.048711    
2024-06-06 02:08:20,960 - Epoch: [140][ 1200/ 1218]    Overall Loss 0.262104    Objective Loss 0.262104                                        LR 0.000250    Time 0.048695    
2024-06-06 02:08:21,825 - Epoch: [140][ 1218/ 1218]    Overall Loss 0.262352    Objective Loss 0.262352    Top1 87.286064    Top5 96.821516    LR 0.000250    Time 0.048684    
2024-06-06 02:08:22,001 - --- validate (epoch=140)-----------
2024-06-06 02:08:22,001 - 34633 samples (256 per mini-batch)
2024-06-06 02:08:27,571 - Epoch: [140][  100/  136]    Loss 0.297584    Top1 86.375000    Top5 98.109375    
2024-06-06 02:08:29,266 - Epoch: [140][  136/  136]    Loss 0.303975    Top1 86.224122    Top5 98.097191    
2024-06-06 02:08:29,431 - ==> Top1: 86.224    Top5: 98.097    Loss: 0.304

2024-06-06 02:08:29,433 - ==> Confusion:
[[  822     0     4     0    11     2     0     3     4    66     0     5     2     0     4     0     0     3     0     0     5]
 [    3   971     0     0    10    16     0    13     3     3     4     1     2     5     2     1     3     1    10     3    12]
 [    5     1   901     5     5     1     8     7     0     3     2     6     2     2     2     4     3     1     2     4     6]
 [    6     2    12   927     0     3     3     3     1     3     9     3     3     2    18     2     1     3     5     0    10]
 [   14     6     2     0   971     2     1     5     3    14     3     3     1     4     8     1     3     0     0     2    11]
 [    6    13     3     6    14   904     4    20     1     3     1    16     3    17     3     1     4     5     4     8     7]
 [    0     3    15     2     4     3  1021     3     0     2     2     4     3     0     1     3     0     5     1     8     6]
 [    2     6    12     1     4    27     1   983     1     7     3     3     0     4     1     1     0     1    11     5     4]
 [    9     3     1     0     3     3     1     3   881    45    10     4     2     8    11     0     3     5     6     1     3]
 [   58     1     1     0     2     2     0     1    29   867     0     2     1    20     6     2     0     5     0     0     4]
 [    0     6     5     7     3     2     2     9    11     1   987     2     1     7     4     1     1     0     6     4     5]
 [    2     1     6     0     1     6     0     3     2     1     0   927    21     5     0     9     1    11     2     9     4]
 [    2     0     5     2     0     1     0     2     3     3     0    68   860     1     1     4     2    18     3     5    15]
 [    5     1     1     0     3     4     1     2    10    18     2    16     2   912     2     2     3     1     0     5    11]
 [    5     1     0    12     7     3     0     1    27    16     4     2     0     7   993     2     1     2    10     0     5]
 [    4     1     3     2     3     2     8     1     0     2     0    12     5     0     1   997     6    12     0     1     6]
 [    3     6     2     1     7     9     2     0     3     0     2     7     2     2     2     7   997     3     0     4    13]
 [    1     2     2     4     1     3     1     2     0     3     0    25    14     0     0    18     2   920     0     2     5]
 [    2     5     7    10     3     1     1    18     5     0     3     1     1     1    19     0     2     0   966     2    11]
 [    5     4     2     0     0     6     8     5     0     0     2    17     4     5     1     8     2     1     1  1010     7]
 [  147   132   167    80   146   143    85   169    83   118   109   181   228   226   164   118   178    73   132   208 11045]]

2024-06-06 02:08:29,435 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 02:08:29,435 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 02:08:29,459 - 

2024-06-06 02:08:29,460 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:08:35,830 - Epoch: [141][  100/ 1218]    Overall Loss 0.262064    Objective Loss 0.262064                                        LR 0.000250    Time 0.063673    
2024-06-06 02:08:40,676 - Epoch: [141][  200/ 1218]    Overall Loss 0.262515    Objective Loss 0.262515                                        LR 0.000250    Time 0.056059    
2024-06-06 02:08:45,426 - Epoch: [141][  300/ 1218]    Overall Loss 0.262901    Objective Loss 0.262901                                        LR 0.000250    Time 0.053198    
2024-06-06 02:08:50,103 - Epoch: [141][  400/ 1218]    Overall Loss 0.261777    Objective Loss 0.261777                                        LR 0.000250    Time 0.051585    
2024-06-06 02:08:54,841 - Epoch: [141][  500/ 1218]    Overall Loss 0.259666    Objective Loss 0.259666                                        LR 0.000250    Time 0.050741    
2024-06-06 02:08:59,601 - Epoch: [141][  600/ 1218]    Overall Loss 0.260398    Objective Loss 0.260398                                        LR 0.000250    Time 0.050214    
2024-06-06 02:09:04,344 - Epoch: [141][  700/ 1218]    Overall Loss 0.260088    Objective Loss 0.260088                                        LR 0.000250    Time 0.049812    
2024-06-06 02:09:09,018 - Epoch: [141][  800/ 1218]    Overall Loss 0.260914    Objective Loss 0.260914                                        LR 0.000250    Time 0.049426    
2024-06-06 02:09:13,799 - Epoch: [141][  900/ 1218]    Overall Loss 0.259893    Objective Loss 0.259893                                        LR 0.000250    Time 0.049244    
2024-06-06 02:09:18,631 - Epoch: [141][ 1000/ 1218]    Overall Loss 0.259573    Objective Loss 0.259573                                        LR 0.000250    Time 0.049149    
2024-06-06 02:09:23,293 - Epoch: [141][ 1100/ 1218]    Overall Loss 0.260646    Objective Loss 0.260646                                        LR 0.000250    Time 0.048917    
2024-06-06 02:09:27,992 - Epoch: [141][ 1200/ 1218]    Overall Loss 0.260586    Objective Loss 0.260586                                        LR 0.000250    Time 0.048755    
2024-06-06 02:09:28,868 - Epoch: [141][ 1218/ 1218]    Overall Loss 0.260141    Objective Loss 0.260141    Top1 90.464548    Top5 98.044010    LR 0.000250    Time 0.048753    
2024-06-06 02:09:29,031 - --- validate (epoch=141)-----------
2024-06-06 02:09:29,032 - 34633 samples (256 per mini-batch)
2024-06-06 02:09:34,751 - Epoch: [141][  100/  136]    Loss 0.299927    Top1 86.570312    Top5 97.875000    
2024-06-06 02:09:36,398 - Epoch: [141][  136/  136]    Loss 0.300376    Top1 86.570612    Top5 97.975919    
2024-06-06 02:09:36,563 - ==> Top1: 86.571    Top5: 97.976    Loss: 0.300

2024-06-06 02:09:36,564 - ==> Confusion:
[[  819     1     3     1    13     1     0     2    10    55     0     5     2     3     1     2     5     2     0     0     6]
 [    1   984     1     0    14    11     3     9     3     1     4     6     3     0     8     1     2     0     6     1     5]
 [    7     0   890     8     2     2    14     5     1    10     3     4     1     1     2     6     2     1     2     1     8]
 [    2     2     7   936     1     7     0     0     2     5    13     1     6     2     9     2     3     2    11     0     5]
 [    9     5     3     0   988     8     0     0     3    13     2     4     1     1     7     4     0     1     1     0     4]
 [    2    15     3     3     9   926     2    16     3     3     1     4     6    22     3     2     6     2     0    10     5]
 [    2     3    18     0     4     7  1014     4     0     1     2     6     1     0     0     5     2     2     4     8     3]
 [    3     6    16     2     0    26     2   959     2     1     6     6     2     4     0     3     2     3    20     9     5]
 [   11     1     1     1     2     0     0     3   886    42    10     2     4    10    11     1     5     4     2     0     6]
 [   39     0     1     1     2     1     0     1    40   887     2     1     0    17     1     0     1     2     1     1     3]
 [    2     2     7    11     1     1     2     5    15     3   994     0     0     7     4     0     0     0     4     0     6]
 [    1     1     0     1     3    12     3     4     2     2     1   908    23     4     1    10     6     7     0    17     5]
 [    2     2     4     4     0     3     0     1     2     3     3    69   845     4     0    10     4    27     2     2     8]
 [    2     2     2     0     4    17     2     3    10    15     9    10     6   893     1     1     1     2     2     6    13]
 [    9     1     2    11     8     4     2     1    21    12     6     2     2     1   987     1     2     2    15     0     9]
 [    4     1     3     1     2     0     4     0     1     5     0    18     7     0     0   999     7    13     0     1     0]
 [    1     7     7     1     4     5     2     0     5     1     2     9     2     2     2     7   998     1     0     4    12]
 [    0     2     2     2     1     1     0     2     0     2     0    11    20     2     1    12     4   936     1     1     5]
 [    2     3     4     7     4     2     1    14     2     1     7     0     2     3    11     1     2     0   981     2     9]
 [    0     3     0     0     3     8    14     6     1     0     2    11     6     6     0     7     4     4     2  1002     9]
 [  137   130   176    89   144   200    77   121    83   100   125   135   239   177   165   107   149    93   140   195 11150]]

2024-06-06 02:09:36,567 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 02:09:36,567 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 02:09:36,584 - 

2024-06-06 02:09:36,584 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:09:42,734 - Epoch: [142][  100/ 1218]    Overall Loss 0.259111    Objective Loss 0.259111                                        LR 0.000250    Time 0.061473    
2024-06-06 02:09:47,439 - Epoch: [142][  200/ 1218]    Overall Loss 0.256487    Objective Loss 0.256487                                        LR 0.000250    Time 0.054253    
2024-06-06 02:09:52,089 - Epoch: [142][  300/ 1218]    Overall Loss 0.257667    Objective Loss 0.257667                                        LR 0.000250    Time 0.051660    
2024-06-06 02:09:56,753 - Epoch: [142][  400/ 1218]    Overall Loss 0.257217    Objective Loss 0.257217                                        LR 0.000250    Time 0.050398    
2024-06-06 02:10:01,332 - Epoch: [142][  500/ 1218]    Overall Loss 0.257789    Objective Loss 0.257789                                        LR 0.000250    Time 0.049472    
2024-06-06 02:10:05,928 - Epoch: [142][  600/ 1218]    Overall Loss 0.259018    Objective Loss 0.259018                                        LR 0.000250    Time 0.048883    
2024-06-06 02:10:10,938 - Epoch: [142][  700/ 1218]    Overall Loss 0.260086    Objective Loss 0.260086                                        LR 0.000250    Time 0.049054    
2024-06-06 02:10:15,823 - Epoch: [142][  800/ 1218]    Overall Loss 0.258698    Objective Loss 0.258698                                        LR 0.000250    Time 0.049027    
2024-06-06 02:10:20,653 - Epoch: [142][  900/ 1218]    Overall Loss 0.259442    Objective Loss 0.259442                                        LR 0.000250    Time 0.048943    
2024-06-06 02:10:25,386 - Epoch: [142][ 1000/ 1218]    Overall Loss 0.259450    Objective Loss 0.259450                                        LR 0.000250    Time 0.048780    
2024-06-06 02:10:30,002 - Epoch: [142][ 1100/ 1218]    Overall Loss 0.260137    Objective Loss 0.260137                                        LR 0.000250    Time 0.048540    
2024-06-06 02:10:34,773 - Epoch: [142][ 1200/ 1218]    Overall Loss 0.259575    Objective Loss 0.259575                                        LR 0.000250    Time 0.048469    
2024-06-06 02:10:35,581 - Epoch: [142][ 1218/ 1218]    Overall Loss 0.259454    Objective Loss 0.259454    Top1 89.975550    Top5 98.777506    LR 0.000250    Time 0.048416    
2024-06-06 02:10:35,763 - --- validate (epoch=142)-----------
2024-06-06 02:10:35,764 - 34633 samples (256 per mini-batch)
2024-06-06 02:10:41,413 - Epoch: [142][  100/  136]    Loss 0.311158    Top1 86.355469    Top5 98.070312    
2024-06-06 02:10:43,130 - Epoch: [142][  136/  136]    Loss 0.304833    Top1 86.359830    Top5 98.039442    
2024-06-06 02:10:43,322 - ==> Top1: 86.360    Top5: 98.039    Loss: 0.305

2024-06-06 02:10:43,323 - ==> Confusion:
[[  831     1     6     0    11     0     0     0     9    45     0     3     3     0     8     2     2     2     4     0     4]
 [    3   983     1     1     7    20     2     8     3     3     3     1     2     0     7     0     4     1     8     1     5]
 [    5     2   887    11     3     2    11     9     0     3     5     3     3     1     2     2     0     0    10     3     8]
 [    4     0     8   927     1     8     0     0     2     5    10     1     4     4    17     3     2     6     9     0     5]
 [   16     9     1     1   966     8     0     0     0    12     3     2     3     2     6     4     5     2     5     0     9]
 [    3    21     3     2     8   908     3    26     3     4     5     7     8    10     2     2     5     4     6     6     7]
 [    2     2    15     3     2     1  1019     8     1     3     4     3     0     1     1     5     1     0     2     8     5]
 [    3     5     8     3     2    23     2   956     3     3     8     5     4     5     0     1     1     1    31     8     5]
 [    7     2     0     2     0     2     0     1   885    43    13     4     6     9    17     0     2     2     3     0     4]
 [   55     0     4     0     6     2     0     1    46   850     2     3     2    15     8     1     1     1     2     0     2]
 [    1     4     4    10     1     1     7     2     7     0   999     1     1     7     4     0     2     0     8     0     5]
 [    1     2     0     0     2    10     1     3     0     2     1   904    35     7     2     5     3    14     1    11     7]
 [    1     1     4     5     1     2     1     4     3     2     0    47   867     5     2     5     4    18     3     8    12]
 [    1     0     1     0     8    15     1     6     9    11     9    13     7   896     5     2     4     0     0     4     9]
 [    8     4     3    14    11     3     0     0    23    12     7     1     2     6   974     0     1     0    19     0    10]
 [    1     1     1     1     2     3     8     0     0     4     0     9     7     5     0   985    11    17     1     5     5]
 [    1     5     3     1     6     4     0     2     6     1     2     4     1     4     0    11   997     2     1     9    12]
 [    3     0     0     3     0     2     1     1     2     2     1    11    22     1     2    13     1   931     1     3     5]
 [    1     4     2     4     1     3     1    11     4     1     6     1     3     2    10     0     2     0   997     1     4]
 [    3     5     0     1     3     7     6    10     1     1     2    14     4     4     1     3     7     1     1  1005     9]
 [  132   156   122    97   159   146    82   127   101    93   133   128   272   194   182    64   133    92   181   196 11142]]

2024-06-06 02:10:43,326 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 02:10:43,326 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 02:10:43,350 - 

2024-06-06 02:10:43,351 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:10:49,544 - Epoch: [143][  100/ 1218]    Overall Loss 0.260232    Objective Loss 0.260232                                        LR 0.000250    Time 0.061906    
2024-06-06 02:10:54,172 - Epoch: [143][  200/ 1218]    Overall Loss 0.257664    Objective Loss 0.257664                                        LR 0.000250    Time 0.054079    
2024-06-06 02:10:58,987 - Epoch: [143][  300/ 1218]    Overall Loss 0.257746    Objective Loss 0.257746                                        LR 0.000250    Time 0.052097    
2024-06-06 02:11:03,715 - Epoch: [143][  400/ 1218]    Overall Loss 0.258031    Objective Loss 0.258031                                        LR 0.000250    Time 0.050888    
2024-06-06 02:11:08,434 - Epoch: [143][  500/ 1218]    Overall Loss 0.259741    Objective Loss 0.259741                                        LR 0.000250    Time 0.050145    
2024-06-06 02:11:13,248 - Epoch: [143][  600/ 1218]    Overall Loss 0.260259    Objective Loss 0.260259                                        LR 0.000250    Time 0.049809    
2024-06-06 02:11:18,077 - Epoch: [143][  700/ 1218]    Overall Loss 0.259893    Objective Loss 0.259893                                        LR 0.000250    Time 0.049589    
2024-06-06 02:11:22,725 - Epoch: [143][  800/ 1218]    Overall Loss 0.260425    Objective Loss 0.260425                                        LR 0.000250    Time 0.049198    
2024-06-06 02:11:27,361 - Epoch: [143][  900/ 1218]    Overall Loss 0.260323    Objective Loss 0.260323                                        LR 0.000250    Time 0.048881    
2024-06-06 02:11:32,141 - Epoch: [143][ 1000/ 1218]    Overall Loss 0.260041    Objective Loss 0.260041                                        LR 0.000250    Time 0.048770    
2024-06-06 02:11:36,888 - Epoch: [143][ 1100/ 1218]    Overall Loss 0.259747    Objective Loss 0.259747                                        LR 0.000250    Time 0.048650    
2024-06-06 02:11:41,561 - Epoch: [143][ 1200/ 1218]    Overall Loss 0.258586    Objective Loss 0.258586                                        LR 0.000250    Time 0.048489    
2024-06-06 02:11:42,437 - Epoch: [143][ 1218/ 1218]    Overall Loss 0.258545    Objective Loss 0.258545    Top1 86.797066    Top5 98.288509    LR 0.000250    Time 0.048491    
2024-06-06 02:11:42,594 - --- validate (epoch=143)-----------
2024-06-06 02:11:42,594 - 34633 samples (256 per mini-batch)
2024-06-06 02:11:48,190 - Epoch: [143][  100/  136]    Loss 0.297268    Top1 86.542969    Top5 98.109375    
2024-06-06 02:11:49,850 - Epoch: [143][  136/  136]    Loss 0.292068    Top1 86.602373    Top5 98.091416    
2024-06-06 02:11:50,041 - ==> Top1: 86.602    Top5: 98.091    Loss: 0.292

2024-06-06 02:11:50,043 - ==> Confusion:
[[  830     0     2     0    14     0     0     2     8    52     1     4     1     4     3     1     1     2     0     0     6]
 [    1   982     1     3     7    21     4     5     5     2     3     4     5     1     6     0     2     1     6     0     4]
 [    6     1   899     4     2     6    19     9     0     5     2     2     2     1     1     0     2     1     1     2     5]
 [    3     1    16   928     1     5     2     1     1     4    10     1     4     2    22     1     3     2     2     2     5]
 [   16    12     1     0   971     6     2     2     1    14     2     2     2     0     8     3     4     0     1     1     6]
 [    4    13     1     1     7   920     4    18     3     6     1     8     7    13     2     1     3     4     2    11    14]
 [    2     4     7     1     1     4  1032     3     2     2     0     2     0     0     1     2     3     3     3     6     8]
 [    3    10    14     1     2    24     3   967     0     4     3     4     3     1     0     1     0     1    17    13     6]
 [    8     1     0     0     0     1     0     3   888    48    10     4     5    11    11     0     3     6     3     0     0]
 [   49     1     1     2     3     1     0     1    35   884     2     0     2    10     1     1     1     3     0     0     4]
 [    0     4     3     9     1     0     0     2    17     2   994     0     1    10     5     0     2     0     5     1     8]
 [    2     1     0     0     3    10     1     0     1     0     0   922    21     4     1     9     2    17     1    11     5]
 [    3     0     0     3     2     0     0     0     3     0     1    46   890     4     2     4     4    22     2     3     6]
 [    2     1     1     0     2    10     0     7    14    10    12    14     4   895     1     1     3     3     0    12     9]
 [    9     1     1    13     7     2     0     1    25    13     5     2     3     6   992     1     0     5     4     0     8]
 [    2     1     0     0     3     2     5     0     0     5     0    16     8     2     0   995     9     8     1     4     5]
 [    3     5     4     1     4     6     1     0     4     2     2    10     4     2     0     6  1006     0     1     3     8]
 [    2     0     2     2     1     0     2     2     0     2     1    14    20     2     0     4     4   940     0     1     6]
 [    3     8     6     8     1     2     0    12     6     1     4     2     1     1    13     0     5     1   973     5     6]
 [    1     5     4     0     1     8     5     3     0     2     0    13     5     4     0    10     2     1     1  1018     5]
 [  164   150   170    77   142   165    99   126    97   108   116   137   268   210   154    75   173    94   123   217 11067]]

2024-06-06 02:11:50,045 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 02:11:50,045 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 02:11:50,071 - 

2024-06-06 02:11:50,071 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:11:56,282 - Epoch: [144][  100/ 1218]    Overall Loss 0.253095    Objective Loss 0.253095                                        LR 0.000250    Time 0.062080    
2024-06-06 02:12:01,061 - Epoch: [144][  200/ 1218]    Overall Loss 0.259584    Objective Loss 0.259584                                        LR 0.000250    Time 0.054915    
2024-06-06 02:12:05,794 - Epoch: [144][  300/ 1218]    Overall Loss 0.256952    Objective Loss 0.256952                                        LR 0.000250    Time 0.052379    
2024-06-06 02:12:10,486 - Epoch: [144][  400/ 1218]    Overall Loss 0.256333    Objective Loss 0.256333                                        LR 0.000250    Time 0.051010    
2024-06-06 02:12:15,401 - Epoch: [144][  500/ 1218]    Overall Loss 0.254440    Objective Loss 0.254440                                        LR 0.000250    Time 0.050634    
2024-06-06 02:12:20,025 - Epoch: [144][  600/ 1218]    Overall Loss 0.254674    Objective Loss 0.254674                                        LR 0.000250    Time 0.049899    
2024-06-06 02:12:24,956 - Epoch: [144][  700/ 1218]    Overall Loss 0.255575    Objective Loss 0.255575                                        LR 0.000250    Time 0.049811    
2024-06-06 02:12:29,459 - Epoch: [144][  800/ 1218]    Overall Loss 0.256665    Objective Loss 0.256665                                        LR 0.000250    Time 0.049211    
2024-06-06 02:12:34,276 - Epoch: [144][  900/ 1218]    Overall Loss 0.256242    Objective Loss 0.256242                                        LR 0.000250    Time 0.049093    
2024-06-06 02:12:39,341 - Epoch: [144][ 1000/ 1218]    Overall Loss 0.255184    Objective Loss 0.255184                                        LR 0.000250    Time 0.049246    
2024-06-06 02:12:44,036 - Epoch: [144][ 1100/ 1218]    Overall Loss 0.255432    Objective Loss 0.255432                                        LR 0.000250    Time 0.049036    
2024-06-06 02:12:48,583 - Epoch: [144][ 1200/ 1218]    Overall Loss 0.255385    Objective Loss 0.255385                                        LR 0.000250    Time 0.048737    
2024-06-06 02:12:49,368 - Epoch: [144][ 1218/ 1218]    Overall Loss 0.255721    Objective Loss 0.255721    Top1 89.731051    Top5 98.044010    LR 0.000250    Time 0.048661    
2024-06-06 02:12:49,541 - --- validate (epoch=144)-----------
2024-06-06 02:12:49,542 - 34633 samples (256 per mini-batch)
2024-06-06 02:12:55,139 - Epoch: [144][  100/  136]    Loss 0.292452    Top1 86.832031    Top5 98.042969    
2024-06-06 02:12:56,809 - Epoch: [144][  136/  136]    Loss 0.296414    Top1 86.602373    Top5 97.964369    
2024-06-06 02:12:56,983 - ==> Top1: 86.602    Top5: 97.964    Loss: 0.296

2024-06-06 02:12:56,984 - ==> Confusion:
[[  822     2     1     0    10     3     0     2     6    69     1     1     2     1     1     0     0     0     2     1     7]
 [    2   970     1     2    15    10     1    15     4     2     2     2     3     2     4     1     5     1     7     6     8]
 [    2     2   896    13     5     2    17     5     0     3     5     2     1     3     3     1     1     2     2     0     5]
 [    4     2     8   935     5     2     3     1     3     2    10     0     6     0    13     2     1     2     7     1     9]
 [   16     8     3     0   975     9     2     3     1    12     3     1     4     2     5     0     4     1     1     0     4]
 [    6    17     3     4    11   904     4    29     4     4     2    11     4    16     2     0     3     2     2     4    11]
 [    0     3    11     0     2     4  1024     3     2     3     1     2     3     0     0     6     2     3     4     7     6]
 [    1    13    10     2     0    31     2   952     1     7     2     4     5     0     1     0     3     0    21    11    11]
 [   11     2     0     1     2     3     0     2   889    44     6     0     4     9    13     0     4     4     3     0     5]
 [   54     0     1     0     2     1     0     1    26   886     0     4     2    11     4     0     0     3     0     1     5]
 [    3     0     4    12     2     2     2     3    12     2   992     1     1     5     7     1     0     0     8     2     5]
 [    7     0     4     0     0    12     2     7     0     3     0   906    16     4     1    10     1    14     3    15     6]
 [    3     0     3     5     1     8     0     4     2     0     1    52   863     3     0     6     1    27     3     6     7]
 [    1     2     0     1     1    12     1     3    13    17    10     9     8   904     4     2     2     3     0     4     4]
 [    9     4     2    24     3     4     0     1    21    11     7     1     3     2   986     0     0     1     9     1     9]
 [    3     3     1     1     1     2     3     0     0     1     0     9     8     1     0  1001     8    14     0     4     6]
 [    3     7     2     0     5     9     2     0     4     1     2     1     1     2     2    14   996     0     1     7    13]
 [    2     1     1     2     1     2     0     1     1     1     0     8    17     2     0     5     3   952     1     3     2]
 [    5     5     5    18     2     4     0    15     4     0     3     2     2     1     5     1     0     0   974     3     9]
 [    0     1     0     1     0     7     5    10     0     0     0     6     5     4     0     1     5     4     3  1028     8]
 [  153   147   153   107   165   152    88   132    95   124   114   120   250   184   142    74   146   116   140   192 11138]]

2024-06-06 02:12:56,987 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 02:12:56,987 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 02:12:57,004 - 

2024-06-06 02:12:57,005 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:13:03,054 - Epoch: [145][  100/ 1218]    Overall Loss 0.259393    Objective Loss 0.259393                                        LR 0.000250    Time 0.060463    
2024-06-06 02:13:07,769 - Epoch: [145][  200/ 1218]    Overall Loss 0.259546    Objective Loss 0.259546                                        LR 0.000250    Time 0.053798    
2024-06-06 02:13:12,434 - Epoch: [145][  300/ 1218]    Overall Loss 0.257729    Objective Loss 0.257729                                        LR 0.000250    Time 0.051409    
2024-06-06 02:13:17,036 - Epoch: [145][  400/ 1218]    Overall Loss 0.256714    Objective Loss 0.256714                                        LR 0.000250    Time 0.050058    
2024-06-06 02:13:21,663 - Epoch: [145][  500/ 1218]    Overall Loss 0.257020    Objective Loss 0.257020                                        LR 0.000250    Time 0.049296    
2024-06-06 02:13:26,260 - Epoch: [145][  600/ 1218]    Overall Loss 0.257619    Objective Loss 0.257619                                        LR 0.000250    Time 0.048739    
2024-06-06 02:13:30,957 - Epoch: [145][  700/ 1218]    Overall Loss 0.257132    Objective Loss 0.257132                                        LR 0.000250    Time 0.048483    
2024-06-06 02:13:35,740 - Epoch: [145][  800/ 1218]    Overall Loss 0.256942    Objective Loss 0.256942                                        LR 0.000250    Time 0.048399    
2024-06-06 02:13:40,297 - Epoch: [145][  900/ 1218]    Overall Loss 0.257665    Objective Loss 0.257665                                        LR 0.000250    Time 0.048083    
2024-06-06 02:13:45,062 - Epoch: [145][ 1000/ 1218]    Overall Loss 0.258437    Objective Loss 0.258437                                        LR 0.000250    Time 0.048038    
2024-06-06 02:13:49,703 - Epoch: [145][ 1100/ 1218]    Overall Loss 0.258538    Objective Loss 0.258538                                        LR 0.000250    Time 0.047888    
2024-06-06 02:13:54,552 - Epoch: [145][ 1200/ 1218]    Overall Loss 0.258460    Objective Loss 0.258460                                        LR 0.000250    Time 0.047936    
2024-06-06 02:13:55,413 - Epoch: [145][ 1218/ 1218]    Overall Loss 0.258361    Objective Loss 0.258361    Top1 86.063570    Top5 98.288509    LR 0.000250    Time 0.047935    
2024-06-06 02:13:55,617 - --- validate (epoch=145)-----------
2024-06-06 02:13:55,617 - 34633 samples (256 per mini-batch)
2024-06-06 02:14:01,077 - Epoch: [145][  100/  136]    Loss 0.296819    Top1 86.593750    Top5 98.035156    
2024-06-06 02:14:02,727 - Epoch: [145][  136/  136]    Loss 0.293773    Top1 86.550400    Top5 98.010568    
2024-06-06 02:14:02,919 - ==> Top1: 86.550    Top5: 98.011    Loss: 0.294

2024-06-06 02:14:02,920 - ==> Confusion:
[[  833     0     2     0     5     0     0     0     6    52     1     2     3     3     4     0     0     6     1     1    12]
 [    2   972     2     1    19    15     2    14     2     1     2     4     2     0     0     0     4     2     8     6     5]
 [    1     1   884     6     7     2    16     5     1     7    10     0     2     4     3     3     5     4     2     4     3]
 [    6     2    13   928     1     4     2     2     0     1     7     0     8     3    18     1     2     5     6     1     6]
 [   13     5     5     2   969     1     2     2     3    13     3     3     1     3     8     2     6     1     4     2     6]
 [    6    20     3     4     8   927     3    13     2     3     3     9     8    11     1     1     3     4     4     2     8]
 [    1     4    15     1     3     1  1012     5     0     2     1     3     2     0     2     4     2     3     3    11    11]
 [    5    12    12     4     2    35     2   936     2     3     3     7     7     1     1     2     1     3    25     7     7]
 [    9     3     0     0     3     1     0     0   876    42    18     3     5    10    12     0     4     3     5     0     8]
 [   45     1     0     1     5     1     0     0    34   882     3     0     4     7     9     0     0     4     1     1     3]
 [    1     0     5     8     1     1     3     2    10     0  1004     2     0     6     7     1     1     0     7     0     5]
 [    2     0     1     0     1     7     4     5     2     3     1   909    27     6     1     5     2    11     3    15     6]
 [    1     1     1     5     0     5     1     0     1     2     0    43   883     3     0     7     1    30     1     4     6]
 [    1     1     0     1     6    11     2     3    11    17    14     6     4   896     2     2     3     3     1     6    11]
 [    6     2     2    11     7     0     0     2    18     9     7     2     3     4  1013     1     1     2     5     2     1]
 [    1     1     0     1     4     2     7     0     0     3     0    16    11     2     0   997     8     9     1     1     2]
 [    3     3     4     1     1     5     1     1     2     2     2     1     3     2     1    10   996     6     0     8    20]
 [    2     2     0     1     2     1     0     0     0     2     1    14    15     0     1     7     1   951     1     1     3]
 [    1     4     4     8     6     1     0    13     3     0     3     0     4     0     7     0     1     1   994     2     6]
 [    3     4     2     1     2     3    12    10     0     1     1    10     6     4     0     5     3     3     0  1007    11]
 [  146   139   128    80   151   128    85   121   103    98   152   124   288   182   176    97   149   122   147   210 11106]]

2024-06-06 02:14:02,923 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 02:14:02,923 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 02:14:02,948 - 

2024-06-06 02:14:02,948 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:14:09,527 - Epoch: [146][  100/ 1218]    Overall Loss 0.254880    Objective Loss 0.254880                                        LR 0.000250    Time 0.065760    
2024-06-06 02:14:14,105 - Epoch: [146][  200/ 1218]    Overall Loss 0.256470    Objective Loss 0.256470                                        LR 0.000250    Time 0.055760    
2024-06-06 02:14:18,842 - Epoch: [146][  300/ 1218]    Overall Loss 0.259026    Objective Loss 0.259026                                        LR 0.000250    Time 0.052957    
2024-06-06 02:14:23,559 - Epoch: [146][  400/ 1218]    Overall Loss 0.259736    Objective Loss 0.259736                                        LR 0.000250    Time 0.051504    
2024-06-06 02:14:28,465 - Epoch: [146][  500/ 1218]    Overall Loss 0.259100    Objective Loss 0.259100                                        LR 0.000250    Time 0.051011    
2024-06-06 02:14:33,444 - Epoch: [146][  600/ 1218]    Overall Loss 0.260340    Objective Loss 0.260340                                        LR 0.000250    Time 0.050804    
2024-06-06 02:14:38,322 - Epoch: [146][  700/ 1218]    Overall Loss 0.259872    Objective Loss 0.259872                                        LR 0.000250    Time 0.050512    
2024-06-06 02:14:43,201 - Epoch: [146][  800/ 1218]    Overall Loss 0.258919    Objective Loss 0.258919                                        LR 0.000250    Time 0.050293    
2024-06-06 02:14:48,182 - Epoch: [146][  900/ 1218]    Overall Loss 0.259334    Objective Loss 0.259334                                        LR 0.000250    Time 0.050238    
2024-06-06 02:14:53,142 - Epoch: [146][ 1000/ 1218]    Overall Loss 0.260248    Objective Loss 0.260248                                        LR 0.000250    Time 0.050172    
2024-06-06 02:14:57,925 - Epoch: [146][ 1100/ 1218]    Overall Loss 0.258955    Objective Loss 0.258955                                        LR 0.000250    Time 0.049957    
2024-06-06 02:15:02,491 - Epoch: [146][ 1200/ 1218]    Overall Loss 0.258586    Objective Loss 0.258586                                        LR 0.000250    Time 0.049597    
2024-06-06 02:15:03,282 - Epoch: [146][ 1218/ 1218]    Overall Loss 0.258625    Objective Loss 0.258625    Top1 85.819071    Top5 98.533007    LR 0.000250    Time 0.049514    
2024-06-06 02:15:03,441 - --- validate (epoch=146)-----------
2024-06-06 02:15:03,441 - 34633 samples (256 per mini-batch)
2024-06-06 02:15:08,944 - Epoch: [146][  100/  136]    Loss 0.298405    Top1 86.046875    Top5 98.128906    
2024-06-06 02:15:10,617 - Epoch: [146][  136/  136]    Loss 0.299521    Top1 86.166373    Top5 98.134727    
2024-06-06 02:15:10,808 - ==> Top1: 86.166    Top5: 98.135    Loss: 0.300

2024-06-06 02:15:10,809 - ==> Confusion:
[[  828     1     2     0    13     1     0     1     7    46     1     3     3     3     6     0     4     2     1     0     9]
 [    1   969     3     2    18    10     1    14     4     2     2     3     3     0     6     0     7     1     6     2     9]
 [    5     2   902     2     3     2    12     3     1     4     4     5     1     5     2     2     0     2     2     0    11]
 [    4     2     7   929     3     8     1     2     1     3    12     1     4     1    13     2     4     4     7     0     8]
 [   14     4     4     0   991     7     1     0     1     6     0     0     2     3     6     2     3     0     2     1     7]
 [    3    16     4     7    15   918     1    24     5     3     0    11     1    17     0     2     2     1     1     5     7]
 [    1     3    13     2     4     3  1026     2     0     2     3     4     0     0     1     9     0     1     1     6     5]
 [    4     6    11     3     3    24     1   971     3     1     5     9     4     3     0     0     0     1    18     6     4]
 [    7     3     1     2     1     3     0     0   889    40    11     2     3    13    12     0     1     5     2     1     6]
 [   68     3     1     1     8     4     3     2    26   850     1     0     0    13     9     1     2     3     1     0     5]
 [    2     1     7    11     1     6     4     2    12     2   990     0     1    13     6     0     0     0     4     0     2]
 [    0     0     2     0     2    14     3     2     1     1     1   920    19     2     0    10     3    13     1    12     5]
 [    1     0     2     3     4     7     0     0     2     0     1    61   879     1     0     5     2    14     3     4     6]
 [    0     1     1     1     5    18     3     0     2    11     9    10     1   912     4     2     3     4     1     6     7]
 [    6     1     3    20    15     4     1     2    18     4     6     3     1     5   983     1     0     4    13     1     7]
 [    5     1     1     2     2     1     6     1     0     1     0    14     8     1     1   999     9    10     0     1     3]
 [    2     7     1     0    12     5     3     0     3     0     4     4     2     2     2     6  1005     1     0     2    11]
 [    1     0     2     3     1     2     0     2     1     1     0    25    20     0     1    17     1   919     2     1     6]
 [    4     1     7    14     4     6     1    17     4     0     2     1     1     2    10     1     1     1   971     1     9]
 [    0     3     1     1     4     6    12     3     1     0     1    17     5     6     0     7     4     3     3  1005     6]
 [  135   141   169    97   175   170    80   147    96    99   148   141   270   207   174   103   127    91   152   224 10986]]

2024-06-06 02:15:10,812 - ==> Best [Top1: 86.654   Top5: 98.068   Sparsity:0.00   Params: 424448 on epoch: 108]
2024-06-06 02:15:10,812 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 02:15:10,836 - 

2024-06-06 02:15:10,837 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:15:17,141 - Epoch: [147][  100/ 1218]    Overall Loss 0.263271    Objective Loss 0.263271                                        LR 0.000250    Time 0.063017    
2024-06-06 02:15:21,852 - Epoch: [147][  200/ 1218]    Overall Loss 0.259055    Objective Loss 0.259055                                        LR 0.000250    Time 0.055050    
2024-06-06 02:15:26,491 - Epoch: [147][  300/ 1218]    Overall Loss 0.259637    Objective Loss 0.259637                                        LR 0.000250    Time 0.052156    
2024-06-06 02:15:31,248 - Epoch: [147][  400/ 1218]    Overall Loss 0.258036    Objective Loss 0.258036                                        LR 0.000250    Time 0.051005    
2024-06-06 02:15:36,003 - Epoch: [147][  500/ 1218]    Overall Loss 0.258958    Objective Loss 0.258958                                        LR 0.000250    Time 0.050311    
2024-06-06 02:15:40,697 - Epoch: [147][  600/ 1218]    Overall Loss 0.258176    Objective Loss 0.258176                                        LR 0.000250    Time 0.049746    
2024-06-06 02:15:45,388 - Epoch: [147][  700/ 1218]    Overall Loss 0.258148    Objective Loss 0.258148                                        LR 0.000250    Time 0.049338    
2024-06-06 02:15:50,023 - Epoch: [147][  800/ 1218]    Overall Loss 0.257313    Objective Loss 0.257313                                        LR 0.000250    Time 0.048963    
2024-06-06 02:15:54,847 - Epoch: [147][  900/ 1218]    Overall Loss 0.257171    Objective Loss 0.257171                                        LR 0.000250    Time 0.048880    
2024-06-06 02:15:59,524 - Epoch: [147][ 1000/ 1218]    Overall Loss 0.256956    Objective Loss 0.256956                                        LR 0.000250    Time 0.048666    
2024-06-06 02:16:04,418 - Epoch: [147][ 1100/ 1218]    Overall Loss 0.256969    Objective Loss 0.256969                                        LR 0.000250    Time 0.048689    
2024-06-06 02:16:09,266 - Epoch: [147][ 1200/ 1218]    Overall Loss 0.257060    Objective Loss 0.257060                                        LR 0.000250    Time 0.048670    
2024-06-06 02:16:10,120 - Epoch: [147][ 1218/ 1218]    Overall Loss 0.257259    Objective Loss 0.257259    Top1 87.286064    Top5 97.066015    LR 0.000250    Time 0.048652    
2024-06-06 02:16:10,321 - --- validate (epoch=147)-----------
2024-06-06 02:16:10,321 - 34633 samples (256 per mini-batch)
2024-06-06 02:16:15,626 - Epoch: [147][  100/  136]    Loss 0.297886    Top1 86.789062    Top5 98.062500    
2024-06-06 02:16:17,277 - Epoch: [147][  136/  136]    Loss 0.295041    Top1 86.743857    Top5 98.102965    
2024-06-06 02:16:17,468 - ==> Top1: 86.744    Top5: 98.103    Loss: 0.295

2024-06-06 02:16:17,469 - ==> Confusion:
[[  816     1     6     1     7     0     0     1     4    73     0     4     1     1     2     3     0     2     2     0     7]
 [    0   970     2     1    14    21     4     8     4     1     1     3     3     0     5     1     4     0     9     1    11]
 [    4     4   892     2     4     1     9    14     1     3     4     2     4     3     3     4     3     0     1     5     7]
 [    4     1     9   927     4     2     1     2     3     3     9     0     4     5    16     1     2     5    12     0     6]
 [   16    12     3     1   974     6     2     1     0    17     1     2     0     1     5     2     3     0     1     2     5]
 [    2    16     3     2    11   908     1    30     4     2     3    12     6    13     2     1     1     1     4    13     8]
 [    1     3     9     2     1     2  1023     3     0     1     3     7     2     2     0     4     1     2     4     7     9]
 [    1     8     6     2     3    24     7   966     0     3     1     8     4     4     3     0     1     0    19     7    10]
 [    7     1     0     2     1     0     0     3   873    51    10     4     2    14    20     0     2     3     3     1     5]
 [   38     0     2     0     9     0     0     0    29   886     0     0     4    16     5     2     0     1     0     2     7]
 [    2     2     7     7     0     2     3     4    13     3   989     0     3    12     8     0     0     0     5     2     2]
 [    2     0     2     1     3     3     3     1     0     3     0   925    24     5     1    11     0    10     2    11     4]
 [    1     0     5     4     5     1     0     3     3     3     1    64   853     1     2     3     1    25     3     6    11]
 [    3     1     2     0     6    10     0     0    12    10     6    10     4   906     5     0     2     6     1     8     9]
 [    7     2     3    21     7     1     0     0    18     9     6     3     3     3   994     0     0     1    12     1     7]
 [    2     1     1     1     7     2     2     1     0     3     0    16     9     1     1   998     3    12     1     3     2]
 [    2    10     4     1     4     5     1     3     1     1     3     4     2     1     3     9  1001     3     1     3    10]
 [    1     1     2     2     1     1     0     3     0     1     0    10    16     0     0     8     1   952     0     4     2]
 [    1     4     4    10     2     4     0    16     5     2     3     3     3     1    11     0     0     1   981     2     5]
 [    1     1     0     0     4     9     8     1     1     2     0    18     5     0     0     4     5     3     6  1006    14]
 [  116   124   144    88   142   141    83   129    93   119   130   148   235   178   172   101   129    98   152   208 11202]]

2024-06-06 02:16:17,472 - ==> Best [Top1: 86.744   Top5: 98.103   Sparsity:0.00   Params: 424448 on epoch: 147]
2024-06-06 02:16:17,472 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 02:16:17,502 - 

2024-06-06 02:16:17,502 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:16:23,777 - Epoch: [148][  100/ 1218]    Overall Loss 0.254401    Objective Loss 0.254401                                        LR 0.000250    Time 0.062718    
2024-06-06 02:16:28,458 - Epoch: [148][  200/ 1218]    Overall Loss 0.252724    Objective Loss 0.252724                                        LR 0.000250    Time 0.054757    
2024-06-06 02:16:33,254 - Epoch: [148][  300/ 1218]    Overall Loss 0.253474    Objective Loss 0.253474                                        LR 0.000250    Time 0.052485    
2024-06-06 02:16:37,826 - Epoch: [148][  400/ 1218]    Overall Loss 0.254891    Objective Loss 0.254891                                        LR 0.000250    Time 0.050790    
2024-06-06 02:16:42,507 - Epoch: [148][  500/ 1218]    Overall Loss 0.256262    Objective Loss 0.256262                                        LR 0.000250    Time 0.049990    
2024-06-06 02:16:47,332 - Epoch: [148][  600/ 1218]    Overall Loss 0.255858    Objective Loss 0.255858                                        LR 0.000250    Time 0.049695    
2024-06-06 02:16:52,151 - Epoch: [148][  700/ 1218]    Overall Loss 0.256108    Objective Loss 0.256108                                        LR 0.000250    Time 0.049477    
2024-06-06 02:16:56,986 - Epoch: [148][  800/ 1218]    Overall Loss 0.256695    Objective Loss 0.256695                                        LR 0.000250    Time 0.049334    
2024-06-06 02:17:01,839 - Epoch: [148][  900/ 1218]    Overall Loss 0.257436    Objective Loss 0.257436                                        LR 0.000250    Time 0.049242    
2024-06-06 02:17:06,604 - Epoch: [148][ 1000/ 1218]    Overall Loss 0.257157    Objective Loss 0.257157                                        LR 0.000250    Time 0.049081    
2024-06-06 02:17:11,172 - Epoch: [148][ 1100/ 1218]    Overall Loss 0.256928    Objective Loss 0.256928                                        LR 0.000250    Time 0.048770    
2024-06-06 02:17:15,694 - Epoch: [148][ 1200/ 1218]    Overall Loss 0.256391    Objective Loss 0.256391                                        LR 0.000250    Time 0.048472    
2024-06-06 02:17:16,479 - Epoch: [148][ 1218/ 1218]    Overall Loss 0.256593    Objective Loss 0.256593    Top1 88.508557    Top5 99.022005    LR 0.000250    Time 0.048400    
2024-06-06 02:17:16,656 - --- validate (epoch=148)-----------
2024-06-06 02:17:16,656 - 34633 samples (256 per mini-batch)
2024-06-06 02:17:22,168 - Epoch: [148][  100/  136]    Loss 0.289204    Top1 86.660156    Top5 98.089844    
2024-06-06 02:17:23,884 - Epoch: [148][  136/  136]    Loss 0.290886    Top1 86.478214    Top5 98.117402    
2024-06-06 02:17:24,080 - ==> Top1: 86.478    Top5: 98.117    Loss: 0.291

2024-06-06 02:17:24,081 - ==> Confusion:
[[  830     3     1     2     9     2     0     0     8    58     0     0     3     4     4     0     1     3     0     1     2]
 [    3   982     2     0     9    17     2    10     4     1     4     1     4     0     2     0     7     1     9     1     4]
 [    5     3   888     7     2     3    14     8     2     3     8     1     1     2     1     2     4     1     2     4     9]
 [    5     1    11   936     1     6     1     3     1     0    13     1     5     5    12     1     0     5     3     0     6]
 [   19     9     3     3   983     9     0     1     1     8     1     1     1     2     4     1     1     1     1     3     2]
 [    4    16     4     4     6   903     2    36     3     5     1    13     8    17     3     0     1     3     0     7     7]
 [    3     3    13     2     2     5  1018     9     1     2     3     4     1     0     0     3     1     2     3     6     5]
 [    4     5    11     1     4    23     2   975     2     3     1     7     5     2     0     1     2     0    19     3     7]
 [    4     0     2     0     1     1     0     3   899    35    10     2     4     9    12     2     2     6     5     1     4]
 [   55     0     2     0     4     4     0     1    32   871     1     2     2    15     6     0     0     1     0     1     4]
 [    0     5     2     9     2     4     2     5    13     0   988     0     1     9     7     0     2     0     8     1     6]
 [    2     3     0     0     1     6     4     2     1     3     0   913    30     7     0     9     1    12     1    10     6]
 [    2     0     5     6     0     5     0     4     3     2     1    35   877     4     0     8     2    21     4     3    13]
 [    3     1     2     1     5     8     0     6    12    18     6     6     7   896     4     5     4     2     1    11     3]
 [    9     3     3    11     5     2     0     1    22     2     2     1     5     3  1000     1     1     1    15     0    11]
 [    2     1     2     0     1     4     5     1     0     4     0     9     7     1     1  1011     9     4     1     0     3]
 [    3     3     4     1     5     4     0     1     2     1     1     1     7     3     0    16  1003     1     1     6     9]
 [    2     1     2     5     1     0     1     0     2     1     0    11    20     1     2     7     1   943     2     3     0]
 [    2     3     6    14     1     4     0    18     3     0     2     0     2     1     7     0     0     0   989     1     5]
 [    0     1     2     1     3     7     8     5     0     0     0     8     6     4     1     6     3     0     2  1018    13]
 [  149   158   176    89   152   176    69   162   103    99   104   113   275   218   164   102   167    94   138   197 11027]]

2024-06-06 02:17:24,084 - ==> Best [Top1: 86.744   Top5: 98.103   Sparsity:0.00   Params: 424448 on epoch: 147]
2024-06-06 02:17:24,084 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 02:17:24,109 - 

2024-06-06 02:17:24,109 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:17:30,346 - Epoch: [149][  100/ 1218]    Overall Loss 0.251690    Objective Loss 0.251690                                        LR 0.000250    Time 0.062335    
2024-06-06 02:17:35,087 - Epoch: [149][  200/ 1218]    Overall Loss 0.251573    Objective Loss 0.251573                                        LR 0.000250    Time 0.054865    
2024-06-06 02:17:39,913 - Epoch: [149][  300/ 1218]    Overall Loss 0.253427    Objective Loss 0.253427                                        LR 0.000250    Time 0.052654    
2024-06-06 02:17:44,525 - Epoch: [149][  400/ 1218]    Overall Loss 0.252822    Objective Loss 0.252822                                        LR 0.000250    Time 0.051016    
2024-06-06 02:17:49,258 - Epoch: [149][  500/ 1218]    Overall Loss 0.254407    Objective Loss 0.254407                                        LR 0.000250    Time 0.050275    
2024-06-06 02:17:54,017 - Epoch: [149][  600/ 1218]    Overall Loss 0.254682    Objective Loss 0.254682                                        LR 0.000250    Time 0.049825    
2024-06-06 02:17:58,670 - Epoch: [149][  700/ 1218]    Overall Loss 0.254887    Objective Loss 0.254887                                        LR 0.000250    Time 0.049351    
2024-06-06 02:18:03,375 - Epoch: [149][  800/ 1218]    Overall Loss 0.255340    Objective Loss 0.255340                                        LR 0.000250    Time 0.049060    
2024-06-06 02:18:08,262 - Epoch: [149][  900/ 1218]    Overall Loss 0.256672    Objective Loss 0.256672                                        LR 0.000250    Time 0.049038    
2024-06-06 02:18:13,034 - Epoch: [149][ 1000/ 1218]    Overall Loss 0.255659    Objective Loss 0.255659                                        LR 0.000250    Time 0.048903    
2024-06-06 02:18:17,854 - Epoch: [149][ 1100/ 1218]    Overall Loss 0.255729    Objective Loss 0.255729                                        LR 0.000250    Time 0.048838    
2024-06-06 02:18:22,520 - Epoch: [149][ 1200/ 1218]    Overall Loss 0.255227    Objective Loss 0.255227                                        LR 0.000250    Time 0.048654    
2024-06-06 02:18:23,365 - Epoch: [149][ 1218/ 1218]    Overall Loss 0.255298    Objective Loss 0.255298    Top1 88.019560    Top5 98.533007    LR 0.000250    Time 0.048629    
2024-06-06 02:18:23,544 - --- validate (epoch=149)-----------
2024-06-06 02:18:23,545 - 34633 samples (256 per mini-batch)
2024-06-06 02:18:29,126 - Epoch: [149][  100/  136]    Loss 0.275319    Top1 87.296875    Top5 98.171875    
2024-06-06 02:18:30,829 - Epoch: [149][  136/  136]    Loss 0.284178    Top1 86.986400    Top5 98.160714    
2024-06-06 02:18:31,007 - ==> Top1: 86.986    Top5: 98.161    Loss: 0.284

2024-06-06 02:18:31,008 - ==> Confusion:
[[  837     0     3     0     4     3     1     0     4    49     1     2     3     3     9     0     1     3     1     0     7]
 [    2   985     6     0    13    14     0     9     2     0     2     0     2     1     4     1     1     1    11     4     5]
 [    5     2   886     6     4     2    19     7     2     2     6     2     5     4     1     0     2     0     2     3    10]
 [    4     3     9   920     1     7     3     3     2     1    15     3     9     1    13     2     2     3     8     0     7]
 [   10     4     3     2   981     7     1     0     0     9     0     2     1     6     5     4     5     2     5     0     7]
 [    1    26     2     1    11   912     2    23     2     4     5    10     6    15     3     1     3     2     0     9     5]
 [    2     2    11     0     5     7  1022     2     0     0     3     2     2     0     0     7     2     3     1    10     5]
 [    0    14    11     1     1    22     4   969     3     3     4     7     4     5     2     1     1     3    11     4     7]
 [   10     2     0     1     0     2     0     1   898    30     8     4     3    11    14     1     3     4     3     1     6]
 [   57     2     2     2     2     2     1     0    36   869     1     1     1    12     7     1     1     1     0     0     3]
 [    0     2     7     8     0     3     1     6    10     4   994     0     0     7     7     0     1     0     8     0     6]
 [    1     1     1     0     2     7     5     1     5     2     1   888    36     9     1    16     2    13     1    13     6]
 [    0     1     3     7     1     3     0     0     2     1     2    43   881     1     2     4     2    25     1     4    12]
 [    2     2     1     2     3     7     0     3    13    13     9     9     6   905     4     1     5     2     0     4    10]
 [    7     2     1    12     5     3     0     0    18     4     6     1     3     3  1012     0     0     3     7     0    11]
 [    3     3     0     2     3     0     6     0     0     3     0    10    10     0     1  1009     5     3     1     2     5]
 [    1    12     1     1     7     6     1     0     3     0     2     6     1     1     2     4  1012     1     1     4     6]
 [    4     1     0     2     0     1     1     1     0     3     0    10    19     2     0     4     0   951     1     1     4]
 [    2     3     2     6     1     2     0    15     4     0     3     1     3     1    16     0     2     1   987     2     7]
 [    2     6     2     2     1     6     6     5     0     1     1    10     7     2     0     6     2     5     3  1015     6]
 [  155   195   127    88   147   151    73   122    78    89   155   121   245   180   155    83   121   109   146   199 11193]]

2024-06-06 02:18:31,010 - ==> Best [Top1: 86.986   Top5: 98.161   Sparsity:0.00   Params: 424448 on epoch: 149]
2024-06-06 02:18:31,011 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/checkpoint.pth.tar
2024-06-06 02:18:31,039 - 

2024-06-06 02:18:31,040 - Initiating quantization aware training (QAT)...
2024-06-06 02:18:31,068 - 

2024-06-06 02:18:31,069 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:18:37,266 - Epoch: [150][  100/ 1218]    Overall Loss 0.481095    Objective Loss 0.481095                                        LR 0.000250    Time 0.061953    
2024-06-06 02:18:42,073 - Epoch: [150][  200/ 1218]    Overall Loss 0.453236    Objective Loss 0.453236                                        LR 0.000250    Time 0.055001    
2024-06-06 02:18:46,641 - Epoch: [150][  300/ 1218]    Overall Loss 0.435463    Objective Loss 0.435463                                        LR 0.000250    Time 0.051887    
2024-06-06 02:18:51,342 - Epoch: [150][  400/ 1218]    Overall Loss 0.423636    Objective Loss 0.423636                                        LR 0.000250    Time 0.050663    
2024-06-06 02:18:56,038 - Epoch: [150][  500/ 1218]    Overall Loss 0.411865    Objective Loss 0.411865                                        LR 0.000250    Time 0.049919    
2024-06-06 02:19:00,732 - Epoch: [150][  600/ 1218]    Overall Loss 0.405029    Objective Loss 0.405029                                        LR 0.000250    Time 0.049419    
2024-06-06 02:19:05,303 - Epoch: [150][  700/ 1218]    Overall Loss 0.402756    Objective Loss 0.402756                                        LR 0.000250    Time 0.048887    
2024-06-06 02:19:09,974 - Epoch: [150][  800/ 1218]    Overall Loss 0.398260    Objective Loss 0.398260                                        LR 0.000250    Time 0.048613    
2024-06-06 02:19:14,549 - Epoch: [150][  900/ 1218]    Overall Loss 0.394962    Objective Loss 0.394962                                        LR 0.000250    Time 0.048292    
2024-06-06 02:19:19,180 - Epoch: [150][ 1000/ 1218]    Overall Loss 0.390775    Objective Loss 0.390775                                        LR 0.000250    Time 0.048092    
2024-06-06 02:19:23,945 - Epoch: [150][ 1100/ 1218]    Overall Loss 0.387182    Objective Loss 0.387182                                        LR 0.000250    Time 0.048049    
2024-06-06 02:19:28,694 - Epoch: [150][ 1200/ 1218]    Overall Loss 0.384881    Objective Loss 0.384881                                        LR 0.000250    Time 0.048001    
2024-06-06 02:19:29,488 - Epoch: [150][ 1218/ 1218]    Overall Loss 0.384735    Objective Loss 0.384735    Top1 83.618582    Top5 97.066015    LR 0.000250    Time 0.047943    
2024-06-06 02:19:29,667 - --- validate (epoch=150)-----------
2024-06-06 02:19:29,667 - 34633 samples (256 per mini-batch)
2024-06-06 02:19:35,234 - Epoch: [150][  100/  136]    Loss 0.401101    Top1 83.480469    Top5 97.628906    
2024-06-06 02:19:36,916 - Epoch: [150][  136/  136]    Loss 0.400650    Top1 83.486848    Top5 97.638091    
2024-06-06 02:19:37,088 - ==> Top1: 83.487    Top5: 97.638    Loss: 0.401

2024-06-06 02:19:37,089 - ==> Confusion:
[[  832     2     0     0     7     2     1     2    10    44     1     2     4     3     2     2     2     0     3     1    11]
 [    0   984     1     2    12     5     3     7     0     2     8     1     7     0     0     1     7     0    13     0    10]
 [   10     1   825    13     9     4    22    10     0     3    17     3     7     2     1    11     5     0    10     2    15]
 [    3     5     3   908     4     3     1     1     1     2    19     1    10     6    15     5     0     5    11     1    12]
 [   38    20     1     1   929     5     0     6     3     8     0     0     2     1     4     7     4     0     7     2    16]
 [    4    63     0     4     9   843     4    31     0     6     0    10     4    17     0     2    12     0     8    10    16]
 [    4     2     7     3     0     5  1000     7     0     2     6     1     3     1     0    16     2     0     4    13    10]
 [    4    17     4     0     3    18     5   908     5     1    15     5     4     3     0     2     2     1    57    14     9]
 [    9     3     0     0     1     1     0     1   892    35    12     3     5     8     4     2     3     0    10     0    13]
 [   82     1     2     2     5     2     0     1    61   804     3     0     4    14     0     3     1     2     2     4     8]
 [    1     5     1    12     1     3     3     2    14     0   982     2     2     7     1     2     3     0    15     2     6]
 [    0     6     1     0     7    12     2     6     1     5     0   865    26    11     0    28     3     4     3    22     9]
 [    0     1     0     5     5     6     0     2     2     0     1    67   837     3     0    18     5     7     7    11    18]
 [    3     1     0     2     3     6     2     3    20    16    13     6     5   882     1     6     2     1     1     6    22]
 [   17    17     2    21    15     0     0     0    60    12     6     0     6     7   861     0     2     4    39     1    28]
 [    1     0     1     0     4     0     2     0     1     1     0     7     5     1     0  1023     7     1     1     6     5]
 [    5     9     1     3     9     1     0     1     2     1     1     4     2     1     0    15   994     0     1     8    14]
 [    1     2     0     4     2     0     0     2     3     5     1    36    38     3     1    49     2   837     7     6     6]
 [    3    12     2     9     2     2     0    12     5     0     7     0     3     1     3     0     1     0   991     0     5]
 [    1     9     0     1     3     1    10    11     1     0     0    12     8     3     0     7     4     0     8  1000     9]
 [  157   280    94   118   145   119    80   129   111    88   208   132   246   194    54   195   219    37   277   333 10716]]

2024-06-06 02:19:37,091 - ==> Best [Top1: 83.487   Top5: 97.638   Sparsity:0.00   Params: 424448 on epoch: 150]
2024-06-06 02:19:37,091 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:19:37,109 - 

2024-06-06 02:19:37,109 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:19:43,247 - Epoch: [151][  100/ 1218]    Overall Loss 0.337414    Objective Loss 0.337414                                        LR 0.000250    Time 0.061355    
2024-06-06 02:19:47,957 - Epoch: [151][  200/ 1218]    Overall Loss 0.342355    Objective Loss 0.342355                                        LR 0.000250    Time 0.054216    
2024-06-06 02:19:52,590 - Epoch: [151][  300/ 1218]    Overall Loss 0.344003    Objective Loss 0.344003                                        LR 0.000250    Time 0.051581    
2024-06-06 02:19:57,262 - Epoch: [151][  400/ 1218]    Overall Loss 0.342647    Objective Loss 0.342647                                        LR 0.000250    Time 0.050359    
2024-06-06 02:20:01,842 - Epoch: [151][  500/ 1218]    Overall Loss 0.341980    Objective Loss 0.341980                                        LR 0.000250    Time 0.049444    
2024-06-06 02:20:06,587 - Epoch: [151][  600/ 1218]    Overall Loss 0.343715    Objective Loss 0.343715                                        LR 0.000250    Time 0.049108    
2024-06-06 02:20:11,185 - Epoch: [151][  700/ 1218]    Overall Loss 0.344542    Objective Loss 0.344542                                        LR 0.000250    Time 0.048659    
2024-06-06 02:20:15,842 - Epoch: [151][  800/ 1218]    Overall Loss 0.343754    Objective Loss 0.343754                                        LR 0.000250    Time 0.048396    
2024-06-06 02:20:20,428 - Epoch: [151][  900/ 1218]    Overall Loss 0.344995    Objective Loss 0.344995                                        LR 0.000250    Time 0.048112    
2024-06-06 02:20:25,017 - Epoch: [151][ 1000/ 1218]    Overall Loss 0.345327    Objective Loss 0.345327                                        LR 0.000250    Time 0.047888    
2024-06-06 02:20:29,584 - Epoch: [151][ 1100/ 1218]    Overall Loss 0.345243    Objective Loss 0.345243                                        LR 0.000250    Time 0.047685    
2024-06-06 02:20:34,263 - Epoch: [151][ 1200/ 1218]    Overall Loss 0.344585    Objective Loss 0.344585                                        LR 0.000250    Time 0.047609    
2024-06-06 02:20:35,084 - Epoch: [151][ 1218/ 1218]    Overall Loss 0.345069    Objective Loss 0.345069    Top1 81.173594    Top5 96.088020    LR 0.000250    Time 0.047579    
2024-06-06 02:20:35,248 - --- validate (epoch=151)-----------
2024-06-06 02:20:35,248 - 34633 samples (256 per mini-batch)
2024-06-06 02:20:40,788 - Epoch: [151][  100/  136]    Loss 0.374235    Top1 83.789062    Top5 97.574219    
2024-06-06 02:20:42,466 - Epoch: [151][  136/  136]    Loss 0.381521    Top1 83.596570    Top5 97.591892    
2024-06-06 02:20:42,628 - ==> Top1: 83.597    Top5: 97.592    Loss: 0.382

2024-06-06 02:20:42,629 - ==> Confusion:
[[  859     0     1     3     7     1     0     0     8    31     0     3     2     2     2     2     2     3     1     0     4]
 [    4   943     1     3    20    24     1    11     4     0     2     2     3     1    11     1    12     3     8     1     8]
 [    6     1   880    11     7     0     2    15     0     3     5     5     3     0     5     2    10     0     3     2    10]
 [    2     2     9   901     2     2     1     4     1     0    13     0     4     1    47     1     2     8     6     1     9]
 [   20     6     4     0   970     1     0     2     1     8     0     1     1     2    13     4     5     1     4     0    11]
 [    7    36     6     8    17   843     1    39     2     3     0    13     2    21     5     1     9     6     4     5    15]
 [    3     1    44     2     2     4   953    15     0     1     4     3     0     1     0    12    10     7     2    11    11]
 [    4    11    11     2     2    16     0   952     2     2     6     6     2     4     4     1     2     5    30     5    10]
 [   11     2     2     0     1     0     0     1   881    30    18     2     3     4    23     0     7     3     4     0    10]
 [  105     0     2     0    11     2     0     1    53   773     2     1     0    11    16     0     6     4     1     1    12]
 [    3     2     5     7     0     0     1     5    15     1   995     0     0     5    14     0     2     0     4     0     5]
 [    1     1     2     0     4     6     0     6     1     2     1   889    29     7     2    12     7    31     0     5     5]
 [    1     1     2     9     1     4     0     4     1     1     6    60   778     3     5     7    10    70     4     7    21]
 [    5     1     3     0     3     6     0     4    32    18    14    11     4   851    15     1     7     7     0     3    16]
 [    8     3     1     7     7     0     0     1    23     5     3     1     0     3  1015     0     3     6     8     0     4]
 [    3     2     5     1     5     1     3     0     0     2     0    14     5     2     1   979    15    23     0     0     5]
 [    5     4     3     3     4     5     1     1     4     0     4     4     1     2     4     5   993     4     3     1    21]
 [    3     2     1     4     1     0     1     1     1     1     0     7     7     1     5    11     4   947     2     1     5]
 [    0     7     2     8     2     0     0    18     5     0     5     2     1     0    30     0     2     2   965     0     9]
 [    1     6     4     1     1     6     6    16     0     0     1    27     8     8     1     6    14     5     5   955    17]
 [  189   163   165   109   222   100    24   161   112    66   195   155   215   168   392    91   287   177   162   149 10630]]

2024-06-06 02:20:42,631 - ==> Best [Top1: 83.597   Top5: 97.592   Sparsity:0.00   Params: 424448 on epoch: 151]
2024-06-06 02:20:42,631 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:20:42,658 - 

2024-06-06 02:20:42,659 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:20:48,859 - Epoch: [152][  100/ 1218]    Overall Loss 0.337825    Objective Loss 0.337825                                        LR 0.000250    Time 0.061977    
2024-06-06 02:20:53,517 - Epoch: [152][  200/ 1218]    Overall Loss 0.337013    Objective Loss 0.337013                                        LR 0.000250    Time 0.054267    
2024-06-06 02:20:58,199 - Epoch: [152][  300/ 1218]    Overall Loss 0.338561    Objective Loss 0.338561                                        LR 0.000250    Time 0.051779    
2024-06-06 02:21:02,794 - Epoch: [152][  400/ 1218]    Overall Loss 0.341018    Objective Loss 0.341018                                        LR 0.000250    Time 0.050316    
2024-06-06 02:21:07,506 - Epoch: [152][  500/ 1218]    Overall Loss 0.341815    Objective Loss 0.341815                                        LR 0.000250    Time 0.049673    
2024-06-06 02:21:12,534 - Epoch: [152][  600/ 1218]    Overall Loss 0.341722    Objective Loss 0.341722                                        LR 0.000250    Time 0.049772    
2024-06-06 02:21:17,569 - Epoch: [152][  700/ 1218]    Overall Loss 0.340952    Objective Loss 0.340952                                        LR 0.000250    Time 0.049852    
2024-06-06 02:21:22,446 - Epoch: [152][  800/ 1218]    Overall Loss 0.340734    Objective Loss 0.340734                                        LR 0.000250    Time 0.049714    
2024-06-06 02:21:27,224 - Epoch: [152][  900/ 1218]    Overall Loss 0.339159    Objective Loss 0.339159                                        LR 0.000250    Time 0.049496    
2024-06-06 02:21:31,925 - Epoch: [152][ 1000/ 1218]    Overall Loss 0.339514    Objective Loss 0.339514                                        LR 0.000250    Time 0.049246    
2024-06-06 02:21:36,657 - Epoch: [152][ 1100/ 1218]    Overall Loss 0.339971    Objective Loss 0.339971                                        LR 0.000250    Time 0.049069    
2024-06-06 02:21:41,331 - Epoch: [152][ 1200/ 1218]    Overall Loss 0.339225    Objective Loss 0.339225                                        LR 0.000250    Time 0.048873    
2024-06-06 02:21:42,120 - Epoch: [152][ 1218/ 1218]    Overall Loss 0.339051    Objective Loss 0.339051    Top1 84.107579    Top5 96.821516    LR 0.000250    Time 0.048798    
2024-06-06 02:21:42,312 - --- validate (epoch=152)-----------
2024-06-06 02:21:42,312 - 34633 samples (256 per mini-batch)
2024-06-06 02:21:47,896 - Epoch: [152][  100/  136]    Loss 0.362104    Top1 83.050781    Top5 97.226562    
2024-06-06 02:21:49,570 - Epoch: [152][  136/  136]    Loss 0.361289    Top1 82.978662    Top5 97.164554    
2024-06-06 02:21:49,750 - ==> Top1: 82.979    Top5: 97.165    Loss: 0.361

2024-06-06 02:21:49,752 - ==> Confusion:
[[  805     2     2     3    10     3     0     0    12    75     0     0     1     2     9     1     2     0     0     0     4]
 [    2   949     2     2    22    29     5    11     4     2     5     1     1     0     3     1     2     4    11     2     5]
 [    9     2   868    12    10     3    16     7     0     7     8     2     2     3     1     6     5     1     3     1     4]
 [    5     4     8   920     3     7     2     2     0     5     9     1     5     2    26     1     0     7     6     2     1]
 [   19    11     4     1   957     9     0     1     2    10     0     2     2     6    12     5     3     0     1     1     8]
 [    4    16     2     5    15   925     2    18     1     5     2     6    10    11     0     1     1     3     2     6     8]
 [    3     3    17     4     4     4  1011     5     0     2     5     4     3     0     0     6     0     2     1     5     7]
 [    3     8     4     4     5    31     3   944     4     3     9     8     7     7     1     0     2     3    19     9     3]
 [    8     3     0     2     2     1     0     2   864    51    14     0     4    23    15     1     1     1     4     0     6]
 [   47     1     1     2     6     1     0     0    50   856     3     0     0    24     4     0     1     1     1     0     3]
 [    1     3     3    17     0     4     3     1    15     0   984     0     1     7    13     0     0     0     6     2     4]
 [    4     3     1     0     4    12     1     4     2     2     5   861    53     6     2    14     3    18     2    10     4]
 [    0     2     3     3     6     5     0     3     0     4     1    46   876     1     2     8     3    26     1     2     3]
 [    3     1     2     2     4    14     0     3    13    10     7     8     8   906     2     0     1     3     0     2    12]
 [   11     0     1    15     6     1     0     1    22     8     4     2     1     7   998     0     1     1    11     0     8]
 [    2     4     2     0    10     0     2     1     1     2     0    10     7     1     0   998     5    16     1     3     1]
 [    5    12     6     2     8    11     0     0     1     4     3     5     7     4     8    12   968     4     2     4     6]
 [    2     2     1     4     2     1     2     0     1     2     1     8    23     3     3     6     1   934     3     4     2]
 [    3    12     4    13     4     3     0    19     4     2     5     1     0     2    15     0     0     0   963     1     7]
 [    3     4     2     1     4    12    15    10     0     1     2    16    17     6     1     2     6     8     3   965    10]
 [  220   212   160   118   207   215    95   153   136   144   182   124   412   292   247   144   172   157   171   185 10186]]

2024-06-06 02:21:49,754 - ==> Best [Top1: 83.597   Top5: 97.592   Sparsity:0.00   Params: 424448 on epoch: 151]
2024-06-06 02:21:49,754 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:21:49,777 - 

2024-06-06 02:21:49,777 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:21:55,964 - Epoch: [153][  100/ 1218]    Overall Loss 0.345010    Objective Loss 0.345010                                        LR 0.000250    Time 0.061844    
2024-06-06 02:22:00,734 - Epoch: [153][  200/ 1218]    Overall Loss 0.344196    Objective Loss 0.344196                                        LR 0.000250    Time 0.054762    
2024-06-06 02:22:05,503 - Epoch: [153][  300/ 1218]    Overall Loss 0.341467    Objective Loss 0.341467                                        LR 0.000250    Time 0.052397    
2024-06-06 02:22:10,480 - Epoch: [153][  400/ 1218]    Overall Loss 0.338395    Objective Loss 0.338395                                        LR 0.000250    Time 0.051736    
2024-06-06 02:22:15,265 - Epoch: [153][  500/ 1218]    Overall Loss 0.338994    Objective Loss 0.338994                                        LR 0.000250    Time 0.050956    
2024-06-06 02:22:20,242 - Epoch: [153][  600/ 1218]    Overall Loss 0.339264    Objective Loss 0.339264                                        LR 0.000250    Time 0.050754    
2024-06-06 02:22:24,934 - Epoch: [153][  700/ 1218]    Overall Loss 0.339015    Objective Loss 0.339015                                        LR 0.000250    Time 0.050204    
2024-06-06 02:22:29,537 - Epoch: [153][  800/ 1218]    Overall Loss 0.337939    Objective Loss 0.337939                                        LR 0.000250    Time 0.049680    
2024-06-06 02:22:34,080 - Epoch: [153][  900/ 1218]    Overall Loss 0.337500    Objective Loss 0.337500                                        LR 0.000250    Time 0.049205    
2024-06-06 02:22:38,925 - Epoch: [153][ 1000/ 1218]    Overall Loss 0.337560    Objective Loss 0.337560                                        LR 0.000250    Time 0.049127    
2024-06-06 02:22:43,516 - Epoch: [153][ 1100/ 1218]    Overall Loss 0.337785    Objective Loss 0.337785                                        LR 0.000250    Time 0.048834    
2024-06-06 02:22:48,143 - Epoch: [153][ 1200/ 1218]    Overall Loss 0.337174    Objective Loss 0.337174                                        LR 0.000250    Time 0.048619    
2024-06-06 02:22:48,936 - Epoch: [153][ 1218/ 1218]    Overall Loss 0.337349    Objective Loss 0.337349    Top1 81.173594    Top5 97.310513    LR 0.000250    Time 0.048551    
2024-06-06 02:22:49,093 - --- validate (epoch=153)-----------
2024-06-06 02:22:49,094 - 34633 samples (256 per mini-batch)
2024-06-06 02:22:54,758 - Epoch: [153][  100/  136]    Loss 0.385314    Top1 80.445312    Top5 96.687500    
2024-06-06 02:22:56,428 - Epoch: [153][  136/  136]    Loss 0.380181    Top1 80.538792    Top5 96.679468    
2024-06-06 02:22:56,623 - ==> Top1: 80.539    Top5: 96.679    Loss: 0.380

2024-06-06 02:22:56,624 - ==> Confusion:
[[ 808    1    4    0    2    2    1    1    7   86    0    3    1    5    2    0    1    2    1    3    1]
 [   6  937    3    1   16   37    3   14    7    2    4    5    2    1    3    2    8    2    7    3    0]
 [   4    0  897    5    1    1   14    6    0   12    2    4    5    7    1    4    2    0    1    2    2]
 [   2    1   12  925    4    4    2    1    6    4    9    2    8    3   14    3    2    8    1    1    4]
 [  27    6    7    1  936    8    1    1    2   27    1    5    2    3    8    7    6    0    1    0    5]
 [  10   10    2    2    6  875    0   31    6   17    4   26    6   16    2    7    3    4    3    9    4]
 [   3    2   32    2    1    5  998    6    0    4    0    5    1    0    0   10    1    5    1    8    2]
 [   4   10   11    0    1   23    3  948    1    9    2   13    5    2    0    2    3    3   21   14    2]
 [   6    3    2    1    1    1    0    2  889   61   10    3    4    9    3    0    2    0    0    3    2]
 [  46    0    1    1    4    3    0    0   34  886    1    0    3   12    3    0    0    5    0    0    2]
 [   1    2   10   12    2    6    3    6   36    4  953    3    2    9    7    1    1    1    3    1    1]
 [   0    1    3    0    0    4    0    3    2    5    0  908   15    8    2   25    2   14    1   18    0]
 [   3    0    2    8    2    1    2    0    5    4    2   75  832    3    0   10    2   33    2    7    2]
 [   4    0    4    1    2   14    0    1   20   27   10   16    5  871    4    4    1    4    2    7    4]
 [   7    2    3   13    5    4    0    0   61   20    2    4    3    7  960    0    0    1    1    0    5]
 [   5    0    3    0    1    1    3    1    0    8    0   14    1    1    0 1016    2    7    0    1    2]
 [   3    4    9    2    2    5    0    1    8    4    3   10    2    5    1   19  972    1    1   13    7]
 [   6    2    2    1    2    1    0    2    2    3    1   21   17    2    1   17    2  919    1    1    2]
 [   5    4   14   17    5    4    1   20   16    3    6    1    6    3   27    0    0    0  917    4    5]
 [   4    2    3    0    2    7    8    9    1    4    0   14   13    2    0    6    1    2    2 1004    4]
 [ 324  146  352  120  195  194  101  163  183  275  154  248  359  268  182  357  232  172  114  351 9442]]

2024-06-06 02:22:56,626 - ==> Best [Top1: 83.597   Top5: 97.592   Sparsity:0.00   Params: 424448 on epoch: 151]
2024-06-06 02:22:56,626 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:22:56,641 - 

2024-06-06 02:22:56,641 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:23:02,919 - Epoch: [154][  100/ 1218]    Overall Loss 0.333063    Objective Loss 0.333063                                        LR 0.000250    Time 0.062751    
2024-06-06 02:23:07,657 - Epoch: [154][  200/ 1218]    Overall Loss 0.335526    Objective Loss 0.335526                                        LR 0.000250    Time 0.055057    
2024-06-06 02:23:12,262 - Epoch: [154][  300/ 1218]    Overall Loss 0.331162    Objective Loss 0.331162                                        LR 0.000250    Time 0.052049    
2024-06-06 02:23:16,934 - Epoch: [154][  400/ 1218]    Overall Loss 0.331797    Objective Loss 0.331797                                        LR 0.000250    Time 0.050711    
2024-06-06 02:23:21,696 - Epoch: [154][  500/ 1218]    Overall Loss 0.331246    Objective Loss 0.331246                                        LR 0.000250    Time 0.050089    
2024-06-06 02:23:26,321 - Epoch: [154][  600/ 1218]    Overall Loss 0.333806    Objective Loss 0.333806                                        LR 0.000250    Time 0.049446    
2024-06-06 02:23:31,063 - Epoch: [154][  700/ 1218]    Overall Loss 0.332874    Objective Loss 0.332874                                        LR 0.000250    Time 0.049154    
2024-06-06 02:23:35,727 - Epoch: [154][  800/ 1218]    Overall Loss 0.334258    Objective Loss 0.334258                                        LR 0.000250    Time 0.048837    
2024-06-06 02:23:40,655 - Epoch: [154][  900/ 1218]    Overall Loss 0.335114    Objective Loss 0.335114                                        LR 0.000250    Time 0.048884    
2024-06-06 02:23:45,348 - Epoch: [154][ 1000/ 1218]    Overall Loss 0.334585    Objective Loss 0.334585                                        LR 0.000250    Time 0.048687    
2024-06-06 02:23:49,913 - Epoch: [154][ 1100/ 1218]    Overall Loss 0.334655    Objective Loss 0.334655                                        LR 0.000250    Time 0.048409    
2024-06-06 02:23:54,506 - Epoch: [154][ 1200/ 1218]    Overall Loss 0.334296    Objective Loss 0.334296                                        LR 0.000250    Time 0.048200    
2024-06-06 02:23:55,285 - Epoch: [154][ 1218/ 1218]    Overall Loss 0.334128    Objective Loss 0.334128    Top1 84.352078    Top5 97.310513    LR 0.000250    Time 0.048127    
2024-06-06 02:23:55,498 - --- validate (epoch=154)-----------
2024-06-06 02:23:55,499 - 34633 samples (256 per mini-batch)
2024-06-06 02:24:01,145 - Epoch: [154][  100/  136]    Loss 0.368091    Top1 84.027344    Top5 97.718750    
2024-06-06 02:24:02,766 - Epoch: [154][  136/  136]    Loss 0.363217    Top1 84.070107    Top5 97.646753    
2024-06-06 02:24:02,936 - ==> Top1: 84.070    Top5: 97.647    Loss: 0.363

2024-06-06 02:24:02,937 - ==> Confusion:
[[  833     1     1     0    14     0     1     2     6    54     0     0     2     1     3     1     3     1     2     0     6]
 [    4   963     4     3    19    12     6     8     3     1     3     1     4     3     1     1    12     0    10     2     3]
 [    7     1   855     7    11     1    21    12     0     4     2     7     1     2     1     4     5     0    11     5    13]
 [    8     2    14   897     4     1     4     4     1     4    12     0     7     1    20     0     2     3    23     1     8]
 [   18     3     1     1   984     3     1     0     3    13     1     1     4     1     6     1     4     1     1     1     6]
 [    3    31     2     4    18   863     4    29     2     8     2    10     9    12     1     2    11     1     8    14     9]
 [    4     1    10     0     2     3  1025     4     1     2     1     3     2     0     0     7     0     0     2    10     9]
 [    0    23    10     0     3    26     4   946     2     5     1     1     5     2     1     1     2     1    24     9    11]
 [    9     4     1     0     3     2     0     4   876    46    10     4     1     7    12     0     5     1     8     0     9]
 [   52     1     2     0     7     1     0     3    31   881     0     2     6     6     3     1     1     1     0     0     3]
 [    2     3    10    12     2     1     4     6    24     1   954     3     2     3     5     0     2     0    15     6     9]
 [    2     1     1     1     3    12     5     1     0     3     1   869    33     5     0    12     7    13     2    29    11]
 [    2     2     4     3     4     3     1     0     2     2     0    48   856     3     2    10     6    15     9    11    12]
 [    1     0     3     0     4     9     2     2    26    25    10    10     5   876     4     2     1     2     2     6    11]
 [    6     1     6    16    11     1     0     0    54    14     6     1     4     3   936     1     2     0    18     4    14]
 [    3     0     1     0     6     1     9     1     0     4     0     6     6     0     0   988    14    10     1     7     9]
 [    0     0     3     0     5     5     1     0     4     3     2     4     3     3     1     6  1012     0     3     7    10]
 [    2     1     1     3     1     1     3     1     2     4     0    14    43     5     2    13     5   888     2     3    11]
 [    4     9     4     2     3     0     1     9     9     0     1     0     7     1     4     1     3     0   984     5    11]
 [    6     5     0     0     1     8    16     7     0     0     0     7     6     1     0     4     8     2     3  1001    13]
 [  199   216   153    52   260   127    93   148   130   142   125   116   273   187   126   103   299    54   235   265 10629]]

2024-06-06 02:24:02,941 - ==> Best [Top1: 84.070   Top5: 97.647   Sparsity:0.00   Params: 424448 on epoch: 154]
2024-06-06 02:24:02,941 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:24:02,969 - 

2024-06-06 02:24:02,970 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:24:09,326 - Epoch: [155][  100/ 1218]    Overall Loss 0.327430    Objective Loss 0.327430                                        LR 0.000250    Time 0.063533    
2024-06-06 02:24:14,022 - Epoch: [155][  200/ 1218]    Overall Loss 0.328072    Objective Loss 0.328072                                        LR 0.000250    Time 0.055237    
2024-06-06 02:24:18,680 - Epoch: [155][  300/ 1218]    Overall Loss 0.328974    Objective Loss 0.328974                                        LR 0.000250    Time 0.052346    
2024-06-06 02:24:23,595 - Epoch: [155][  400/ 1218]    Overall Loss 0.330219    Objective Loss 0.330219                                        LR 0.000250    Time 0.051542    
2024-06-06 02:24:28,161 - Epoch: [155][  500/ 1218]    Overall Loss 0.332048    Objective Loss 0.332048                                        LR 0.000250    Time 0.050363    
2024-06-06 02:24:32,733 - Epoch: [155][  600/ 1218]    Overall Loss 0.332088    Objective Loss 0.332088                                        LR 0.000250    Time 0.049584    
2024-06-06 02:24:37,374 - Epoch: [155][  700/ 1218]    Overall Loss 0.332960    Objective Loss 0.332960                                        LR 0.000250    Time 0.049128    
2024-06-06 02:24:41,936 - Epoch: [155][  800/ 1218]    Overall Loss 0.332979    Objective Loss 0.332979                                        LR 0.000250    Time 0.048688    
2024-06-06 02:24:46,489 - Epoch: [155][  900/ 1218]    Overall Loss 0.331873    Objective Loss 0.331873                                        LR 0.000250    Time 0.048335    
2024-06-06 02:24:51,050 - Epoch: [155][ 1000/ 1218]    Overall Loss 0.331807    Objective Loss 0.331807                                        LR 0.000250    Time 0.048060    
2024-06-06 02:24:55,688 - Epoch: [155][ 1100/ 1218]    Overall Loss 0.332369    Objective Loss 0.332369                                        LR 0.000250    Time 0.047906    
2024-06-06 02:25:00,330 - Epoch: [155][ 1200/ 1218]    Overall Loss 0.333065    Objective Loss 0.333065                                        LR 0.000250    Time 0.047780    
2024-06-06 02:25:01,122 - Epoch: [155][ 1218/ 1218]    Overall Loss 0.333320    Objective Loss 0.333320    Top1 80.929095    Top5 96.821516    LR 0.000250    Time 0.047724    
2024-06-06 02:25:01,312 - --- validate (epoch=155)-----------
2024-06-06 02:25:01,312 - 34633 samples (256 per mini-batch)
2024-06-06 02:25:07,015 - Epoch: [155][  100/  136]    Loss 0.374725    Top1 84.367188    Top5 97.550781    
2024-06-06 02:25:08,722 - Epoch: [155][  136/  136]    Loss 0.372276    Top1 84.425259    Top5 97.600554    
2024-06-06 02:25:08,910 - ==> Top1: 84.425    Top5: 97.601    Loss: 0.372

2024-06-06 02:25:08,911 - ==> Confusion:
[[  808     2     2     1     6     2     0     1     4    84     1     0     1     0     6     0     1     1     2     3     6]
 [    0   964     2     5     7    15     3     9     7     8     6     1     0     1     6     0     3     3    11     4     8]
 [    7     1   865    16     2     0    32     1     0     6     9     1     0     3     7     0     5     0     1     7     7]
 [    1     1     4   931     1     1     2     3     0     4    15     1     3     3    20     1     2    10     3     0    10]
 [   21    13     4     3   948     2     2     2     3    14     1     0     2     3    16     1     4     2     0     2    11]
 [    5    29     2    10     7   876     5    18     4     9     3     4     4    16     7     0     1     5     1    17    20]
 [    2     3     7     1     1     2  1042     3     0     2     2     3     0     0     0     3     2     1     2     3     7]
 [    1     7    17     7     1    18    10   926     3     8    11     6     2     3     3     0     0     8    15    20    11]
 [    6     3     0     5     1     1     0     0   848    73     8     1     2     9    26     0     2     6     5     1     5]
 [   48     0     1     3     1     0     0     0    25   895     1     0     0     5     7     0     1     3     1     4     6]
 [    0     3     3    13     0     2     6     0    20     3   982     0     1     2    10     0     0     3     8     4     4]
 [    2     1     5     0     3    20     6     3     1     3     2   839    19    20     0    18     1    20     0    32    16]
 [    2     2     1    10     0     6     1     2     8     1     0    41   815     2     4     9     4    51     2    15    19]
 [    2     0     3     0     1     8     0     4    23    56    10     2     2   843     8     1     5     8     0    13    12]
 [    5     1     2    23     3     0     1     2    20     6     9     1     2     1  1009     0     0     2     2     3     6]
 [    5     3     4     1     1     1    15     0     1     4     0     6     5     0     1   982     7    16     0     4    10]
 [    5     9     4     4     4     6     2     1     4     3     4     3     1     2     2     7   979     5     0    10    17]
 [    2     0     1     3     0     3     4     1     2     1     0    11     6     6     4     7     1   942     0     5     6]
 [    3     8     7    30     2     1     1    22     5     0     8     1     1     1    24     0     1     2   922     5    14]
 [    2     7     4     0     0     4    18     2     1     1     0     5     6     1     2     2     3     4     1  1016     9]
 [  190   160   183   151   124   112   138   100   157   200   159    64   200   208   228    83   127   124    94   323 10807]]

2024-06-06 02:25:08,913 - ==> Best [Top1: 84.425   Top5: 97.601   Sparsity:0.00   Params: 424448 on epoch: 155]
2024-06-06 02:25:08,913 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:25:08,941 - 

2024-06-06 02:25:08,942 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:25:15,329 - Epoch: [156][  100/ 1218]    Overall Loss 0.328560    Objective Loss 0.328560                                        LR 0.000250    Time 0.063846    
2024-06-06 02:25:20,115 - Epoch: [156][  200/ 1218]    Overall Loss 0.329086    Objective Loss 0.329086                                        LR 0.000250    Time 0.055843    
2024-06-06 02:25:24,746 - Epoch: [156][  300/ 1218]    Overall Loss 0.333409    Objective Loss 0.333409                                        LR 0.000250    Time 0.052657    
2024-06-06 02:25:29,416 - Epoch: [156][  400/ 1218]    Overall Loss 0.330595    Objective Loss 0.330595                                        LR 0.000250    Time 0.051164    
2024-06-06 02:25:34,064 - Epoch: [156][  500/ 1218]    Overall Loss 0.329547    Objective Loss 0.329547                                        LR 0.000250    Time 0.050224    
2024-06-06 02:25:38,853 - Epoch: [156][  600/ 1218]    Overall Loss 0.331443    Objective Loss 0.331443                                        LR 0.000250    Time 0.049832    
2024-06-06 02:25:43,603 - Epoch: [156][  700/ 1218]    Overall Loss 0.331340    Objective Loss 0.331340                                        LR 0.000250    Time 0.049495    
2024-06-06 02:25:48,361 - Epoch: [156][  800/ 1218]    Overall Loss 0.332190    Objective Loss 0.332190                                        LR 0.000250    Time 0.049254    
2024-06-06 02:25:53,011 - Epoch: [156][  900/ 1218]    Overall Loss 0.332851    Objective Loss 0.332851                                        LR 0.000250    Time 0.048945    
2024-06-06 02:25:57,775 - Epoch: [156][ 1000/ 1218]    Overall Loss 0.331973    Objective Loss 0.331973                                        LR 0.000250    Time 0.048813    
2024-06-06 02:26:02,445 - Epoch: [156][ 1100/ 1218]    Overall Loss 0.332928    Objective Loss 0.332928                                        LR 0.000250    Time 0.048619    
2024-06-06 02:26:07,081 - Epoch: [156][ 1200/ 1218]    Overall Loss 0.332413    Objective Loss 0.332413                                        LR 0.000250    Time 0.048429    
2024-06-06 02:26:07,878 - Epoch: [156][ 1218/ 1218]    Overall Loss 0.332227    Objective Loss 0.332227    Top1 82.151589    Top5 96.821516    LR 0.000250    Time 0.048367    
2024-06-06 02:26:08,038 - --- validate (epoch=156)-----------
2024-06-06 02:26:08,039 - 34633 samples (256 per mini-batch)
2024-06-06 02:26:13,681 - Epoch: [156][  100/  136]    Loss 0.363938    Top1 84.480469    Top5 97.695312    
2024-06-06 02:26:15,337 - Epoch: [156][  136/  136]    Loss 0.366321    Top1 84.387723    Top5 97.724713    
2024-06-06 02:26:15,517 - ==> Top1: 84.388    Top5: 97.725    Loss: 0.366

2024-06-06 02:26:15,518 - ==> Confusion:
[[  833     2     6     3    17     0     0     2     4    36     0     3     2     1     5     2     3     1     2     0     9]
 [    1   992     0     1    13     8     2     8     0     1     0     1     2     1     6     2     5     0    11     3     6]
 [    3     1   894     4     2     0    12     8     0     2     6     3     2     1     1     3     6     2     6     1    13]
 [    6     2    17   919     3     7     3     2     1     1    15     0     8     0    11     0     1     3     9     0     8]
 [    7    16     2     3   978     6     0     1     0     5     1     2     1     1    11     0    11     1     1     0     7]
 [    3    33     2     4    12   896     5    20     1     0     1    24     7    12     3     1     5     2     2     2     8]
 [    4     5    31     3     4     8   998     5     0     1     3     3     1     0     2     8     2     1     1     1     5]
 [    0    22    15     1     4    38     3   927     1     3     0    10     1     3     1     1     2     1    28     5    11]
 [   13     8     2     0     3     2     0     3   846    33    18     2     4    15    22     1     4     3    10     1    12]
 [   93     2     8     1    15     3     0     2    38   775     0     2     1    35     8     1     3     3     2     0     9]
 [    1     9    12     9     2     2     2     6     8     0   959     2     2     7     6     0     2     1    17     3    14]
 [    3     2     2     1     2     8     2     4     1     1     0   921    23     5     0     6     7     9     2     3     9]
 [    4     2     3     5     0     2     0     2     0     0     0    72   851     0     0     5     4    26     6     2    11]
 [    2     3     0     4     6     9     1     3     9     6     7    20     6   877     9     1    12     5     1     2    18]
 [    2     8     1    19    14     0     0     0    22     4     6     3     4     2   974     0     4     5    20     1     9]
 [    2     1     4     0     5     0     3     1     0     1     0    14    12     1     0   992    10     9     1     2     8]
 [    2    17     8     3     7     7     2     3     1     2     0     5     1     1     1    10   978     0     2     5    17]
 [    3     5     3     3     2     1     0     0     0     0     0    15    30     1     1    12     2   917     7     0     3]
 [    3    14    10     6     2     2     0    11     3     0     2     1     5     1     8     0     0     1   978     1    10]
 [    3     6     9     1     3    14    11    15     0     0     0    19    11     1     0     7    11     3     7   951    16]
 [  162   320   238    76   228   175    68   167    61    42   137   156   268   160   157   114   252    96   159   126 10770]]

2024-06-06 02:26:15,521 - ==> Best [Top1: 84.425   Top5: 97.601   Sparsity:0.00   Params: 424448 on epoch: 155]
2024-06-06 02:26:15,521 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:26:15,543 - 

2024-06-06 02:26:15,543 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:26:21,927 - Epoch: [157][  100/ 1218]    Overall Loss 0.327467    Objective Loss 0.327467                                        LR 0.000250    Time 0.063818    
2024-06-06 02:26:26,637 - Epoch: [157][  200/ 1218]    Overall Loss 0.324505    Objective Loss 0.324505                                        LR 0.000250    Time 0.055447    
2024-06-06 02:26:31,358 - Epoch: [157][  300/ 1218]    Overall Loss 0.326544    Objective Loss 0.326544                                        LR 0.000250    Time 0.052694    
2024-06-06 02:26:35,930 - Epoch: [157][  400/ 1218]    Overall Loss 0.326711    Objective Loss 0.326711                                        LR 0.000250    Time 0.050946    
2024-06-06 02:26:40,490 - Epoch: [157][  500/ 1218]    Overall Loss 0.327571    Objective Loss 0.327571                                        LR 0.000250    Time 0.049874    
2024-06-06 02:26:45,057 - Epoch: [157][  600/ 1218]    Overall Loss 0.328158    Objective Loss 0.328158                                        LR 0.000250    Time 0.049170    
2024-06-06 02:26:49,681 - Epoch: [157][  700/ 1218]    Overall Loss 0.329115    Objective Loss 0.329115                                        LR 0.000250    Time 0.048749    
2024-06-06 02:26:54,449 - Epoch: [157][  800/ 1218]    Overall Loss 0.328466    Objective Loss 0.328466                                        LR 0.000250    Time 0.048614    
2024-06-06 02:26:59,248 - Epoch: [157][  900/ 1218]    Overall Loss 0.329918    Objective Loss 0.329918                                        LR 0.000250    Time 0.048541    
2024-06-06 02:27:03,917 - Epoch: [157][ 1000/ 1218]    Overall Loss 0.329052    Objective Loss 0.329052                                        LR 0.000250    Time 0.048354    
2024-06-06 02:27:08,527 - Epoch: [157][ 1100/ 1218]    Overall Loss 0.329367    Objective Loss 0.329367                                        LR 0.000250    Time 0.048147    
2024-06-06 02:27:13,102 - Epoch: [157][ 1200/ 1218]    Overall Loss 0.328803    Objective Loss 0.328803                                        LR 0.000250    Time 0.047946    
2024-06-06 02:27:13,912 - Epoch: [157][ 1218/ 1218]    Overall Loss 0.328674    Objective Loss 0.328674    Top1 85.330073    Top5 97.799511    LR 0.000250    Time 0.047902    
2024-06-06 02:27:14,094 - --- validate (epoch=157)-----------
2024-06-06 02:27:14,095 - 34633 samples (256 per mini-batch)
2024-06-06 02:27:19,563 - Epoch: [157][  100/  136]    Loss 0.355838    Top1 84.371094    Top5 97.421875    
2024-06-06 02:27:21,252 - Epoch: [157][  136/  136]    Loss 0.358755    Top1 84.165391    Top5 97.444634    
2024-06-06 02:27:21,423 - ==> Top1: 84.165    Top5: 97.445    Loss: 0.359

2024-06-06 02:27:21,424 - ==> Confusion:
[[  777     3     1     2     4     2     1     1     9    96     1     1     2     0    10     1     1     0     5     0    14]
 [    2   962     2     1     7    38     4    10     2     3     4     2     3     3     4     2     2     1     6     2     3]
 [    7     2   885     7     2     3    25    11     0     5     2     1     2     2     2     1     1     0     6     0     6]
 [    7     3    12   915     0     8     6     1     3     1    12     2     8     2    18     1     2     4     7     1     3]
 [   13    16     4     0   941    19     1     1     1    13     5     2     1     5     8     2     2     1     2     0    17]
 [    2    13     5     2     4   941     2    14     2     4     3    12     7    16     0     2     1     2     3     1     7]
 [    1     4    12     2     3     8  1028     4     0     3     1     4     0     1     1     2     2     2     0     4     4]
 [    3    14    14     0     0    39     5   946     2     4     4    11     3     4     2     1     0     1     8    10     6]
 [    8     4     0     0     1     6     1     2   849    59    16     2     4    15    22     1     1     4     1     1     5]
 [   30     1     3     0     4     2     1     1    31   889     1     3     2    18     5     2     1     2     0     0     5]
 [    0     3     8     8     0     4     3     5    13     1   982     1     2     7     8     1     1     0    11     0     6]
 [    2     1     2     0     1    14     7     8     1     2     0   896    21     8     1    14     4    10     1    11     7]
 [    2     4     5     3     1     5     1     4     3     0     1    68   851     2     4     2     1    22     1     3    12]
 [    3     0     5     0     2    16     0     4    11    23     8     8     5   893     6     2     1     3     1     3     7]
 [    2     5     2     9     5     1     1     1    21    11     7     5     1     7  1003     0     0     4     5     0     8]
 [    4     1     7     0     2     1     5     1     0     2     0    21     9     1     1   991     2    11     1     1     5]
 [    5    16     9     0     7     9     1     3     6     0     6     8     3     1     2     9   969     3     2     4     9]
 [    1     2     0     4     0     4     4     3     1     2     0    23    21     3     1    16     1   908     2     1     8]
 [    2    15     4    13     1     2     2    33     4     0     5     2     3     2    18     0     0     0   939     0    13]
 [    3     5     6     1     1    13    17    10     2     2     1    23     6     2     0     4     7     2     4   971     8]
 [  154   236   249    85   136   211   131   172    98   135   171   139   301   233   214   120   155    76   128   175 10613]]

2024-06-06 02:27:21,426 - ==> Best [Top1: 84.425   Top5: 97.601   Sparsity:0.00   Params: 424448 on epoch: 155]
2024-06-06 02:27:21,426 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:27:21,445 - 

2024-06-06 02:27:21,445 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:27:27,695 - Epoch: [158][  100/ 1218]    Overall Loss 0.321517    Objective Loss 0.321517                                        LR 0.000250    Time 0.062476    
2024-06-06 02:27:32,516 - Epoch: [158][  200/ 1218]    Overall Loss 0.323318    Objective Loss 0.323318                                        LR 0.000250    Time 0.055335    
2024-06-06 02:27:37,232 - Epoch: [158][  300/ 1218]    Overall Loss 0.325126    Objective Loss 0.325126                                        LR 0.000250    Time 0.052600    
2024-06-06 02:27:41,885 - Epoch: [158][  400/ 1218]    Overall Loss 0.326398    Objective Loss 0.326398                                        LR 0.000250    Time 0.051078    
2024-06-06 02:27:46,547 - Epoch: [158][  500/ 1218]    Overall Loss 0.328213    Objective Loss 0.328213                                        LR 0.000250    Time 0.050184    
2024-06-06 02:27:51,283 - Epoch: [158][  600/ 1218]    Overall Loss 0.329610    Objective Loss 0.329610                                        LR 0.000250    Time 0.049709    
2024-06-06 02:27:55,830 - Epoch: [158][  700/ 1218]    Overall Loss 0.329842    Objective Loss 0.329842                                        LR 0.000250    Time 0.049101    
2024-06-06 02:28:00,535 - Epoch: [158][  800/ 1218]    Overall Loss 0.331658    Objective Loss 0.331658                                        LR 0.000250    Time 0.048842    
2024-06-06 02:28:05,140 - Epoch: [158][  900/ 1218]    Overall Loss 0.330779    Objective Loss 0.330779                                        LR 0.000250    Time 0.048530    
2024-06-06 02:28:09,731 - Epoch: [158][ 1000/ 1218]    Overall Loss 0.331059    Objective Loss 0.331059                                        LR 0.000250    Time 0.048266    
2024-06-06 02:28:14,299 - Epoch: [158][ 1100/ 1218]    Overall Loss 0.330309    Objective Loss 0.330309                                        LR 0.000250    Time 0.048029    
2024-06-06 02:28:18,875 - Epoch: [158][ 1200/ 1218]    Overall Loss 0.331551    Objective Loss 0.331551                                        LR 0.000250    Time 0.047839    
2024-06-06 02:28:19,696 - Epoch: [158][ 1218/ 1218]    Overall Loss 0.331891    Objective Loss 0.331891    Top1 84.841076    Top5 96.577017    LR 0.000250    Time 0.047805    
2024-06-06 02:28:19,870 - --- validate (epoch=158)-----------
2024-06-06 02:28:19,870 - 34633 samples (256 per mini-batch)
2024-06-06 02:28:25,461 - Epoch: [158][  100/  136]    Loss 0.378230    Top1 85.078125    Top5 97.746094    
2024-06-06 02:28:27,136 - Epoch: [158][  136/  136]    Loss 0.377882    Top1 85.043167    Top5 97.707389    
2024-06-06 02:28:27,306 - ==> Top1: 85.043    Top5: 97.707    Loss: 0.378

2024-06-06 02:28:27,307 - ==> Confusion:
[[  839     1     0     0    17     2     1     0     4    33     0     5     1     3     3     6     1     3     0     0    12]
 [    2   978     1     2    19    18     5     4     1     0     1     3     2     0     0     1     4     2     7     3    10]
 [    4     2   822    11    11     3    49    10     0     2     0     6     4     0     1    13     4     3     2     4    19]
 [    4     6    10   879     5     9     8     3     0     0     8     5     9     5    22     5     3     8     7     2    18]
 [   10     8     0     1   973    11     3     0     2     5     0     2     3     1     3     4     8     2     2     1    15]
 [    5    26     0     4     8   899     5    14     4     1     1    17     8     7     2     0     5     9     2    12    14]
 [    1     3     3     0     3     5  1023     2     0     0     0     8     0     0     0    10     6     5     1     9     7]
 [    0    16     9     2     4    39     6   899     2     2     2    16    10     2     1     2     0     2    28    26     9]
 [   14     4     0     2     0     1     1     1   848    42    12     9     6    14    18     0     4     6    10     0    10]
 [   92     4     4     0    10     1     1     1    36   800     1    11     0     9     6     1     1     8     1     0    14]
 [    1     6     5    10     3     9    14     4    14     0   940     1     1    11    13     2     5     0    10     3    12]
 [    2     3     1     0     2     7     2     1     0     1     1   892    28     2     0    16     1    22     0    17    13]
 [    2     4     4     1     0     4     0     0     2     0     1    59   821     1     3    11     2    56     3    10    11]
 [    2     1     1     0     4    15     2     2     9    19     2    19     8   874     2     4     9     5     0    13    10]
 [    7     7     1     6    21     4     1     1    19    13     3     6     4     8   966     0     0     6     5     2    18]
 [    3     0     1     0     2     1    11     1     0     0     0    14     4     0     0  1001     6    11     0     2     9]
 [    5    14     0     0     8     3     5     0     1     0     0     7     1     0     1    13   987     4     1     4    18]
 [    2     3     0     0     1     2     1     0     0     1     0    21    17     1     1    18     1   927     0     3     6]
 [    1    23     5     6     3     2     2    19     5     2     2     5     4     0    11     0     2     2   952     1    11]
 [    3     4     1     0     1     8     7     4     0     0     0    25     3     1     0     9     3     2     1  1000    16]
 [  146   232    72    58   161   195   133   104    48    72    71   186   214   188   109   133   133   142   122   280 11133]]

2024-06-06 02:28:27,309 - ==> Best [Top1: 85.043   Top5: 97.707   Sparsity:0.00   Params: 424448 on epoch: 158]
2024-06-06 02:28:27,309 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:28:27,336 - 

2024-06-06 02:28:27,337 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:28:33,544 - Epoch: [159][  100/ 1218]    Overall Loss 0.324152    Objective Loss 0.324152                                        LR 0.000250    Time 0.062049    
2024-06-06 02:28:38,383 - Epoch: [159][  200/ 1218]    Overall Loss 0.322415    Objective Loss 0.322415                                        LR 0.000250    Time 0.055201    
2024-06-06 02:28:43,101 - Epoch: [159][  300/ 1218]    Overall Loss 0.329129    Objective Loss 0.329129                                        LR 0.000250    Time 0.052521    
2024-06-06 02:28:47,910 - Epoch: [159][  400/ 1218]    Overall Loss 0.329200    Objective Loss 0.329200                                        LR 0.000250    Time 0.051407    
2024-06-06 02:28:52,673 - Epoch: [159][  500/ 1218]    Overall Loss 0.329648    Objective Loss 0.329648                                        LR 0.000250    Time 0.050648    
2024-06-06 02:28:57,327 - Epoch: [159][  600/ 1218]    Overall Loss 0.328926    Objective Loss 0.328926                                        LR 0.000250    Time 0.049959    
2024-06-06 02:29:02,019 - Epoch: [159][  700/ 1218]    Overall Loss 0.328617    Objective Loss 0.328617                                        LR 0.000250    Time 0.049523    
2024-06-06 02:29:06,829 - Epoch: [159][  800/ 1218]    Overall Loss 0.329490    Objective Loss 0.329490                                        LR 0.000250    Time 0.049343    
2024-06-06 02:29:11,719 - Epoch: [159][  900/ 1218]    Overall Loss 0.328849    Objective Loss 0.328849                                        LR 0.000250    Time 0.049291    
2024-06-06 02:29:16,568 - Epoch: [159][ 1000/ 1218]    Overall Loss 0.329416    Objective Loss 0.329416                                        LR 0.000250    Time 0.049209    
2024-06-06 02:29:21,092 - Epoch: [159][ 1100/ 1218]    Overall Loss 0.329700    Objective Loss 0.329700                                        LR 0.000250    Time 0.048847    
2024-06-06 02:29:25,795 - Epoch: [159][ 1200/ 1218]    Overall Loss 0.330048    Objective Loss 0.330048                                        LR 0.000250    Time 0.048694    
2024-06-06 02:29:26,610 - Epoch: [159][ 1218/ 1218]    Overall Loss 0.330160    Objective Loss 0.330160    Top1 84.596577    Top5 98.533007    LR 0.000250    Time 0.048643    
2024-06-06 02:29:26,773 - --- validate (epoch=159)-----------
2024-06-06 02:29:26,773 - 34633 samples (256 per mini-batch)
2024-06-06 02:29:32,495 - Epoch: [159][  100/  136]    Loss 0.379890    Top1 83.957031    Top5 97.457031    
2024-06-06 02:29:34,158 - Epoch: [159][  136/  136]    Loss 0.376546    Top1 84.003696    Top5 97.499495    
2024-06-06 02:29:34,379 - ==> Top1: 84.004    Top5: 97.499    Loss: 0.377

2024-06-06 02:29:34,380 - ==> Confusion:
[[  792     2     5     0     8     3     0     1    11    68     1     2     4     6     5     3     1     0     2     1    16]
 [    1   973     1     1    17    14     1     4     3     2     2     3     5     2     4     2     9     1    12     2     4]
 [    3     5   879     8     4     3     6     7     2     4     4     1     6     6     2     9     4     0     2     4    11]
 [    2     3    12   901     2     6     2     1     1     1    11     2    12     4    35     2     1     2     7     1     8]
 [   14    16     2     0   953    12     1     1     2    12     0     1     2     4    12     8     6     0     0     0     8]
 [    1    35     1     4     4   864     2    21     2     4     2    19    17    22     3     2     9     2     5    10    14]
 [    0    10    29     1     1     8   948    10     0     1     2     7     4     3     1    22     9     3     3    19     5]
 [    2    17    13     1     3    32     0   915     1     3     2    15    13     0     1     2     1     1    36    10     9]
 [    4     5     2     0     2     3     0     0   869    38     5     2     9    18    20     1     4     2     8     0    10]
 [   47     2     5     0     5     1     0     1    49   838     2     1     3    29     7     4     0     0     0     0     7]
 [    1     3     9     6     2     1     2     5    17     6   947     4     5    18    10     0     4     0    15     2     7]
 [    1     3     1     0     1     5     1     3     3     2     0   911    26    13     0    15     5     8     0     8     5]
 [    1     5     1     5     0     1     0     4     2     0     0    67   856     3     3    12     4    10     2     9    10]
 [    1     1     1     0     2     5     0     1     9     9     1    12     9   918     4     4     8     0     1     6     9]
 [    7     3     1    11     9     0     0     0    20    12     3     0     5     5   998     0     6     3     5     1     9]
 [    2     5     5     0     3     1     0     0     0     1     0    20    14     3     0   995     6     5     0     1     5]
 [    0     7     2     0     7     3     0     0     6     0     1     6     5     2     3     8  1004     0     2     3    13]
 [    0     7     1     3     1     0     0     1     0     3     1    23    41     3     1    16     4   889     1     3     7]
 [    1     7     3    10     2     1     1    14     4     1     7     2     7     1    17     2     1     0   965     4     8]
 [    0     6     0     0     1     7     0     8     0     0     0    24     8     6     0    11     7     2     5   996     7]
 [  127   203   140    71   200   126    46   120    90   105   129   199   350   273   203   150   261    50   159   248 10682]]

2024-06-06 02:29:34,382 - ==> Best [Top1: 85.043   Top5: 97.707   Sparsity:0.00   Params: 424448 on epoch: 158]
2024-06-06 02:29:34,382 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:29:34,405 - 

2024-06-06 02:29:34,405 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:29:40,635 - Epoch: [160][  100/ 1218]    Overall Loss 0.321648    Objective Loss 0.321648                                        LR 0.000250    Time 0.062267    
2024-06-06 02:29:45,283 - Epoch: [160][  200/ 1218]    Overall Loss 0.325829    Objective Loss 0.325829                                        LR 0.000250    Time 0.054366    
2024-06-06 02:29:49,895 - Epoch: [160][  300/ 1218]    Overall Loss 0.326296    Objective Loss 0.326296                                        LR 0.000250    Time 0.051611    
2024-06-06 02:29:54,658 - Epoch: [160][  400/ 1218]    Overall Loss 0.325337    Objective Loss 0.325337                                        LR 0.000250    Time 0.050611    
2024-06-06 02:29:59,558 - Epoch: [160][  500/ 1218]    Overall Loss 0.326686    Objective Loss 0.326686                                        LR 0.000250    Time 0.050285    
2024-06-06 02:30:04,109 - Epoch: [160][  600/ 1218]    Overall Loss 0.326505    Objective Loss 0.326505                                        LR 0.000250    Time 0.049486    
2024-06-06 02:30:08,769 - Epoch: [160][  700/ 1218]    Overall Loss 0.328903    Objective Loss 0.328903                                        LR 0.000250    Time 0.049071    
2024-06-06 02:30:13,452 - Epoch: [160][  800/ 1218]    Overall Loss 0.327677    Objective Loss 0.327677                                        LR 0.000250    Time 0.048788    
2024-06-06 02:30:18,266 - Epoch: [160][  900/ 1218]    Overall Loss 0.328420    Objective Loss 0.328420                                        LR 0.000250    Time 0.048715    
2024-06-06 02:30:22,963 - Epoch: [160][ 1000/ 1218]    Overall Loss 0.327965    Objective Loss 0.327965                                        LR 0.000250    Time 0.048538    
2024-06-06 02:30:27,777 - Epoch: [160][ 1100/ 1218]    Overall Loss 0.327454    Objective Loss 0.327454                                        LR 0.000250    Time 0.048501    
2024-06-06 02:30:32,524 - Epoch: [160][ 1200/ 1218]    Overall Loss 0.327862    Objective Loss 0.327862                                        LR 0.000250    Time 0.048413    
2024-06-06 02:30:33,338 - Epoch: [160][ 1218/ 1218]    Overall Loss 0.327847    Objective Loss 0.327847    Top1 81.418093    Top5 98.288509    LR 0.000250    Time 0.048365    
2024-06-06 02:30:33,549 - --- validate (epoch=160)-----------
2024-06-06 02:30:33,549 - 34633 samples (256 per mini-batch)
2024-06-06 02:30:38,994 - Epoch: [160][  100/  136]    Loss 0.356810    Top1 84.632812    Top5 97.789062    
2024-06-06 02:30:40,688 - Epoch: [160][  136/  136]    Loss 0.361654    Top1 84.725551    Top5 97.759362    
2024-06-06 02:30:40,898 - ==> Top1: 84.726    Top5: 97.759    Loss: 0.362

2024-06-06 02:30:40,899 - ==> Confusion:
[[  860     1     2     0     7     0     1     1     5    22     1     2     2     1     3     2     1     2     0     4    14]
 [    1   924     1     2    25    34     5    14     2     1     5     3     2     1     8     2    11     0     7     5    10]
 [   10     3   876     6     4     0    17     2     0     8    11     1     7     2     1     2     5     0     1     6     8]
 [    4     0    14   916     2     4     4     1     4     3    19     1    10     1    11     2     3     4     2     1    10]
 [   26     6     0     1   952    13     1     1     3     6     1     1     3     3     8     1     8     1     5     1    13]
 [    5    15     6     8     2   902     3    17     6     3     4    12     9    14     1     0     6     3     0    14    13]
 [    5     1    14     1     2     4  1021     6     1     2     2     1     3     0     0     1     4     2     1     7     8]
 [    1    12    18     2     1    35     4   925     1     0     6     3     5     1     0     1     3     2    22    19    16]
 [   17     1     2     0     1     2     0     1   873    37    15     3     5    15    11     1     2     1     6     1     8]
 [  121     2     2     0    11     4     1     1    37   792     1     0     2    10     6     2     0     2     1     0     6]
 [    1     3     9    10     3     4     6     6    10     0   985     0     0     7     4     0     1     0     5     5     5]
 [    2     3     5     0     2    14     2     2     3     2     3   855    29     3     0    16     2    19     0    42     7]
 [    1     1     5     1     3     2     3     3     1     0     3    53   841     2     0    10     4    43     1     9     9]
 [    1     1     1     1     3     8     1     1    17    16    10    15     7   882     1     2     4     1     2    17    10]
 [   11     3     5    20     7     0     0     0    22     5     9     1     4     4   971     1     1     7    11     4    12]
 [    4     1     2     0     7     1     8     1     0     1     0    14     8     1     0   982    11    13     0     4     8]
 [    6     8     1     2     7     7     0     1     3     1     3     7     2     0     0     8   986     1     1     7    21]
 [    2     1     3     1     1     1     0     3     1     1     0    17    14     1     1     7     0   939     3     4     5]
 [    7     4     9    17     3     3     2    27    10     0     9     2     5     2    10     2     1     0   934     4     7]
 [    4     3     3     0     0     3     7     2     1     2     2     5     6     1     1     5     5     4     2  1026     6]
 [  190   141   170   103   182   141    95   144    92    61   183   122   295   174   125    85   201    96   102   329 10901]]

2024-06-06 02:30:40,901 - ==> Best [Top1: 85.043   Top5: 97.707   Sparsity:0.00   Params: 424448 on epoch: 158]
2024-06-06 02:30:40,901 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:30:40,924 - 

2024-06-06 02:30:40,924 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:30:47,059 - Epoch: [161][  100/ 1218]    Overall Loss 0.324721    Objective Loss 0.324721                                        LR 0.000250    Time 0.061319    
2024-06-06 02:30:51,873 - Epoch: [161][  200/ 1218]    Overall Loss 0.329817    Objective Loss 0.329817                                        LR 0.000250    Time 0.054720    
2024-06-06 02:30:56,501 - Epoch: [161][  300/ 1218]    Overall Loss 0.331244    Objective Loss 0.331244                                        LR 0.000250    Time 0.051901    
2024-06-06 02:31:01,095 - Epoch: [161][  400/ 1218]    Overall Loss 0.329779    Objective Loss 0.329779                                        LR 0.000250    Time 0.050407    
2024-06-06 02:31:05,695 - Epoch: [161][  500/ 1218]    Overall Loss 0.329357    Objective Loss 0.329357                                        LR 0.000250    Time 0.049521    
2024-06-06 02:31:10,296 - Epoch: [161][  600/ 1218]    Overall Loss 0.328837    Objective Loss 0.328837                                        LR 0.000250    Time 0.048933    
2024-06-06 02:31:14,920 - Epoch: [161][  700/ 1218]    Overall Loss 0.330396    Objective Loss 0.330396                                        LR 0.000250    Time 0.048546    
2024-06-06 02:31:19,720 - Epoch: [161][  800/ 1218]    Overall Loss 0.330137    Objective Loss 0.330137                                        LR 0.000250    Time 0.048476    
2024-06-06 02:31:24,264 - Epoch: [161][  900/ 1218]    Overall Loss 0.329937    Objective Loss 0.329937                                        LR 0.000250    Time 0.048136    
2024-06-06 02:31:28,827 - Epoch: [161][ 1000/ 1218]    Overall Loss 0.330600    Objective Loss 0.330600                                        LR 0.000250    Time 0.047885    
2024-06-06 02:31:33,487 - Epoch: [161][ 1100/ 1218]    Overall Loss 0.331386    Objective Loss 0.331386                                        LR 0.000250    Time 0.047766    
2024-06-06 02:31:38,099 - Epoch: [161][ 1200/ 1218]    Overall Loss 0.331712    Objective Loss 0.331712                                        LR 0.000250    Time 0.047627    
2024-06-06 02:31:38,975 - Epoch: [161][ 1218/ 1218]    Overall Loss 0.332359    Objective Loss 0.332359    Top1 80.440098    Top5 97.066015    LR 0.000250    Time 0.047642    
2024-06-06 02:31:39,148 - --- validate (epoch=161)-----------
2024-06-06 02:31:39,148 - 34633 samples (256 per mini-batch)
2024-06-06 02:31:44,793 - Epoch: [161][  100/  136]    Loss 0.395845    Top1 83.750000    Top5 97.496094    
2024-06-06 02:31:46,454 - Epoch: [161][  136/  136]    Loss 0.395917    Top1 83.752490    Top5 97.493720    
2024-06-06 02:31:46,629 - ==> Top1: 83.752    Top5: 97.494    Loss: 0.396

2024-06-06 02:31:46,630 - ==> Confusion:
[[  820     2     9     0    11     3     0     0     9    50     0     0     4     2     5     0     1     0     4     0    11]
 [    1   962     3     1    16    21     6     4     3     2     6     3     3     3     2     0     3     5    11     3     5]
 [    1     3   867    11     2     0    30     4     2     4    12     0     3     4     3     3     0     0     4     3    14]
 [    8     1     8   903     0     1     4     1     1     1    18     1     8     2    23     2     2     5    17     0    10]
 [   18    11     4     1   953    11     1     0     3    11     4     6     1     0    10     2     3     2     2     0    11]
 [    9    27     8     6     9   864     7    20     2     3    10     8    13    13     2     3     4     4     5     9    17]
 [    0     8    19     3     0     0  1013     3     0     2     2     0     8     1     1     6     2     1     2     9     6]
 [    3    15    17     4     2    47     8   881     0     2    19     6     8     2     2     2     1     2    35    14     7]
 [    9    10     1     1     0     2     1     2   845    30    24     2     4    13    29     2     2     6    10     1     8]
 [   64     4     4     0     5     5     0     0    45   822     3     0     2    15    21     1     0     1     1     0     8]
 [    1     6     4     7     1     1     6     0     6     0  1003     1     2     6    11     0     0     0     5     0     4]
 [    6     4     1     0     2    20     3     1     2     2     2   774    99     5     2    15     5    40     3    13    12]
 [    0     1     1     5     3     0     2     1     1     2     1    21   906     2     4     3     1    24     6     2     9]
 [    2     4     2     0     4    15     3     0     8    11    31    11     8   878     4     2     3     2     1     5     7]
 [    6     0     3    11     8     1     0     0    14     7     9     0     4     4  1000     1     2     2    15     0    11]
 [    4     0     9     1     3     2    15     0     1     4     0     8    17     1     1   961     1    26     2     0    10]
 [    8    12     5     6     6     3     1     0     3     2     4     4     5     2     1     9   966    10     2     1    22]
 [    3     2     0     1     3     2     0     2     0     4     1     5    37     1     1    11     0   926     1     1     4]
 [    1     6     7     5     1     1     0     9     3     1     9     0     3     1    13     0     1     2   988     0     7]
 [    3    13     4     0     2    10    22     6     0     2     2    28    14     5     2     7     4     4     3   931    26]
 [  169   261   156   103   162   144   123   109    74    85   208   105   379   217   201   109   148   148   163   125 10743]]

2024-06-06 02:31:46,632 - ==> Best [Top1: 85.043   Top5: 97.707   Sparsity:0.00   Params: 424448 on epoch: 158]
2024-06-06 02:31:46,632 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:31:46,649 - 

2024-06-06 02:31:46,649 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:31:52,931 - Epoch: [162][  100/ 1218]    Overall Loss 0.323493    Objective Loss 0.323493                                        LR 0.000250    Time 0.062799    
2024-06-06 02:31:57,602 - Epoch: [162][  200/ 1218]    Overall Loss 0.325416    Objective Loss 0.325416                                        LR 0.000250    Time 0.054741    
2024-06-06 02:32:02,244 - Epoch: [162][  300/ 1218]    Overall Loss 0.326864    Objective Loss 0.326864                                        LR 0.000250    Time 0.051961    
2024-06-06 02:32:07,016 - Epoch: [162][  400/ 1218]    Overall Loss 0.328315    Objective Loss 0.328315                                        LR 0.000250    Time 0.050896    
2024-06-06 02:32:11,667 - Epoch: [162][  500/ 1218]    Overall Loss 0.329036    Objective Loss 0.329036                                        LR 0.000250    Time 0.050016    
2024-06-06 02:32:16,263 - Epoch: [162][  600/ 1218]    Overall Loss 0.328069    Objective Loss 0.328069                                        LR 0.000250    Time 0.049336    
2024-06-06 02:32:20,816 - Epoch: [162][  700/ 1218]    Overall Loss 0.328911    Objective Loss 0.328911                                        LR 0.000250    Time 0.048789    
2024-06-06 02:32:25,461 - Epoch: [162][  800/ 1218]    Overall Loss 0.328438    Objective Loss 0.328438                                        LR 0.000250    Time 0.048495    
2024-06-06 02:32:30,235 - Epoch: [162][  900/ 1218]    Overall Loss 0.329245    Objective Loss 0.329245                                        LR 0.000250    Time 0.048408    
2024-06-06 02:32:34,963 - Epoch: [162][ 1000/ 1218]    Overall Loss 0.329379    Objective Loss 0.329379                                        LR 0.000250    Time 0.048294    
2024-06-06 02:32:39,670 - Epoch: [162][ 1100/ 1218]    Overall Loss 0.330096    Objective Loss 0.330096                                        LR 0.000250    Time 0.048181    
2024-06-06 02:32:44,322 - Epoch: [162][ 1200/ 1218]    Overall Loss 0.329571    Objective Loss 0.329571                                        LR 0.000250    Time 0.048041    
2024-06-06 02:32:45,158 - Epoch: [162][ 1218/ 1218]    Overall Loss 0.329191    Objective Loss 0.329191    Top1 84.352078    Top5 98.288509    LR 0.000250    Time 0.048017    
2024-06-06 02:32:45,316 - --- validate (epoch=162)-----------
2024-06-06 02:32:45,316 - 34633 samples (256 per mini-batch)
2024-06-06 02:32:50,969 - Epoch: [162][  100/  136]    Loss 0.338371    Top1 83.386719    Top5 97.445312    
2024-06-06 02:32:52,647 - Epoch: [162][  136/  136]    Loss 0.342180    Top1 83.333815    Top5 97.395548    
2024-06-06 02:32:52,829 - ==> Top1: 83.334    Top5: 97.396    Loss: 0.342

2024-06-06 02:32:52,830 - ==> Confusion:
[[  821     3     3     1     5     3     0     6     7    52     0     1     3     5     4     0     1     5     2     1     8]
 [    4   952     1     2    15    14     4    17     4     0     5     3     4     0     8     1     2     0    17     4     6]
 [    5     2   890     8     1     0    13    11     0     6     8     3     3     4     0     3     1     0     6     2     4]
 [    0     1     8   929     2     5     3     0     3     1    14     2     6     6    14     2     0     4     9     1     6]
 [   13     7     6     0   961     9     0     3     0     9     1     3     1     7    11     5     5     2     7     0     4]
 [    2    21     5     6     5   886     1    47     0     1     6     3    12    19     2     0     4     3     6     6     8]
 [    0     4    18     1     1     3  1010    10     1     2     6     3     4     0     0     3     1     3     4     9     3]
 [    3     9    10     2     1    18     1   972     2     1     2     7     3     3     0     0     0     1    21    11    10]
 [   12     0     1     0     1     0     0     0   892    23    14     2     7    18    18     0     2     2     9     0     1]
 [   60     1     3     1     4     0     0     3    54   837     2     5     3    14     6     1     1     1     1     0     4]
 [    0     1    10     8     1     0     4     3    13     1   976     2     3    13    10     0     0     2     9     2     6]
 [    0     0     2     1     3    10     3    10     2     0     1   876    37     9     0     5     3    25     4    14     6]
 [    0     3     2    10     3     3     0     1     1     0     2    53   846     5     1     5     4    39     4     4     9]
 [    1     0     0     0     2     8     0     0    14    13     6     9     4   923     1     0     3     7     3     3     4]
 [    8     1     3    21     5     1     0     0    25     4     7     2     4     8   982     0     2     2    19     0     4]
 [    1     1     3     2     2     3     3     0     0     2     1    17     9     3     0   987     9    15     1     3     4]
 [    3     6     1     1     6     5     0     2     4     1     4     6     5     4     1    12   989     4     5     4     9]
 [    2     1     1     1     2     2     1     5     2     1     0     6    15     2     1     6     2   947     0     2     6]
 [    2     5     8    11     2     2     1    26     4     0     8     4     5     1    11     0     0     1   962     0     5]
 [    2     6     2     0     0     8     3    18     1     0     0    12     7    12     0     2     5     4     3   993    10]
 [  149   195   207   165   141   163    86   211   108   101   181   176   308   302   203   122   229   136   236   282 10231]]

2024-06-06 02:32:52,832 - ==> Best [Top1: 85.043   Top5: 97.707   Sparsity:0.00   Params: 424448 on epoch: 158]
2024-06-06 02:32:52,832 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:32:52,856 - 

2024-06-06 02:32:52,856 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:32:59,182 - Epoch: [163][  100/ 1218]    Overall Loss 0.322978    Objective Loss 0.322978                                        LR 0.000250    Time 0.063229    
2024-06-06 02:33:03,902 - Epoch: [163][  200/ 1218]    Overall Loss 0.322524    Objective Loss 0.322524                                        LR 0.000250    Time 0.055207    
2024-06-06 02:33:08,814 - Epoch: [163][  300/ 1218]    Overall Loss 0.324549    Objective Loss 0.324549                                        LR 0.000250    Time 0.053171    
2024-06-06 02:33:13,443 - Epoch: [163][  400/ 1218]    Overall Loss 0.326528    Objective Loss 0.326528                                        LR 0.000250    Time 0.051448    
2024-06-06 02:33:18,222 - Epoch: [163][  500/ 1218]    Overall Loss 0.328564    Objective Loss 0.328564                                        LR 0.000250    Time 0.050712    
2024-06-06 02:33:22,934 - Epoch: [163][  600/ 1218]    Overall Loss 0.326720    Objective Loss 0.326720                                        LR 0.000250    Time 0.050111    
2024-06-06 02:33:27,671 - Epoch: [163][  700/ 1218]    Overall Loss 0.326035    Objective Loss 0.326035                                        LR 0.000250    Time 0.049716    
2024-06-06 02:33:32,320 - Epoch: [163][  800/ 1218]    Overall Loss 0.326259    Objective Loss 0.326259                                        LR 0.000250    Time 0.049310    
2024-06-06 02:33:37,167 - Epoch: [163][  900/ 1218]    Overall Loss 0.327194    Objective Loss 0.327194                                        LR 0.000250    Time 0.049215    
2024-06-06 02:33:42,243 - Epoch: [163][ 1000/ 1218]    Overall Loss 0.326803    Objective Loss 0.326803                                        LR 0.000250    Time 0.049368    
2024-06-06 02:33:46,969 - Epoch: [163][ 1100/ 1218]    Overall Loss 0.326654    Objective Loss 0.326654                                        LR 0.000250    Time 0.049174    
2024-06-06 02:33:51,620 - Epoch: [163][ 1200/ 1218]    Overall Loss 0.327494    Objective Loss 0.327494                                        LR 0.000250    Time 0.048950    
2024-06-06 02:33:52,419 - Epoch: [163][ 1218/ 1218]    Overall Loss 0.327819    Objective Loss 0.327819    Top1 85.085575    Top5 95.843521    LR 0.000250    Time 0.048882    
2024-06-06 02:33:52,634 - --- validate (epoch=163)-----------
2024-06-06 02:33:52,634 - 34633 samples (256 per mini-batch)
2024-06-06 02:33:58,301 - Epoch: [163][  100/  136]    Loss 0.364062    Top1 82.425781    Top5 97.128906    
2024-06-06 02:33:59,965 - Epoch: [163][  136/  136]    Loss 0.362136    Top1 82.415615    Top5 97.268501    
2024-06-06 02:34:00,136 - ==> Top1: 82.416    Top5: 97.269    Loss: 0.362

2024-06-06 02:34:00,137 - ==> Confusion:
[[  843     1     4     0     6     1     0     1     8    36     0     0     4     1     4     3     5     0     1     3    10]
 [    2   935     2     3    10    26     1    19     1     1     4     4     7     0     4     1    10     1    16     6    10]
 [   11     2   875     7     1     0    20     9     0     4     3     7     6     3     2     4     3     1     4     2     6]
 [    4     1    10   917     0     5     1     3     1     3     5     3     8     3    28     2     2     4    10     1     5]
 [   24    19     3     2   925    10     1     4     1     9     0     1     2     4     7     7    17     3     5     2     8]
 [    7    24     2     4     6   853     4    29     5     9     2    16    14    22     4     4    13     1     4     9    11]
 [    4     1    15     2     2     1  1004     4     0     1     3     4     3     1     1    15     3     4     2    13     3]
 [    5    13    10     1     1    17     5   956     0     3     1     6     4     3     1     1     4     2    26    13     5]
 [    5     1     1     2     1     2     0     3   880    39     8     3     6    14    20     0     3     5     5     0     4]
 [   96     2     1     1     4     2     0     1    51   802     1     2     3    11     9     2     4     3     0     1     5]
 [    4     1     3    17     1     2     2     4    13     1   974     1     2    12     3     0     1     0    16     2     5]
 [    2     1     0     1     0     8     3     3     0     2     1   890    31     9     0    17     6    13     0    17     7]
 [    3     1     6     3     2     0     1     6     0     0     0    65   843     2     3    10     8    24     4     7     7]
 [    6     1     0     0     2     4     0     3    12    15     4    11     6   895     4     7     6     3     2    11     9]
 [    8     3     2    12     4     0     0     0    24     6     8     1     2     8   998     0     5     0    12     1     4]
 [    4     2     3     0     1     0     2     0     0     2     0    17    10     2     0   996     9     9     0     5     4]
 [    4     5     1     4     2     3     2     0     4     0     2     8     4     4     1    12  1005     1     0     4     6]
 [    3     2     0     1     0     0     1     2     0     2     0    12    35     2     2     9     2   919     3     8     2]
 [    2     6     4    10     2     1     0    23     4     2     2     2     2     1    18     1     1     3   968     3     3]
 [    2     3     3     0     0     3    10    12     2     3     0    18    11     0     1     6    10     1     3   996     4]
 [  215   160   208   155   153   163   105   177    87   107   164   161   368   247   216   184   381   117   191   304 10069]]

2024-06-06 02:34:00,140 - ==> Best [Top1: 85.043   Top5: 97.707   Sparsity:0.00   Params: 424448 on epoch: 158]
2024-06-06 02:34:00,140 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:34:00,155 - 

2024-06-06 02:34:00,155 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:34:06,367 - Epoch: [164][  100/ 1218]    Overall Loss 0.328106    Objective Loss 0.328106                                        LR 0.000250    Time 0.062089    
2024-06-06 02:34:11,113 - Epoch: [164][  200/ 1218]    Overall Loss 0.324763    Objective Loss 0.324763                                        LR 0.000250    Time 0.054768    
2024-06-06 02:34:15,972 - Epoch: [164][  300/ 1218]    Overall Loss 0.327425    Objective Loss 0.327425                                        LR 0.000250    Time 0.052700    
2024-06-06 02:34:20,552 - Epoch: [164][  400/ 1218]    Overall Loss 0.326149    Objective Loss 0.326149                                        LR 0.000250    Time 0.050970    
2024-06-06 02:34:25,200 - Epoch: [164][  500/ 1218]    Overall Loss 0.327124    Objective Loss 0.327124                                        LR 0.000250    Time 0.050068    
2024-06-06 02:34:29,936 - Epoch: [164][  600/ 1218]    Overall Loss 0.328035    Objective Loss 0.328035                                        LR 0.000250    Time 0.049614    
2024-06-06 02:34:34,747 - Epoch: [164][  700/ 1218]    Overall Loss 0.327557    Objective Loss 0.327557                                        LR 0.000250    Time 0.049396    
2024-06-06 02:34:39,559 - Epoch: [164][  800/ 1218]    Overall Loss 0.328143    Objective Loss 0.328143                                        LR 0.000250    Time 0.049234    
2024-06-06 02:34:44,506 - Epoch: [164][  900/ 1218]    Overall Loss 0.328112    Objective Loss 0.328112                                        LR 0.000250    Time 0.049258    
2024-06-06 02:34:49,207 - Epoch: [164][ 1000/ 1218]    Overall Loss 0.327855    Objective Loss 0.327855                                        LR 0.000250    Time 0.049031    
2024-06-06 02:34:53,936 - Epoch: [164][ 1100/ 1218]    Overall Loss 0.327327    Objective Loss 0.327327                                        LR 0.000250    Time 0.048871    
2024-06-06 02:34:58,691 - Epoch: [164][ 1200/ 1218]    Overall Loss 0.328390    Objective Loss 0.328390                                        LR 0.000250    Time 0.048758    
2024-06-06 02:34:59,487 - Epoch: [164][ 1218/ 1218]    Overall Loss 0.328628    Objective Loss 0.328628    Top1 84.596577    Top5 97.555012    LR 0.000250    Time 0.048691    
2024-06-06 02:34:59,665 - --- validate (epoch=164)-----------
2024-06-06 02:34:59,665 - 34633 samples (256 per mini-batch)
2024-06-06 02:35:05,358 - Epoch: [164][  100/  136]    Loss 0.361513    Top1 82.960938    Top5 97.605469    
2024-06-06 02:35:07,022 - Epoch: [164][  136/  136]    Loss 0.367742    Top1 82.782317    Top5 97.597667    
2024-06-06 02:35:07,196 - ==> Top1: 82.782    Top5: 97.598    Loss: 0.368

2024-06-06 02:35:07,198 - ==> Confusion:
[[  861     1     2     0    14     1     0     1     6    32     0     0     3     1     3     1     2     0     0     0     3]
 [    2   952     5     5    35    18     3     7     3     5     1     0     3     0     1     0    10     1     9     0     3]
 [    8     2   895     7     4     1    12     3     1     3     2     1     4     2     0     6     9     0     1     1     8]
 [    5     1    19   926     1     5     1     1     3     5    13     2     3     1    15     2     2     2     3     1     5]
 [   21     8     2     4   985     3     1     0     1     5     0     1     4     2     3     4     6     0     0     1     3]
 [   11    24     4     3    17   908     4    10     3     7     4     7     7     7     2     2     9     2     1     5     6]
 [    2     3    27     0     1     6   996     2     2     2     0     3     0     0     1    21     5     2     3     6     4]
 [    4    15    20     2     5    54     7   901     3     4     4     4     3     3     0     0     3     5    24     8     8]
 [    9     5     0     0     2     2     1     2   875    49    10     1     4    15    11     0     3     4     6     0     3]
 [   96     0     6     0    10     4     0     0    48   815     1     0     3    12     5     0     1     0     0     0     0]
 [    2     6    10    12     2     1     2     6    17     1   959     1     0    14     9     0     1     0    10     0    11]
 [    3     5     6     1     7    22     1     5     2     3     0   865    27     6     1    18     5    15     0    14     5]
 [    0     0     5     2     2     0     1     2     2     3     1    49   864     4     1    14     9    23     5     6     2]
 [    4     2     6     1     9    13     0     4     9    20     6     6     6   887     3     2     5     3     1    11     3]
 [    6     3     4    30    18     1     0     0    39     6     5     1     5     8   952     0     2     0    12     1     5]
 [    0     1     5     1    12     1     5     2     1     5     0    13     5     2     0   994     8     5     0     2     4]
 [    2     9     3     2    10     4     0     0     2     1     0     4     2     1     0     9  1004     0     3     4    12]
 [    3     1     2     4     3     1     2     1     2     4     0    11    29     4     3    19     2   907     1     2     4]
 [    2     5    11    11     5     3     0    20    11     1     7     1     5     1     9     0     0     0   961     0     5]
 [    1     2     7     1     7     8    10    11     1     3     0    21     5     2     0     6     9     3     4   978     9]
 [  249   191   255   120   318   174    69   113   140   149   127   130   302   240   176   137   395    76   149   237 10185]]

2024-06-06 02:35:07,200 - ==> Best [Top1: 85.043   Top5: 97.707   Sparsity:0.00   Params: 424448 on epoch: 158]
2024-06-06 02:35:07,200 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:35:07,215 - 

2024-06-06 02:35:07,216 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:35:13,477 - Epoch: [165][  100/ 1218]    Overall Loss 0.312871    Objective Loss 0.312871                                        LR 0.000250    Time 0.062583    
2024-06-06 02:35:18,159 - Epoch: [165][  200/ 1218]    Overall Loss 0.321980    Objective Loss 0.321980                                        LR 0.000250    Time 0.054693    
2024-06-06 02:35:22,806 - Epoch: [165][  300/ 1218]    Overall Loss 0.321368    Objective Loss 0.321368                                        LR 0.000250    Time 0.051939    
2024-06-06 02:35:27,529 - Epoch: [165][  400/ 1218]    Overall Loss 0.322663    Objective Loss 0.322663                                        LR 0.000250    Time 0.050757    
2024-06-06 02:35:32,378 - Epoch: [165][  500/ 1218]    Overall Loss 0.321872    Objective Loss 0.321872                                        LR 0.000250    Time 0.050300    
2024-06-06 02:35:36,906 - Epoch: [165][  600/ 1218]    Overall Loss 0.326256    Objective Loss 0.326256                                        LR 0.000250    Time 0.049460    
2024-06-06 02:35:41,451 - Epoch: [165][  700/ 1218]    Overall Loss 0.328117    Objective Loss 0.328117                                        LR 0.000250    Time 0.048885    
2024-06-06 02:35:46,005 - Epoch: [165][  800/ 1218]    Overall Loss 0.326722    Objective Loss 0.326722                                        LR 0.000250    Time 0.048465    
2024-06-06 02:35:50,635 - Epoch: [165][  900/ 1218]    Overall Loss 0.326264    Objective Loss 0.326264                                        LR 0.000250    Time 0.048222    
2024-06-06 02:35:55,311 - Epoch: [165][ 1000/ 1218]    Overall Loss 0.325967    Objective Loss 0.325967                                        LR 0.000250    Time 0.048074    
2024-06-06 02:36:00,000 - Epoch: [165][ 1100/ 1218]    Overall Loss 0.325833    Objective Loss 0.325833                                        LR 0.000250    Time 0.047965    
2024-06-06 02:36:04,721 - Epoch: [165][ 1200/ 1218]    Overall Loss 0.325486    Objective Loss 0.325486                                        LR 0.000250    Time 0.047900    
2024-06-06 02:36:05,544 - Epoch: [165][ 1218/ 1218]    Overall Loss 0.325883    Objective Loss 0.325883    Top1 84.352078    Top5 97.799511    LR 0.000250    Time 0.047868    
2024-06-06 02:36:05,727 - --- validate (epoch=165)-----------
2024-06-06 02:36:05,727 - 34633 samples (256 per mini-batch)
2024-06-06 02:36:11,285 - Epoch: [165][  100/  136]    Loss 0.368547    Top1 84.808594    Top5 97.699219    
2024-06-06 02:36:12,944 - Epoch: [165][  136/  136]    Loss 0.367917    Top1 84.722663    Top5 97.744925    
2024-06-06 02:36:13,130 - ==> Top1: 84.723    Top5: 97.745    Loss: 0.368

2024-06-06 02:36:13,131 - ==> Confusion:
[[  819     2     2     0    15     1     0     3     6    55     0     0     1     5     5     1     0     4     0     1    11]
 [    2   942     2     2    14    29     2    10     3     3     4     3     3     1    12     0     6     1    11     1    12]
 [    6     0   855    15     4     4    12    14     0     6     4     2     3     7     4     8     3     0     5     1    17]
 [    2     1     5   936     2    12     2     3     2     2     7     2     5     5     9     1     1     7     6     1     5]
 [   12     8     3     0   956    14     1     2     0    16     0     2     0     7     4     7     8     1     2     2     9]
 [    4    18     5     2    10   912     3    11     1     6     1    15     9    20     2     5     2     2     0     5    10]
 [    3     2    12     0     1     9  1007     5     0     4     1     3     1     3     0     7     1     0     1     7    19]
 [    1    14     7     4     1    42     5   925     0     5     2    10     6     3     2     1     0     1    31     6    11]
 [   12     3     0     1     0     5     0     1   826    61    11     2     3    22    29     3     2     2     5     1    13]
 [   65     0     3     0     6     5     1     0    23   844     1     1     1    24     3     1     1     4     2     1    15]
 [    0     6     7    21     1     7     5     9     8     1   937     1     0    19    11     0     1     3    13     1    13]
 [    2     2     1     0     3    13     2     2     1     3     0   864    27    17     0    19     7    22     1    10    15]
 [    1     4     2     0     4     7     1     1     0     0     0    59   825     2     3    13     3    38     5     4    23]
 [    2     0     1     1     3    11     0     1     5    14     6     8     5   925     4     4     2     1     0     1     7]
 [    6     1     1    16    12     5     0     2    12    10     3     0     4    14   987     1     2     0    12     0    10]
 [    0     0     0     1     1     3     4     0     0     4     0     8     6     2     0  1011     9     7     1     1     8]
 [    4     6     3     2     5    13     3     0     1     1     1     2     3     5     1    17   972     1     1     5    26]
 [    2     1     0     2     1     2     3     2     1     3     0    11    20     2     0    20     3   926     0     0     6]
 [    2     8     2    15     2     5     1    19     1     2     2     0     5     1    13     0     2     1   962     0    15]
 [    2     5     2     1     3    20    12     7     0     1     0    12     8     8     0     9     8     4     2   972    12]
 [  143   161   133    99   182   239    64   148    65   124   125   116   209   323   155   160   128    92   180   147 10939]]

2024-06-06 02:36:13,133 - ==> Best [Top1: 85.043   Top5: 97.707   Sparsity:0.00   Params: 424448 on epoch: 158]
2024-06-06 02:36:13,133 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:36:13,156 - 

2024-06-06 02:36:13,156 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:36:19,528 - Epoch: [166][  100/ 1218]    Overall Loss 0.322046    Objective Loss 0.322046                                        LR 0.000250    Time 0.063688    
2024-06-06 02:36:24,249 - Epoch: [166][  200/ 1218]    Overall Loss 0.321976    Objective Loss 0.321976                                        LR 0.000250    Time 0.055442    
2024-06-06 02:36:28,805 - Epoch: [166][  300/ 1218]    Overall Loss 0.322507    Objective Loss 0.322507                                        LR 0.000250    Time 0.052142    
2024-06-06 02:36:33,465 - Epoch: [166][  400/ 1218]    Overall Loss 0.320991    Objective Loss 0.320991                                        LR 0.000250    Time 0.050751    
2024-06-06 02:36:38,176 - Epoch: [166][  500/ 1218]    Overall Loss 0.322000    Objective Loss 0.322000                                        LR 0.000250    Time 0.050019    
2024-06-06 02:36:42,922 - Epoch: [166][  600/ 1218]    Overall Loss 0.320756    Objective Loss 0.320756                                        LR 0.000250    Time 0.049589    
2024-06-06 02:36:47,486 - Epoch: [166][  700/ 1218]    Overall Loss 0.320426    Objective Loss 0.320426                                        LR 0.000250    Time 0.049022    
2024-06-06 02:36:52,065 - Epoch: [166][  800/ 1218]    Overall Loss 0.320298    Objective Loss 0.320298                                        LR 0.000250    Time 0.048616    
2024-06-06 02:36:56,812 - Epoch: [166][  900/ 1218]    Overall Loss 0.323282    Objective Loss 0.323282                                        LR 0.000250    Time 0.048486    
2024-06-06 02:37:01,387 - Epoch: [166][ 1000/ 1218]    Overall Loss 0.324579    Objective Loss 0.324579                                        LR 0.000250    Time 0.048210    
2024-06-06 02:37:06,103 - Epoch: [166][ 1100/ 1218]    Overall Loss 0.324855    Objective Loss 0.324855                                        LR 0.000250    Time 0.048113    
2024-06-06 02:37:10,721 - Epoch: [166][ 1200/ 1218]    Overall Loss 0.326161    Objective Loss 0.326161                                        LR 0.000250    Time 0.047951    
2024-06-06 02:37:11,530 - Epoch: [166][ 1218/ 1218]    Overall Loss 0.326100    Objective Loss 0.326100    Top1 84.841076    Top5 97.555012    LR 0.000250    Time 0.047905    
2024-06-06 02:37:11,715 - --- validate (epoch=166)-----------
2024-06-06 02:37:11,715 - 34633 samples (256 per mini-batch)
2024-06-06 02:37:17,186 - Epoch: [166][  100/  136]    Loss 0.360881    Top1 85.011719    Top5 97.570312    
2024-06-06 02:37:18,864 - Epoch: [166][  136/  136]    Loss 0.363145    Top1 84.849710    Top5 97.577455    
2024-06-06 02:37:19,023 - ==> Top1: 84.850    Top5: 97.577    Loss: 0.363

2024-06-06 02:37:19,024 - ==> Confusion:
[[  788     1     1     0    13     1     1     0     7    93     0     2     0     2     8     0     0     5     1     1     7]
 [    1   943     0     0    25    14     3     6     9     4     7     2     2     3    11     0     1     4    12     2    14]
 [    1     2   872    11     4     1    19     4     2     9     9     5     1     7     5     2     1     2     0     6     7]
 [    2     0     8   923     0     4     4     1     1     3    21     0     3     3    18     3     4     6     4     2     6]
 [   19     3     3     1   967     3     0     3     1    14     1     2     3     4    11     3     3     4     1     1     7]
 [    2    32     3     7    18   867     5    14     1     6     5     8     1    28     7     0     3     9     3    10    14]
 [    1     2    13     2     0     7   998     4     0     5     4     2     0     3     1     5     1    11     1    17     9]
 [    2    15    13     5     5    31     4   922     2    10    10     5     7     5     0     0     1     6    13    10    11]
 [    9     1     1     0     0     0     0     0   836    83    12     3     5    15    23     1     2     3     3     0     5]
 [   36     1     1     0     6     0     0     0    22   896     2     0     0    13    11     1     0     6     1     0     5]
 [    0     2     4     8     1     1     2     2    14     1   995     0     0     8     9     0     1     1     5     1     9]
 [    1     1     3     0     2    11     3     5     2     5     0   865    25    17     1     8     2    36     1    17     6]
 [    3     0     3     8     1     0     3     6     3     1     4    44   802     6     6     5     3    74     0    10    13]
 [    1     1     0     1     3     6     1     0    10    24     7     4     3   919     4     2     1     6     0     2     6]
 [    5     0     3    19     8     0     0     1    23    13     8     1     1     9   987     1     1     1     8     1     8]
 [    2     0     3     1     8     1     9     0     0     5     0    13     5     1     3   970     9    25     0     5     6]
 [    2    13     3     3     9     7     0     1     5     2     3     6     0    10     2     9   965     1     1     7    23]
 [    2     1     3     7     0     0     0     1     2     0     1     5     5     2     4     4     2   960     0     1     5]
 [    2     2     5    15     4     3     3    16     8     2     5     0     1     2    20     1     0     1   951     3    14]
 [    1     3     3     0     1     9     7     6     1     2     2    13     7     4     2     6     1     7     2   998    13]
 [  119   125   149   115   205   120    73   106   112   204   201   104   221   258   210    86    92   165    89   216 10962]]

2024-06-06 02:37:19,026 - ==> Best [Top1: 85.043   Top5: 97.707   Sparsity:0.00   Params: 424448 on epoch: 158]
2024-06-06 02:37:19,027 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:37:19,050 - 

2024-06-06 02:37:19,050 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:37:25,174 - Epoch: [167][  100/ 1218]    Overall Loss 0.325996    Objective Loss 0.325996                                        LR 0.000250    Time 0.061212    
2024-06-06 02:37:30,183 - Epoch: [167][  200/ 1218]    Overall Loss 0.319564    Objective Loss 0.319564                                        LR 0.000250    Time 0.055642    
2024-06-06 02:37:34,789 - Epoch: [167][  300/ 1218]    Overall Loss 0.324387    Objective Loss 0.324387                                        LR 0.000250    Time 0.052442    
2024-06-06 02:37:39,677 - Epoch: [167][  400/ 1218]    Overall Loss 0.320659    Objective Loss 0.320659                                        LR 0.000250    Time 0.051546    
2024-06-06 02:37:44,546 - Epoch: [167][  500/ 1218]    Overall Loss 0.321173    Objective Loss 0.321173                                        LR 0.000250    Time 0.050973    
2024-06-06 02:37:49,143 - Epoch: [167][  600/ 1218]    Overall Loss 0.322740    Objective Loss 0.322740                                        LR 0.000250    Time 0.050134    
2024-06-06 02:37:53,793 - Epoch: [167][  700/ 1218]    Overall Loss 0.322199    Objective Loss 0.322199                                        LR 0.000250    Time 0.049612    
2024-06-06 02:37:58,588 - Epoch: [167][  800/ 1218]    Overall Loss 0.323350    Objective Loss 0.323350                                        LR 0.000250    Time 0.049402    
2024-06-06 02:38:03,259 - Epoch: [167][  900/ 1218]    Overall Loss 0.323250    Objective Loss 0.323250                                        LR 0.000250    Time 0.049100    
2024-06-06 02:38:07,890 - Epoch: [167][ 1000/ 1218]    Overall Loss 0.324059    Objective Loss 0.324059                                        LR 0.000250    Time 0.048820    
2024-06-06 02:38:12,436 - Epoch: [167][ 1100/ 1218]    Overall Loss 0.324301    Objective Loss 0.324301                                        LR 0.000250    Time 0.048512    
2024-06-06 02:38:17,027 - Epoch: [167][ 1200/ 1218]    Overall Loss 0.324713    Objective Loss 0.324713                                        LR 0.000250    Time 0.048294    
2024-06-06 02:38:17,851 - Epoch: [167][ 1218/ 1218]    Overall Loss 0.324718    Objective Loss 0.324718    Top1 84.841076    Top5 98.044010    LR 0.000250    Time 0.048256    
2024-06-06 02:38:18,030 - --- validate (epoch=167)-----------
2024-06-06 02:38:18,031 - 34633 samples (256 per mini-batch)
2024-06-06 02:38:23,465 - Epoch: [167][  100/  136]    Loss 0.377091    Top1 82.691406    Top5 97.089844    
2024-06-06 02:38:25,115 - Epoch: [167][  136/  136]    Loss 0.377764    Top1 82.658158    Top5 97.034620    
2024-06-06 02:38:25,317 - ==> Top1: 82.658    Top5: 97.035    Loss: 0.378

2024-06-06 02:38:25,318 - ==> Confusion:
[[  791     3     2     0     8     5     0     0    10    90     0     4     1     7     1     1     0     0     3     0     5]
 [    4   947     3     0    22    20     2    23     5     3     5     3     1     2     4     0     2     3     7     4     3]
 [    7     0   886     4     4     0     9    12     1     5    14     2     4     4     3     3     3     0     2     2     5]
 [    4     2    15   912     1     9     4     4     4     2    15     0     5     1    16     1     0     5    10     5     1]
 [   17     9     2     2   952    15     0     4     3    21     1     4     2     7     5     1     0     0     1     2     6]
 [    5    25     2     0    12   888     4    30     1     6     9     8     4    18     1     0     3     6     3    14     4]
 [    1     2    24     2     3     1   989     7     0     4     9     4     1     3     0     2     1     2     2    22     7]
 [    2    11    10     3     2    29     2   968     2     5     4     5     4     3     0     0     0     2    14    11     0]
 [   11     0     0     0     3     3     1     3   867    58    11     3     5    11     7     0     2     1    11     1     4]
 [   38     0     3     1     7     1     0     2    42   874     2     0     1    23     3     0     2     0     0     1     1]
 [    1     0     4    10     1     2     1     5    14     2   989     1     2    10     3     0     0     0    14     3     2]
 [    3     3     3     0     0    19     2     7     1     3     0   838    42     9     1    13     2    29     1    29     6]
 [    1     1     1     6     5     8     1     5     1     0     1    45   874     2     1     0     0    24     5     7     7]
 [    3     0     3     2     4    15     1     3    11    10    11     7     2   906     3     1     1     1     0    11     6]
 [    5     2     4    16     8     2     0     3    35    16     9     2     2    10   963     0     1     1     9     2     8]
 [    6     0     1     0     5     4    10     0     0     3     0    18    12     8     1   972     4    16     0     3     3]
 [   10    14     7     2    18     6     1     2     5     0     3     6     7     5     3     7   945     3     5    11    12]
 [    1     1     0     0     1     2     0     4     1     4     0     7    31     7     3     8     1   928     2     0     4]
 [    7     7    10     4     3     0     0    24    10     0    13     1     2     1    15     0     0     0   948     3    10]
 [    4     3     2     0     2    10     6    11     0     2     4    12     7     6     0     1     4     6     3  1001     4]
 [  205   192   222   120   269   237    77   184   125   175   223   126   370   274   168    79   111   108   141   337 10189]]

2024-06-06 02:38:25,321 - ==> Best [Top1: 85.043   Top5: 97.707   Sparsity:0.00   Params: 424448 on epoch: 158]
2024-06-06 02:38:25,321 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:38:25,339 - 

2024-06-06 02:38:25,339 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:38:31,372 - Epoch: [168][  100/ 1218]    Overall Loss 0.306874    Objective Loss 0.306874                                        LR 0.000250    Time 0.060303    
2024-06-06 02:38:36,077 - Epoch: [168][  200/ 1218]    Overall Loss 0.309818    Objective Loss 0.309818                                        LR 0.000250    Time 0.053668    
2024-06-06 02:38:40,700 - Epoch: [168][  300/ 1218]    Overall Loss 0.316485    Objective Loss 0.316485                                        LR 0.000250    Time 0.051183    
2024-06-06 02:38:45,407 - Epoch: [168][  400/ 1218]    Overall Loss 0.319303    Objective Loss 0.319303                                        LR 0.000250    Time 0.050150    
2024-06-06 02:38:50,159 - Epoch: [168][  500/ 1218]    Overall Loss 0.322033    Objective Loss 0.322033                                        LR 0.000250    Time 0.049620    
2024-06-06 02:38:55,279 - Epoch: [168][  600/ 1218]    Overall Loss 0.321571    Objective Loss 0.321571                                        LR 0.000250    Time 0.049880    
2024-06-06 02:38:59,943 - Epoch: [168][  700/ 1218]    Overall Loss 0.320810    Objective Loss 0.320810                                        LR 0.000250    Time 0.049415    
2024-06-06 02:39:04,661 - Epoch: [168][  800/ 1218]    Overall Loss 0.321901    Objective Loss 0.321901                                        LR 0.000250    Time 0.049129    
2024-06-06 02:39:09,361 - Epoch: [168][  900/ 1218]    Overall Loss 0.320289    Objective Loss 0.320289                                        LR 0.000250    Time 0.048889    
2024-06-06 02:39:13,919 - Epoch: [168][ 1000/ 1218]    Overall Loss 0.321135    Objective Loss 0.321135                                        LR 0.000250    Time 0.048557    
2024-06-06 02:39:18,873 - Epoch: [168][ 1100/ 1218]    Overall Loss 0.322224    Objective Loss 0.322224                                        LR 0.000250    Time 0.048644    
2024-06-06 02:39:23,523 - Epoch: [168][ 1200/ 1218]    Overall Loss 0.322462    Objective Loss 0.322462                                        LR 0.000250    Time 0.048464    
2024-06-06 02:39:24,341 - Epoch: [168][ 1218/ 1218]    Overall Loss 0.322146    Objective Loss 0.322146    Top1 85.330073    Top5 98.777506    LR 0.000250    Time 0.048419    
2024-06-06 02:39:24,512 - --- validate (epoch=168)-----------
2024-06-06 02:39:24,512 - 34633 samples (256 per mini-batch)
2024-06-06 02:39:30,270 - Epoch: [168][  100/  136]    Loss 0.361758    Top1 85.113281    Top5 97.882812    
2024-06-06 02:39:31,950 - Epoch: [168][  136/  136]    Loss 0.359410    Top1 85.389657    Top5 97.871972    
2024-06-06 02:39:32,111 - ==> Top1: 85.390    Top5: 97.872    Loss: 0.359

2024-06-06 02:39:32,113 - ==> Confusion:
[[  804     2     0     1    10     4     0     0     6    73     1     0     2     2    10     3     0     1     1     0    11]
 [    2   977     1     1    14     9     3     8     1     2     2     1     1     0     6     1     4     2     7     1    20]
 [    4     4   880     4     6     1    16    14     0     6     4     0     5     0     3     2     2     1     0     1    17]
 [    7     4    10   925     2     4     3     1     2     0     9     0     4     1    17     2     0     5     5     1    14]
 [   14    16     0     0   965     3     0     0     0    10     1     0     3     6    12     5     6     1     0     1    11]
 [    3    42     2     5    15   875     7    27     2     3     3     2     9    10     2     3     4     4     1     8    16]
 [    3     0    12     4     0     1  1025     7     0     2     2     1     0     1     2     6     4     3     0     5     8]
 [    6    21     9     1     2    27     8   927     3     0     9     5     7     1     1     0     1     0    25    15     9]
 [   12     6     1     0     0     0     1     2   846    59    14     1     2     7    33     0     1     3     6     0     8]
 [   49     0     0     1     5     4     0     2    26   881     1     0     2     6    12     0     2     1     1     0     8]
 [    2     5     6    14     2     2     2     6    10     3   978     1     1     4     6     0     1     0     8     1    12]
 [    3     1     1     0     0    12    10     5     2     2     0   812    60     4     0    20     5    19     3    40    12]
 [    1     6     4     3     2     5     2     3     2     0     2    30   855     0     5     6     3    40     3     8    15]
 [    4     1     1     2     2    15     1     3    14    21    15     9     3   869     7     1     6     5     0     7    15]
 [    4     8     2    13     8     4     1     1     8     7     6     0     3     2  1001     2     1     3     6     0    18]
 [    2     1     5     1     1     0    11     0     1     1     0     7     8     2     1   997     3    13     1     5     6]
 [    2    10     1     1     7     6     1     1     2     4     5     4     2     3     3    10   977     0     2     5    26]
 [    1     3     0     2     3     0     3     2     0     3     0     4    23     0     0    11     1   942     2     1     4]
 [    2     9     8    13     2     2     3    16     3     0     5     0     4     1    15     0     2     0   952     3    18]
 [    2     7     4     1     2     5    12     4     1     1     1     4     6     2     0     6     2     2     2  1014    10]
 [  126   256   138    89   172   131   121   118    74   110   152    72   328   137   167   101   125    89   104   251 11071]]

2024-06-06 02:39:32,115 - ==> Best [Top1: 85.390   Top5: 97.872   Sparsity:0.00   Params: 424448 on epoch: 168]
2024-06-06 02:39:32,115 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:39:32,142 - 

2024-06-06 02:39:32,142 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:39:38,240 - Epoch: [169][  100/ 1218]    Overall Loss 0.323294    Objective Loss 0.323294                                        LR 0.000250    Time 0.060959    
2024-06-06 02:39:42,914 - Epoch: [169][  200/ 1218]    Overall Loss 0.319197    Objective Loss 0.319197                                        LR 0.000250    Time 0.053838    
2024-06-06 02:39:47,510 - Epoch: [169][  300/ 1218]    Overall Loss 0.322203    Objective Loss 0.322203                                        LR 0.000250    Time 0.051203    
2024-06-06 02:39:52,137 - Epoch: [169][  400/ 1218]    Overall Loss 0.324697    Objective Loss 0.324697                                        LR 0.000250    Time 0.049966    
2024-06-06 02:39:56,774 - Epoch: [169][  500/ 1218]    Overall Loss 0.324293    Objective Loss 0.324293                                        LR 0.000250    Time 0.049243    
2024-06-06 02:40:01,402 - Epoch: [169][  600/ 1218]    Overall Loss 0.323520    Objective Loss 0.323520                                        LR 0.000250    Time 0.048746    
2024-06-06 02:40:06,134 - Epoch: [169][  700/ 1218]    Overall Loss 0.324875    Objective Loss 0.324875                                        LR 0.000250    Time 0.048540    
2024-06-06 02:40:10,844 - Epoch: [169][  800/ 1218]    Overall Loss 0.326556    Objective Loss 0.326556                                        LR 0.000250    Time 0.048358    
2024-06-06 02:40:15,568 - Epoch: [169][  900/ 1218]    Overall Loss 0.326161    Objective Loss 0.326161                                        LR 0.000250    Time 0.048228    
2024-06-06 02:40:20,314 - Epoch: [169][ 1000/ 1218]    Overall Loss 0.326054    Objective Loss 0.326054                                        LR 0.000250    Time 0.048150    
2024-06-06 02:40:24,991 - Epoch: [169][ 1100/ 1218]    Overall Loss 0.325253    Objective Loss 0.325253                                        LR 0.000250    Time 0.048023    
2024-06-06 02:40:29,587 - Epoch: [169][ 1200/ 1218]    Overall Loss 0.325503    Objective Loss 0.325503                                        LR 0.000250    Time 0.047849    
2024-06-06 02:40:30,380 - Epoch: [169][ 1218/ 1218]    Overall Loss 0.325854    Objective Loss 0.325854    Top1 86.308068    Top5 97.799511    LR 0.000250    Time 0.047793    
2024-06-06 02:40:30,569 - --- validate (epoch=169)-----------
2024-06-06 02:40:30,570 - 34633 samples (256 per mini-batch)
2024-06-06 02:40:36,100 - Epoch: [169][  100/  136]    Loss 0.374710    Top1 83.562500    Top5 97.472656    
2024-06-06 02:40:37,823 - Epoch: [169][  136/  136]    Loss 0.368516    Top1 83.712067    Top5 97.563018    
2024-06-06 02:40:38,020 - ==> Top1: 83.712    Top5: 97.563    Loss: 0.369

2024-06-06 02:40:38,021 - ==> Confusion:
[[  857     0     0     1     7     1     1     1     1    44     0     0     3     1     1     2     1     2     3     1     4]
 [    2   923     2     3    16    35     5    11     6     3     1     1     6     1     4     0    16     0    18     4     6]
 [    6     2   869    17     2     3    18     8     1     4     2     3     3     0     1     1     8     1     9     2    10]
 [    3     1     6   942     3     8     3     4     1     4     4     2     7     1     8     1     3     3     6     2     4]
 [   25     6     0     4   956    10     1     0     2    11     1     2     5     1     5     3     6     1     7     1     7]
 [    7    10     3     5    11   901     4    35     4     9     1     5     9     9     1     0     5     6     5     5     8]
 [    6     2    15     2     3     7  1010     8     0     2     3     3     4     0     0     4     2     3     2     4     6]
 [    3     3    11     2     3    23     2   935     0     4     2     6     7     0     1     0     3     0    44    15    13]
 [   20     2     3     3     1     2     0     0   856    53     6     1     9     9    17     0     2     2     9     0     7]
 [   90     0     0     0     1     5     1     2    35   846     0     1     4     4     4     0     4     1     0     0     3]
 [    4     1     9    28     3     5     4     8    12     2   934     0     2     8     6     0     2     1    21     2    12]
 [    4     0     0     0     1    13     3     3     0     4     1   865    49     5     0    16     4    19     0    14    10]
 [    3     0     1     3     2     4     1     2     0     4     1    44   858     1     0     3     8    34     6     4    16]
 [    4     0     5     1     6    16     1     5    14    40     3    13     5   849     4     1     7     4     2     5    16]
 [   12     0     2    34    17     2     0     1    24     6     1     0     1     9   951     0     5     2    19     0    12]
 [    1     0     6     1     3     0     7     0     0     6     1    11    10     3     0   972    15    18     1     4     7]
 [    2     6     2     5     8     6     2     0     4     1     1     5     3     2     1     1   995     4     1     5    18]
 [    0     2     0     0     3     1     0     1     1     3     0     8    17     2     0     1     3   948     1     4    10]
 [    4     3     4    13     3     1     1     8     2     1     4     2     2     0     7     0     2     0   985     4    12]
 [    4     2     1     0     1    12     7     8     0     3     1    10    12     1     1     6     6     2     8   992    11]
 [  234   131   198   146   192   196    82   155    90   142    96   124   316   172   142    86   253   118   277   234 10548]]

2024-06-06 02:40:38,023 - ==> Best [Top1: 85.390   Top5: 97.872   Sparsity:0.00   Params: 424448 on epoch: 168]
2024-06-06 02:40:38,023 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:40:38,046 - 

2024-06-06 02:40:38,046 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:40:44,350 - Epoch: [170][  100/ 1218]    Overall Loss 0.317411    Objective Loss 0.317411                                        LR 0.000250    Time 0.063008    
2024-06-06 02:40:49,103 - Epoch: [170][  200/ 1218]    Overall Loss 0.322088    Objective Loss 0.322088                                        LR 0.000250    Time 0.055259    
2024-06-06 02:40:53,690 - Epoch: [170][  300/ 1218]    Overall Loss 0.322200    Objective Loss 0.322200                                        LR 0.000250    Time 0.052127    
2024-06-06 02:40:58,237 - Epoch: [170][  400/ 1218]    Overall Loss 0.321772    Objective Loss 0.321772                                        LR 0.000250    Time 0.050456    
2024-06-06 02:41:02,846 - Epoch: [170][  500/ 1218]    Overall Loss 0.322447    Objective Loss 0.322447                                        LR 0.000250    Time 0.049581    
2024-06-06 02:41:07,536 - Epoch: [170][  600/ 1218]    Overall Loss 0.322404    Objective Loss 0.322404                                        LR 0.000250    Time 0.049131    
2024-06-06 02:41:12,262 - Epoch: [170][  700/ 1218]    Overall Loss 0.323720    Objective Loss 0.323720                                        LR 0.000250    Time 0.048859    
2024-06-06 02:41:16,864 - Epoch: [170][  800/ 1218]    Overall Loss 0.323077    Objective Loss 0.323077                                        LR 0.000250    Time 0.048503    
2024-06-06 02:41:21,493 - Epoch: [170][  900/ 1218]    Overall Loss 0.323283    Objective Loss 0.323283                                        LR 0.000250    Time 0.048254    
2024-06-06 02:41:26,131 - Epoch: [170][ 1000/ 1218]    Overall Loss 0.323228    Objective Loss 0.323228                                        LR 0.000250    Time 0.048065    
2024-06-06 02:41:30,703 - Epoch: [170][ 1100/ 1218]    Overall Loss 0.324202    Objective Loss 0.324202                                        LR 0.000250    Time 0.047849    
2024-06-06 02:41:35,354 - Epoch: [170][ 1200/ 1218]    Overall Loss 0.324164    Objective Loss 0.324164                                        LR 0.000250    Time 0.047736    
2024-06-06 02:41:36,191 - Epoch: [170][ 1218/ 1218]    Overall Loss 0.324251    Objective Loss 0.324251    Top1 86.308068    Top5 99.022005    LR 0.000250    Time 0.047718    
2024-06-06 02:41:36,385 - --- validate (epoch=170)-----------
2024-06-06 02:41:36,385 - 34633 samples (256 per mini-batch)
2024-06-06 02:41:42,071 - Epoch: [170][  100/  136]    Loss 0.358016    Top1 85.265625    Top5 97.800781    
2024-06-06 02:41:43,751 - Epoch: [170][  136/  136]    Loss 0.361151    Top1 85.060491    Top5 97.802674    
2024-06-06 02:41:43,952 - ==> Top1: 85.060    Top5: 97.803    Loss: 0.361

2024-06-06 02:41:43,953 - ==> Confusion:
[[  793     1     8     2    15     3     0     1    14    61     0     4     2     1     5     2     3     2     0     2    12]
 [    0   967     1     1    10    24     1    14     7     1     4     3     2     0     5     1    12     0     4     1     5]
 [    9     5   835     7     2     2    27    18     1     5     8     5     3     5     2     3     5     3     5     3    17]
 [    4     1     9   900     1    12     0     5     2     2    12     3     8     4    17     2     1     9    12     0    12]
 [   18    18     0     2   936    14     1     4     3    12     2     6     2     4     3     3     6     1     3     2    14]
 [    2    18     2     4     9   915     2    15     1     2     3    12     5    10     1     1    10     0     3    13    15]
 [    4     5    15     1     3     9   991     6     0     0     5     5     3     0     1    15     2     1     1     9    10]
 [    3     9     7     2     4    35     2   949     2     3     3    10     4     0     1     0     1     1    15    16    10]
 [    6     3     1     0     2     1     0     5   894    32     6     5     4     4    14     1     4     4     5     0    11]
 [   55     2     1     2     9     3     0     0    69   815     0     1     0    19    11     1     2     2     1     1     7]
 [    0     8     3    10     1     3     3     3    16     0   967     0     3     7     8     0     4     0    13     0    15]
 [    0     2     2     0     1     6     1     5     1     1     1   903    30     2     4     4     3    22     4    12     7]
 [    2     1     0     3     4     2     1     4     1     0     0    53   862     1     1     5     5    27     5     6    12]
 [    1     1     2     2     3    16     1     3    15    13    10    20     5   871     6     3     8     2     1     5    13]
 [    6     1     4    23     6     2     0     1    31     9     4     2     1     3   957     1     1     5    20     1    20]
 [    5     0     0     1     4     1     9     1     0     1     0    24     3     2     1   976    16     5     0     4    13]
 [    2     7     2     0     6     4     1     1     7     1     0     4     2     1     3     4   998     1     1     1    26]
 [    2     5     0     2     1     1     0     3     0     1     0    12    20     4     2    10     0   929     1     5     7]
 [    4    12     5     9     0     3     0    27     4     1     3     2     3     3    14     0     2     1   955     0    10]
 [    2     3     4     0     1    10    11     7     1     0     1    16     5     4     1     3     4     2     1   988    24]
 [  103   208   118    86   154   192    87   175   110    86   112   153   262   155   149    73   193    94   155   209 11058]]

2024-06-06 02:41:43,955 - ==> Best [Top1: 85.390   Top5: 97.872   Sparsity:0.00   Params: 424448 on epoch: 168]
2024-06-06 02:41:43,956 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:41:43,978 - 

2024-06-06 02:41:43,978 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:41:50,582 - Epoch: [171][  100/ 1218]    Overall Loss 0.320257    Objective Loss 0.320257                                        LR 0.000250    Time 0.066017    
2024-06-06 02:41:55,418 - Epoch: [171][  200/ 1218]    Overall Loss 0.323661    Objective Loss 0.323661                                        LR 0.000250    Time 0.057166    
2024-06-06 02:42:00,181 - Epoch: [171][  300/ 1218]    Overall Loss 0.323550    Objective Loss 0.323550                                        LR 0.000250    Time 0.053981    
2024-06-06 02:42:04,826 - Epoch: [171][  400/ 1218]    Overall Loss 0.322170    Objective Loss 0.322170                                        LR 0.000250    Time 0.052092    
2024-06-06 02:42:09,489 - Epoch: [171][  500/ 1218]    Overall Loss 0.322127    Objective Loss 0.322127                                        LR 0.000250    Time 0.050997    
2024-06-06 02:42:14,340 - Epoch: [171][  600/ 1218]    Overall Loss 0.322717    Objective Loss 0.322717                                        LR 0.000250    Time 0.050579    
2024-06-06 02:42:18,954 - Epoch: [171][  700/ 1218]    Overall Loss 0.322140    Objective Loss 0.322140                                        LR 0.000250    Time 0.049943    
2024-06-06 02:42:23,647 - Epoch: [171][  800/ 1218]    Overall Loss 0.322524    Objective Loss 0.322524                                        LR 0.000250    Time 0.049563    
2024-06-06 02:42:28,466 - Epoch: [171][  900/ 1218]    Overall Loss 0.322811    Objective Loss 0.322811                                        LR 0.000250    Time 0.049408    
2024-06-06 02:42:33,034 - Epoch: [171][ 1000/ 1218]    Overall Loss 0.324237    Objective Loss 0.324237                                        LR 0.000250    Time 0.049034    
2024-06-06 02:42:37,880 - Epoch: [171][ 1100/ 1218]    Overall Loss 0.324144    Objective Loss 0.324144                                        LR 0.000250    Time 0.048980    
2024-06-06 02:42:42,729 - Epoch: [171][ 1200/ 1218]    Overall Loss 0.324039    Objective Loss 0.324039                                        LR 0.000250    Time 0.048937    
2024-06-06 02:42:43,576 - Epoch: [171][ 1218/ 1218]    Overall Loss 0.324150    Objective Loss 0.324150    Top1 83.129584    Top5 96.088020    LR 0.000250    Time 0.048909    
2024-06-06 02:42:43,739 - --- validate (epoch=171)-----------
2024-06-06 02:42:43,739 - 34633 samples (256 per mini-batch)
2024-06-06 02:42:49,301 - Epoch: [171][  100/  136]    Loss 0.359043    Top1 83.875000    Top5 97.250000    
2024-06-06 02:42:50,984 - Epoch: [171][  136/  136]    Loss 0.364182    Top1 83.680305    Top5 97.280051    
2024-06-06 02:42:51,153 - ==> Top1: 83.680    Top5: 97.280    Loss: 0.364

2024-06-06 02:42:51,155 - ==> Confusion:
[[  831     1     2     0     4     1     0     4    11    55     0     3     1     3     3     0     1     4     0     1     6]
 [    5   964     2     4    13    13     4    10     4     1     8     1     2     1     3     1     6     0     9     3     9]
 [    5     2   866    13     3     0    25     7     1     7    10     5     2     5     4     2     4     2     1     2     4]
 [    5     0     7   942     2     2     2     4     2     4    13     2     7     2    12     1     0     3     2     0     4]
 [   23    20     2     2   943    10     1     1     3    19     3     2     0     3     6     0     4     1     2     1     8]
 [    5    32     0     3    10   873     7    37     2     9     9    10     8    11     3     1     3     4     2     5     9]
 [    3     2    15     2     1     3  1005     4     1     3    14     3     5     2     0     6     1     6     0     3     7]
 [    2    15    13     9     2    21     1   936     4     6    13     7     3     3     1     0     2     2    21     9     7]
 [    9     3     0     0     3     2     1     0   872    58    13     3     3     6    16     0     1     4     7     0     1]
 [   61     0     1     1     1     1     0     1    32   874     2     2     1     5     7     0     2     1     1     0     8]
 [    0     1     4    18     2     1     0     3    13     4   992     0     4     4     5     0     1     1     5     1     5]
 [    2     0     3     0     2    15     2     6     2     3     4   869    43    12     0     5     5    17     0    16     5]
 [    1     1     2     2     2     2     1     1     4     0     5    55   863    10     0     3     3    22     4     5     9]
 [    4     0     0     3     2    11     2     6    27    27    16     9     9   860     2     2     3     2     0     4    12]
 [   10     4     1    28     9     0     0     2    33    15     8     2     4     6   958     0     1     2     8     1     6]
 [    2     0     2     1     4     2     4     2     0     5     1     9    14     3     1   985     7    14     0     4     6]
 [    1     8     4     2    10     7     0     3     8     1     3     7     7     3     4     9   970     1     1     6    17]
 [    5     0     2     7     1     2     2     1     2     2     0    16    38     4     4     5     1   905     2     2     4]
 [    4     9     4    14     3     2     2    18     7     2    11     0     2     0    11     0     2     0   957     1     9]
 [    1     3     2     2     1     5    15     9     1     2     6    12    11    10     0     6     4     4     3   983     8]
 [  155   187   166   164   201   129    91   178   124   184   229   129   333   242   155    93   185   122   146   186 10533]]

2024-06-06 02:42:51,157 - ==> Best [Top1: 85.390   Top5: 97.872   Sparsity:0.00   Params: 424448 on epoch: 168]
2024-06-06 02:42:51,157 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:42:51,180 - 

2024-06-06 02:42:51,180 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:42:57,516 - Epoch: [172][  100/ 1218]    Overall Loss 0.325027    Objective Loss 0.325027                                        LR 0.000250    Time 0.063338    
2024-06-06 02:43:02,324 - Epoch: [172][  200/ 1218]    Overall Loss 0.322483    Objective Loss 0.322483                                        LR 0.000250    Time 0.055698    
2024-06-06 02:43:06,898 - Epoch: [172][  300/ 1218]    Overall Loss 0.320335    Objective Loss 0.320335                                        LR 0.000250    Time 0.052372    
2024-06-06 02:43:11,484 - Epoch: [172][  400/ 1218]    Overall Loss 0.321270    Objective Loss 0.321270                                        LR 0.000250    Time 0.050738    
2024-06-06 02:43:16,262 - Epoch: [172][  500/ 1218]    Overall Loss 0.320683    Objective Loss 0.320683                                        LR 0.000250    Time 0.050142    
2024-06-06 02:43:21,044 - Epoch: [172][  600/ 1218]    Overall Loss 0.321603    Objective Loss 0.321603                                        LR 0.000250    Time 0.049752    
2024-06-06 02:43:25,588 - Epoch: [172][  700/ 1218]    Overall Loss 0.320345    Objective Loss 0.320345                                        LR 0.000250    Time 0.049133    
2024-06-06 02:43:30,154 - Epoch: [172][  800/ 1218]    Overall Loss 0.321830    Objective Loss 0.321830                                        LR 0.000250    Time 0.048696    
2024-06-06 02:43:35,076 - Epoch: [172][  900/ 1218]    Overall Loss 0.322611    Objective Loss 0.322611                                        LR 0.000250    Time 0.048753    
2024-06-06 02:43:40,028 - Epoch: [172][ 1000/ 1218]    Overall Loss 0.322803    Objective Loss 0.322803                                        LR 0.000250    Time 0.048827    
2024-06-06 02:43:44,791 - Epoch: [172][ 1100/ 1218]    Overall Loss 0.323052    Objective Loss 0.323052                                        LR 0.000250    Time 0.048717    
2024-06-06 02:43:49,473 - Epoch: [172][ 1200/ 1218]    Overall Loss 0.322941    Objective Loss 0.322941                                        LR 0.000250    Time 0.048557    
2024-06-06 02:43:50,294 - Epoch: [172][ 1218/ 1218]    Overall Loss 0.323095    Objective Loss 0.323095    Top1 83.863081    Top5 98.044010    LR 0.000250    Time 0.048513    
2024-06-06 02:43:50,477 - --- validate (epoch=172)-----------
2024-06-06 02:43:50,477 - 34633 samples (256 per mini-batch)
2024-06-06 02:43:55,873 - Epoch: [172][  100/  136]    Loss 0.357749    Top1 83.558594    Top5 97.433594    
2024-06-06 02:43:57,557 - Epoch: [172][  136/  136]    Loss 0.355369    Top1 83.385788    Top5 97.531256    
2024-06-06 02:43:57,744 - ==> Top1: 83.386    Top5: 97.531    Loss: 0.355

2024-06-06 02:43:57,746 - ==> Confusion:
[[  839     2     0     0     2     1     0     1     9    66     0     1     2     1     3     0     0     1     0     1     2]
 [    3   946     1     0    20    24     2    10     4     3     3     3     3     1    10     0    11     2     6     3     8]
 [   11     2   871     3     1     3    14     9     0    10     5     1     8     0     5     5     5     1     3     4     9]
 [    7     4    14   882     5     2     2     3     3     4    16     1     6     2    40     1     0     3    14     1     6]
 [   36     5     0     0   953     8     1     0     1    20     0     1     4     3     6     4     7     0     0     0     5]
 [   13    17     4     4    11   885     2    28     5     3     2     2    14    18     4     1     7     3     3     9     8]
 [    3     1    20     0     1     3  1012     6     3     3     7     2     2     0     1     6     0     1     2     9     4]
 [    5     8    14     1     0    29     4   949     2     5     4     5     3     2     3     1     1     0    25     9     7]
 [    9     2     0     2     1     1     0     1   880    64     7     0     5     8    12     0     2     3     2     0     3]
 [   68     0     0     1     1     1     0     1    42   869     0     0     3     6     5     0     0     1     0     2     1]
 [    4     5    10     4     0     4     1     4    26     1   972     1     0     3     9     0     0     1    12     0     7]
 [    4     3     1     0     0    13     2     8     2     4     0   849    36    11     3    22    10    14     0    22     7]
 [    2     1     4     2     2     3     0     2     6     3     1    38   858     3     3     9     3    25     7    10    13]
 [    8     2     4     0     8     7     1     7    28    29     7    10     8   853     8     0     6     0     0     5    10]
 [   14     0     0     4     9     1     0     0    38    17     2     0     1     2   989     0     2     1    10     3     5]
 [    6     4     6     0     1     2     3     2     0     4     1     5     7     0     1   993    14     8     1     2     6]
 [   10     8     6     2     6     5     0     0     5     2     0     4     3     3     2     7   995     1     1     4     8]
 [    8     2     1     3     0     0     0     0     1     1     0     6    34     2     8    11     4   911     1     4     8]
 [    4     5     7     2     4     3     0    14    13     1     5     0     1     2    17     0     0     1   975     1     3]
 [    5     1     1     0     2     5    11     7     1     0     0    11     6     3     1     8     4     5     1  1002    14]
 [  356   153   189    69   245   137    78   147   208   192   130    96   276   210   248   104   191    99   169   239 10396]]

2024-06-06 02:43:57,748 - ==> Best [Top1: 85.390   Top5: 97.872   Sparsity:0.00   Params: 424448 on epoch: 168]
2024-06-06 02:43:57,748 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:43:57,763 - 

2024-06-06 02:43:57,763 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:44:04,028 - Epoch: [173][  100/ 1218]    Overall Loss 0.321389    Objective Loss 0.321389                                        LR 0.000250    Time 0.062622    
2024-06-06 02:44:08,680 - Epoch: [173][  200/ 1218]    Overall Loss 0.325304    Objective Loss 0.325304                                        LR 0.000250    Time 0.054565    
2024-06-06 02:44:13,351 - Epoch: [173][  300/ 1218]    Overall Loss 0.322300    Objective Loss 0.322300                                        LR 0.000250    Time 0.051936    
2024-06-06 02:44:18,251 - Epoch: [173][  400/ 1218]    Overall Loss 0.324330    Objective Loss 0.324330                                        LR 0.000250    Time 0.051197    
2024-06-06 02:44:23,181 - Epoch: [173][  500/ 1218]    Overall Loss 0.324861    Objective Loss 0.324861                                        LR 0.000250    Time 0.050814    
2024-06-06 02:44:28,021 - Epoch: [173][  600/ 1218]    Overall Loss 0.324375    Objective Loss 0.324375                                        LR 0.000250    Time 0.050408    
2024-06-06 02:44:32,695 - Epoch: [173][  700/ 1218]    Overall Loss 0.324082    Objective Loss 0.324082                                        LR 0.000250    Time 0.049881    
2024-06-06 02:44:37,390 - Epoch: [173][  800/ 1218]    Overall Loss 0.323258    Objective Loss 0.323258                                        LR 0.000250    Time 0.049513    
2024-06-06 02:44:42,126 - Epoch: [173][  900/ 1218]    Overall Loss 0.322533    Objective Loss 0.322533                                        LR 0.000250    Time 0.049272    
2024-06-06 02:44:47,186 - Epoch: [173][ 1000/ 1218]    Overall Loss 0.323373    Objective Loss 0.323373                                        LR 0.000250    Time 0.049402    
2024-06-06 02:44:52,005 - Epoch: [173][ 1100/ 1218]    Overall Loss 0.323173    Objective Loss 0.323173                                        LR 0.000250    Time 0.049290    
2024-06-06 02:44:56,727 - Epoch: [173][ 1200/ 1218]    Overall Loss 0.323407    Objective Loss 0.323407                                        LR 0.000250    Time 0.049116    
2024-06-06 02:44:57,548 - Epoch: [173][ 1218/ 1218]    Overall Loss 0.323612    Objective Loss 0.323612    Top1 83.863081    Top5 97.066015    LR 0.000250    Time 0.049064    
2024-06-06 02:44:57,721 - --- validate (epoch=173)-----------
2024-06-06 02:44:57,721 - 34633 samples (256 per mini-batch)
2024-06-06 02:45:03,440 - Epoch: [173][  100/  136]    Loss 0.369386    Top1 85.449219    Top5 97.761719    
2024-06-06 02:45:05,138 - Epoch: [173][  136/  136]    Loss 0.367020    Top1 85.331909    Top5 97.744925    
2024-06-06 02:45:05,331 - ==> Top1: 85.332    Top5: 97.745    Loss: 0.367

2024-06-06 02:45:05,332 - ==> Confusion:
[[  828     0     0     0    15     4     0     1     6    47     0     4     2     2     8     0     0     2     0     2    10]
 [    5   962     1     2    16    21     1     7     2     2     3     6     2     1     8     1     1     1     7     2    12]
 [    6     2   864    13     4     0    16     8     0     4     6     5     2     6     3     5     3     4     3     3    13]
 [    3     0     6   910     3     4     3     3     1     3    22     4     9     1    18     1     0     4     4     0    17]
 [   25     8     2     2   968     7     0     1     3     6     0     1     0     6    10     0     4     0     2     1     8]
 [    3    22     1     5    15   886     2    17     5     6     1    15     8    21     4     2     4     6     2     4    14]
 [    2     4    10     2     3    11   985     7     0     3     6     3     1     2     1    17     1     2     2    10    14]
 [    3     9    20     1     3    37     4   924     1     4     7    10     7     4     1     0     0     2    17    12    11]
 [   12     5     1     0     1     2     0     1   848    46    12     5     4    16    27     2     3     4     5     0     8]
 [   70     1     2     0    10     1     0     0    29   835     4     1     2    26     8     0     1     1     3     1     6]
 [    3     4     4     7     0     1     5     2    11     1   992     1     0    12     9     0     2     0     5     2     3]
 [    1     1     1     0     4    12     1     2     0     0     0   863    40     9     1    20     4    21     0    16    15]
 [    1     1     4     3     0     4     1     1     4     1     3    56   859     3     1     5     4    18     4     4    18]
 [    2     0     1     0     6     8     0     2     7    14     7     9     9   898     4     2     4     4     1     9    14]
 [    6     5     4    15    10     0     0     1    14     7     6     2     3     8  1009     0     0     0     4     0     4]
 [    8     1     3     1     4     0     6     1     0     3     0     9    13     1     0   999     3     6     0     1     7]
 [    5    11     1     2     8     3     1     0     6     3     0     4     2     3     2    19   965     1     1     5    30]
 [    3     1     0     0     1     1     2     1     1     5     0    13    39     3     3     7     2   915     2     0     6]
 [    3    13     6    10     4     0     1    12    10     2    10     3     5     1    26     0     1     0   934     1    16]
 [    1     4     2     0     3     9     6     8     0     1     2    19    13     5     0     3     8     7     3   976    18]
 [  153   140   140    80   235   147    57   117    79   109   161   139   288   232   183    85   103   102   102   146 11134]]

2024-06-06 02:45:05,335 - ==> Best [Top1: 85.390   Top5: 97.872   Sparsity:0.00   Params: 424448 on epoch: 168]
2024-06-06 02:45:05,335 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:45:05,358 - 

2024-06-06 02:45:05,358 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:45:11,686 - Epoch: [174][  100/ 1218]    Overall Loss 0.321534    Objective Loss 0.321534                                        LR 0.000250    Time 0.063259    
2024-06-06 02:45:16,427 - Epoch: [174][  200/ 1218]    Overall Loss 0.326599    Objective Loss 0.326599                                        LR 0.000250    Time 0.055324    
2024-06-06 02:45:21,211 - Epoch: [174][  300/ 1218]    Overall Loss 0.323016    Objective Loss 0.323016                                        LR 0.000250    Time 0.052824    
2024-06-06 02:45:25,875 - Epoch: [174][  400/ 1218]    Overall Loss 0.320964    Objective Loss 0.320964                                        LR 0.000250    Time 0.051272    
2024-06-06 02:45:30,464 - Epoch: [174][  500/ 1218]    Overall Loss 0.319680    Objective Loss 0.319680                                        LR 0.000250    Time 0.050192    
2024-06-06 02:45:35,045 - Epoch: [174][  600/ 1218]    Overall Loss 0.318642    Objective Loss 0.318642                                        LR 0.000250    Time 0.049460    
2024-06-06 02:45:39,645 - Epoch: [174][  700/ 1218]    Overall Loss 0.319680    Objective Loss 0.319680                                        LR 0.000250    Time 0.048963    
2024-06-06 02:45:44,240 - Epoch: [174][  800/ 1218]    Overall Loss 0.321546    Objective Loss 0.321546                                        LR 0.000250    Time 0.048584    
2024-06-06 02:45:48,805 - Epoch: [174][  900/ 1218]    Overall Loss 0.322352    Objective Loss 0.322352                                        LR 0.000250    Time 0.048255    
2024-06-06 02:45:53,434 - Epoch: [174][ 1000/ 1218]    Overall Loss 0.323509    Objective Loss 0.323509                                        LR 0.000250    Time 0.048057    
2024-06-06 02:45:58,011 - Epoch: [174][ 1100/ 1218]    Overall Loss 0.325042    Objective Loss 0.325042                                        LR 0.000250    Time 0.047847    
2024-06-06 02:46:02,577 - Epoch: [174][ 1200/ 1218]    Overall Loss 0.324651    Objective Loss 0.324651                                        LR 0.000250    Time 0.047663    
2024-06-06 02:46:03,423 - Epoch: [174][ 1218/ 1218]    Overall Loss 0.325059    Objective Loss 0.325059    Top1 86.063570    Top5 97.555012    LR 0.000250    Time 0.047653    
2024-06-06 02:46:03,593 - --- validate (epoch=174)-----------
2024-06-06 02:46:03,594 - 34633 samples (256 per mini-batch)
2024-06-06 02:46:09,304 - Epoch: [174][  100/  136]    Loss 0.354699    Top1 85.074219    Top5 97.816406    
2024-06-06 02:46:10,945 - Epoch: [174][  136/  136]    Loss 0.351985    Top1 85.034505    Top5 97.744925    
2024-06-06 02:46:11,144 - ==> Top1: 85.035    Top5: 97.745    Loss: 0.352

2024-06-06 02:46:11,145 - ==> Confusion:
[[  821     3     4     0    13     1     1     0     6    59     0     1     1     2     2     1     3     0     1     2    10]
 [    2   955     1     0    20    24     2    16     4     1     4     1     4     4     2     1     5     2     7     2     6]
 [    6     4   870    10     2     1    24    11     1     2    11     3     2     4     0     0     2     0     5     4     8]
 [    4     2     9   936     3     6     2     0     4     2     9     0     9     1     8     1     2     3     8     2     5]
 [   12    12     1     1   974     6     0     2     2    11     1     4     1     3     4     1     5     0     3     6     5]
 [    4    23     4     3    11   888     3    41     3     2     5     9     5    11     0     2     2     3     4     7    13]
 [    1     2    16     0     1     3  1023     2     4     3     7     1     2     1     0     4     1     1     1     8     5]
 [    1     6     7     1     3    31     8   947     1     3     6     8     3     4     0     1     0     2    29     9     7]
 [    9     4     1     3     2     1     0     3   866    48    22     3     4     7     6     1     7     1     4     1     9]
 [   63     1     0     0     8     2     5     3    36   859     2     1     0    13     2     0     0     1     1     0     4]
 [    2     6     3     6     1     4     3     7    14     3   993     0     2     5     3     0     0     0     6     1     5]
 [    3     3     1     3     1    11     2     4     1     0     1   887    34     6     0    13     2    14     2    13    10]
 [    0     3     4     8     0     4     2     4     3     0     5    52   856     1     1     5     6    16     5     3    17]
 [    6     2     0     1     2    14     3     3    11    19     8    10     7   875     2     1     8     0     1     9    19]
 [   10     4     2    28     9     1     0     1    54    16     8     2     0     3   915     0     3     0    19     0    23]
 [    2     1     6     1     2     2    11     1     2     1     0     8    12     4     0   988     7    10     0     3     5]
 [    2     7     7     2    10     7     1     0     5     1     4     3     2     1     1    11   985     1     3     5    14]
 [    2     0     1    10     2     2     3     1     1     1     1    13    32     1     2    15     2   899     2     0    15]
 [    0    10     6    13     2     2     2    14     7     2     4     0     2     3     8     0     2     0   970     1    10]
 [    1     5     3     0     3    10     7    13     0     0     2    15     7     3     0     4     5     1     0   997    12]
 [  177   166   161   106   196   172    98   168   114   130   176   123   263   166    89    85   180    61   135   220 10946]]

2024-06-06 02:46:11,147 - ==> Best [Top1: 85.390   Top5: 97.872   Sparsity:0.00   Params: 424448 on epoch: 168]
2024-06-06 02:46:11,148 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:46:11,170 - 

2024-06-06 02:46:11,170 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:46:17,419 - Epoch: [175][  100/ 1218]    Overall Loss 0.311093    Objective Loss 0.311093                                        LR 0.000250    Time 0.062460    
2024-06-06 02:46:22,058 - Epoch: [175][  200/ 1218]    Overall Loss 0.316225    Objective Loss 0.316225                                        LR 0.000250    Time 0.054413    
2024-06-06 02:46:26,711 - Epoch: [175][  300/ 1218]    Overall Loss 0.320992    Objective Loss 0.320992                                        LR 0.000250    Time 0.051779    
2024-06-06 02:46:31,319 - Epoch: [175][  400/ 1218]    Overall Loss 0.320249    Objective Loss 0.320249                                        LR 0.000250    Time 0.050348    
2024-06-06 02:46:36,000 - Epoch: [175][  500/ 1218]    Overall Loss 0.322101    Objective Loss 0.322101                                        LR 0.000250    Time 0.049636    
2024-06-06 02:46:40,870 - Epoch: [175][  600/ 1218]    Overall Loss 0.322706    Objective Loss 0.322706                                        LR 0.000250    Time 0.049477    
2024-06-06 02:46:45,602 - Epoch: [175][  700/ 1218]    Overall Loss 0.324237    Objective Loss 0.324237                                        LR 0.000250    Time 0.049166    
2024-06-06 02:46:50,201 - Epoch: [175][  800/ 1218]    Overall Loss 0.322748    Objective Loss 0.322748                                        LR 0.000250    Time 0.048766    
2024-06-06 02:46:55,079 - Epoch: [175][  900/ 1218]    Overall Loss 0.323337    Objective Loss 0.323337                                        LR 0.000250    Time 0.048765    
2024-06-06 02:46:59,714 - Epoch: [175][ 1000/ 1218]    Overall Loss 0.323491    Objective Loss 0.323491                                        LR 0.000250    Time 0.048522    
2024-06-06 02:47:04,304 - Epoch: [175][ 1100/ 1218]    Overall Loss 0.324358    Objective Loss 0.324358                                        LR 0.000250    Time 0.048282    
2024-06-06 02:47:08,919 - Epoch: [175][ 1200/ 1218]    Overall Loss 0.324650    Objective Loss 0.324650                                        LR 0.000250    Time 0.048103    
2024-06-06 02:47:09,834 - Epoch: [175][ 1218/ 1218]    Overall Loss 0.324368    Objective Loss 0.324368    Top1 85.574572    Top5 98.533007    LR 0.000250    Time 0.048143    
2024-06-06 02:47:10,024 - --- validate (epoch=175)-----------
2024-06-06 02:47:10,024 - 34633 samples (256 per mini-batch)
2024-06-06 02:47:15,620 - Epoch: [175][  100/  136]    Loss 0.359652    Top1 83.218750    Top5 97.609375    
2024-06-06 02:47:17,305 - Epoch: [175][  136/  136]    Loss 0.359386    Top1 83.175006    Top5 97.554356    
2024-06-06 02:47:17,512 - ==> Top1: 83.175    Top5: 97.554    Loss: 0.359

2024-06-06 02:47:17,513 - ==> Confusion:
[[  838     3     6     0     8     2     0     0     7    46     1     1     1     6     3     2     0     1     3     0     3]
 [    2   986     0     1    12    19     2     6     2     4     1     1     0     1     5     0     5     2     5     1     8]
 [    5     3   888    14     2     2    12     8     0     3    12     1     2     6     1     1     4     0     0     0     6]
 [    2     6     6   920     2     7     3     1     1     1    15     1     4     1    21     3     6     6     6     0     4]
 [   21    22     5     0   948     9     0     1     2    10     3     0     0     4    11     5     6     1     1     3     2]
 [    2    42     2     4     8   902     1    31     1     2     3     6     8     9     1     3     1     0     0     9     8]
 [    2    11    10     2     2     5  1011     8     0     1     8     3     0     4     0     3     0     6     0     4     6]
 [    1    22    10     3     1    29     4   944     2     4     5     7     2     4     1     1     0     3    20     7     7]
 [    8    12     1     2     1     5     0     3   865    31    17     2     2    15    22     1     1     6     6     0     2]
 [   65     2     1     0     7     5     0     3    51   813     3     2     0    22    14     6     1     2     1     0     3]
 [    1     6     2     8     2     4     2     4    11     1   993     1     1     8     8     0     0     1     5     2     4]
 [    0     4     2     0     2    23     3     8     0     2     0   891    18    12     1     4     4    22     1     9     5]
 [    1     3     3    10     1     8     0     6     1     0     6    64   839     7     1     7     4    20     2     7     5]
 [    3     4     1     1     4    16     3     4    16    10    11     6     3   895     2     4     4     3     1     5     5]
 [    9     5     2    11     3     2     0     1    20    13     9     3     0     4   995     0     1     0    12     2     6]
 [    1     4     7     1     3     1     7     0     1     3     1    13     2     3     0   984    13    19     0     1     2]
 [    1    13     3     0     6    10     0     1     0     3     3     4     0     3     1     7   992     6     2     5    12]
 [    3     4     2     1     2     4     2     2     2     1     0    20    11     0     1     6     3   932     4     3     2]
 [    0    15     5    21     6     3     1    21     4     1     7     2     2     3    14     0     1     0   944     2     6]
 [    0    14     4     0     2    13    19    10     1     1     2    16     6     2     1    10     9     3     0   969     6]
 [  166   298   172   126   213   218   111   157    88    92   237   150   285   269   215   128   281   112   148   210 10256]]

2024-06-06 02:47:17,515 - ==> Best [Top1: 85.390   Top5: 97.872   Sparsity:0.00   Params: 424448 on epoch: 168]
2024-06-06 02:47:17,515 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:47:17,538 - 

2024-06-06 02:47:17,538 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:47:23,728 - Epoch: [176][  100/ 1218]    Overall Loss 0.320686    Objective Loss 0.320686                                        LR 0.000250    Time 0.061865    
2024-06-06 02:47:28,469 - Epoch: [176][  200/ 1218]    Overall Loss 0.319898    Objective Loss 0.319898                                        LR 0.000250    Time 0.054630    
2024-06-06 02:47:33,076 - Epoch: [176][  300/ 1218]    Overall Loss 0.320942    Objective Loss 0.320942                                        LR 0.000250    Time 0.051770    
2024-06-06 02:47:37,696 - Epoch: [176][  400/ 1218]    Overall Loss 0.319591    Objective Loss 0.319591                                        LR 0.000250    Time 0.050374    
2024-06-06 02:47:42,375 - Epoch: [176][  500/ 1218]    Overall Loss 0.318448    Objective Loss 0.318448                                        LR 0.000250    Time 0.049652    
2024-06-06 02:47:47,007 - Epoch: [176][  600/ 1218]    Overall Loss 0.320325    Objective Loss 0.320325                                        LR 0.000250    Time 0.049094    
2024-06-06 02:47:51,940 - Epoch: [176][  700/ 1218]    Overall Loss 0.320667    Objective Loss 0.320667                                        LR 0.000250    Time 0.049126    
2024-06-06 02:47:56,949 - Epoch: [176][  800/ 1218]    Overall Loss 0.320679    Objective Loss 0.320679                                        LR 0.000250    Time 0.049243    
2024-06-06 02:48:01,498 - Epoch: [176][  900/ 1218]    Overall Loss 0.320703    Objective Loss 0.320703                                        LR 0.000250    Time 0.048825    
2024-06-06 02:48:06,123 - Epoch: [176][ 1000/ 1218]    Overall Loss 0.321502    Objective Loss 0.321502                                        LR 0.000250    Time 0.048565    
2024-06-06 02:48:10,723 - Epoch: [176][ 1100/ 1218]    Overall Loss 0.322347    Objective Loss 0.322347                                        LR 0.000250    Time 0.048330    
2024-06-06 02:48:15,428 - Epoch: [176][ 1200/ 1218]    Overall Loss 0.321536    Objective Loss 0.321536                                        LR 0.000250    Time 0.048222    
2024-06-06 02:48:16,312 - Epoch: [176][ 1218/ 1218]    Overall Loss 0.321488    Objective Loss 0.321488    Top1 85.085575    Top5 98.044010    LR 0.000250    Time 0.048233    
2024-06-06 02:48:16,479 - --- validate (epoch=176)-----------
2024-06-06 02:48:16,480 - 34633 samples (256 per mini-batch)
2024-06-06 02:48:22,160 - Epoch: [176][  100/  136]    Loss 0.366783    Top1 84.273438    Top5 97.621094    
2024-06-06 02:48:23,867 - Epoch: [176][  136/  136]    Loss 0.361641    Top1 84.303988    Top5 97.695839    
2024-06-06 02:48:24,069 - ==> Top1: 84.304    Top5: 97.696    Loss: 0.362

2024-06-06 02:48:24,070 - ==> Confusion:
[[  837     0     4     1     9     4     0     1     7    32     0     1     5     3     5     0     4     3     2     2    11]
 [    1   942     2     4    16    30     1     9     5     1     2     0     4     2    10     1    11     2     7     4     9]
 [    4     1   863    13     2     7    17    11     0     2    10     2     8     3     2     4     6     2     1     4     8]
 [    2     4     3   929     0     8     0     1     1     3     7     1    15     3    16     3     2     2     5     3     8]
 [   17    10     3     0   952    11     1     0     1     9     0     4     3     2    11     6     9     0     3     2    10]
 [    1    13     4     2     8   927     2     8     1     3     5    10    15    18     0     3    10     2     2     6     3]
 [    2     4     8     1     1     9  1005     5     3     1     6     2     3     2     0     6     1     3     1    16     7]
 [    2    11     8     2     3    57     2   916     2     3     2    10     7     6     1     1     2     2    10    20    10]
 [   11     3     0     3     3     1     0     1   859    32    16     3     8    20    17     0     1     4    10     1     9]
 [   96     1     4     1     6     3     0     3    43   787     1     1     5    29     8     1     0     5     1     0     6]
 [    0     3     6    16     2     2     9     1     7     1   979     0     6    12     5     0     1     1     5     2     6]
 [    1     0     1     0     3     9     1     3     1     0     1   855    65     7     0    15     6    17     0    19     7]
 [    2     1     2     3     4     2     1     2     1     0     0    33   902     0     2     8     1    16     3     4     8]
 [    1     1     2     1     2    17     1     1     5     7     9    12    16   897     2     4     3     2     0     8    10]
 [    8     3     3    28     3     2     0     0    14    11    12     1    11     5   965     0     0     3    16     0    13]
 [    2     0     2     1     4     0     4     1     0     2     0     6    12     6     0  1000    10    11     0     2     3]
 [    5     8     2     3     6     5     1     2     2     2     3     3    11     3     0    14   980     0     0     4    18]
 [    1     4     0     4     3     3     2     1     1     3     0     6    54     4     1    12     3   897     0     1     5]
 [    1     9     8    16     1     5     0    21     4     2     9     1    13     0     6     1     0     0   951     5     5]
 [    1     7     2     0     1    10     2     5     0     0     0    13    19     4     0     6     6     3     0   990    19]
 [  147   159   140   151   146   258    74   121    78    69   148   111   439   225   118   158   244    93   109   181 10763]]

2024-06-06 02:48:24,072 - ==> Best [Top1: 85.390   Top5: 97.872   Sparsity:0.00   Params: 424448 on epoch: 168]
2024-06-06 02:48:24,073 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:48:24,095 - 

2024-06-06 02:48:24,095 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:48:30,374 - Epoch: [177][  100/ 1218]    Overall Loss 0.318913    Objective Loss 0.318913                                        LR 0.000250    Time 0.062764    
2024-06-06 02:48:35,126 - Epoch: [177][  200/ 1218]    Overall Loss 0.319498    Objective Loss 0.319498                                        LR 0.000250    Time 0.055128    
2024-06-06 02:48:39,960 - Epoch: [177][  300/ 1218]    Overall Loss 0.317599    Objective Loss 0.317599                                        LR 0.000250    Time 0.052859    
2024-06-06 02:48:44,776 - Epoch: [177][  400/ 1218]    Overall Loss 0.316325    Objective Loss 0.316325                                        LR 0.000250    Time 0.051679    
2024-06-06 02:48:49,582 - Epoch: [177][  500/ 1218]    Overall Loss 0.318438    Objective Loss 0.318438                                        LR 0.000250    Time 0.050950    
2024-06-06 02:48:54,347 - Epoch: [177][  600/ 1218]    Overall Loss 0.320399    Objective Loss 0.320399                                        LR 0.000250    Time 0.050397    
2024-06-06 02:48:59,120 - Epoch: [177][  700/ 1218]    Overall Loss 0.321389    Objective Loss 0.321389                                        LR 0.000250    Time 0.050013    
2024-06-06 02:49:03,902 - Epoch: [177][  800/ 1218]    Overall Loss 0.321086    Objective Loss 0.321086                                        LR 0.000250    Time 0.049737    
2024-06-06 02:49:08,910 - Epoch: [177][  900/ 1218]    Overall Loss 0.321537    Objective Loss 0.321537                                        LR 0.000250    Time 0.049772    
2024-06-06 02:49:13,713 - Epoch: [177][ 1000/ 1218]    Overall Loss 0.323212    Objective Loss 0.323212                                        LR 0.000250    Time 0.049596    
2024-06-06 02:49:18,458 - Epoch: [177][ 1100/ 1218]    Overall Loss 0.322710    Objective Loss 0.322710                                        LR 0.000250    Time 0.049399    
2024-06-06 02:49:23,227 - Epoch: [177][ 1200/ 1218]    Overall Loss 0.322844    Objective Loss 0.322844                                        LR 0.000250    Time 0.049255    
2024-06-06 02:49:24,108 - Epoch: [177][ 1218/ 1218]    Overall Loss 0.323212    Objective Loss 0.323212    Top1 82.396088    Top5 98.288509    LR 0.000250    Time 0.049250    
2024-06-06 02:49:24,292 - --- validate (epoch=177)-----------
2024-06-06 02:49:24,292 - 34633 samples (256 per mini-batch)
2024-06-06 02:49:29,745 - Epoch: [177][  100/  136]    Loss 0.358150    Top1 83.800781    Top5 97.546875    
2024-06-06 02:49:31,415 - Epoch: [177][  136/  136]    Loss 0.354823    Top1 83.882424    Top5 97.482170    
2024-06-06 02:49:31,604 - ==> Top1: 83.882    Top5: 97.482    Loss: 0.355

2024-06-06 02:49:31,605 - ==> Confusion:
[[  856     0     2     1    11     3     0     1     8    34     0     0     0     1     1     2     0     3     1     2     5]
 [    4   976     4     2    20    17     1     8     5     2     1     1     2     1     7     0     2     1     3     1     5]
 [   12     2   893     5     1     1    13     9     0     5     3     4     3     0     3     2     5     1     3     3     2]
 [    8     4    15   927     2     5     2     3     1     1     7     1     4     3    16     1     1     5     5     2     3]
 [   27     8    10     1   959     3     3     3     1     8     0     0     1     3     9     2     8     1     1     1     5]
 [    6    31     3     1    12   878     3    40     1     9     6    12     9    13     3     0     3     0     1     7     5]
 [    3     5    18     1     0     2  1023     4     1     4     2     5     2     0     1     1     2     3     1     5     3]
 [    3    11    11     2     4    19     2   964     3     2     3     8     6     3     0     1     0     4    14     7    10]
 [   10     5     1     1     2     1     1     2   865    55     9     3     6     3    22     1     2     4     2     0     7]
 [   85     1     3     1     6     3     0     1    35   842     1     1     0     5     4     0     1     3     3     1     5]
 [    1     7    10    12     3     2     7     7     9     3   965     2     0     6    12     1     3     1     7     1     5]
 [    4     1     5     0     2    15     4     5     3     1     2   880    15     6     0    11     9    27     0    16     5]
 [    2     2     5     3     4     4     0     6     0     3     0    44   829     4     1     6     7    58     2     4    11]
 [    7     0     2     0     4    10     0     5    13    33     7    10     7   872     2     1     2     8     1    10     7]
 [   14     7     2    14    12     1     1     2    18    14     7     1     3     2   970     1     1     1    13     2    12]
 [    7     1     5     0     2     1     6     1     0     3     0    13     6     0     1   988    15    10     0     2     5]
 [    2    15     7     0     7     4     3     0     3     1     2     4     3     2     1     7   991     4     1     6     9]
 [    1     4     2     0     1     2     3     1     0     2     1    10    13     0     2     4     1   954     1     2     1]
 [    3    13     7     6     0     4     1    19     5     1     4     2     2     2    18     1     1     3   954     3     9]
 [    7     2     7     0     2    10     6    12     1     1     3    15     7     0     0     7     5     3     1   990     9]
 [  216   231   235   108   199   177   111   174    89   136   129   155   298   196   167    92   220   138   104   282 10475]]

2024-06-06 02:49:31,607 - ==> Best [Top1: 85.390   Top5: 97.872   Sparsity:0.00   Params: 424448 on epoch: 168]
2024-06-06 02:49:31,607 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:49:31,630 - 

2024-06-06 02:49:31,630 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:49:37,908 - Epoch: [178][  100/ 1218]    Overall Loss 0.323766    Objective Loss 0.323766                                        LR 0.000250    Time 0.062758    
2024-06-06 02:49:42,596 - Epoch: [178][  200/ 1218]    Overall Loss 0.322036    Objective Loss 0.322036                                        LR 0.000250    Time 0.054806    
2024-06-06 02:49:47,408 - Epoch: [178][  300/ 1218]    Overall Loss 0.325555    Objective Loss 0.325555                                        LR 0.000250    Time 0.052573    
2024-06-06 02:49:52,322 - Epoch: [178][  400/ 1218]    Overall Loss 0.326026    Objective Loss 0.326026                                        LR 0.000250    Time 0.051709    
2024-06-06 02:49:57,307 - Epoch: [178][  500/ 1218]    Overall Loss 0.324813    Objective Loss 0.324813                                        LR 0.000250    Time 0.051334    
2024-06-06 02:50:02,112 - Epoch: [178][  600/ 1218]    Overall Loss 0.323672    Objective Loss 0.323672                                        LR 0.000250    Time 0.050782    
2024-06-06 02:50:06,902 - Epoch: [178][  700/ 1218]    Overall Loss 0.323166    Objective Loss 0.323166                                        LR 0.000250    Time 0.050369    
2024-06-06 02:50:11,718 - Epoch: [178][  800/ 1218]    Overall Loss 0.324164    Objective Loss 0.324164                                        LR 0.000250    Time 0.050089    
2024-06-06 02:50:16,525 - Epoch: [178][  900/ 1218]    Overall Loss 0.323391    Objective Loss 0.323391                                        LR 0.000250    Time 0.049864    
2024-06-06 02:50:21,238 - Epoch: [178][ 1000/ 1218]    Overall Loss 0.323712    Objective Loss 0.323712                                        LR 0.000250    Time 0.049588    
2024-06-06 02:50:25,827 - Epoch: [178][ 1100/ 1218]    Overall Loss 0.323527    Objective Loss 0.323527                                        LR 0.000250    Time 0.049250    
2024-06-06 02:50:30,402 - Epoch: [178][ 1200/ 1218]    Overall Loss 0.323674    Objective Loss 0.323674                                        LR 0.000250    Time 0.048957    
2024-06-06 02:50:31,192 - Epoch: [178][ 1218/ 1218]    Overall Loss 0.323875    Objective Loss 0.323875    Top1 87.286064    Top5 97.555012    LR 0.000250    Time 0.048882    
2024-06-06 02:50:31,378 - --- validate (epoch=178)-----------
2024-06-06 02:50:31,379 - 34633 samples (256 per mini-batch)
2024-06-06 02:50:37,082 - Epoch: [178][  100/  136]    Loss 0.369710    Top1 84.304688    Top5 97.589844    
2024-06-06 02:50:38,739 - Epoch: [178][  136/  136]    Loss 0.374598    Top1 84.168279    Top5 97.447521    
2024-06-06 02:50:38,902 - ==> Top1: 84.168    Top5: 97.448    Loss: 0.375

2024-06-06 02:50:38,903 - ==> Confusion:
[[  822     1     0     0     3     2     1     0     7    72     0     1     2     3     3     1     0     1     1     2     9]
 [    5   973     2     0    18    14     3     9     7     2     6     0     3     0     5     1     5     0     4     1     5]
 [    9     2   874     8     7     2    23     6     0     8     6     2     2     2     1     3     1     0     7     3     4]
 [    4     5    12   914     0     7     4     1     1     7    14     0     2     1    20     1     0     6    10     0     7]
 [   33    14     4     1   925    15     1     0     2    26     1     3     1     5     8     4     1     0     1     2     7]
 [    7    23     0     2    13   898     3    26     2    12     4     5     6    13     1     0     4     3     2     8    11]
 [    3     5    11     1     4     5  1011     8     0     3     5     1     0     2     0     5     1     0     1     7    13]
 [    3     9    13     3     1    37     5   938     1    10    13     4     2     2     2     0     0     0    16    13     5]
 [   10     3     2     1     3     2     0     0   880    56    11     3     1     7     8     0     3     3     3     0     6]
 [   51     2     1     0     3     2     0     0    43   881     0     0     1     7     4     1     0     2     0     2     1]
 [    1     6     5     9     1     4     5     6    13     4   984     0     1     7     5     0     0     0     6     0     7]
 [    5     1     5     1     2    30     7     3     2     1     1   833    20    14     2    16     3    25     1    30     9]
 [    6     1     2     5     1    10     3     5     6     4     0    47   810    11     0    10     5    43     4    12    10]
 [    3     2     0     1     4    13     1     3    17    26    11     4     3   885     5     0     1     5     1     8     8]
 [    7     5     2    17     6     2     0     0    45    25     7     1     0     7   946     0     3     2    10     2    11]
 [    6     1     3     1     6     4     6     1     2     5     0     8     7     2     0   979    12     9     1     6     7]
 [    4     9     5     2     9     4     2     0     4     2     3     1     1     3     2     8   995     1     1     5    11]
 [    5     3     2     1     0     3     6     4     4     5     1     6    21     1     6    10     3   913     1     1     9]
 [    4     6    10    12     2     4     1    14     8     4     9     2     2     1    19     1     0     0   942     5    12]
 [    1     8     4     0     3     7    12     4     0     3     2     8     6     1     1     2     3     1     1  1012     9]
 [  179   270   215    92   171   164   126   107   149   218   150    78   210   211   150   103   167    74   119   244 10735]]

2024-06-06 02:50:38,905 - ==> Best [Top1: 85.390   Top5: 97.872   Sparsity:0.00   Params: 424448 on epoch: 168]
2024-06-06 02:50:38,906 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:50:38,930 - 

2024-06-06 02:50:38,930 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:50:45,115 - Epoch: [179][  100/ 1218]    Overall Loss 0.331235    Objective Loss 0.331235                                        LR 0.000250    Time 0.061822    
2024-06-06 02:50:49,793 - Epoch: [179][  200/ 1218]    Overall Loss 0.326168    Objective Loss 0.326168                                        LR 0.000250    Time 0.054292    
2024-06-06 02:50:54,407 - Epoch: [179][  300/ 1218]    Overall Loss 0.324530    Objective Loss 0.324530                                        LR 0.000250    Time 0.051567    
2024-06-06 02:50:59,018 - Epoch: [179][  400/ 1218]    Overall Loss 0.322898    Objective Loss 0.322898                                        LR 0.000250    Time 0.050200    
2024-06-06 02:51:03,666 - Epoch: [179][  500/ 1218]    Overall Loss 0.321459    Objective Loss 0.321459                                        LR 0.000250    Time 0.049451    
2024-06-06 02:51:08,503 - Epoch: [179][  600/ 1218]    Overall Loss 0.319432    Objective Loss 0.319432                                        LR 0.000250    Time 0.049268    
2024-06-06 02:51:13,238 - Epoch: [179][  700/ 1218]    Overall Loss 0.317931    Objective Loss 0.317931                                        LR 0.000250    Time 0.048991    
2024-06-06 02:51:18,095 - Epoch: [179][  800/ 1218]    Overall Loss 0.318495    Objective Loss 0.318495                                        LR 0.000250    Time 0.048936    
2024-06-06 02:51:22,934 - Epoch: [179][  900/ 1218]    Overall Loss 0.319574    Objective Loss 0.319574                                        LR 0.000250    Time 0.048874    
2024-06-06 02:51:27,709 - Epoch: [179][ 1000/ 1218]    Overall Loss 0.318723    Objective Loss 0.318723                                        LR 0.000250    Time 0.048759    
2024-06-06 02:51:32,338 - Epoch: [179][ 1100/ 1218]    Overall Loss 0.318257    Objective Loss 0.318257                                        LR 0.000250    Time 0.048533    
2024-06-06 02:51:37,044 - Epoch: [179][ 1200/ 1218]    Overall Loss 0.317903    Objective Loss 0.317903                                        LR 0.000250    Time 0.048409    
2024-06-06 02:51:37,857 - Epoch: [179][ 1218/ 1218]    Overall Loss 0.317887    Objective Loss 0.317887    Top1 85.819071    Top5 98.777506    LR 0.000250    Time 0.048360    
2024-06-06 02:51:38,032 - --- validate (epoch=179)-----------
2024-06-06 02:51:38,032 - 34633 samples (256 per mini-batch)
2024-06-06 02:51:43,485 - Epoch: [179][  100/  136]    Loss 0.342786    Top1 83.230469    Top5 97.507812    
2024-06-06 02:51:45,175 - Epoch: [179][  136/  136]    Loss 0.346228    Top1 83.154795    Top5 97.537031    
2024-06-06 02:51:45,379 - ==> Top1: 83.155    Top5: 97.537    Loss: 0.346

2024-06-06 02:51:45,380 - ==> Confusion:
[[  841     2     1     1    10     4     0     3    10    38     0     3     1     2     4     2     2     0     1     2     4]
 [    3   980     0     3     9    10     2    18     1     4     4     2     3     1     1     0     6     1     8     0     7]
 [    8     2   874     7     3     5    23     9     0     2     8     1     2     3     1     3     7     1     2     5     4]
 [    3     6     8   920     2     4     2     3     1     0     9     2     7     4    25     1     3     3     5     4     4]
 [   19    13     3     0   960     5     2     3     4     9     4     2     2     6     6     2     2     1     3     1     7]
 [    3    34     4     4     9   890     2    33     3     4     4    10     5    22     1     0     6     0     1     5     3]
 [    3     2    19     2     2     4   989    10     0     2     5     9     1     2     0     8     4     3     2    12     7]
 [    0    14    10     0     0    12     6   978     0     2     8     8     3     2     1     2     2     1    15     9     4]
 [   11     3     1     4     1     2     0     1   862    41    12     3     5    21    22     0     3     1     3     1     5]
 [   85     4     3     1    11     0     0     5    31   821     1     3     1    19    10     1     1     2     0     0     2]
 [    0     5     7    11     0     4     3     7     9     3   975     2     0    13     8     0     3     0     7     1     6]
 [    0     3     1     1     1    14     2     4     1     1     0   897    22    11     1    13     3    16     0    17     3]
 [    3     0     4     9     0     1     0     6     0     1     2    70   833     9     2    10     5    21     4     5    10]
 [    1     0     0     1     1     8     2     2    15    11     8    10     3   920     4     2     1     3     1     5     3]
 [    8     3     2    16    12     2     0     2    11     8     4     3     4     3  1003     0     2     3     6     1     5]
 [    0     1     4     0     3     1     5     0     0     2     0    22     7     3     0   991     8     9     1     3     6]
 [    4    14     2     2     7     4     0     4     3     0     3     7     2     2     2     8   995     2     0     6     5]
 [    2     3     1     1     2     1     0     1     0     2     2    10    20     6     6     7     5   927     2     1     6]
 [    0    10     9    10     1     0     0    26     6     1     3     1     1     1    17     1     1     1   960     1     8]
 [    1     6     5     1     0     7     9     8     1     2     0    20     6     7     1     6     4     2     1   994     7]
 [  215   259   224   130   184   186   110   207   104   121   159   178   316   280   211   123   270    65   151   250 10189]]

2024-06-06 02:51:45,382 - ==> Best [Top1: 85.390   Top5: 97.872   Sparsity:0.00   Params: 424448 on epoch: 168]
2024-06-06 02:51:45,382 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:51:45,405 - 

2024-06-06 02:51:45,405 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:51:51,867 - Epoch: [180][  100/ 1218]    Overall Loss 0.294411    Objective Loss 0.294411                                        LR 0.000125    Time 0.064601    
2024-06-06 02:51:56,580 - Epoch: [180][  200/ 1218]    Overall Loss 0.301218    Objective Loss 0.301218                                        LR 0.000125    Time 0.055857    
2024-06-06 02:52:01,332 - Epoch: [180][  300/ 1218]    Overall Loss 0.299820    Objective Loss 0.299820                                        LR 0.000125    Time 0.053070    
2024-06-06 02:52:06,253 - Epoch: [180][  400/ 1218]    Overall Loss 0.296858    Objective Loss 0.296858                                        LR 0.000125    Time 0.052099    
2024-06-06 02:52:11,008 - Epoch: [180][  500/ 1218]    Overall Loss 0.296782    Objective Loss 0.296782                                        LR 0.000125    Time 0.051185    
2024-06-06 02:52:15,772 - Epoch: [180][  600/ 1218]    Overall Loss 0.296234    Objective Loss 0.296234                                        LR 0.000125    Time 0.050592    
2024-06-06 02:52:20,502 - Epoch: [180][  700/ 1218]    Overall Loss 0.296442    Objective Loss 0.296442                                        LR 0.000125    Time 0.050119    
2024-06-06 02:52:25,205 - Epoch: [180][  800/ 1218]    Overall Loss 0.296230    Objective Loss 0.296230                                        LR 0.000125    Time 0.049731    
2024-06-06 02:52:30,122 - Epoch: [180][  900/ 1218]    Overall Loss 0.296760    Objective Loss 0.296760                                        LR 0.000125    Time 0.049666    
2024-06-06 02:52:34,790 - Epoch: [180][ 1000/ 1218]    Overall Loss 0.296673    Objective Loss 0.296673                                        LR 0.000125    Time 0.049365    
2024-06-06 02:52:39,663 - Epoch: [180][ 1100/ 1218]    Overall Loss 0.297164    Objective Loss 0.297164                                        LR 0.000125    Time 0.049306    
2024-06-06 02:52:44,503 - Epoch: [180][ 1200/ 1218]    Overall Loss 0.296384    Objective Loss 0.296384                                        LR 0.000125    Time 0.049224    
2024-06-06 02:52:45,340 - Epoch: [180][ 1218/ 1218]    Overall Loss 0.296397    Objective Loss 0.296397    Top1 87.775061    Top5 98.044010    LR 0.000125    Time 0.049183    
2024-06-06 02:52:45,519 - --- validate (epoch=180)-----------
2024-06-06 02:52:45,519 - 34633 samples (256 per mini-batch)
2024-06-06 02:52:51,117 - Epoch: [180][  100/  136]    Loss 0.332057    Top1 85.304688    Top5 97.828125    
2024-06-06 02:52:52,794 - Epoch: [180][  136/  136]    Loss 0.336423    Top1 85.282823    Top5 97.759362    
2024-06-06 02:52:52,969 - ==> Top1: 85.283    Top5: 97.759    Loss: 0.336

2024-06-06 02:52:52,970 - ==> Confusion:
[[  800     2     6     2    10     2     0     2     4    82     0     0     4     1     3     0     2     0     0     2     9]
 [    2   960     3     3    20    10     4    16     3     3     1     1     3     0     1     1     0     4    13     4    11]
 [    1     1   897     8     1     1    12    13     2     8     4     1     0     4     1     0     4     1     2     5     4]
 [    3     3     8   930     2     3     2     3     3     2    12     0     3     1     5     3     1     5    16     0    11]
 [   11     3     5     0   980     8     0     1     4    10     2     1     3     4     5     4     2     0     3     1     7]
 [    2    32     7     4    11   872     5    34     3     5     3    11     8    10     3     2     6     2     3    10    10]
 [    0     3    24     2     2     1  1010     2     1     3     5     4     0     1     0    10     1     3     1     7     6]
 [    0     8    11     2     0    28     1   957     1     3     5     5    10     0     1     2     1     1    29     5     7]
 [    5     2     1     1     1     2     0     2   863    57    15     1     6    13    14     1     2     1     8     0     7]
 [   47     3     3     0     6     2     0     1    33   873     0     1     0    14    10     0     1     1     2     1     3]
 [    0     3     8    14     0     2     4     3    11     3   988     0     0     5     4     0     0     0    10     0     9]
 [    2     2     2     1     0    16     3     6     1     2     1   867    39     7     3    21     2    17     2    11     6]
 [    1     3     3     4     2     3     2     2     1     2     2    37   878     3     1     8     3    22     5     3    10]
 [    1     0     3     3     1    10     2     7    11    21    12    11    13   867     6     3     5     1     1    10    13]
 [    3     5     5    21    12     2     0     1    22    11     6     1     2     2   975     0     2     0    12     1    15]
 [    1     1     1     0     3     1     4     0     0     9     0     6    12     1     2  1007     3     8     2     2     3]
 [    5     9     3     1    11     4     0     0     3     3     2     3     2     1     5     5   988     1     2     7    17]
 [    0     3     2     2     0     1     1     0     3     4     0     9    26     0     2     6     4   933     2     1     6]
 [    1     5     8    10     6     1     0    16     1     4     6     2     2     0     9     1     0     0   977     1     8]
 [    2     5     5     1     2     7    10     7     2     2     1    11     7     4     0     5     4     2     5   992    14]
 [  136   186   220   101   167   114    89   146   102   174   145    87   268   169   136   125   161   101   167   216 10922]]

2024-06-06 02:52:52,973 - ==> Best [Top1: 85.390   Top5: 97.872   Sparsity:0.00   Params: 424448 on epoch: 168]
2024-06-06 02:52:52,973 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:52:52,996 - 

2024-06-06 02:52:52,996 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:52:59,347 - Epoch: [181][  100/ 1218]    Overall Loss 0.286075    Objective Loss 0.286075                                        LR 0.000125    Time 0.063484    
2024-06-06 02:53:03,920 - Epoch: [181][  200/ 1218]    Overall Loss 0.290105    Objective Loss 0.290105                                        LR 0.000125    Time 0.054595    
2024-06-06 02:53:08,460 - Epoch: [181][  300/ 1218]    Overall Loss 0.289672    Objective Loss 0.289672                                        LR 0.000125    Time 0.051523    
2024-06-06 02:53:13,042 - Epoch: [181][  400/ 1218]    Overall Loss 0.293397    Objective Loss 0.293397                                        LR 0.000125    Time 0.050093    
2024-06-06 02:53:17,751 - Epoch: [181][  500/ 1218]    Overall Loss 0.291381    Objective Loss 0.291381                                        LR 0.000125    Time 0.049490    
2024-06-06 02:53:22,347 - Epoch: [181][  600/ 1218]    Overall Loss 0.290876    Objective Loss 0.290876                                        LR 0.000125    Time 0.048898    
2024-06-06 02:53:26,944 - Epoch: [181][  700/ 1218]    Overall Loss 0.291510    Objective Loss 0.291510                                        LR 0.000125    Time 0.048477    
2024-06-06 02:53:31,612 - Epoch: [181][  800/ 1218]    Overall Loss 0.290429    Objective Loss 0.290429                                        LR 0.000125    Time 0.048250    
2024-06-06 02:53:36,233 - Epoch: [181][  900/ 1218]    Overall Loss 0.290938    Objective Loss 0.290938                                        LR 0.000125    Time 0.048021    
2024-06-06 02:53:40,945 - Epoch: [181][ 1000/ 1218]    Overall Loss 0.290993    Objective Loss 0.290993                                        LR 0.000125    Time 0.047929    
2024-06-06 02:53:45,684 - Epoch: [181][ 1100/ 1218]    Overall Loss 0.291353    Objective Loss 0.291353                                        LR 0.000125    Time 0.047877    
2024-06-06 02:53:50,380 - Epoch: [181][ 1200/ 1218]    Overall Loss 0.291380    Objective Loss 0.291380                                        LR 0.000125    Time 0.047799    
2024-06-06 02:53:51,194 - Epoch: [181][ 1218/ 1218]    Overall Loss 0.291581    Objective Loss 0.291581    Top1 87.530562    Top5 97.799511    LR 0.000125    Time 0.047760    
2024-06-06 02:53:51,392 - --- validate (epoch=181)-----------
2024-06-06 02:53:51,393 - 34633 samples (256 per mini-batch)
2024-06-06 02:53:57,091 - Epoch: [181][  100/  136]    Loss 0.328459    Top1 84.589844    Top5 97.621094    
2024-06-06 02:53:58,770 - Epoch: [181][  136/  136]    Loss 0.333633    Top1 84.595617    Top5 97.638091    
2024-06-06 02:53:58,938 - ==> Top1: 84.596    Top5: 97.638    Loss: 0.334

2024-06-06 02:53:58,940 - ==> Confusion:
[[  824     0     5     1     9     1     1     1    12    47     1     2     5     5     3     3     4     1     1     0     5]
 [    2   962     4     0    14    18     2     9     5     3     6     4     8     1     2     0     8     1     3     1    10]
 [    5     6   871     5     2     2    23    10     1     5     5     2     2     3     1     3     9     2     6     3     4]
 [    3     3     8   922     4     3     5     2     2     1    14     1     8     2    13     3     0     8     8     2     4]
 [   14    11     4     0   965     5     0     1     2     9     3     2     1     6     4     5     8     1     5     1     7]
 [    1    19     1     4     8   928     3    13     3     1     2     6    16     9     1     1     5     4     1     8     9]
 [    0     3    15     1     2     1  1041     2     1     3     3     1     1     0     1     2     3     0     1     2     3]
 [    3     4    11     0     3    37     4   939     2     3     6     7     3     4     2     0     0     1    23    17     8]
 [    6     2     4     1     2     2     0     0   883    34    16     5     7     7    15     0     1     4     4     2     7]
 [   61     0     2     0     6     3     0     2    56   846     0     1     3    11     4     2     0     2     0     0     2]
 [    2     8     5    10     2     2     3     3    10     4   976     0     1     8     8     0     1     1     8     2    10]
 [    2     2     0     0     0    14     1     3     0     1     1   883    53     4     0    10     3    20     1    11     2]
 [    2     1     4     4     3     4     2     0     1     2     0    45   866     1     0    11     5    28     4     0    12]
 [    3     3     1     1     4    14     0     2    15    12     5    13     6   897     2     3     4     5     0     5     6]
 [    8     2     1    13    10     4     0     1    34    12     8     1     5     5   974     0     2     1     9     1     7]
 [    1     1     4     0     4     0     9     0     1     6     0     9     9     2     0   984    13     9     1     3    10]
 [    1     9     2     2     5    11     1     1     3     2     2     7     7     1     2    10   990     4     0     3     9]
 [    0     1     1     0     3     3     3     2     0     3     1    12    15     5     1     4     0   947     0     1     3]
 [    3     4     9     9     1     1     3     9     7     0     2     2     5     0    12     0     3     0   974     7     7]
 [    1     5     5     1     5     6     9     4     1     0     1    13    12     8     0     6    11     2     3   995     0]
 [  143   198   176    69   190   174    95   117   111   130   154   165   365   224   133   109   277   117   152   202 10631]]

2024-06-06 02:53:58,942 - ==> Best [Top1: 85.390   Top5: 97.872   Sparsity:0.00   Params: 424448 on epoch: 168]
2024-06-06 02:53:58,942 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:53:58,966 - 

2024-06-06 02:53:58,966 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:54:05,161 - Epoch: [182][  100/ 1218]    Overall Loss 0.291679    Objective Loss 0.291679                                        LR 0.000125    Time 0.061929    
2024-06-06 02:54:09,894 - Epoch: [182][  200/ 1218]    Overall Loss 0.293467    Objective Loss 0.293467                                        LR 0.000125    Time 0.054616    
2024-06-06 02:54:14,526 - Epoch: [182][  300/ 1218]    Overall Loss 0.289044    Objective Loss 0.289044                                        LR 0.000125    Time 0.051843    
2024-06-06 02:54:19,151 - Epoch: [182][  400/ 1218]    Overall Loss 0.290251    Objective Loss 0.290251                                        LR 0.000125    Time 0.050440    
2024-06-06 02:54:24,008 - Epoch: [182][  500/ 1218]    Overall Loss 0.290215    Objective Loss 0.290215                                        LR 0.000125    Time 0.050063    
2024-06-06 02:54:28,558 - Epoch: [182][  600/ 1218]    Overall Loss 0.290119    Objective Loss 0.290119                                        LR 0.000125    Time 0.049300    
2024-06-06 02:54:33,116 - Epoch: [182][  700/ 1218]    Overall Loss 0.289664    Objective Loss 0.289664                                        LR 0.000125    Time 0.048765    
2024-06-06 02:54:37,662 - Epoch: [182][  800/ 1218]    Overall Loss 0.288752    Objective Loss 0.288752                                        LR 0.000125    Time 0.048350    
2024-06-06 02:54:42,283 - Epoch: [182][  900/ 1218]    Overall Loss 0.288516    Objective Loss 0.288516                                        LR 0.000125    Time 0.048103    
2024-06-06 02:54:47,107 - Epoch: [182][ 1000/ 1218]    Overall Loss 0.288662    Objective Loss 0.288662                                        LR 0.000125    Time 0.048115    
2024-06-06 02:54:51,862 - Epoch: [182][ 1100/ 1218]    Overall Loss 0.288485    Objective Loss 0.288485                                        LR 0.000125    Time 0.048062    
2024-06-06 02:54:56,437 - Epoch: [182][ 1200/ 1218]    Overall Loss 0.289150    Objective Loss 0.289150                                        LR 0.000125    Time 0.047868    
2024-06-06 02:54:57,269 - Epoch: [182][ 1218/ 1218]    Overall Loss 0.288964    Objective Loss 0.288964    Top1 88.264059    Top5 97.555012    LR 0.000125    Time 0.047842    
2024-06-06 02:54:57,445 - --- validate (epoch=182)-----------
2024-06-06 02:54:57,446 - 34633 samples (256 per mini-batch)
2024-06-06 02:55:03,024 - Epoch: [182][  100/  136]    Loss 0.322935    Top1 85.738281    Top5 97.957031    
2024-06-06 02:55:04,713 - Epoch: [182][  136/  136]    Loss 0.323473    Top1 85.765022    Top5 97.897959    
2024-06-06 02:55:04,893 - ==> Top1: 85.765    Top5: 97.898    Loss: 0.323

2024-06-06 02:55:04,894 - ==> Confusion:
[[  793     2     4     1    11     0     0     1     4    81     1     2     5     3     5     0     3     0     1     0    14]
 [    4   958     4     1    10    28     6    14     1     1     3     3     1     0     4     0     4     1     9     1    10]
 [    3     0   869     8     2     0    33    10     1     7     5     6     2     5     3     1     1     2     5     1     6]
 [    5     2     7   923     2     5     2     1     2     2    13     2     8     3     8     3     1     6    10     0    11]
 [   13    16     3     0   943    11     2     6     1    13     2     3     0     3     5     2    11     0     7     1    12]
 [    2    11     1     1     5   928     4    26     0     7     3     5     5    21     1     1     2     0     5     5    10]
 [    1     2     7     1     0     2  1034     4     0     2     3     6     1     1     0     3     2     2     1     7     7]
 [    3     5     8     1     2    30     5   968     1     3     2     5     2     5     0     1     1     0    19    10     6]
 [    7     2     1     0     0     3     0     4   866    50    14     5     8    18     7     0     2     0     8     0     7]
 [   36     0     3     0     4     1     0     3    37   884     0     0     1    17     4     1     3     1     2     0     4]
 [    1     1     5     8     0     2     2     6    14     1   994     0     2     7     1     0     1     0     7     1    11]
 [    0     0     5     1     0    12     2     3     2     0     2   907    28     6     0    10     6    11     1     9     6]
 [    2     0     4     3     3     4     1     1     1     1     0    54   864     2     0    11     6    18     6     5     9]
 [    3     1     1     2     5    10     0     5     6    16    12    12     5   894     2     4     1     3     2     5    12]
 [    4     2     1    20     8     3     0     2    32     4     5     2     3     9   960     1     3     2    23     0    14]
 [    3     0     4     0     2     3     5     0     0     3     0    18    10     0     0   998     7     7     0     2     4]
 [    1     2     4     0     3     6     3     1     4     4     4     4     4     2     2     4  1002     1     4     4    13]
 [    1     0     1     0     1     2     4     1     0     2     0    11    20     2     3    10     1   937     2     3     4]
 [    4     4     7     5     1     4     0    21     8     1     3     1     3     0     6     0     3     1   980     3     3]
 [    0     6     2     0     0     5    12    11     3     2     2    14     9     5     0    10     4     4     2   985    12]
 [  101   134   178    86   123   204   108   168    90   137   121   140   284   202   107    96   202    79   165   191 11016]]

2024-06-06 02:55:04,896 - ==> Best [Top1: 85.765   Top5: 97.898   Sparsity:0.00   Params: 424448 on epoch: 182]
2024-06-06 02:55:04,896 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:55:04,926 - 

2024-06-06 02:55:04,926 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:55:11,203 - Epoch: [183][  100/ 1218]    Overall Loss 0.303394    Objective Loss 0.303394                                        LR 0.000125    Time 0.062739    
2024-06-06 02:55:16,027 - Epoch: [183][  200/ 1218]    Overall Loss 0.293868    Objective Loss 0.293868                                        LR 0.000125    Time 0.055476    
2024-06-06 02:55:20,605 - Epoch: [183][  300/ 1218]    Overall Loss 0.289912    Objective Loss 0.289912                                        LR 0.000125    Time 0.052239    
2024-06-06 02:55:25,357 - Epoch: [183][  400/ 1218]    Overall Loss 0.290145    Objective Loss 0.290145                                        LR 0.000125    Time 0.051054    
2024-06-06 02:55:29,920 - Epoch: [183][  500/ 1218]    Overall Loss 0.289709    Objective Loss 0.289709                                        LR 0.000125    Time 0.049964    
2024-06-06 02:55:34,551 - Epoch: [183][  600/ 1218]    Overall Loss 0.290302    Objective Loss 0.290302                                        LR 0.000125    Time 0.049342    
2024-06-06 02:55:39,119 - Epoch: [183][  700/ 1218]    Overall Loss 0.289707    Objective Loss 0.289707                                        LR 0.000125    Time 0.048816    
2024-06-06 02:55:43,778 - Epoch: [183][  800/ 1218]    Overall Loss 0.290831    Objective Loss 0.290831                                        LR 0.000125    Time 0.048536    
2024-06-06 02:55:48,455 - Epoch: [183][  900/ 1218]    Overall Loss 0.289448    Objective Loss 0.289448                                        LR 0.000125    Time 0.048337    
2024-06-06 02:55:53,088 - Epoch: [183][ 1000/ 1218]    Overall Loss 0.289561    Objective Loss 0.289561                                        LR 0.000125    Time 0.048135    
2024-06-06 02:55:57,695 - Epoch: [183][ 1100/ 1218]    Overall Loss 0.288590    Objective Loss 0.288590                                        LR 0.000125    Time 0.047945    
2024-06-06 02:56:02,518 - Epoch: [183][ 1200/ 1218]    Overall Loss 0.289118    Objective Loss 0.289118                                        LR 0.000125    Time 0.047967    
2024-06-06 02:56:03,406 - Epoch: [183][ 1218/ 1218]    Overall Loss 0.289005    Objective Loss 0.289005    Top1 85.330073    Top5 97.066015    LR 0.000125    Time 0.047987    
2024-06-06 02:56:03,564 - --- validate (epoch=183)-----------
2024-06-06 02:56:03,564 - 34633 samples (256 per mini-batch)
2024-06-06 02:56:09,067 - Epoch: [183][  100/  136]    Loss 0.327603    Top1 86.070312    Top5 97.992188    
2024-06-06 02:56:10,748 - Epoch: [183][  136/  136]    Loss 0.332671    Top1 85.857419    Top5 97.944157    
2024-06-06 02:56:10,907 - ==> Top1: 85.857    Top5: 97.944    Loss: 0.333

2024-06-06 02:56:10,908 - ==> Confusion:
[[  808     2     3     3     9     0     0     2     7    63     1     4     3     4     5     1     2     0     2     1    11]
 [    1   963     2     3    13    21     1     4     4     2     2     6     4     0     4     2     6     3    14     3     5]
 [    3     4   871     5     3     0    29     7     2     5     8     4     1     6     0     3     3     2     5     3     6]
 [    2     3     4   930     4     4     2     4     0     6    12     2     6     4    14     2     1     5     4     2     5]
 [   13    14     4     2   952     4     1     3     5    11     1     3     5     3    10     5     4     3     3     0     8]
 [    2    20     3     4    10   883     9    34     3     3     5    17     7    15     3     3     4     2     3     6     7]
 [    0     3     9     1     0     3  1021     5     0     3     2     6     1     1     2     5     3     4     2     7     8]
 [    2     6     5     3     1    16     5   965     2     2     1    10     3     6     1     1     3     0    27    12     6]
 [    5     1     1     1     1     1     0     2   842    54    17     5     3    17    35     2     3     3     4     1     4]
 [   48     1     0     1     3     0     0     1    33   879     0     1     3    10    13     1     2     4     0     0     1]
 [    0     2     5    13     1     2     5     4     9     2   987     2     1    11     7     0     1     0     3     3     6]
 [    0     1     0     0     0     8     1     1     2     2     0   883    30     8     2    24     3    17     1    15    13]
 [    1     0     2     6     2     3     1     1     3     2     2    52   846     3     1     9     4    40     2     4    11]
 [    1     2     1     1     2    12     0     4     8    14     8     8     5   893     6     7     5     2     1     6    15]
 [   11     2     3    17     4     0     0     0    14     9     6     3     0     4   996     2     3     2    13     1     8]
 [    0     3     2     0     1     0     5     0     1     6     0    19     8     0     0   987     9    16     0     2     7]
 [    1     4     3     2     5     6     1     1     6     4     1     8     6     2     3    11   989     2     3     3    11]
 [    1     1     1     2     0     1     0     0     0     4     0    15    13     0     1    10     3   940     5     2     6]
 [    2     3     8     9     1     1     1    11     6     1     6     2     1     2    14     0     0     0   976     4    10]
 [    1     2     0     0     0     7    14     2     1     1     1    19     9     3     0     7     6     1     7  1000     7]
 [  131   154   127    81   143   145    88   150    94   121   114   163   225   169   169   132   142   107   140   213 11124]]

2024-06-06 02:56:10,910 - ==> Best [Top1: 85.857   Top5: 97.944   Sparsity:0.00   Params: 424448 on epoch: 183]
2024-06-06 02:56:10,910 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:56:10,937 - 

2024-06-06 02:56:10,937 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:56:17,336 - Epoch: [184][  100/ 1218]    Overall Loss 0.286274    Objective Loss 0.286274                                        LR 0.000125    Time 0.063960    
2024-06-06 02:56:22,136 - Epoch: [184][  200/ 1218]    Overall Loss 0.281853    Objective Loss 0.281853                                        LR 0.000125    Time 0.055973    
2024-06-06 02:56:26,882 - Epoch: [184][  300/ 1218]    Overall Loss 0.278726    Objective Loss 0.278726                                        LR 0.000125    Time 0.053128    
2024-06-06 02:56:31,659 - Epoch: [184][  400/ 1218]    Overall Loss 0.279126    Objective Loss 0.279126                                        LR 0.000125    Time 0.051785    
2024-06-06 02:56:36,424 - Epoch: [184][  500/ 1218]    Overall Loss 0.282266    Objective Loss 0.282266                                        LR 0.000125    Time 0.050952    
2024-06-06 02:56:41,060 - Epoch: [184][  600/ 1218]    Overall Loss 0.283263    Objective Loss 0.283263                                        LR 0.000125    Time 0.050184    
2024-06-06 02:56:45,705 - Epoch: [184][  700/ 1218]    Overall Loss 0.283369    Objective Loss 0.283369                                        LR 0.000125    Time 0.049649    
2024-06-06 02:56:50,373 - Epoch: [184][  800/ 1218]    Overall Loss 0.282425    Objective Loss 0.282425                                        LR 0.000125    Time 0.049275    
2024-06-06 02:56:55,036 - Epoch: [184][  900/ 1218]    Overall Loss 0.283348    Objective Loss 0.283348                                        LR 0.000125    Time 0.048979    
2024-06-06 02:56:59,693 - Epoch: [184][ 1000/ 1218]    Overall Loss 0.284194    Objective Loss 0.284194                                        LR 0.000125    Time 0.048736    
2024-06-06 02:57:04,293 - Epoch: [184][ 1100/ 1218]    Overall Loss 0.285203    Objective Loss 0.285203                                        LR 0.000125    Time 0.048485    
2024-06-06 02:57:08,949 - Epoch: [184][ 1200/ 1218]    Overall Loss 0.285071    Objective Loss 0.285071                                        LR 0.000125    Time 0.048323    
2024-06-06 02:57:09,747 - Epoch: [184][ 1218/ 1218]    Overall Loss 0.285112    Objective Loss 0.285112    Top1 83.618582    Top5 97.066015    LR 0.000125    Time 0.048262    
2024-06-06 02:57:09,949 - --- validate (epoch=184)-----------
2024-06-06 02:57:09,949 - 34633 samples (256 per mini-batch)
2024-06-06 02:57:15,535 - Epoch: [184][  100/  136]    Loss 0.327478    Top1 85.039062    Top5 97.714844    
2024-06-06 02:57:17,302 - Epoch: [184][  136/  136]    Loss 0.334582    Top1 84.739988    Top5 97.655415    
2024-06-06 02:57:17,467 - ==> Top1: 84.740    Top5: 97.655    Loss: 0.335

2024-06-06 02:57:17,468 - ==> Confusion:
[[  832     1     2     0    14     5     0     1     7    53     0     2     2     1     5     0     0     1     1     1     3]
 [    2   959     1     0    14    28     1     8     3     2     4     3     5     0     6     0     3     2    11     6     5]
 [    7     1   893     4     8     2    17     7     2     2     4     3     0     2     2     3     2     1     3     4     3]
 [    7     1     7   926     0     2     2     2     2     2     9     5    11     1    22     1     0     5     3     2     6]
 [   16     8     2     1   965     9     1     2     2     6     2     3     2     2     9     4     4     0     2     2    12]
 [    8    24     4     2    12   912     5    19     1     5     1     8    10    10     2     1     4     1     4     6     4]
 [    4     4    21     4     0     3  1004     3     1     1     2     7     2     1     0     6     1     5     1     9     7]
 [    7    10    12     1     2    38     2   919     2     2     5    19     7     0     2     1     0     1    24    12    11]
 [   13     2     3     0     2     4     0     0   884    39     7     8     4     6    12     1     2     2     5     0     8]
 [   77     0     2     0     5     5     0     1    25   842     1     1     1    13    13     1     1     2     1     0    10]
 [    2     4     8    19     1     1     4     2    13     2   962     1     4     5     8     0     0     0    13     3    12]
 [    4     2     2     1     1    11     1     1     1     0     0   908    35     5     0     3     2    14     2    14     4]
 [    4     0     1     3     1     3     0     2     0     1     1    44   890     0     0     5     1    21     4     6     8]
 [    4     0     3     3     5    23     0     3     5    18    12     7    11   868     6     0     1     3     0    11    18]
 [    9     2     2    24     7     1     0     1    23     8     7     4     1     2   991     0     0     0     6     0    10]
 [    7     0     6     0     1     0     4     0     0     0     0    24    18     3     1   972     6    16     0     5     3]
 [    7    11     4     5     9     8     1     1     2     0     3     7     1     0     2     8   977     3     1    12    10]
 [    4     0     2     3     2     2     1     0     0     0     0    10    36     2     2     3     0   925     1     6     6]
 [    4     8     6    10     4     1     0    18     4     0     3     4     5     1    18     0     2     0   962     3     5]
 [    5     1     7     0     2    10     4     3     0     0     0    12    13     4     0     5     4     2     2  1007     7]
 [  218   153   220   137   191   183    82   123    76   102   133   181   361   140   174    87   141   102   146   232 10750]]

2024-06-06 02:57:17,471 - ==> Best [Top1: 85.857   Top5: 97.944   Sparsity:0.00   Params: 424448 on epoch: 183]
2024-06-06 02:57:17,471 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:57:17,494 - 

2024-06-06 02:57:17,494 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:57:23,696 - Epoch: [185][  100/ 1218]    Overall Loss 0.286379    Objective Loss 0.286379                                        LR 0.000125    Time 0.061998    
2024-06-06 02:57:28,487 - Epoch: [185][  200/ 1218]    Overall Loss 0.287783    Objective Loss 0.287783                                        LR 0.000125    Time 0.054941    
2024-06-06 02:57:33,091 - Epoch: [185][  300/ 1218]    Overall Loss 0.285489    Objective Loss 0.285489                                        LR 0.000125    Time 0.051970    
2024-06-06 02:57:37,769 - Epoch: [185][  400/ 1218]    Overall Loss 0.284063    Objective Loss 0.284063                                        LR 0.000125    Time 0.050667    
2024-06-06 02:57:42,376 - Epoch: [185][  500/ 1218]    Overall Loss 0.285622    Objective Loss 0.285622                                        LR 0.000125    Time 0.049745    
2024-06-06 02:57:46,950 - Epoch: [185][  600/ 1218]    Overall Loss 0.285920    Objective Loss 0.285920                                        LR 0.000125    Time 0.049075    
2024-06-06 02:57:51,616 - Epoch: [185][  700/ 1218]    Overall Loss 0.284638    Objective Loss 0.284638                                        LR 0.000125    Time 0.048727    
2024-06-06 02:57:56,223 - Epoch: [185][  800/ 1218]    Overall Loss 0.285794    Objective Loss 0.285794                                        LR 0.000125    Time 0.048392    
2024-06-06 02:58:00,908 - Epoch: [185][  900/ 1218]    Overall Loss 0.285248    Objective Loss 0.285248                                        LR 0.000125    Time 0.048218    
2024-06-06 02:58:05,594 - Epoch: [185][ 1000/ 1218]    Overall Loss 0.284899    Objective Loss 0.284899                                        LR 0.000125    Time 0.048080    
2024-06-06 02:58:10,457 - Epoch: [185][ 1100/ 1218]    Overall Loss 0.284057    Objective Loss 0.284057                                        LR 0.000125    Time 0.048129    
2024-06-06 02:58:15,471 - Epoch: [185][ 1200/ 1218]    Overall Loss 0.284261    Objective Loss 0.284261                                        LR 0.000125    Time 0.048294    
2024-06-06 02:58:16,306 - Epoch: [185][ 1218/ 1218]    Overall Loss 0.284130    Objective Loss 0.284130    Top1 87.530562    Top5 99.022005    LR 0.000125    Time 0.048267    
2024-06-06 02:58:16,491 - --- validate (epoch=185)-----------
2024-06-06 02:58:16,491 - 34633 samples (256 per mini-batch)
2024-06-06 02:58:22,160 - Epoch: [185][  100/  136]    Loss 0.334526    Top1 85.535156    Top5 97.753906    
2024-06-06 02:58:23,791 - Epoch: [185][  136/  136]    Loss 0.335936    Top1 85.606214    Top5 97.733376    
2024-06-06 02:58:23,967 - ==> Top1: 85.606    Top5: 97.733    Loss: 0.336

2024-06-06 02:58:23,969 - ==> Confusion:
[[  807     0     3     1    11     3     1     0     3    76     0     4     3     2     5     1     1     3     0     0     7]
 [    3   964     1     1    20    17     3    15     0     2     3     0     4     1     5     1     2     0     8     2    11]
 [    6     2   904     9     3     3    13     4     0     2     3     3     1     2     2     2     3     1     1     3     3]
 [    3     1    12   927     2     5     3     5     2     4    11     1     1     1    16     2     2     6     2     2     8]
 [    8    10     5     1   974     8     2     3     1    11     0     2     3     0     9     5     4     0     1     1     6]
 [    5    23     3     4    16   904     5    20     0     9     4     6     4    13     4     2     4     2     1     2    12]
 [    3     2    12     0     2     4  1020     2     0     4     5     0     4     0     2     7     1     2     3     9     4]
 [    3     9     9     4     1    26     1   961     1     5     2     5     4     1     5     0     1     2    19    13     5]
 [   13     5     2     2     0     2     2     1   832    69    11     2     3     9    28     1     1     2    13     2     2]
 [   40     1     2     1    11     1     0     1    20   896     1     0     2     6     9     0     0     2     0     0     8]
 [    2     2     7    11     2     2     2     6     9     2   987     0     0     7    11     0     0     1     6     1     6]
 [    6     3     2     0     0     9     2     4     2     3     2   893    33     6     2    10     3    13     1     9     8]
 [    2     3     3     4     1     1     2     6     3     3     4    47   843     5     4    10     3    28     4     1    18]
 [    4     1     1     2     2     9     0     4    11    21    12    10     3   891     7     1     2     4     1     8     7]
 [   10     1     4    14     6     2     0     2    10     8     5     0     1     2  1010     1     0     1    10     1    10]
 [    5     1     2     1     1     0     6     2     0     5     2    12     8     0     0   999     8     6     2     1     5]
 [    6     8     3     0     7     5     2     0     3     3     2     6     1     0     1     7   988     2     3     9    16]
 [    3     0     1     5     3     0     1     0     2     2     0    15    28     0     3    15     1   917     1     3     5]
 [    3     5     8    10     3     3     1    16     2     1     6     1     2     1    15     0     0     0   968     1    12]
 [    1     4     6     0     1     7    13     8     0     2     1    15     6     2     1     8     4     2     9   988    10]
 [  160   158   179    87   203   158   104   144    71   135   162   127   242   184   204   109   124    86   128   192 10975]]

2024-06-06 02:58:23,972 - ==> Best [Top1: 85.857   Top5: 97.944   Sparsity:0.00   Params: 424448 on epoch: 183]
2024-06-06 02:58:23,972 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:58:23,995 - 

2024-06-06 02:58:23,995 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:58:30,464 - Epoch: [186][  100/ 1218]    Overall Loss 0.286515    Objective Loss 0.286515                                        LR 0.000125    Time 0.064668    
2024-06-06 02:58:35,057 - Epoch: [186][  200/ 1218]    Overall Loss 0.288573    Objective Loss 0.288573                                        LR 0.000125    Time 0.055287    
2024-06-06 02:58:39,670 - Epoch: [186][  300/ 1218]    Overall Loss 0.286302    Objective Loss 0.286302                                        LR 0.000125    Time 0.052229    
2024-06-06 02:58:44,267 - Epoch: [186][  400/ 1218]    Overall Loss 0.285819    Objective Loss 0.285819                                        LR 0.000125    Time 0.050660    
2024-06-06 02:58:48,834 - Epoch: [186][  500/ 1218]    Overall Loss 0.283755    Objective Loss 0.283755                                        LR 0.000125    Time 0.049659    
2024-06-06 02:58:53,447 - Epoch: [186][  600/ 1218]    Overall Loss 0.284741    Objective Loss 0.284741                                        LR 0.000125    Time 0.049068    
2024-06-06 02:58:58,162 - Epoch: [186][  700/ 1218]    Overall Loss 0.284864    Objective Loss 0.284864                                        LR 0.000125    Time 0.048791    
2024-06-06 02:59:02,788 - Epoch: [186][  800/ 1218]    Overall Loss 0.285802    Objective Loss 0.285802                                        LR 0.000125    Time 0.048472    
2024-06-06 02:59:07,461 - Epoch: [186][  900/ 1218]    Overall Loss 0.285904    Objective Loss 0.285904                                        LR 0.000125    Time 0.048269    
2024-06-06 02:59:12,145 - Epoch: [186][ 1000/ 1218]    Overall Loss 0.286114    Objective Loss 0.286114                                        LR 0.000125    Time 0.048125    
2024-06-06 02:59:16,854 - Epoch: [186][ 1100/ 1218]    Overall Loss 0.285828    Objective Loss 0.285828                                        LR 0.000125    Time 0.048029    
2024-06-06 02:59:21,465 - Epoch: [186][ 1200/ 1218]    Overall Loss 0.286365    Objective Loss 0.286365                                        LR 0.000125    Time 0.047867    
2024-06-06 02:59:22,297 - Epoch: [186][ 1218/ 1218]    Overall Loss 0.286414    Objective Loss 0.286414    Top1 87.286064    Top5 98.533007    LR 0.000125    Time 0.047842    
2024-06-06 02:59:22,485 - --- validate (epoch=186)-----------
2024-06-06 02:59:22,485 - 34633 samples (256 per mini-batch)
2024-06-06 02:59:28,233 - Epoch: [186][  100/  136]    Loss 0.326435    Top1 85.242188    Top5 97.718750    
2024-06-06 02:59:29,928 - Epoch: [186][  136/  136]    Loss 0.326757    Top1 85.230849    Top5 97.733376    
2024-06-06 02:59:30,108 - ==> Top1: 85.231    Top5: 97.733    Loss: 0.327

2024-06-06 02:59:30,109 - ==> Confusion:
[[  836     3     1     1    14     6     0     0     2    49     0     2     0     2     4     3     3     0     0     0     5]
 [    4   979     1     0    16    20     0     6     2     1     5     1     2     0     4     0     3     2     8     2     7]
 [    4     2   887     7     5     6     7     5     2     6     4     6     5     1     2     3     5     0     4     4     5]
 [    6     0    12   915     4     5     3     1     1     2    11     1     7     4    19     1     2     2     8     0    12]
 [   11    14     2     2   962     4     1     2     0    15     1     0     1     2     9     5     7     0     3     3    10]
 [    6    18     2     6     4   918     3    18     0     4     1    15     4    15     2     2     5     1     2     7    10]
 [    3     3    21     3     1     2  1007     3     0     0     4     3     6     1     3     7     3     2     2     7     5]
 [    3    13    10     3     1    38     1   937     3     2     5     9     9     6     0     1     1     1    14    12     8]
 [   15     6     1     1     2     3     0     1   886    37    10     3     3     9    15     0     2     1     3     0     4]
 [   76     0     0     1     5     4     0     1    44   833     2     1     2    19     4     1     3     1     0     0     4]
 [    2     5     9    13     1     1     1     5    15     0   983     1     0     5    10     0     2     0     3     1     7]
 [    2     1     2     1     3    14     2     1     0     3     0   920    21     2     1     7     2    10     1     8    10]
 [    2     2     6     6     3     1     3     1     1     1     2    58   865     1     0     4     6    21     0     5     7]
 [    2     2     0     1     3    14     0     4     9    16    12    12     3   894     2     3     4     4     1     6     9]
 [   11     2     3     6    10     3     0     2    27    12     8     3     2     0   992     0     0     0     7     1     9]
 [    6     1     1     0     3     1     3     0     0     6     0    13     7     1     0   997     8    11     1     3     4]
 [    2     6     4     0     3     7     0     1     0     2     1     4     3     3     1    11  1002     0     0     7    15]
 [    1     2     1     2     1     2     1     1     1     3     1    16    23     1     3    12     3   928     1     2     0]
 [    5     7     7    11     2     2     1    20     4     2     6     1     1     1    14     0     1     2   954     3    14]
 [    1     4     4     1     4    10    15     2     0     1     2    21    10     2     1     3     5     3     1   988    10]
 [  216   165   153    92   176   184    68   102    98   101   142   169   296   187   182   105   233    81   120   227 10835]]

2024-06-06 02:59:30,111 - ==> Best [Top1: 85.857   Top5: 97.944   Sparsity:0.00   Params: 424448 on epoch: 183]
2024-06-06 02:59:30,111 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 02:59:30,134 - 

2024-06-06 02:59:30,134 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 02:59:36,593 - Epoch: [187][  100/ 1218]    Overall Loss 0.289493    Objective Loss 0.289493                                        LR 0.000125    Time 0.064557    
2024-06-06 02:59:41,170 - Epoch: [187][  200/ 1218]    Overall Loss 0.281000    Objective Loss 0.281000                                        LR 0.000125    Time 0.055154    
2024-06-06 02:59:45,888 - Epoch: [187][  300/ 1218]    Overall Loss 0.280314    Objective Loss 0.280314                                        LR 0.000125    Time 0.052489    
2024-06-06 02:59:50,459 - Epoch: [187][  400/ 1218]    Overall Loss 0.279597    Objective Loss 0.279597                                        LR 0.000125    Time 0.050788    
2024-06-06 02:59:55,111 - Epoch: [187][  500/ 1218]    Overall Loss 0.280694    Objective Loss 0.280694                                        LR 0.000125    Time 0.049931    
2024-06-06 02:59:59,828 - Epoch: [187][  600/ 1218]    Overall Loss 0.280005    Objective Loss 0.280005                                        LR 0.000125    Time 0.049464    
2024-06-06 03:00:04,492 - Epoch: [187][  700/ 1218]    Overall Loss 0.279328    Objective Loss 0.279328                                        LR 0.000125    Time 0.049049    
2024-06-06 03:00:09,051 - Epoch: [187][  800/ 1218]    Overall Loss 0.279205    Objective Loss 0.279205                                        LR 0.000125    Time 0.048614    
2024-06-06 03:00:13,599 - Epoch: [187][  900/ 1218]    Overall Loss 0.280063    Objective Loss 0.280063                                        LR 0.000125    Time 0.048264    
2024-06-06 03:00:18,227 - Epoch: [187][ 1000/ 1218]    Overall Loss 0.280093    Objective Loss 0.280093                                        LR 0.000125    Time 0.048064    
2024-06-06 03:00:23,094 - Epoch: [187][ 1100/ 1218]    Overall Loss 0.279697    Objective Loss 0.279697                                        LR 0.000125    Time 0.048118    
2024-06-06 03:00:27,720 - Epoch: [187][ 1200/ 1218]    Overall Loss 0.281111    Objective Loss 0.281111                                        LR 0.000125    Time 0.047961    
2024-06-06 03:00:28,519 - Epoch: [187][ 1218/ 1218]    Overall Loss 0.281500    Objective Loss 0.281500    Top1 81.662592    Top5 95.354523    LR 0.000125    Time 0.047908    
2024-06-06 03:00:28,722 - --- validate (epoch=187)-----------
2024-06-06 03:00:28,722 - 34633 samples (256 per mini-batch)
2024-06-06 03:00:34,438 - Epoch: [187][  100/  136]    Loss 0.318667    Top1 84.750000    Top5 97.734375    
2024-06-06 03:00:36,093 - Epoch: [187][  136/  136]    Loss 0.320557    Top1 84.679352    Top5 97.744925    
2024-06-06 03:00:36,297 - ==> Top1: 84.679    Top5: 97.745    Loss: 0.321

2024-06-06 03:00:36,298 - ==> Confusion:
[[  809     0     4     2    17     0     0     2     7    70     0     3     0     3     5     0     1     2     1     1     4]
 [    1   954     1     3    14    22     4    18     2     3     5     2     2     3     2     0     4     1    10     7     5]
 [    5     0   890    11     2     0    14     6     1     3    11     4     2     1     2     1     3     1     2     7     4]
 [    3     0     2   948     2     4     2     4     0     2    14     2     6     2    11     1     1     2     3     0     7]
 [   13     6     5     1   965    10     2     6     1    13     1     1     0     3     7     4     4     0     5     4     3]
 [    3    14     4     8     7   905     4    24     4     5     5    11     4    18     2     3     1     3     0    11     7]
 [    0     2    12     1     2     4  1013     3     0     4     3     5     0     1     2     9     1     1     3    15     5]
 [    3    12     6     4     1    19     4   965     0     2     5     5     1     2     2     1     0     4    15    20     6]
 [    5     2     0     2     3     1     1     1   863    41    25     5     1    11    17     0     3     2     9     2     8]
 [   33     2     4     1    11     3     1     1    47   866     3     0     1    13     7     0     1     2     0     1     4]
 [    0     0     4     9     1     1     2     3     8     1  1014     1     0     3     7     0     1     0     6     1     2]
 [    1     3     1     0     1    11     1     8     0     2     1   893    31     7     1    12     2     8     2    23     3]
 [    0     0     1     7     1     5     0     2     2     1     2    48   870     3     1     6     4    23     2     8     9]
 [    2     2     1     2     3    18     0     3    13    13     7     9     3   899     4     2     1     3     1     8     7]
 [    3     2     4    31     3     2     0     0    24     7    12     1     1     2   986     0     2     0    12     0     6]
 [    3     0     0     2     1     1     4     0     0     2     3    12     6     2     1  1007     5     6     3     7     1]
 [    3     6     6     1     8     3     1     3     6     0     3     5     2     1     1    11   982     1     2    10    17]
 [    4     1     0     3     2     3     2     1     2     3     0     9    32     1     3     9     1   917     2     8     2]
 [    2     1     9    15     3     2     0    21     6     2    13     2     2     2    12     0     3     2   948     3    10]
 [    1     1     1     0     1     5     7     2     0     2     2    15     6     1     0     7     1     0     2  1025     9]
 [  146   149   187   147   196   146    81   158    98   105   223   135   285   219   175   109   176    83   162   344 10608]]

2024-06-06 03:00:36,300 - ==> Best [Top1: 85.857   Top5: 97.944   Sparsity:0.00   Params: 424448 on epoch: 183]
2024-06-06 03:00:36,300 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 03:00:36,315 - 

2024-06-06 03:00:36,316 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 03:00:42,706 - Epoch: [188][  100/ 1218]    Overall Loss 0.271953    Objective Loss 0.271953                                        LR 0.000125    Time 0.063882    
2024-06-06 03:00:47,407 - Epoch: [188][  200/ 1218]    Overall Loss 0.279201    Objective Loss 0.279201                                        LR 0.000125    Time 0.055437    
2024-06-06 03:00:52,028 - Epoch: [188][  300/ 1218]    Overall Loss 0.281202    Objective Loss 0.281202                                        LR 0.000125    Time 0.052351    
2024-06-06 03:00:56,648 - Epoch: [188][  400/ 1218]    Overall Loss 0.282336    Objective Loss 0.282336                                        LR 0.000125    Time 0.050809    
2024-06-06 03:01:01,318 - Epoch: [188][  500/ 1218]    Overall Loss 0.283128    Objective Loss 0.283128                                        LR 0.000125    Time 0.049984    
2024-06-06 03:01:06,019 - Epoch: [188][  600/ 1218]    Overall Loss 0.282129    Objective Loss 0.282129                                        LR 0.000125    Time 0.049484    
2024-06-06 03:01:10,888 - Epoch: [188][  700/ 1218]    Overall Loss 0.281773    Objective Loss 0.281773                                        LR 0.000125    Time 0.049360    
2024-06-06 03:01:15,713 - Epoch: [188][  800/ 1218]    Overall Loss 0.280823    Objective Loss 0.280823                                        LR 0.000125    Time 0.049219    
2024-06-06 03:01:20,421 - Epoch: [188][  900/ 1218]    Overall Loss 0.282096    Objective Loss 0.282096                                        LR 0.000125    Time 0.048972    
2024-06-06 03:01:25,232 - Epoch: [188][ 1000/ 1218]    Overall Loss 0.282099    Objective Loss 0.282099                                        LR 0.000125    Time 0.048884    
2024-06-06 03:01:29,917 - Epoch: [188][ 1100/ 1218]    Overall Loss 0.282029    Objective Loss 0.282029                                        LR 0.000125    Time 0.048697    
2024-06-06 03:01:34,479 - Epoch: [188][ 1200/ 1218]    Overall Loss 0.282591    Objective Loss 0.282591                                        LR 0.000125    Time 0.048439    
2024-06-06 03:01:35,273 - Epoch: [188][ 1218/ 1218]    Overall Loss 0.282694    Objective Loss 0.282694    Top1 88.508557    Top5 98.533007    LR 0.000125    Time 0.048374    
2024-06-06 03:01:35,458 - --- validate (epoch=188)-----------
2024-06-06 03:01:35,458 - 34633 samples (256 per mini-batch)
2024-06-06 03:01:40,963 - Epoch: [188][  100/  136]    Loss 0.325251    Top1 85.726562    Top5 97.800781    
2024-06-06 03:01:42,637 - Epoch: [188][  136/  136]    Loss 0.326331    Top1 85.773684    Top5 97.851760    
2024-06-06 03:01:42,807 - ==> Top1: 85.774    Top5: 97.852    Loss: 0.326

2024-06-06 03:01:42,808 - ==> Confusion:
[[  840     0     1     0     8     1     0     1     6    54     0     1     1     3     4     0     0     0     2     1     8]
 [    4   938     4     2    17    21     3    25     6     3     7     4     1     0     6     1     4     0     6     2     9]
 [    9     1   876     5     5     0    11    12     1    10     6     3     3     4     4     2     1     0     3     2    12]
 [    5     2     7   919     1     3     2     1     1     1    16     1     6     3    22     4     0     3    10     0     9]
 [   13     4     3     1   972     4     1     2     2    13     2     2     4     2     5     4     4     0     0     4    12]
 [   10    16     2     0    17   885     1    39     3     6     3    12     3    18     1     2     2     2     1     9    11]
 [    2     3    16     2     1     2  1014     7     0     4     3     5     1     0     0     8     1     2     3     8     4]
 [    4     7     9     1     3    17     2   977     4     4     7     6     1     4     0     0     0     1    12    10     8]
 [    8     1     1     0     3     0     0     4   882    46     9     2     6     6    17     0     0     3     4     0    10]
 [   54     0     0     0     4     1     0     1    37   870     0     1     1    14    11     0     0     2     0     0     5]
 [    0     1     7     6     2     1     0    10     8     1   994     1     1     8    10     0     0     0     5     3     6]
 [    3     1     0     0     2     6     1     6     1     2     1   900    27     9     2    12     0    11     1    17     9]
 [    3     1     2     3     4     5     1     1     2     3     1    60   855     2     2     7     0    19     3     5    16]
 [    2     0     2     3     6    11     0     2    19    21     8    12     3   887     4     1     0     3     1     6    10]
 [   16     5     1     8     4     2     0     0    22     9     1     2     1     2   996     0     1     1    14     0    13]
 [    4     1     4     0     6     3     6     1     1     4     2    16     5     2     1   996     4     7     0     0     3]
 [    3     4     2     0    12     9     1     1     1     4     3     5     4     6     2     9   984     3     2     4    13]
 [    5     1     1     2     0     0     1     2     2     3     0    10    46     5     7    15     2   898     3     2     0]
 [    3     2     6     4     2     2     2    21     7     1     4     0     3     1    20     0     1     0   965     6     8]
 [    4     2     2     0     3     9     6     6     0     2     1    16     6     1     2     6     2     2     3  1007     8]
 [  196   103   154    68   210   134    58   162   107   136   150   148   259   199   180   117    90    72   127   211 11051]]

2024-06-06 03:01:42,811 - ==> Best [Top1: 85.857   Top5: 97.944   Sparsity:0.00   Params: 424448 on epoch: 183]
2024-06-06 03:01:42,811 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 03:01:42,841 - 

2024-06-06 03:01:42,841 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 03:01:48,989 - Epoch: [189][  100/ 1218]    Overall Loss 0.273846    Objective Loss 0.273846                                        LR 0.000125    Time 0.061454    
2024-06-06 03:01:53,664 - Epoch: [189][  200/ 1218]    Overall Loss 0.274560    Objective Loss 0.274560                                        LR 0.000125    Time 0.054092    
2024-06-06 03:01:58,549 - Epoch: [189][  300/ 1218]    Overall Loss 0.277911    Objective Loss 0.277911                                        LR 0.000125    Time 0.052336    
2024-06-06 03:02:03,188 - Epoch: [189][  400/ 1218]    Overall Loss 0.279085    Objective Loss 0.279085                                        LR 0.000125    Time 0.050846    
2024-06-06 03:02:07,790 - Epoch: [189][  500/ 1218]    Overall Loss 0.278754    Objective Loss 0.278754                                        LR 0.000125    Time 0.049876    
2024-06-06 03:02:12,392 - Epoch: [189][  600/ 1218]    Overall Loss 0.277831    Objective Loss 0.277831                                        LR 0.000125    Time 0.049230    
2024-06-06 03:02:16,959 - Epoch: [189][  700/ 1218]    Overall Loss 0.277674    Objective Loss 0.277674                                        LR 0.000125    Time 0.048719    
2024-06-06 03:02:21,880 - Epoch: [189][  800/ 1218]    Overall Loss 0.277603    Objective Loss 0.277603                                        LR 0.000125    Time 0.048778    
2024-06-06 03:02:26,646 - Epoch: [189][  900/ 1218]    Overall Loss 0.279550    Objective Loss 0.279550                                        LR 0.000125    Time 0.048651    
2024-06-06 03:02:31,253 - Epoch: [189][ 1000/ 1218]    Overall Loss 0.280870    Objective Loss 0.280870                                        LR 0.000125    Time 0.048391    
2024-06-06 03:02:35,921 - Epoch: [189][ 1100/ 1218]    Overall Loss 0.280848    Objective Loss 0.280848                                        LR 0.000125    Time 0.048234    
2024-06-06 03:02:40,500 - Epoch: [189][ 1200/ 1218]    Overall Loss 0.281622    Objective Loss 0.281622                                        LR 0.000125    Time 0.048029    
2024-06-06 03:02:41,294 - Epoch: [189][ 1218/ 1218]    Overall Loss 0.281577    Objective Loss 0.281577    Top1 87.530562    Top5 98.288509    LR 0.000125    Time 0.047971    
2024-06-06 03:02:41,484 - --- validate (epoch=189)-----------
2024-06-06 03:02:41,484 - 34633 samples (256 per mini-batch)
2024-06-06 03:02:47,059 - Epoch: [189][  100/  136]    Loss 0.324615    Top1 85.765625    Top5 97.972656    
2024-06-06 03:02:48,776 - Epoch: [189][  136/  136]    Loss 0.331507    Top1 85.617763    Top5 97.961482    
2024-06-06 03:02:48,936 - ==> Top1: 85.618    Top5: 97.961    Loss: 0.332

2024-06-06 03:02:48,937 - ==> Confusion:
[[  789     3     4     2    10     1     0     0     8    87     1     1     2     5     4     4     0     2     0     1     7]
 [    3   959     2     1    20    21     3     6     6     2     4     3     3     3     5     1     4     1     6     2     8]
 [    4     1   882     3     7     2    16     6     1     5     8     3     3     1     2     8     4     1     0     3    10]
 [    2     0    13   925     1     3     2     0     1     6    11     1     9     5    15     2     0     4     5     1    10]
 [   15     8     3     0   971    14     1     0     1    11     2     1     4     5     4     3     0     3     1     0     7]
 [    3    13     4     3    13   894     3    24     1     5     3    20    14    26     0     2     6     1     0     4     4]
 [    0     2    10     2     2     4  1016     5     1     2     1     6     1     1     0     6     0     3     1    12    11]
 [    3     9    16     1     4    36     5   937     2     1     5     7    12     3     1     0     0     1    15     8    11]
 [    5     6     1     0     1     1     1     2   865    57    14     1     6    13    15     0     2     3     2     0     7]
 [   29     2     1     1     5     0     1     1    37   893     1     1     3    17     2     1     0     3     1     0     2]
 [    1     2    13     8     1     1     5     4    11     3   987     2     2     9     4     0     1     0     1     2     7]
 [    2     2     3     0     0     5     1     1     1     1     0   913    36     7     0     7     2    10     0    13     7]
 [    1     0     5     4     0     3     0     1     0     1     1    45   892     4     0     7     3    14     0     2    12]
 [    1     1     1     0     0     5     1     3     8    16     8    13     9   915     4     0     2     4     0     7     3]
 [    2     3     3    17    12     3     0     0    22    12    10     3     3     5   981     2     2     1     4     0    13]
 [    1     2     2     0     3     1     4     3     0     5     0    11    10     2     0  1003     9     4     0     2     4]
 [    1     9     3     1    10     5     0     0     5     1     5     7     5     3     3     8   979     2     0     5    20]
 [    0     2     1     0     0     0     2     1     0     2     0    11    46     0     1     9     1   925     0     1     3]
 [    3    13    10     9     5     3     0    27     6     2     4     4     4     1    20     2     2     1   927     2    13]
 [    2     3     3     1     1     9     8     6     0     2     2    16    11     4     0     8     7     0     0   989    16]
 [  139   169   164    90   190   138    81   111    75   155   156   133   295   272   135   120   145    88    79   187 11010]]

2024-06-06 03:02:48,940 - ==> Best [Top1: 85.857   Top5: 97.944   Sparsity:0.00   Params: 424448 on epoch: 183]
2024-06-06 03:02:48,940 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 03:02:48,962 - 

2024-06-06 03:02:48,962 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 03:02:55,197 - Epoch: [190][  100/ 1218]    Overall Loss 0.267093    Objective Loss 0.267093                                        LR 0.000063    Time 0.062331    
2024-06-06 03:02:59,997 - Epoch: [190][  200/ 1218]    Overall Loss 0.271892    Objective Loss 0.271892                                        LR 0.000063    Time 0.055152    
2024-06-06 03:03:04,868 - Epoch: [190][  300/ 1218]    Overall Loss 0.270688    Objective Loss 0.270688                                        LR 0.000063    Time 0.052999    
2024-06-06 03:03:09,514 - Epoch: [190][  400/ 1218]    Overall Loss 0.268779    Objective Loss 0.268779                                        LR 0.000063    Time 0.051360    
2024-06-06 03:03:14,111 - Epoch: [190][  500/ 1218]    Overall Loss 0.269752    Objective Loss 0.269752                                        LR 0.000063    Time 0.050278    
2024-06-06 03:03:18,802 - Epoch: [190][  600/ 1218]    Overall Loss 0.269363    Objective Loss 0.269363                                        LR 0.000063    Time 0.049702    
2024-06-06 03:03:23,695 - Epoch: [190][  700/ 1218]    Overall Loss 0.269494    Objective Loss 0.269494                                        LR 0.000063    Time 0.049590    
2024-06-06 03:03:28,310 - Epoch: [190][  800/ 1218]    Overall Loss 0.269077    Objective Loss 0.269077                                        LR 0.000063    Time 0.049157    
2024-06-06 03:03:33,018 - Epoch: [190][  900/ 1218]    Overall Loss 0.270287    Objective Loss 0.270287                                        LR 0.000063    Time 0.048924    
2024-06-06 03:03:37,720 - Epoch: [190][ 1000/ 1218]    Overall Loss 0.270197    Objective Loss 0.270197                                        LR 0.000063    Time 0.048732    
2024-06-06 03:03:42,309 - Epoch: [190][ 1100/ 1218]    Overall Loss 0.270210    Objective Loss 0.270210                                        LR 0.000063    Time 0.048472    
2024-06-06 03:03:46,882 - Epoch: [190][ 1200/ 1218]    Overall Loss 0.270143    Objective Loss 0.270143                                        LR 0.000063    Time 0.048242    
2024-06-06 03:03:47,688 - Epoch: [190][ 1218/ 1218]    Overall Loss 0.270376    Objective Loss 0.270376    Top1 88.264059    Top5 98.777506    LR 0.000063    Time 0.048190    
2024-06-06 03:03:47,856 - --- validate (epoch=190)-----------
2024-06-06 03:03:47,857 - 34633 samples (256 per mini-batch)
2024-06-06 03:03:53,340 - Epoch: [190][  100/  136]    Loss 0.311979    Top1 85.703125    Top5 97.867188    
2024-06-06 03:03:55,019 - Epoch: [190][  136/  136]    Loss 0.308505    Top1 85.557128    Top5 97.845985    
2024-06-06 03:03:55,183 - ==> Top1: 85.557    Top5: 97.846    Loss: 0.309

2024-06-06 03:03:55,184 - ==> Confusion:
[[  849     1     4     0     3     1     0     2     7    41     0     1     2     2     1     1     0     2     0     4    10]
 [    1   981     2     2     7     8     1     6     2     2     9     3     3     0     8     1     4     1    14     1     7]
 [    4     7   897     6     1     2     7     7     0     5     6     4     0     5     3     2     2     3     6     0     3]
 [    3     3    13   921     0     7     1     8     3     1     9     3     4     2    15     3     1     7     6     1     5]
 [   21     8     1     1   954     6     3     1     2    17     3     0     0     5    10     2     6     3     4     0     7]
 [    2    30     2     5    11   893     5    29     1     6     3    11     5    15     1     0     3     5     0    12     4]
 [    0    10     8     1     0     2  1021     3     1     2     4     7     1     1     0     8     2     2     3     4     6]
 [    2    13     7     0     0    16     4   972     2     2     6     5     3     3     0     0     2     3    19    11     7]
 [    6     8     1     1     0     1     1     0   900    36     9     4     1     9    13     0     0     3     5     0     4]
 [   75     2     0     0     7     3     0     1    38   838     2     1     0     9    10     1     1     5     1     0     7]
 [    0     2     5    11     0     1     2     6    13     1  1001     0     0     5     2     0     2     0    10     0     3]
 [    0     0     1     1     1    11     2     4     0     5     0   905    21     6     1     9     1    22     6    13     2]
 [    0     3     2     2     0     3     0     5     3     1     3    53   851     5     0     4     0    42     3     5    10]
 [    2     0     2     0     3     7     0     4    19    19    10     6     3   907     1     2     1     5     0     4     6]
 [    6     2     2    16     6     1     0     1    29     9    11     1     0     4   988     0     1     3    15     0     3]
 [    4     0     2     0     1     1     6     0     0     4     1    13     3     0     0  1006     9    13     1     1     1]
 [    1     6     2     2     4     2     3     4     5     1     2     5     1     2     2     6   997     5     2     6    14]
 [    2     3     0     4     1     1     0     3     0     3     0     9     9     1     1     9     3   948     2     1     5]
 [    1     5     5     9     0     1     1    21     5     2     6     1     2     2     8     0     1     1   978     2     7]
 [    1     7     1     0     0    10    14    10     0     2     0    15     4     2     0     7     4     5     2   996     8]
 [  158   211   178    85   115   126    82   153   106   118   165   146   247   236   162   109   178   152   180   197 10828]]

2024-06-06 03:03:55,186 - ==> Best [Top1: 85.857   Top5: 97.944   Sparsity:0.00   Params: 424448 on epoch: 183]
2024-06-06 03:03:55,186 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 03:03:55,208 - 

2024-06-06 03:03:55,208 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 03:04:01,317 - Epoch: [191][  100/ 1218]    Overall Loss 0.284472    Objective Loss 0.284472                                        LR 0.000063    Time 0.061062    
2024-06-06 03:04:06,104 - Epoch: [191][  200/ 1218]    Overall Loss 0.278970    Objective Loss 0.278970                                        LR 0.000063    Time 0.054455    
2024-06-06 03:04:10,869 - Epoch: [191][  300/ 1218]    Overall Loss 0.270756    Objective Loss 0.270756                                        LR 0.000063    Time 0.052181    
2024-06-06 03:04:15,435 - Epoch: [191][  400/ 1218]    Overall Loss 0.268723    Objective Loss 0.268723                                        LR 0.000063    Time 0.050545    
2024-06-06 03:04:20,161 - Epoch: [191][  500/ 1218]    Overall Loss 0.267437    Objective Loss 0.267437                                        LR 0.000063    Time 0.049886    
2024-06-06 03:04:24,793 - Epoch: [191][  600/ 1218]    Overall Loss 0.268173    Objective Loss 0.268173                                        LR 0.000063    Time 0.049288    
2024-06-06 03:04:29,362 - Epoch: [191][  700/ 1218]    Overall Loss 0.268318    Objective Loss 0.268318                                        LR 0.000063    Time 0.048771    
2024-06-06 03:04:33,954 - Epoch: [191][  800/ 1218]    Overall Loss 0.269700    Objective Loss 0.269700                                        LR 0.000063    Time 0.048412    
2024-06-06 03:04:38,663 - Epoch: [191][  900/ 1218]    Overall Loss 0.269834    Objective Loss 0.269834                                        LR 0.000063    Time 0.048263    
2024-06-06 03:04:43,502 - Epoch: [191][ 1000/ 1218]    Overall Loss 0.269645    Objective Loss 0.269645                                        LR 0.000063    Time 0.048274    
2024-06-06 03:04:48,229 - Epoch: [191][ 1100/ 1218]    Overall Loss 0.268993    Objective Loss 0.268993                                        LR 0.000063    Time 0.048181    
2024-06-06 03:04:52,970 - Epoch: [191][ 1200/ 1218]    Overall Loss 0.268082    Objective Loss 0.268082                                        LR 0.000063    Time 0.048115    
2024-06-06 03:04:53,787 - Epoch: [191][ 1218/ 1218]    Overall Loss 0.268051    Objective Loss 0.268051    Top1 85.819071    Top5 97.799511    LR 0.000063    Time 0.048075    
2024-06-06 03:04:53,946 - --- validate (epoch=191)-----------
2024-06-06 03:04:53,947 - 34633 samples (256 per mini-batch)
2024-06-06 03:04:59,566 - Epoch: [191][  100/  136]    Loss 0.324342    Top1 85.253906    Top5 97.945312    
2024-06-06 03:05:01,254 - Epoch: [191][  136/  136]    Loss 0.316019    Top1 85.352121    Top5 97.918171    
2024-06-06 03:05:01,444 - ==> Top1: 85.352    Top5: 97.918    Loss: 0.316

2024-06-06 03:05:01,445 - ==> Confusion:
[[  833     0     5     1    16     0     0     0     4    47     0     4     2     3     6     0     2     0     2     1     5]
 [    1   975     2     1    17    25     2     2     0     0     6     1     4     1     2     1     5     0     8     1     9]
 [    3     5   888     8     2     1    13    10     1     3     5     1     4     5     1     3     5     3     3     3     3]
 [    3     3     8   929     1     4     3     1     2     3    16     1     5     3    16     1     2     1     5     0     9]
 [    9    10     4     1   983    12     0     0     1     5     1     4     1     4     6     3     1     0     3     2     4]
 [    1    16     3     4    10   935     4    16     0     3     3     7     2    14     5     1     4     0     1     6     8]
 [    2     7    14     1     4     7  1017     4     2     1     3     2     1     2     1     6     2     2     1     4     3]
 [    1    15    14     0     3    31     2   937     2     1     7     8     6     3     2     1     1     1    22    11     9]
 [    7     5     1     0     4     2     0     1   879    34    15     6     2    18    19     0     1     0     3     1     4]
 [   63     5     1     3     9     2     1     0    26   839     2     2     3    17    14     3     2     2     1     0     6]
 [    0     5     4    10     5     2     3     3     8     0   989     0     1     9     9     0     0     0    10     1     5]
 [    2     1     1     0     3    10     3     2     0     2     0   921    16     9     0    18     1     7     0    10     5]
 [    1     1     2     2     3     7     0     6     0     1     1    73   847     3     6     8     3    14     1     6    10]
 [    2     0     1     0     3    15     0     4    11    15    13     6     4   909     3     1     4     0     1     3     6]
 [    3     4     2    16     7     4     0     1    18     4     8     1     2     5   997     1     0     1    15     1     8]
 [    3     4     1     0     4     2     3     0     0     2     3    11     9     3     1   996     9     7     2     1     5]
 [    1    10     4     1     6     8     1     0     1     1     5     2     1     4     5     6   996     0     1     7    12]
 [    2     2     0     4     2     0     0     0     0     2     0    12    24     3     3    15     3   921     1     6     5]
 [    3     8     6     8     2     2     1    11     1     2     2     2     1     0    13     0     2     0   989     1     4]
 [    1     4     1     0     3    10    13     9     0     1     0    13     8     5     2     4     6     1     4   996     7]
 [  141   178   177    93   185   199    68   128    89    92   156   141   253   251   187   120   263    54   141   232 10784]]

2024-06-06 03:05:01,447 - ==> Best [Top1: 85.857   Top5: 97.944   Sparsity:0.00   Params: 424448 on epoch: 183]
2024-06-06 03:05:01,447 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 03:05:01,470 - 

2024-06-06 03:05:01,470 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 03:05:07,717 - Epoch: [192][  100/ 1218]    Overall Loss 0.268054    Objective Loss 0.268054                                        LR 0.000063    Time 0.062441    
2024-06-06 03:05:12,334 - Epoch: [192][  200/ 1218]    Overall Loss 0.267692    Objective Loss 0.267692                                        LR 0.000063    Time 0.054295    
2024-06-06 03:05:16,885 - Epoch: [192][  300/ 1218]    Overall Loss 0.261088    Objective Loss 0.261088                                        LR 0.000063    Time 0.051361    
2024-06-06 03:05:21,602 - Epoch: [192][  400/ 1218]    Overall Loss 0.263605    Objective Loss 0.263605                                        LR 0.000063    Time 0.050309    
2024-06-06 03:05:26,334 - Epoch: [192][  500/ 1218]    Overall Loss 0.265082    Objective Loss 0.265082                                        LR 0.000063    Time 0.049706    
2024-06-06 03:05:31,147 - Epoch: [192][  600/ 1218]    Overall Loss 0.264903    Objective Loss 0.264903                                        LR 0.000063    Time 0.049441    
2024-06-06 03:05:35,754 - Epoch: [192][  700/ 1218]    Overall Loss 0.265999    Objective Loss 0.265999                                        LR 0.000063    Time 0.048957    
2024-06-06 03:05:40,393 - Epoch: [192][  800/ 1218]    Overall Loss 0.266720    Objective Loss 0.266720                                        LR 0.000063    Time 0.048634    
2024-06-06 03:05:45,171 - Epoch: [192][  900/ 1218]    Overall Loss 0.266452    Objective Loss 0.266452                                        LR 0.000063    Time 0.048537    
2024-06-06 03:05:49,802 - Epoch: [192][ 1000/ 1218]    Overall Loss 0.266957    Objective Loss 0.266957                                        LR 0.000063    Time 0.048313    
2024-06-06 03:05:54,457 - Epoch: [192][ 1100/ 1218]    Overall Loss 0.266281    Objective Loss 0.266281                                        LR 0.000063    Time 0.048150    
2024-06-06 03:05:59,151 - Epoch: [192][ 1200/ 1218]    Overall Loss 0.267006    Objective Loss 0.267006                                        LR 0.000063    Time 0.048048    
2024-06-06 03:05:59,950 - Epoch: [192][ 1218/ 1218]    Overall Loss 0.266862    Objective Loss 0.266862    Top1 86.063570    Top5 97.799511    LR 0.000063    Time 0.047994    
2024-06-06 03:06:00,125 - --- validate (epoch=192)-----------
2024-06-06 03:06:00,125 - 34633 samples (256 per mini-batch)
2024-06-06 03:06:05,757 - Epoch: [192][  100/  136]    Loss 0.318823    Top1 86.441406    Top5 97.949219    
2024-06-06 03:06:07,372 - Epoch: [192][  136/  136]    Loss 0.317174    Top1 86.270320    Top5 97.921058    
2024-06-06 03:06:07,537 - ==> Top1: 86.270    Top5: 97.921    Loss: 0.317

2024-06-06 03:06:07,538 - ==> Confusion:
[[  831     2     5     1     4     1     0     3     8    49     1     1     3     0     4     0     4     1     3     0    10]
 [    0   966     6     2    20    16     1    10     1     2     5     1     6     0     5     0     5     0     8     2     7]
 [    3     1   909     7     4     0     9     5     0     1     3     1     3     0     3     2     5     1     2     4     7]
 [    7     3    13   924     2     3     4     0     2     2    13     0     4     0    18     2     3     2     5     1     8]
 [   17     9     3     2   971     7     0     2     1     8     1     0     2     3     9     2     6     0     2     1     8]
 [    9    24     1     7     6   907     4    24     0     6     0     8     5    11     3     2     6     1     4     6     9]
 [    2     3    21     0     1     2  1014     5     1     3     4     3     2     0     0     5     5     2     0     5     8]
 [    2     9    10     3     0    19     3   977     1     4     3     1     3     2     2     0     1     1    22    11     3]
 [    9     2     2     4     2     2     0     1   880    33    16     4     3     5    21     2     2     2     4     1     7]
 [   57     0     0     0     4     1     1     0    23   876     3     2     4    12     7     1     0     3     1     1     5]
 [    1     2     7     7     0     1     2     6    12     0   994     0     1     3     9     0     1     0     9     2     7]
 [    2     0     0     0     1     7     1     5     0     3     1   906    27     8     1     9     5    11     2    13     9]
 [    0     2     3     1     2     6     3     3     1     1     1    45   879     1     2     3     4    23     3     4     8]
 [    0     1     7     1     3    16     1     8    11    12     6    11     9   883     9     2     4     1     0     2    14]
 [    5     2     6    14     4     0     0     2    24     7     6     1     2     4   996     1     3     1    12     0     8]
 [    4     1     4     0     2     0     8     1     0     3     0    10    13     1     0   988    10     7     1     7     6]
 [    4     5     7     3     2     3     0     0     2     2     3     2     4     2     1     7  1007     1     2     4    11]
 [    3     2     2     1     1     1     1     0     1     3     1     8    32     0     1     5     3   930     2     0     8]
 [    3     5     8     7     3     3     0    18     7     0     6     1     2     2    12     1     0     1   966     3    10]
 [    0     3     6     0     1     6    11    11     0     3     1    15     8     3     1     5     7     3     7   985    12]
 [  161   141   225    71   147   143    81   154    87   121   127   120   290   138   174    83   190    77   154   159 11089]]

2024-06-06 03:06:07,540 - ==> Best [Top1: 86.270   Top5: 97.921   Sparsity:0.00   Params: 424448 on epoch: 192]
2024-06-06 03:06:07,540 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 03:06:07,567 - 

2024-06-06 03:06:07,567 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 03:06:13,995 - Epoch: [193][  100/ 1218]    Overall Loss 0.279575    Objective Loss 0.279575                                        LR 0.000063    Time 0.064247    
2024-06-06 03:06:18,845 - Epoch: [193][  200/ 1218]    Overall Loss 0.268987    Objective Loss 0.268987                                        LR 0.000063    Time 0.056364    
2024-06-06 03:06:23,438 - Epoch: [193][  300/ 1218]    Overall Loss 0.268078    Objective Loss 0.268078                                        LR 0.000063    Time 0.052880    
2024-06-06 03:06:28,076 - Epoch: [193][  400/ 1218]    Overall Loss 0.266406    Objective Loss 0.266406                                        LR 0.000063    Time 0.051250    
2024-06-06 03:06:32,917 - Epoch: [193][  500/ 1218]    Overall Loss 0.265408    Objective Loss 0.265408                                        LR 0.000063    Time 0.050680    
2024-06-06 03:06:37,656 - Epoch: [193][  600/ 1218]    Overall Loss 0.262984    Objective Loss 0.262984                                        LR 0.000063    Time 0.050127    
2024-06-06 03:06:42,249 - Epoch: [193][  700/ 1218]    Overall Loss 0.262639    Objective Loss 0.262639                                        LR 0.000063    Time 0.049526    
2024-06-06 03:06:47,052 - Epoch: [193][  800/ 1218]    Overall Loss 0.263464    Objective Loss 0.263464                                        LR 0.000063    Time 0.049336    
2024-06-06 03:06:51,732 - Epoch: [193][  900/ 1218]    Overall Loss 0.262740    Objective Loss 0.262740                                        LR 0.000063    Time 0.049052    
2024-06-06 03:06:56,335 - Epoch: [193][ 1000/ 1218]    Overall Loss 0.263147    Objective Loss 0.263147                                        LR 0.000063    Time 0.048748    
2024-06-06 03:07:01,018 - Epoch: [193][ 1100/ 1218]    Overall Loss 0.262785    Objective Loss 0.262785                                        LR 0.000063    Time 0.048572    
2024-06-06 03:07:05,767 - Epoch: [193][ 1200/ 1218]    Overall Loss 0.262090    Objective Loss 0.262090                                        LR 0.000063    Time 0.048480    
2024-06-06 03:07:06,587 - Epoch: [193][ 1218/ 1218]    Overall Loss 0.262023    Objective Loss 0.262023    Top1 85.574572    Top5 98.777506    LR 0.000063    Time 0.048436    
2024-06-06 03:07:06,748 - --- validate (epoch=193)-----------
2024-06-06 03:07:06,748 - 34633 samples (256 per mini-batch)
2024-06-06 03:07:12,328 - Epoch: [193][  100/  136]    Loss 0.313205    Top1 85.515625    Top5 97.937500    
2024-06-06 03:07:14,065 - Epoch: [193][  136/  136]    Loss 0.320096    Top1 85.470505    Top5 97.843098    
2024-06-06 03:07:14,248 - ==> Top1: 85.471    Top5: 97.843    Loss: 0.320

2024-06-06 03:07:14,249 - ==> Confusion:
[[  835     1     3     0     2     1     0     2     6    62     1     1     1     2     2     0     1     3     1     0     7]
 [    3   966     4     1    19    13     3    13     3     7     4     1     4     1     4     0     2     0     6     2     7]
 [    7     2   892     8     2     0    14     7     0     7     5     3     1     4     3     2     1     1     4     3     4]
 [    3     1    12   913     2     5     3     1     4     2    20     2     6     2    14     3     1     4     7     2     9]
 [   15     7     5     0   983     3     3     2     2    13     1     2     0     2     4     1     2     0     0     1     8]
 [    6    24     5     6    12   887     2    35     5     5     2    12     7    10     2     1     1     1     1     6    13]
 [    2     2    13     1     2     2  1022     5     0     5     4     2     1     1     2     2     3     3     1     7     6]
 [    3     8    14     2     1    24     1   982     1     1     3     6     1     5     0     1     1     3    11     3     6]
 [    7     2     1     0     0     1     0     2   900    47     8     4     1     5     6     0     3     3     6     1     5]
 [   55     1     3     0     6     1     1     0    32   869     2     1     1    14     3     2     0     3     1     1     5]
 [    1     2     8     7     0     0     5     3    20     1   991     0     1     6     7     0     0     0     8     1     3]
 [    5     4     1     0     0    10     1     2     0     3     1   917    25     3     1     6     4    14     1    10     3]
 [    2     1     5     4     1     1     3     6     1     1     1    66   844     3     4     5     1    31     2     6     7]
 [    2     0     3     1     3     9     0     3    23    25     6    10     3   882     7     2     2     4     1     8     7]
 [   12     2     6    10     8     0     0     0    26    13     4     0     0     3  1002     0     3     1     7     0     1]
 [    5     1     5     1     4     0     9     1     0     3     0    16     6     1     1   987     6    13     1     4     2]
 [    3    13    10     0    11     3     1     1     4     3     1     6     3     2     1     7   982     1     1     6    13]
 [    1     0     1     3     0     2     0     0     1     1     0    13    15     1     2     6     2   947     2     1     7]
 [    2     6    15     5     1     2     0    27     4     4     2     1     1     1    13     1     0     0   968     2     3]
 [    3     4     5     1     1     5    12     7     2     1     0    24     8     2     0     3     5    10     1   984    10]
 [  230   153   230    65   200   127    75   169   133   135   158   172   257   170   180    76   154    98   116   186 10848]]

2024-06-06 03:07:14,251 - ==> Best [Top1: 86.270   Top5: 97.921   Sparsity:0.00   Params: 424448 on epoch: 192]
2024-06-06 03:07:14,251 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 03:07:14,274 - 

2024-06-06 03:07:14,274 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 03:07:20,552 - Epoch: [194][  100/ 1218]    Overall Loss 0.263603    Objective Loss 0.263603                                        LR 0.000063    Time 0.062755    
2024-06-06 03:07:25,214 - Epoch: [194][  200/ 1218]    Overall Loss 0.268517    Objective Loss 0.268517                                        LR 0.000063    Time 0.054679    
2024-06-06 03:07:29,825 - Epoch: [194][  300/ 1218]    Overall Loss 0.270056    Objective Loss 0.270056                                        LR 0.000063    Time 0.051814    
2024-06-06 03:07:34,502 - Epoch: [194][  400/ 1218]    Overall Loss 0.269541    Objective Loss 0.269541                                        LR 0.000063    Time 0.050548    
2024-06-06 03:07:39,115 - Epoch: [194][  500/ 1218]    Overall Loss 0.265287    Objective Loss 0.265287                                        LR 0.000063    Time 0.049661    
2024-06-06 03:07:43,835 - Epoch: [194][  600/ 1218]    Overall Loss 0.264789    Objective Loss 0.264789                                        LR 0.000063    Time 0.049248    
2024-06-06 03:07:48,433 - Epoch: [194][  700/ 1218]    Overall Loss 0.264161    Objective Loss 0.264161                                        LR 0.000063    Time 0.048778    
2024-06-06 03:07:53,263 - Epoch: [194][  800/ 1218]    Overall Loss 0.263951    Objective Loss 0.263951                                        LR 0.000063    Time 0.048716    
2024-06-06 03:07:57,958 - Epoch: [194][  900/ 1218]    Overall Loss 0.262298    Objective Loss 0.262298                                        LR 0.000063    Time 0.048517    
2024-06-06 03:08:02,560 - Epoch: [194][ 1000/ 1218]    Overall Loss 0.263563    Objective Loss 0.263563                                        LR 0.000063    Time 0.048265    
2024-06-06 03:08:07,550 - Epoch: [194][ 1100/ 1218]    Overall Loss 0.264252    Objective Loss 0.264252                                        LR 0.000063    Time 0.048412    
2024-06-06 03:08:12,278 - Epoch: [194][ 1200/ 1218]    Overall Loss 0.264547    Objective Loss 0.264547                                        LR 0.000063    Time 0.048316    
2024-06-06 03:08:13,170 - Epoch: [194][ 1218/ 1218]    Overall Loss 0.264507    Objective Loss 0.264507    Top1 88.264059    Top5 97.555012    LR 0.000063    Time 0.048335    
2024-06-06 03:08:13,329 - --- validate (epoch=194)-----------
2024-06-06 03:08:13,329 - 34633 samples (256 per mini-batch)
2024-06-06 03:08:19,000 - Epoch: [194][  100/  136]    Loss 0.308973    Top1 86.515625    Top5 97.992188    
2024-06-06 03:08:20,746 - Epoch: [194][  136/  136]    Loss 0.308988    Top1 86.388704    Top5 98.030780    
2024-06-06 03:08:20,924 - ==> Top1: 86.389    Top5: 98.031    Loss: 0.309

2024-06-06 03:08:20,925 - ==> Confusion:
[[  828     2     2     1    12     1     1     1     8    49     0     1     0     2     7     1     5     1     2     0     7]
 [    2   984     2     1    17     8     1    10     1     1     3     1     2     1     4     0     7     2     5     5     6]
 [    3     6   896     5     2     3    11     6     0     5     5     3     1     2     2     3     1     2     3     4     7]
 [    1     1     8   929     1     4     3     1     2     1    18     0     8     5    16     1     1     4     4     1     7]
 [   15     7     1     2   978     9     1     4     0     7     1     1     1     2     4     4     7     1     3     0     6]
 [    6    17     3     1     7   910     2    22     2     1     2     7     7    16     2     1     6     5     5    10    11]
 [    3     6    21     2     2    10   993     4     0     0     2     2     2     2     0     9     2     3     1    17     5]
 [    2     9    10     2     3    20     1   960     4     0     7     7     3     2     1     1     1     2    19    13    10]
 [    8     3     0     1     0     4     0     0   876    40     9     6     4     8    25     0     6     3     5     0     4]
 [   58     0     2     0     8     1     0     2    36   865     1     2     1    12     3     1     4     2     1     0     2]
 [    0     2     8     6     1     4     1     3    12     1   993     1     2     9     3     0     0     1    12     2     3]
 [    0     1     1     0     1     9     2     2     2     0     0   899    29     9     0    11     6    13     3    16     7]
 [    0     1     3     6     0     2     0     3     4     1     2    49   853     5     1     8     5    27     3    10    12]
 [    1     0     3     0     1    16     2     6    12    10     2     6     3   911     4     4     2     1     0     9     8]
 [    4     1     5    18     9     5     0     0    21     6     6     2     0     2   986     2     1     2    12     2    14]
 [    4     1     0     1     5     0     3     1     0     1     0    18     7     3     0   998     8     8     0     6     2]
 [    2    11     4     0     5     5     1     2     0     0     1     6     6     0     1     7  1002     2     2     1    14]
 [    1     4     2     4     0     3     1     1     0     1     0    12    17     3     3     8     1   933     3     2     6]
 [    4     6     9     9     1     2     0    19     4     1     8     3     1     1    11     0     5     0   963     1    10]
 [    2     1     2     0     2     5     6     7     0     0     0    18     7     5     1     3     6     2     1  1013     7]
 [  143   208   141    67   156   153    59   144    67    75   151   140   224   210   146    88   212    65   106   228 11149]]

2024-06-06 03:08:20,927 - ==> Best [Top1: 86.389   Top5: 98.031   Sparsity:0.00   Params: 424448 on epoch: 194]
2024-06-06 03:08:20,928 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 03:08:20,955 - 

2024-06-06 03:08:20,955 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 03:08:27,088 - Epoch: [195][  100/ 1218]    Overall Loss 0.253202    Objective Loss 0.253202                                        LR 0.000031    Time 0.061309    
2024-06-06 03:08:31,757 - Epoch: [195][  200/ 1218]    Overall Loss 0.252558    Objective Loss 0.252558                                        LR 0.000031    Time 0.053988    
2024-06-06 03:08:36,575 - Epoch: [195][  300/ 1218]    Overall Loss 0.255134    Objective Loss 0.255134                                        LR 0.000031    Time 0.052044    
2024-06-06 03:08:41,272 - Epoch: [195][  400/ 1218]    Overall Loss 0.256654    Objective Loss 0.256654                                        LR 0.000031    Time 0.050770    
2024-06-06 03:08:45,988 - Epoch: [195][  500/ 1218]    Overall Loss 0.256621    Objective Loss 0.256621                                        LR 0.000031    Time 0.050046    
2024-06-06 03:08:50,585 - Epoch: [195][  600/ 1218]    Overall Loss 0.258766    Objective Loss 0.258766                                        LR 0.000031    Time 0.049364    
2024-06-06 03:08:55,364 - Epoch: [195][  700/ 1218]    Overall Loss 0.258094    Objective Loss 0.258094                                        LR 0.000031    Time 0.049136    
2024-06-06 03:08:59,958 - Epoch: [195][  800/ 1218]    Overall Loss 0.258498    Objective Loss 0.258498                                        LR 0.000031    Time 0.048734    
2024-06-06 03:09:04,541 - Epoch: [195][  900/ 1218]    Overall Loss 0.258362    Objective Loss 0.258362                                        LR 0.000031    Time 0.048410    
2024-06-06 03:09:09,085 - Epoch: [195][ 1000/ 1218]    Overall Loss 0.258329    Objective Loss 0.258329                                        LR 0.000031    Time 0.048111    
2024-06-06 03:09:13,645 - Epoch: [195][ 1100/ 1218]    Overall Loss 0.258922    Objective Loss 0.258922                                        LR 0.000031    Time 0.047881    
2024-06-06 03:09:18,305 - Epoch: [195][ 1200/ 1218]    Overall Loss 0.258675    Objective Loss 0.258675                                        LR 0.000031    Time 0.047773    
2024-06-06 03:09:19,168 - Epoch: [195][ 1218/ 1218]    Overall Loss 0.258585    Objective Loss 0.258585    Top1 87.530562    Top5 97.310513    LR 0.000031    Time 0.047775    
2024-06-06 03:09:19,335 - --- validate (epoch=195)-----------
2024-06-06 03:09:19,335 - 34633 samples (256 per mini-batch)
2024-06-06 03:09:24,846 - Epoch: [195][  100/  136]    Loss 0.309026    Top1 86.082031    Top5 97.855469    
2024-06-06 03:09:26,469 - Epoch: [195][  136/  136]    Loss 0.305899    Top1 86.244333    Top5 97.889296    
2024-06-06 03:09:26,651 - ==> Top1: 86.244    Top5: 97.889    Loss: 0.306

2024-06-06 03:09:26,652 - ==> Confusion:
[[  822     0     6     0     6     3     0     2    17    54     0     6     2     2     5     0     0     0     0     1     5]
 [    0   973     2     0    14     9     5    13     3     4     3     1     2     4     3     1     6     1    16     2     1]
 [    4     1   894     5     2     1    12    13     0     9     4     3     2     1     4     3     4     1     1     0     6]
 [    2     3    14   919     1     3     1     0     2     2     9     1     5     3    21     3     1     3    11     3     9]
 [   15     9     2     0   972     5     1     0     1    10     1     2     3     3    10     4     2     1     4     0     9]
 [   10    24     3     4    10   886     3    35     3     5     4    11     9    11     1     4     6     3     2     0     9]
 [    1     2    12     0     2     3  1025     6     0     3     6     1     0     0     1     4     2     5     0     5     8]
 [    6     8     7     0     2    19     4   961     1     3     4    10     1     1     1     0     2     0    31    11     5]
 [    8     3     0     1     4     3     0     1   891    33    10     3     5     8    16     0     6     1     5     1     3]
 [   55     0     1     0     4     0     0     3    49   851     1     1     2    15     8     1     1     2     0     2     5]
 [    0     4     6     9     1     2     1    13     5     1   989     1     1     6     9     0     0     2     4     2     8]
 [    1     1     0     1     1     2     2     7     0     3     0   924    22     8     0     8     4    11     0    11     5]
 [    1     0     7     6     1     2     0     3     4     2     1    44   874     4     3     8     2    17     2     7     7]
 [    1     0     0     0     1     7     0     6    18    19     9    14     5   894     3     2     7     4     1     4     6]
 [    4     0     0    17     5     0     1     2    19     5     8     1     2     2  1003     1     0     3    12     0    13]
 [    2     1     8     0     1     2     4     1     0     3     1    12    10     1     0   996    11     5     2     2     4]
 [    0     8     2     3     4     6     3     0     1     2     3     9     1     7     1     5   995     3     1     4    14]
 [    2     2     0     7     0     1     0     3     0     0     0     9    20     2     3     8     2   934     5     1     6]
 [    1     4     4    10     1     1     1    19     6     1     5     1     0     2     6     0     0     0   991     0     5]
 [    2     4     6     0     0     6     6    14     0     2     0    14     6     3     0     4     6     4     2  1002     7]
 [  142   152   135    72   138   139    85   160    91    95   143   149   257   185   165    89   220    89   173   180 11073]]

2024-06-06 03:09:26,654 - ==> Best [Top1: 86.389   Top5: 98.031   Sparsity:0.00   Params: 424448 on epoch: 194]
2024-06-06 03:09:26,654 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 03:09:26,677 - 

2024-06-06 03:09:26,677 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 03:09:32,920 - Epoch: [196][  100/ 1218]    Overall Loss 0.255187    Objective Loss 0.255187                                        LR 0.000031    Time 0.062404    
2024-06-06 03:09:37,795 - Epoch: [196][  200/ 1218]    Overall Loss 0.257058    Objective Loss 0.257058                                        LR 0.000031    Time 0.055563    
2024-06-06 03:09:42,419 - Epoch: [196][  300/ 1218]    Overall Loss 0.258247    Objective Loss 0.258247                                        LR 0.000031    Time 0.052449    
2024-06-06 03:09:47,168 - Epoch: [196][  400/ 1218]    Overall Loss 0.257753    Objective Loss 0.257753                                        LR 0.000031    Time 0.051205    
2024-06-06 03:09:51,988 - Epoch: [196][  500/ 1218]    Overall Loss 0.258152    Objective Loss 0.258152                                        LR 0.000031    Time 0.050600    
2024-06-06 03:09:56,723 - Epoch: [196][  600/ 1218]    Overall Loss 0.257340    Objective Loss 0.257340                                        LR 0.000031    Time 0.050056    
2024-06-06 03:10:01,517 - Epoch: [196][  700/ 1218]    Overall Loss 0.257080    Objective Loss 0.257080                                        LR 0.000031    Time 0.049750    
2024-06-06 03:10:06,209 - Epoch: [196][  800/ 1218]    Overall Loss 0.255756    Objective Loss 0.255756                                        LR 0.000031    Time 0.049394    
2024-06-06 03:10:10,983 - Epoch: [196][  900/ 1218]    Overall Loss 0.255651    Objective Loss 0.255651                                        LR 0.000031    Time 0.049208    
2024-06-06 03:10:15,686 - Epoch: [196][ 1000/ 1218]    Overall Loss 0.255742    Objective Loss 0.255742                                        LR 0.000031    Time 0.048989    
2024-06-06 03:10:20,305 - Epoch: [196][ 1100/ 1218]    Overall Loss 0.255106    Objective Loss 0.255106                                        LR 0.000031    Time 0.048732    
2024-06-06 03:10:24,883 - Epoch: [196][ 1200/ 1218]    Overall Loss 0.255348    Objective Loss 0.255348                                        LR 0.000031    Time 0.048485    
2024-06-06 03:10:25,714 - Epoch: [196][ 1218/ 1218]    Overall Loss 0.255356    Objective Loss 0.255356    Top1 90.464548    Top5 98.533007    LR 0.000031    Time 0.048450    
2024-06-06 03:10:25,884 - --- validate (epoch=196)-----------
2024-06-06 03:10:25,884 - 34633 samples (256 per mini-batch)
2024-06-06 03:10:31,547 - Epoch: [196][  100/  136]    Loss 0.311092    Top1 86.425781    Top5 97.976562    
2024-06-06 03:10:33,266 - Epoch: [196][  136/  136]    Loss 0.308338    Top1 86.382930    Top5 97.990356    
2024-06-06 03:10:33,458 - ==> Top1: 86.383    Top5: 97.990    Loss: 0.308

2024-06-06 03:10:33,459 - ==> Confusion:
[[  824     1     6     0    10     0     0     1    10    49     0     2     3     3     6     0     2     1     1     3     9]
 [    4   960     2     3    11    23     1     9     5     3     5     2     2     0     3     0     6     0    13     4     7]
 [    6     1   888    13     5     3    11     9     1     3     2     2     3     2     4     3     2     0     0     5     7]
 [    4     2     6   928     3     5     1     1     1     3    12     1     7     2    15     2     2     4     6     2     9]
 [   22    11     0     2   965     7     3     1     1     3     2     3     0     4     9     3     4     1     3     1     9]
 [    5    17     4     2    12   919     1    24     2     3     1     9     5    11     3     1     5     2     5     8     4]
 [    3     4    14     2     1     3  1014     6     0     3     1     2     0     2     1     9     5     3     1     5     7]
 [    7     7    10     2     1    19     6   963     5     2     2     9     4     5     1     0     0     1    19    11     3]
 [    6     3     0     1     0     2     0     3   884    44    12     1     4    10    18     1     3     2     2     2     4]
 [   43     0     5     0     9     2     1     2    41   870     2     2     1    12     2     0     0     2     2     1     4]
 [    2     2     7    15     1     5     4     3     6     1   984     1     4     3    11     2     0     1     5     1     6]
 [    2     1     2     1     2    12     1     3     0     3     1   914    21     7     0    10     2    10     4    14     1]
 [    1     1     1     4     2     5     0     1     1     2     1    60   864     7     2     3     4    14     2     5    15]
 [    1     0     3     1     5    12     0     2     8    17     4     8     2   911     2     2     7     1     1     6     8]
 [    6     1     4    11     8     2     1     0    19     7     4     4     2     1  1008     0     1     2     7     0    10]
 [    3     1     3     0     4     4     4     0     0     3     0     9     8     4     1   997     8     9     2     4     2]
 [    1     7     4     1     6     2     0     2     4     3     1     4     1     4     2     5  1010     3     0     2    10]
 [    1     4     0     0     0     1     0     1     1     7     0    15    22     1     1     7     2   937     0     2     3]
 [    4     4     5    14     3     1     0    18     5     1     3     2     2     2    10     0     1     0   969     6     8]
 [    0     3     3     1     3     9     5     4     0     0     0    12     5     3     1     5     6     4     4  1008    12]
 [  142   137   186   104   160   153    73   120    79    94   117   124   270   206   157   101   154    83   149   223 11100]]

2024-06-06 03:10:33,461 - ==> Best [Top1: 86.389   Top5: 98.031   Sparsity:0.00   Params: 424448 on epoch: 194]
2024-06-06 03:10:33,461 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 03:10:33,483 - 

2024-06-06 03:10:33,484 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 03:10:39,681 - Epoch: [197][  100/ 1218]    Overall Loss 0.245121    Objective Loss 0.245121                                        LR 0.000031    Time 0.061950    
2024-06-06 03:10:44,491 - Epoch: [197][  200/ 1218]    Overall Loss 0.244397    Objective Loss 0.244397                                        LR 0.000031    Time 0.055016    
2024-06-06 03:10:49,251 - Epoch: [197][  300/ 1218]    Overall Loss 0.247380    Objective Loss 0.247380                                        LR 0.000031    Time 0.052536    
2024-06-06 03:10:53,839 - Epoch: [197][  400/ 1218]    Overall Loss 0.250173    Objective Loss 0.250173                                        LR 0.000031    Time 0.050868    
2024-06-06 03:10:58,404 - Epoch: [197][  500/ 1218]    Overall Loss 0.249875    Objective Loss 0.249875                                        LR 0.000031    Time 0.049820    
2024-06-06 03:11:03,053 - Epoch: [197][  600/ 1218]    Overall Loss 0.251081    Objective Loss 0.251081                                        LR 0.000031    Time 0.049263    
2024-06-06 03:11:07,881 - Epoch: [197][  700/ 1218]    Overall Loss 0.250624    Objective Loss 0.250624                                        LR 0.000031    Time 0.049119    
2024-06-06 03:11:12,544 - Epoch: [197][  800/ 1218]    Overall Loss 0.251522    Objective Loss 0.251522                                        LR 0.000031    Time 0.048806    
2024-06-06 03:11:17,097 - Epoch: [197][  900/ 1218]    Overall Loss 0.253267    Objective Loss 0.253267                                        LR 0.000031    Time 0.048440    
2024-06-06 03:11:21,657 - Epoch: [197][ 1000/ 1218]    Overall Loss 0.253716    Objective Loss 0.253716                                        LR 0.000031    Time 0.048154    
2024-06-06 03:11:26,262 - Epoch: [197][ 1100/ 1218]    Overall Loss 0.253836    Objective Loss 0.253836                                        LR 0.000031    Time 0.047961    
2024-06-06 03:11:30,841 - Epoch: [197][ 1200/ 1218]    Overall Loss 0.254482    Objective Loss 0.254482                                        LR 0.000031    Time 0.047779    
2024-06-06 03:11:31,693 - Epoch: [197][ 1218/ 1218]    Overall Loss 0.254624    Objective Loss 0.254624    Top1 85.330073    Top5 96.088020    LR 0.000031    Time 0.047772    
2024-06-06 03:11:31,856 - --- validate (epoch=197)-----------
2024-06-06 03:11:31,857 - 34633 samples (256 per mini-batch)
2024-06-06 03:11:37,573 - Epoch: [197][  100/  136]    Loss 0.307846    Top1 85.980469    Top5 97.859375    
2024-06-06 03:11:39,234 - Epoch: [197][  136/  136]    Loss 0.301832    Top1 85.961366    Top5 97.877747    
2024-06-06 03:11:39,417 - ==> Top1: 85.961    Top5: 97.878    Loss: 0.302

2024-06-06 03:11:39,418 - ==> Confusion:
[[  829     1     1     0    12     1     1     1     7    54     1     1     0     2     3     1     5     0     2     2     7]
 [    2   984     2     4    17     6     1     6     2     2     2     0     4     1     7     0     7     1     9     0     6]
 [    3     5   895     8     2     1    12     4     1     5     5     2     2     3     5     1     7     0     3     2     4]
 [    3     3     9   932     1     3     0     1     0     2     5     0     9     6    28     3     2     2     2     0     5]
 [   11     7     3     0   979     3     2     0     1    13     3     1     3     5    13     1     5     0     0     1     3]
 [    5    26     2     0    11   888     3    24     2     5     5    10     8    22     3     1     6     2     2     8    10]
 [    0     1    19     0     4     1  1018     5     0     3     5     3     0     0     1     7     0     1     1     5    12]
 [    2    14    15     1     2    23     4   941     3     5     6     7     5     6     0     0     1     3    20    12     7]
 [    5     0     1     0     0     1     2     1   892    43     9     2     3    13    13     1     4     0     6     2     4]
 [   55     2     1     0     4     0     0     0    43   865     1     1     0    15     5     1     1     1     1     0     5]
 [    0     3     5     9     0     0     4     5    13     2   998     1     0     5     8     0     1     0     8     1     1]
 [    2     2     5     0     0    10     0     2     1     3     3   906    34     5     0    10     1    10     0    11     6]
 [    2     0     3     3     2     0     2     1     1     4     1    39   878     4     1     6     8    25     1     7     7]
 [    0     2     1     0     6    10     0     2     8    16     3     7     4   912     6     2     3     0     1     8    10]
 [    4     2     5    10     4     1     0     0    22     5     3     2     2     6  1019     0     0     0     4     1     8]
 [    3     0     3     1     2     1     3     1     0     4     2     6     8     2     0  1008     8     8     2     4     0]
 [    2     9     2     0     9     3     1     1     5     3     3     5     1     1     2     5  1000     0     0     6    14]
 [    1     3     1     4     0     0     1     0     2     2     0    13    18     2     4     8     4   935     0     4     3]
 [    1     7     5     6     4     3     0    14     5     4     4     1     0     1    13     0     1     2   978     2     7]
 [    4     6     3     1     0     5     8     4     0     3     1    10     6     3     0     7     7     3     2  1011     4]
 [  144   194   214    82   148   135    68   111   104   131   159   107   292   221   185   102   221    82   133   196 10903]]

2024-06-06 03:11:39,420 - ==> Best [Top1: 86.389   Top5: 98.031   Sparsity:0.00   Params: 424448 on epoch: 194]
2024-06-06 03:11:39,420 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 03:11:39,442 - 

2024-06-06 03:11:39,442 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 03:11:45,672 - Epoch: [198][  100/ 1218]    Overall Loss 0.260603    Objective Loss 0.260603                                        LR 0.000031    Time 0.062268    
2024-06-06 03:11:50,507 - Epoch: [198][  200/ 1218]    Overall Loss 0.260833    Objective Loss 0.260833                                        LR 0.000031    Time 0.055299    
2024-06-06 03:11:55,156 - Epoch: [198][  300/ 1218]    Overall Loss 0.257095    Objective Loss 0.257095                                        LR 0.000031    Time 0.052358    
2024-06-06 03:11:59,731 - Epoch: [198][  400/ 1218]    Overall Loss 0.257648    Objective Loss 0.257648                                        LR 0.000031    Time 0.050702    
2024-06-06 03:12:04,296 - Epoch: [198][  500/ 1218]    Overall Loss 0.256606    Objective Loss 0.256606                                        LR 0.000031    Time 0.049687    
2024-06-06 03:12:08,871 - Epoch: [198][  600/ 1218]    Overall Loss 0.256792    Objective Loss 0.256792                                        LR 0.000031    Time 0.049028    
2024-06-06 03:12:13,512 - Epoch: [198][  700/ 1218]    Overall Loss 0.256388    Objective Loss 0.256388                                        LR 0.000031    Time 0.048652    
2024-06-06 03:12:18,329 - Epoch: [198][  800/ 1218]    Overall Loss 0.255224    Objective Loss 0.255224                                        LR 0.000031    Time 0.048589    
2024-06-06 03:12:23,061 - Epoch: [198][  900/ 1218]    Overall Loss 0.254699    Objective Loss 0.254699                                        LR 0.000031    Time 0.048446    
2024-06-06 03:12:27,659 - Epoch: [198][ 1000/ 1218]    Overall Loss 0.254024    Objective Loss 0.254024                                        LR 0.000031    Time 0.048196    
2024-06-06 03:12:32,330 - Epoch: [198][ 1100/ 1218]    Overall Loss 0.254427    Objective Loss 0.254427                                        LR 0.000031    Time 0.048060    
2024-06-06 03:12:37,084 - Epoch: [198][ 1200/ 1218]    Overall Loss 0.254004    Objective Loss 0.254004                                        LR 0.000031    Time 0.048014    
2024-06-06 03:12:37,891 - Epoch: [198][ 1218/ 1218]    Overall Loss 0.254248    Objective Loss 0.254248    Top1 88.508557    Top5 97.555012    LR 0.000031    Time 0.047967    
2024-06-06 03:12:38,054 - --- validate (epoch=198)-----------
2024-06-06 03:12:38,054 - 34633 samples (256 per mini-batch)
2024-06-06 03:12:43,648 - Epoch: [198][  100/  136]    Loss 0.288762    Top1 86.792969    Top5 98.105469    
2024-06-06 03:12:45,352 - Epoch: [198][  136/  136]    Loss 0.297209    Top1 86.703433    Top5 98.108740    
2024-06-06 03:12:45,537 - ==> Top1: 86.703    Top5: 98.109    Loss: 0.297

2024-06-06 03:12:45,539 - ==> Confusion:
[[  845     2     1     1     6     1     0     2    13    41     0     1     1     1     2     2     1     1     1     0     9]
 [    4   969     1     2    13    22     4    13     4     4     0     1     3     0     2     0     1     1     8     4     7]
 [    6     1   895     6     2     1    14     7     0     8     3     1     2     2     2     2     4     1     2    10     1]
 [    6     0     7   935     1     1     3     3     2     5     9     1     4     1    14     1     0     6     6     4     7]
 [   14     9     2     2   971    13     0     0     2    10     2     0     4     3     4     0     3     1     1     3    10]
 [    4    14     2     2     4   924     1    31     4     3     4     7     9    18     3     1     4     3     1     1     3]
 [    1     2    10     3     2     2  1025     5     2     3     2     3     0     0     0     4     3     4     3     3     9]
 [    4     9     9     3     2    19     3   973     2     5     7     5     0     2     1     1     1     1    20     9     1]
 [    9     1     0     1     0     1     0     3   898    39    12     5     0     9    10     1     1     1    10     0     1]
 [   67     0     1     2     2     1     0     0    37   865     0     2     4    10     4     1     1     2     0     1     1]
 [    0     1     4    11     2     0     3     8    16     0   993     0     2     3     4     0     0     0     8     2     7]
 [    1     0     1     0     1    10     1     5     0     4     0   912    25     5     2     8     2    16     0    11     7]
 [    1     2     3     2     0     2     0     4     3     2     0    46   873     3     0     6     1    30     3     6     8]
 [    2     0     3     2     2    11     1     4     8    18    10    16     3   892     3     3     2     3     0     8    10]
 [    9     3     0    11     5     0     1     0    23    12     6     1     4     2   992     1     3     2    13     0    10]
 [    1     2     0     1     3     0     7     1     1     4     0     8     6     1     1  1011     5     9     2     0     3]
 [    3     9     3     1     4     6     2     1     2     2     1     4     3     2     1     5  1001     2     0     5    15]
 [    2     1     0     1     1     1     2     2     0     1     0     9    22     1     0     7     1   947     2     3     2]
 [    1     6     5     9     2     2     1    19     7     3     5     2     2     1     8     0     1     3   972     0     9]
 [    2     1     2     1     0     4     7     9     0     1     0    20     6     5     0     4     1     3     3  1012     7]
 [  131   156   140    96   134   181    87   163   116   133   129   139   230   177   141    85   135   109   113   214 11123]]

2024-06-06 03:12:45,541 - ==> Best [Top1: 86.703   Top5: 98.109   Sparsity:0.00   Params: 424448 on epoch: 198]
2024-06-06 03:12:45,541 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 03:12:45,568 - 

2024-06-06 03:12:45,568 - Training epoch: 311705 samples (256 per mini-batch)
2024-06-06 03:12:51,690 - Epoch: [199][  100/ 1218]    Overall Loss 0.260393    Objective Loss 0.260393                                        LR 0.000031    Time 0.061194    
2024-06-06 03:12:56,492 - Epoch: [199][  200/ 1218]    Overall Loss 0.254186    Objective Loss 0.254186                                        LR 0.000031    Time 0.054598    
2024-06-06 03:13:01,133 - Epoch: [199][  300/ 1218]    Overall Loss 0.253917    Objective Loss 0.253917                                        LR 0.000031    Time 0.051863    
2024-06-06 03:13:05,990 - Epoch: [199][  400/ 1218]    Overall Loss 0.254762    Objective Loss 0.254762                                        LR 0.000031    Time 0.051035    
2024-06-06 03:13:10,812 - Epoch: [199][  500/ 1218]    Overall Loss 0.255548    Objective Loss 0.255548                                        LR 0.000031    Time 0.050468    
2024-06-06 03:13:15,588 - Epoch: [199][  600/ 1218]    Overall Loss 0.254794    Objective Loss 0.254794                                        LR 0.000031    Time 0.050013    
2024-06-06 03:13:20,250 - Epoch: [199][  700/ 1218]    Overall Loss 0.253305    Objective Loss 0.253305                                        LR 0.000031    Time 0.049526    
2024-06-06 03:13:24,873 - Epoch: [199][  800/ 1218]    Overall Loss 0.254383    Objective Loss 0.254383                                        LR 0.000031    Time 0.049112    
2024-06-06 03:13:29,627 - Epoch: [199][  900/ 1218]    Overall Loss 0.254574    Objective Loss 0.254574                                        LR 0.000031    Time 0.048935    
2024-06-06 03:13:34,431 - Epoch: [199][ 1000/ 1218]    Overall Loss 0.254379    Objective Loss 0.254379                                        LR 0.000031    Time 0.048844    
2024-06-06 03:13:39,091 - Epoch: [199][ 1100/ 1218]    Overall Loss 0.254246    Objective Loss 0.254246                                        LR 0.000031    Time 0.048638    
2024-06-06 03:13:43,662 - Epoch: [199][ 1200/ 1218]    Overall Loss 0.253470    Objective Loss 0.253470                                        LR 0.000031    Time 0.048392    
2024-06-06 03:13:44,541 - Epoch: [199][ 1218/ 1218]    Overall Loss 0.253612    Objective Loss 0.253612    Top1 85.819071    Top5 97.799511    LR 0.000031    Time 0.048399    
2024-06-06 03:13:44,732 - --- validate (epoch=199)-----------
2024-06-06 03:13:44,733 - 34633 samples (256 per mini-batch)
2024-06-06 03:13:50,515 - Epoch: [199][  100/  136]    Loss 0.300384    Top1 86.578125    Top5 98.003906    
2024-06-06 03:13:52,312 - Epoch: [199][  136/  136]    Loss 0.304016    Top1 86.498426    Top5 98.048104    
2024-06-06 03:13:52,530 - ==> Top1: 86.498    Top5: 98.048    Loss: 0.304

2024-06-06 03:13:52,532 - ==> Confusion:
[[  828     1     5     1    10     2     0     3     5    55     1     2     0     3     8     0     1     0     0     0     6]
 [    4   971     3     0    14    12     2    10     1     4     4     1     2     1     2     0     5     1    13     4     9]
 [    4     2   896     5     2     3    19     1     0     1     4     3     3     5     3     2     3     1     2     1    10]
 [   10     1    12   913     1     5     3     0     1     0    12     0     6     2    23     2     3     1    13     0     8]
 [   15     8     3     1   972     6     4     1     0    16     2     1     1     3     8     2     3     0     2     2     4]
 [    7    21     1     1     4   915     3    28     3     2     2    13     6    10     1     1     3     1     2    10     9]
 [    2     3    12     1     2     1  1022     3     0     2     6     2     0     0     1     8     3     1     0     9     8]
 [    1     9    12     3     3    20     5   955     2     2     5    11     8     1     3     1     1     0    21    11     3]
 [    8     4     1     1     1     4     0     2   861    54    12     3     5    13    17     0     5     1     6     0     4]
 [   58     0     0     0     5     2     1     0    30   863     1     2     1    17     9     1     2     1     1     2     5]
 [    0     5     6     7     0     1     5     4     8     2   998     2     2     3     7     0     1     0     7     1     5]
 [    2     3     2     0     2     5     1     3     3     1     0   914    27     5     1    10     3    14     0    11     4]
 [    0     0     3     3     3     1     2     2     0     2     2    40   889     5     2     2     0    21     2     3    13]
 [    5     0     0     1     5    12     0     1    13    10    10     9     5   894     5     2     6     2     0     8    13]
 [    5     3     2    16    11     1     0     1    20     5     4     2     3     4   999     0     1     1     8     0    12]
 [    4     2     5     0     1     1     5     1     1     3     1    10     8     2     1  1005     5     6     1     1     3]
 [    2     5     3     2     6     5     1     1     3     2     2     4     1     3     2     5  1014     2     0     1     8]
 [    0     0     1     1     3     3     1     1     0     1     2    10    21     2     1     9     1   943     0     0     5]
 [    4     6     6     8     3     0     0    15     4     0     3     0     4     1    10     0     1     1   982     3     7]
 [    2     1     2     0     0     4     8     7     0     0     1     8     8     4     0     5     4     3     6  1015    10]
 [  163   152   177    88   168   141    66   114    65   108   125   102   265   222   154    93   192    79   129   221 11108]]

2024-06-06 03:13:52,534 - ==> Best [Top1: 86.703   Top5: 98.109   Sparsity:0.00   Params: 424448 on epoch: 198]
2024-06-06 03:13:52,534 - Saving checkpoint to: logs/nas_original/2024.06.05-230322/qat_checkpoint.pth.tar
2024-06-06 03:13:52,556 - --- test ---------------------
2024-06-06 03:13:52,556 - 11005 samples (256 per mini-batch)
2024-06-06 03:13:54,273 - Test: [   43/   43]    Loss 0.172691    Top1 92.694230    Top5 99.318492    
2024-06-06 03:13:54,461 - ==> Top1: 92.694    Top5: 99.318    Loss: 0.173

2024-06-06 03:13:54,462 - ==> Confusion:
[[ 399    0    0    1    4    0    0    0    0   16    0    1    0    0    0    1    0    2    0    0    1]
 [   1  368    2    0    4   10    1    9    3    0    1    0    0    0    1    1    0    0    1    0    4]
 [   0    1  403    0    0    0    4    0    0    0    0    0    1    1    0    0    0    0    1    0    1]
 [   0    0    8  372    1    0    0    0    0    1    0    1    5    0    4    0    0    0    1    1    2]
 [   0    0    0    0  405    1    0    0    0    0    2    0    1    0    0    0    2    0    0    0    0]
 [   2    5    1    0    0  380    1    7    0    1    0    1    0    0    0    0    0    0    1    1    2]
 [   0    0    0    0    0    4  409    1    0    0    0    0    0    0    0    1    0    0    0    0    4]
 [   2    4    7    0    0    1    0  380    0    1    0    0    0    0    0    0    0    0    2    4    4]
 [   2    0    0    0    0    0    0    0  370   15    5    1    0    0    2    0    0    0    1    0    0]
 [  38    0    0    0    2    2    0    0    6  352    0    0    0    2    0    0    0    0    0    0    0]
 [   1    1    4    1    0    0    0    0    6    0  375    0    0    1    2    0    0    0    2    0    6]
 [   2    0    0    0    2    4    2    0    0    0    0  400    5    2    0    1    0    1    0    2    3]
 [   0    0    0    0    0    0    0    0    0    0    0    5  388    0    0    3    1    2    0    0    6]
 [   1    1    0    0    1    4    0    0    2    3    0    3    2  379    1    0    0    0    0    0    3]
 [   0    0    0    2    0    0    0    0    1    1    0    0    1    1  434    0    0    1    0    0    4]
 [   0    0    1    0    0    0    1    0    1    0    0    1    1    0    0  388    1    0    0    0    0]
 [   0    1    0    1    2    0    0    0    0    0    0    0    1    0    0    4  396    0    0    1    0]
 [   1    0    1    1    0    0    0    0    0    0    0    2    1    0    0    0    0  400    0    2    0]
 [   1    1    2    3    0    0    0    7    0    0    1    0    0    0    2    0    0    0  388    0    3]
 [   0    1    0    0    0    1    0    1    0    0    0    6    1    0    0    0    3    1    0  400    4]
 [   9   20   48   13   17   22    4   21   10    6   17    9   55   60   16   13   17   18    8   26 2415]]

2024-06-06 03:13:54,664 - 
2024-06-06 03:13:54,665 - Log file for this run: /home/merveeyuboglu/Github/ai8x-training-merve/ai8x-training/logs/nas_original/2024.06.05-230322/2024.06.05-230322.log
